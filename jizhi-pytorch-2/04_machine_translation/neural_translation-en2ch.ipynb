{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器翻译的神经网络实现\n",
    "\n",
    "本节课我们讲述了利用编码器－解码器架构实现汉－英机器翻译。\n",
    "\n",
    "整个代码包括了数据预处理、编码器＋简单解码器以及编码器＋带有注意力机制的解码器三个部分组成。\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第VIII课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 用到的包\n",
    "#from __future__ import unicode_literals, print_function, division\n",
    "# 进行系统操作，如io、正则表达式的包\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "#import time\n",
    "#import math\n",
    "\n",
    "#Pytorch必备的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as DataSet\n",
    "\n",
    "\n",
    "# 绘图所用的包\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 判断本机是否有支持的GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# 即时绘图\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、数据准备\n",
    "\n",
    "从硬盘读取语料文件，进行基本的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# 读取平行语料库\n",
    "# 这是人民日报语料库\n",
    "lines = open('data/chinese.txt', encoding = 'utf-8')\n",
    "chinese = lines.read().strip().split('\\n')\n",
    "lines = open('data/english.txt', encoding = 'utf-8')\n",
    "english = lines.read().strip().split('\\n')\n",
    "print(len(chinese))\n",
    "print(len(english))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义两个特殊符号，分别对应句子头和句子尾\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "# 定义一个语言类，方便进行自动的建立、词频的统计等\n",
    "# 在这个对象中，最重要的是两个字典：word2index，index2word\n",
    "# 故名思议，第一个字典是将word映射到索引，第二个是将索引映射到word\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        # 在语言中添加一个新句子，句子是用空格隔开的一组单词\n",
    "        # 将单词切分出来，并分别进行处理\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        # 插入一个单词，如果单词已经在字典中，则更新字典中对应单词的频率\n",
    "        # 同时建立反向索引，可以从单词编号找到单词\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "# 将unicode编码转变为ascii编码\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 把输入的英文字符串转成小写\n",
    "def normalizeEngString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "# 对输入的单词对做过滤，保证每句话的单词数不能超过MAX_LENGTH\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# 输入一个句子，输出一个单词对应的编码序列\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "# 和上面的函数功能类似，不同在于输出的序列等长＝MAX_LENGTH\n",
    "def indexFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    for i in range(MAX_LENGTH - len(indexes)):\n",
    "        indexes.append(EOS_token)\n",
    "    return(indexes)\n",
    "\n",
    "# 从一个词对到下标\n",
    "def indexFromPair(pair):\n",
    "    input_variable = indexFromSentence(input_lang, pair[0])\n",
    "    target_variable = indexFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "# 从一个列表到句子\n",
    "def SentenceFromList(lang, lst):\n",
    "    result = [lang.index2word[i] for i in lst if i != EOS_token]\n",
    "    if lang.name == 'Chinese':\n",
    "        result = ' '.join(result)\n",
    "    else:\n",
    "        result = ' '.join(result)\n",
    "    return(result)\n",
    "\n",
    "# 计算准确度的函数\n",
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行num_classes列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效句子对： 19919\n",
      "总单词数:\n",
      "English 13493\n",
      "Chinese 18671\n",
      "训练记录： 17928\n",
      "校验记录： 995\n",
      "测试记录： 996\n"
     ]
    }
   ],
   "source": [
    "# 处理数据形成训练数据\n",
    "# 设置句子的最大长度\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "#对英文做标准化处理\n",
    "pairs = [[normalizeEngString(eng), chi] for chi, eng in zip(chinese, english)]\n",
    "\n",
    "# 对句子对做过滤，处理掉那些超过MAX_LENGTH长度的句子\n",
    "input_lang = Lang('English')\n",
    "output_lang = Lang('Chinese')\n",
    "pairs = [pair for pair in pairs if filterPair(pair)]\n",
    "print('有效句子对：', len(pairs))\n",
    "\n",
    "# 建立两个字典（中文的和英文的）\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(\"总单词数:\")\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "\n",
    "# 形成训练集，首先，打乱所有句子的顺序\n",
    "random_idx = np.random.permutation(range(len(pairs)))\n",
    "pairs = [pairs[i] for i in random_idx]\n",
    "\n",
    "# 将语言转变为单词的编码构成的序列\n",
    "pairs = [indexFromPair(pair) for pair in pairs]\n",
    "    \n",
    "# 形成训练集、校验集和测试集\n",
    "valid_size = len(pairs) // 10\n",
    "if valid_size > 10000:\n",
    "    valid_size = 10000\n",
    "pairs = pairs[ : - valid_size]\n",
    "valid_pairs = pairs[-valid_size : -valid_size // 2]\n",
    "test_pairs = pairs[- valid_size // 2 :]\n",
    "\n",
    "# 利用PyTorch的dataset和dataloader对象，将数据加载到加载器里面，并且自动分批\n",
    "\n",
    "batch_size = 1024 #一撮包含30个数据记录，这个数字越大，系统在训练的时候，每一个周期处理的数据就越多，这样处理越快，但总的数据量会减少\n",
    "\n",
    "print('训练记录：', len(pairs))\n",
    "print('校验记录：', len(valid_pairs))\n",
    "print('测试记录：', len(test_pairs))\n",
    "\n",
    "# 形成训练对列表，用于喂给train_dataset\n",
    "pairs_X = [pair[0] for pair in pairs]\n",
    "pairs_Y = [pair[1] for pair in pairs]\n",
    "valid_X = [pair[0] for pair in valid_pairs]\n",
    "valid_Y = [pair[1] for pair in valid_pairs]\n",
    "test_X = [pair[0] for pair in test_pairs]\n",
    "test_Y = [pair[1] for pair in test_pairs]\n",
    "\n",
    "\n",
    "# 形成训练集\n",
    "train_dataset = DataSet.TensorDataset(torch.LongTensor(pairs_X), torch.LongTensor(pairs_Y))\n",
    "# 形成数据加载器\n",
    "train_loader = DataSet.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "\n",
    "# 校验数据\n",
    "valid_dataset = DataSet.TensorDataset(torch.LongTensor(valid_X), torch.LongTensor(valid_Y))\n",
    "valid_loader = DataSet.DataLoader(valid_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "# 测试数据\n",
    "test_dataset = DataSet.TensorDataset(torch.LongTensor(test_X), torch.LongTensor(test_Y))\n",
    "test_loader = DataSet.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, num_workers = 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、构建编码器及简单的解码器RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构建编码器RNN\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # 第一层Embeddeing\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # 第二层GRU，注意GRU中可以定义很多层，主要靠num_layers控制\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True, \n",
    "                          num_layers = self.n_layers, bidirectional = True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #前馈过程\n",
    "        #input尺寸： batch_size, length_seq\n",
    "        embedded = self.embedding(input)\n",
    "        #embedded尺寸：batch_size, length_seq, hidden_size\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output尺寸：batch_size, length_seq, hidden_size\n",
    "        # hidden尺寸：num_layers * directions, batch_size, hidden_size\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 对隐含单元变量全部进行初始化\n",
    "        #num_layers * num_directions, batch, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "# 解码器网络\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # GRU单元\n",
    "        # 设置batch_first为True的作用就是为了让GRU接受的张量可以和其它单元类似，第一个维度为batch_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True,\n",
    "                        num_layers = self.n_layers, bidirectional = True)\n",
    "        # 最后的全链接层\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input大小：batch_size, length_seq\n",
    "        output = self.embedding(input)\n",
    "        # embedded大小：batch_size, length_seq, hidden_size\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output大小：batch_size, length_seq, hidden_size * directions\n",
    "        # hidden大小：n_layers * directions, batch_size, hidden_size\n",
    "        output = self.softmax(self.out(output[:, -1, :]))\n",
    "        # output大小：batch_size * output_size\n",
    "        # 从output中取时间步重新开始\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 初始化隐含单元的状态，输入变量的尺寸：num_layers * directions, batch_size, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进程：0% 训练损失：109.9733，校验损失：92.9247，词正确率：41.17%\n",
      "进程：1% 训练损失：87.8239，校验损失：87.3932，词正确率：42.02%\n",
      "进程：2% 训练损失：83.8612，校验损失：83.7487，词正确率：42.87%\n",
      "进程：3% 训练损失：80.1325，校验损失：79.9911，词正确率：43.30%\n",
      "进程：4% 训练损失：75.8655，校验损失：76.6219，词正确率：43.80%\n",
      "进程：5% 训练损失：71.7143，校验损失：74.5334，词正确率：44.13%\n",
      "进程：6% 训练损失：70.2667，校验损失：69.2976，词正确率：44.70%\n",
      "进程：7% 训练损失：66.1796，校验损失：66.0941，词正确率：45.48%\n",
      "进程：8% 训练损失：62.3394，校验损失：62.4132，词正确率：46.03%\n",
      "进程：9% 训练损失：58.8069，校验损失：59.8183，词正确率：46.85%\n",
      "进程：10% 训练损失：56.3496，校验损失：59.4263，词正确率：46.47%\n",
      "进程：11% 训练损失：54.3407，校验损失：57.1895，词正确率：45.73%\n",
      "进程：12% 训练损失：49.8752，校验损失：53.4917，词正确率：48.78%\n",
      "进程：13% 训练损失：48.7215，校验损失：49.8750，词正确率：49.44%\n",
      "进程：14% 训练损失：44.2087，校验损失：47.5318，词正确率：50.91%\n",
      "进程：15% 训练损失：43.6451，校验损失：44.8748，词正确率：51.74%\n",
      "进程：16% 训练损失：40.9163，校验损失：42.7357，词正确率：52.91%\n",
      "进程：17% 训练损失：39.4894，校验损失：41.1448，词正确率：53.88%\n",
      "进程：18% 训练损失：35.8536，校验损失：40.9991，词正确率：53.54%\n",
      "进程：19% 训练损失：35.1695，校验损失：40.8788，词正确率：53.12%\n",
      "进程：20% 训练损失：29.9313，校验损失：39.0692，词正确率：55.01%\n",
      "进程：21% 训练损失：34.6380，校验损失：35.0035，词正确率：57.53%\n",
      "进程：22% 训练损失：30.6411，校验损失：33.3453，词正确率：58.25%\n",
      "进程：23% 训练损失：28.9975，校验损失：33.8572，词正确率：57.74%\n",
      "进程：24% 训练损失：28.7352，校验损失：30.6883，词正确率：60.91%\n",
      "进程：25% 训练损失：25.1459，校验损失：30.8286，词正确率：61.04%\n",
      "进程：26% 训练损失：25.4422，校验损失：28.2195，词正确率：63.95%\n",
      "进程：27% 训练损失：25.2868，校验损失：26.8499，词正确率：65.10%\n",
      "进程：28% 训练损失：22.6872，校验损失：25.4940，词正确率：66.30%\n",
      "进程：28% 训练损失：21.9534，校验损失：24.3684，词正确率：67.64%\n",
      "进程：30% 训练损失：20.6166，校验损失：24.5506，词正确率：67.43%\n",
      "进程：31% 训练损失：20.3859，校验损失：22.2673，词正确率：70.71%\n",
      "进程：32% 训练损失：19.3241，校验损失：20.7919，词正确率：72.35%\n",
      "进程：33% 训练损失：18.4089，校验损失：19.9725，词正确率：73.11%\n",
      "进程：34% 训练损失：16.5613，校验损失：19.2713，词正确率：74.05%\n",
      "进程：35% 训练损失：16.6961，校验损失：17.8819，词正确率：76.64%\n",
      "进程：36% 训练损失：13.5601，校验损失：17.4919，词正确率：77.29%\n",
      "进程：37% 训练损失：13.0188，校验损失：16.3079，词正确率：79.64%\n",
      "进程：38% 训练损失：13.8475，校验损失：15.3929，词正确率：80.25%\n",
      "进程：39% 训练损失：12.9926，校验损失：14.4679，词正确率：81.19%\n",
      "进程：40% 训练损失：10.8313，校验损失：13.4967，词正确率：83.40%\n",
      "进程：41% 训练损失：10.9589，校验损失：12.6593，词正确率：84.78%\n",
      "进程：42% 训练损失：10.4597，校验损失：11.2758，词正确率：86.57%\n",
      "进程：43% 训练损失：7.7984，校验损失：11.1251，词正确率：86.94%\n",
      "进程：44% 训练损失：8.2984，校验损失：9.5720，词正确率：89.11%\n",
      "进程：45% 训练损失：7.0131，校验损失：8.0899，词正确率：91.76%\n",
      "进程：46% 训练损失：6.6116，校验损失：7.2747，词正确率：92.79%\n",
      "进程：47% 训练损失：5.9018，校验损失：6.7912，词正确率：93.70%\n",
      "进程：48% 训练损失：5.5871，校验损失：6.2620，词正确率：94.35%\n",
      "进程：49% 训练损失：4.4288，校验损失：5.7701，词正确率：94.80%\n",
      "进程：50% 训练损失：4.6398，校验损失：4.7925，词正确率：96.33%\n",
      "进程：51% 训练损失：4.0038，校验损失：4.0295，词正确率：97.42%\n",
      "进程：52% 训练损失：3.3316，校验损失：3.6054，词正确率：97.73%\n",
      "进程：53% 训练损失：3.2009，校验损失：3.2548，词正确率：98.11%\n",
      "进程：54% 训练损失：2.7510，校验损失：2.8545，词正确率：98.48%\n",
      "进程：55% 训练损失：2.5064，校验损失：2.5360，词正确率：98.82%\n",
      "进程：56% 训练损失：2.1529，校验损失：2.2399，词正确率：99.08%\n",
      "进程：56% 训练损失：1.8295，校验损失：1.9691，词正确率：99.33%\n",
      "进程：57% 训练损失：1.8098，校验损失：1.8042，词正确率：99.39%\n",
      "进程：59% 训练损失：1.5742，校验损失：1.5520，词正确率：99.60%\n",
      "进程：60% 训练损失：1.4404，校验损失：1.4918，词正确率：99.58%\n",
      "进程：61% 训练损失：1.3609，校验损失：1.3185，词正确率：99.68%\n",
      "进程：62% 训练损失：1.2226，校验损失：1.2292，词正确率：99.69%\n",
      "进程：63% 训练损失：1.0967，校验损失：1.0601，词正确率：99.85%\n",
      "进程：64% 训练损失：1.0242，校验损失：1.0493，词正确率：99.79%\n",
      "进程：65% 训练损失：0.9239，校验损失：0.9991，词正确率：99.78%\n",
      "进程：66% 训练损失：0.8992，校验损失：0.9052，词正确率：99.84%\n",
      "进程：67% 训练损失：0.8174，校验损失：0.8423，词正确率：99.87%\n",
      "进程：68% 训练损失：0.7659，校验损失：0.7535，词正确率：99.92%\n",
      "进程：69% 训练损失：0.7232，校验损失：0.7276，词正确率：99.93%\n",
      "进程：70% 训练损失：0.6898，校验损失：0.6796，词正确率：99.92%\n",
      "进程：71% 训练损失：0.6575，校验损失：0.6689，词正确率：99.91%\n",
      "进程：72% 训练损失：0.6216，校验损失：0.6343，词正确率：99.88%\n",
      "进程：73% 训练损失：0.5839，校验损失：0.5954，词正确率：99.92%\n",
      "进程：74% 训练损失：0.5610，校验损失：0.6170，词正确率：99.87%\n",
      "进程：75% 训练损失：0.5312，校验损失：0.5037，词正确率：99.98%\n",
      "进程：76% 训练损失：0.5049，校验损失：0.5962，词正确率：99.85%\n",
      "进程：77% 训练损失：0.4809，校验损失：0.5132，词正确率：99.95%\n",
      "进程：78% 训练损失：0.4734，校验损失：0.4857，词正确率：99.93%\n",
      "进程：79% 训练损失：0.4537，校验损失：0.4486，词正确率：99.94%\n",
      "进程：80% 训练损失：0.4347，校验损失：0.4569，词正确率：99.88%\n",
      "进程：81% 训练损失：0.4175，校验损失：0.4086，词正确率：99.95%\n",
      "进程：82% 训练损失：0.3987，校验损失：0.3806，词正确率：99.96%\n",
      "进程：83% 训练损失：0.3839，校验损失：0.3908，词正确率：99.93%\n",
      "进程：84% 训练损失：0.3645，校验损失：0.3480，词正确率：99.98%\n",
      "进程：85% 训练损失：0.3605，校验损失：0.3604，词正确率：99.93%\n",
      "进程：86% 训练损失：0.3399，校验损失：0.3309，词正确率：99.96%\n",
      "进程：87% 训练损失：0.3326，校验损失：0.3214，词正确率：99.95%\n",
      "进程：88% 训练损失：0.3105，校验损失：0.3067，词正确率：99.97%\n",
      "进程：89% 训练损失：0.3063，校验损失：0.2923，词正确率：99.97%\n",
      "进程：90% 训练损失：0.2909，校验损失：0.3389，词正确率：99.91%\n",
      "进程：91% 训练损失：0.2896，校验损失：0.2897，词正确率：99.93%\n",
      "进程：92% 训练损失：0.2824，校验损失：0.2756，词正确率：99.94%\n",
      "进程：93% 训练损失：0.2685，校验损失：0.3117，词正确率：99.92%\n",
      "进程：94% 训练损失：0.2722，校验损失：0.2689，词正确率：99.95%\n",
      "进程：95% 训练损失：0.2575，校验损失：0.2574，词正确率：99.96%\n",
      "进程：96% 训练损失：0.2544，校验损失：0.2400，词正确率：99.97%\n",
      "进程：97% 训练损失：0.2493，校验损失：0.2389，词正确率：99.97%\n",
      "进程：98% 训练损失：0.2419，校验损失：0.2246，词正确率：99.95%\n",
      "进程：99% 训练损失：0.2351，校验损失：0.2233，词正确率：99.96%\n"
     ]
    }
   ],
   "source": [
    "# 开始训练过程\n",
    "# 定义网络结构\n",
    "hidden_size = 512\n",
    "max_length = MAX_LENGTH\n",
    "n_layers = 1\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers = n_layers)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words, n_layers = n_layers)\n",
    "\n",
    "if use_cuda:\n",
    "    # 如果本机有GPU可用，则将模型加载到GPU上\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "learning_rate = 0.001\n",
    "# 为两个网络分别定义优化器\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.NLLLoss()\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "plot_losses = []\n",
    "\n",
    "# 开始200轮的循环\n",
    "num_epoch = 100\n",
    "for epoch in range(num_epoch):\n",
    "    print_loss_total = 0\n",
    "    # 对训练数据循环\n",
    "    for data in train_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "        \n",
    "        # 初始化编码器状态\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "        # 清空梯度\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # 开始编码器的计算，对时间步的循环由系统自动完成\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "        \n",
    "        # 开始解码器的工作\n",
    "        # 输入给解码器的第一个字符\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        # 让解码器的隐藏层状态等于编码器的隐藏层状态\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 以teacher_forcing_ratio的比例用target中的翻译结果作为监督信息\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        base = torch.zeros(target_variable.size()[0])\n",
    "        if use_teacher_forcing:\n",
    "            # 教师监督: 将下一个时间步的监督信息输入给解码器\n",
    "            # 对时间步循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 开始一步解码\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # decoder_ouput大小：batch_size, output_size\n",
    "                # 计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "                # 将训练数据当做下一时间步的输入\n",
    "                decoder_input = target_variable[:, di].unsqueeze(1)  # Teacher forcing\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                \n",
    "        else:\n",
    "            # 没有教师训练: 使用解码器自己的预测作为下一时间步的输入\n",
    "            # 开始对时间步进行循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 进行一步解码\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "                \n",
    "                #从输出结果（概率的对数值）中选择出一个数值最大的单词作为输出放到了topi中\n",
    "                topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "                #topi 尺寸：batch_size, k\n",
    "                ni = topi[:, 0]\n",
    "\n",
    "                # 将输出结果ni包裹成Variable作为解码器的输入\n",
    "                decoder_input = Variable(ni.unsqueeze(1))\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "                #计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "        \n",
    "            \n",
    "        \n",
    "        # 开始反向传播\n",
    "        loss.backward()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 开始梯度下降\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        # 累加总误差\n",
    "        print_loss_total += loss.data.numpy()[0]\n",
    "\n",
    "    # 计算训练时候的平均误差\n",
    "    print_loss_avg = print_loss_total / len(train_loader)\n",
    "        \n",
    "    # 开始跑校验数据集\n",
    "    valid_loss = 0\n",
    "    rights = []\n",
    "    # 对校验数据集循环\n",
    "    for data in valid_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 没有教师监督: 使用解码器自己的预测作为下一时间步解码器的输入\n",
    "        for di in range(MAX_LENGTH):\n",
    "            # 一步解码器运算\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "            \n",
    "            # 选择输出最大的项作为解码器的预测答案\n",
    "            topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "            #topi 尺寸：batch_size, k\n",
    "            ni = topi[:, 0]\n",
    "            decoder_input = Variable(ni.unsqueeze(1))\n",
    "            # decoder_input大小：batch_size, length_seq\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            \n",
    "            # 计算预测的准确率，记录在right中，right为一个二元组，分别存储猜对的个数和总数\n",
    "            right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "            rights.append(right)\n",
    "            \n",
    "            # 计算损失函数\n",
    "            loss += criterion(decoder_output, target_variable[:, di])\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 累加校验时期的损失函数\n",
    "        valid_loss += loss.data.numpy()[0]\n",
    "    # 打印每一个Epoch的输出结果\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('进程：%d%% 训练损失：%.4f，校验损失：%.4f，词正确率：%.2f%%' % (epoch * 1.0 / num_epoch * 100, \n",
    "                                                    print_loss_avg,\n",
    "                                                    valid_loss / len(valid_loader),\n",
    "                                                    100.0 * right_ratio))\n",
    "    # 记录基本统计指标\n",
    "    plot_losses.append([print_loss_avg, valid_loss / len(valid_loader), right_ratio])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3fb8bb0fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3fba17cba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将统计指标绘图\n",
    "a = [i[0] for i in plot_losses]\n",
    "b = [i[1] for i in plot_losses]\n",
    "c = [i[2] * 100 for i in plot_losses]\n",
    "plt.plot(a, label = 'Training Loss')\n",
    "plt.plot(b, label = 'Validation Loss')\n",
    "plt.plot(c, label = 'Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "among the largest enterprises in taiwan are information related enterprises .\n",
      "机器翻译： 在 台湾 百 大企业 中 , 信息 产业 企业 占 了 二十八 .\n",
      "标准翻译： 在 台湾 百 大企业 中 , 信息 产业 企业 占 了 二十八 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "only with the adoption of the one country two systems principle can the taiwan issue be resolved peacefully .\n",
      "机器翻译： 只有 实行 \" 一国两制 \" 方针 , 才能 使 台湾 问题 得到 和平 解决 .\n",
      "标准翻译： 只有 实行 \" 一国两制 \" 方针 , 才能 使 台湾 问题 得到 和平 解决 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      " without computers or without going on the web i can still make the same money . \n",
      "机器翻译： \" 没有 计算机 , 不 上网 , 我 一样 能 赚钱 . \"\n",
      "标准翻译： \" 没有 计算机 , 不 上网 , 我 一样 能 赚钱 . \"\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      " it is a pressing task to raise the position of patents .\n",
      "机器翻译： \" 专利 的 ' 地位 ' 亟待 提高 .\n",
      "标准翻译： \" 专利 的 ' 地位 ' 亟待 提高 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "article . the creation of a testamentary trust shall follow the provisions of the inheritance law concerning wills .\n",
      "机器翻译： 第十三 设立 遗嘱 信托 , 应当 遵守 继承法 关於 遗嘱 的 规定 .\n",
      "标准翻译： 第十三 设立 遗嘱 信托 , 应当 遵守 继承法 关於 遗嘱 的 规定 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      " the core product of the network economic era internet may likewise become the tool of hegemonism . \n",
      "机器翻译： \" 网络 经济 时代 的 核心 产物 --- 因特网 , 同样 可能 成为 霸权主义 的 工具 \" .\n",
      "标准翻译： \" 网络 经济 时代 的 核心 产物 --- 因特网 , 同样 可能 成为 霸权主义 的 工具 \" .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "during this period president jiang also met with egyptian president mubarak in alexandria egypt .\n",
      "机器翻译： 在此 期间 , 江主席 还 在 埃及 亚历山 大港 同 埃及 总统 穆巴拉克 会晤 .\n",
      "标准翻译： 在此 期间 , 江主席 还 在 埃及 亚历山 大港 同 埃及 总统 穆巴拉克 会晤 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "i feel greatly honored to have this experience .\n",
      "机器翻译： 对 於 这 段 经历 , 个人 深感 荣幸 .\n",
      "标准翻译： 对 於 这 段 经历 , 个人 深感 荣幸 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "taiwan certainly understands the importance of internationalization .\n",
      "机器翻译： 台湾 不是不 明白 国际化 的 重要 .\n",
      "标准翻译： 台湾 不是不 明白 国际化 的 重要 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "but emancipation of the mind and seeking truth from facts is a powerful force for guiding social progress .\n",
      "机器翻译： 而 解放 思想 , 实事求是 , 则是 引导 社会 敖那看 力量 .\n",
      "标准翻译： 而 解放 思想 , 实事求是 , 则是 引导 社会 敖那看 力量 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "total volume of retail sales in society in was . trillion yuan . percent of gdp .\n",
      "机器翻译： 1999年 我国 社会 消费品 零售 总额 为 31135亿 , 占 GDP 的 37.9% .\n",
      "标准翻译： 1999年 我国 社会 消费品 零售 总额 为 31135亿 , 占 GDP 的 37.9% .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "us attitude and policy is the most important basis for such a mentality or strategy .\n",
      "机器翻译： 美国 的 态度 和 政策 是 这种 心态 或 战略 的 首要 依据 .\n",
      "标准翻译： 美国 的 态度 和 政策 是 这种 心态 或 战略 的 首要 依据 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "this is a rule proven by countless examples . we should keep it firmly in our minds .\n",
      "机器翻译： 这个 凝聚 了 无数 经验 教训 的 规律性 认识 , 应当 为 我们 所 牢记 .\n",
      "标准翻译： 这个 凝聚 了 无数 经验 教训 的 规律性 认识 , 应当 为 我们 所 牢记 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "croatia wishes to develop friendly relations with china in all fields and supports the one china policy .\n",
      "机器翻译： 克罗地亚 希望 在 各个 领域 与 中国 发展 友好 关系 , 并 支持 一个 中国 的 政策 .\n",
      "标准翻译： 克罗地亚 希望 在 各个 领域 与 中国 发展 友好 关系 , 并 支持 一个 中国 的 政策 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "this is certainly not saying something frightening just to scare people .\n",
      "机器翻译： 这 决 不是 危言耸听 .\n",
      "标准翻译： 这 决 不是 危言耸听 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "chi haotian conveyed president jiang zemin s cordial regards and favorable blessings to king sihanouk .\n",
      "机器翻译： 迟浩田 转达 了 江泽民 主席 对 西哈努克 国王 的 亲切 问候 和 良好 祝愿 .\n",
      "标准翻译： 迟浩田 转达 了 江泽民 主席 对 西哈努克 国王 的 亲切 问候 和 良好 祝愿 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "organization personnel departments are responsible for the concrete procedures of investigation and verification .\n",
      "机器翻译： 具体 调查 核实 工作 , 由 组织 ( 人事 ) 部门 进行 .\n",
      "标准翻译： 具体 调查 核实 工作 , 由 组织 ( 人事 ) 部门 进行 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "the deputies freely aired their views and the atmosphere at the two meetings was very lively .\n",
      "机器翻译： 代表 们 畅所欲言 , 两 会场 气氛 都 很 活跃 .\n",
      "标准翻译： 代表 们 畅所欲言 , 两 会场 气氛 都 很 活跃 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "therefore making an appropriate amendment to the existing ordinance is necessary .\n",
      "机器翻译： 因此 , 对 现行 条例 进行 适当 充实 和 修改 是 必要 的 .\n",
      "标准翻译： 因此 , 对 现行 条例 进行 适当 充实 和 修改 是 必要 的 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "among these there are five factors which should attract our serious attention .\n",
      "机器翻译： 这 其中 有 五 因素 应该 引起 我们 的 高度 关注 .\n",
      "标准翻译： 这 其中 有 五 因素 应该 引起 我们 的 高度 关注 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上测试模型运行的效果\n",
    "\n",
    "# 首先，在测试集中随机选择20个句子作为测试\n",
    "indices = np.random.choice(range(len(test_X)), 20)\n",
    "\n",
    "# 对每个句子进行循环\n",
    "for ind in indices:\n",
    "    data = [test_X[ind]]\n",
    "    target = [test_Y[ind]]\n",
    "    # 把源语言的句子打印出来\n",
    "    print(SentenceFromList(input_lang, data[0]))\n",
    "    input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "    # input_variable的大小：batch_size, length_seq\n",
    "    target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "    # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "    # 初始化编码器\n",
    "    encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # 编码器开始编码，结果存储到了encoder_hidden中\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "    # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    # 将SOS作为解码器的第一个输入\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    # 将编码器的隐含层单元数值拷贝给解码器的隐含层单元\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    # 没有教师指导下的预测: 使用解码器自己的预测作为解码器下一时刻的输入\n",
    "    output_sentence = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    rights = []\n",
    "    # 按照输出字符进行时间步循环\n",
    "    for di in range(MAX_LENGTH):\n",
    "        # 解码器一个时间步的计算\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "        \n",
    "        # 解码器的输出\n",
    "        topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "        #topi 尺寸：batch_size, k\n",
    "        ni = topi[:, 0]\n",
    "        decoder_input = Variable(ni.unsqueeze(1))\n",
    "        ni = ni.cpu().numpy()[0]\n",
    "        \n",
    "        # 将本时间步输出的单词编码加到output_sentence里面\n",
    "        output_sentence.append(ni)\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        \n",
    "        # 计算输出字符的准确度\n",
    "        right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "        rights.append(right)\n",
    "    # 解析出编码器给出的翻译结果\n",
    "    sentence = SentenceFromList(output_lang, output_sentence)\n",
    "    # 解析出标准答案\n",
    "    standard = SentenceFromList(output_lang, target[0])\n",
    "    \n",
    "    # 将句子打印出来\n",
    "    print('机器翻译：', sentence)\n",
    "    print('标准翻译：', standard)\n",
    "    # 输出本句话的准确率\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('词准确率：', 100.0 * right_ratio)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效句子对： 19919\n",
      "总单词数:\n",
      "English 13493\n",
      "Chinese 18671\n",
      "训练记录： 17928\n",
      "校验记录： 995\n",
      "测试记录： 996\n"
     ]
    }
   ],
   "source": [
    "# 重新处理数据形成训练数据、校验数据与测试数据，主要是MAX_Length更大了\n",
    "# 设置句子的最大长度\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "#对英文做标准化处理\n",
    "pairs = [[normalizeEngString(eng), chi] for chi, eng in zip(chinese, english)]\n",
    "\n",
    "# 对句子对做过滤，处理掉那些超过MAX_LENGTH长度的句子\n",
    "input_lang = Lang('English')\n",
    "output_lang = Lang('Chinese')\n",
    "pairs = [pair for pair in pairs if filterPair(pair)]\n",
    "print('有效句子对：', len(pairs))\n",
    "\n",
    "# 建立两个字典（中文的和英文的）\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(\"总单词数:\")\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "\n",
    "# 形成训练集，首先，打乱所有句子的顺序\n",
    "random_idx = np.random.permutation(range(len(pairs)))\n",
    "pairs = [pairs[i] for i in random_idx]\n",
    "\n",
    "# 将语言转变为单词的编码构成的序列\n",
    "pairs = [indexFromPair(pair) for pair in pairs]\n",
    "    \n",
    "# 形成训练集、校验集和测试集\n",
    "valid_size = len(pairs) // 10\n",
    "if valid_size > 10000:\n",
    "    valid_size = 10000\n",
    "pairs = pairs[ : - valid_size]\n",
    "valid_pairs = pairs[-valid_size : -valid_size // 2]\n",
    "test_pairs = pairs[- valid_size // 2 :]\n",
    "\n",
    "# 利用PyTorch的dataset和dataloader对象，将数据加载到加载器里面，并且自动分批\n",
    "\n",
    "batch_size = 128 #一撮包含30个数据记录，这个数字越大，系统在训练的时候，每一个周期处理的数据就越多，这样处理越快，但总的数据量会减少\n",
    "\n",
    "print('训练记录：', len(pairs))\n",
    "print('校验记录：', len(valid_pairs))\n",
    "print('测试记录：', len(test_pairs))\n",
    "\n",
    "# 形成训练对列表，用于喂给train_dataset\n",
    "pairs_X = [pair[0] for pair in pairs]\n",
    "pairs_Y = [pair[1] for pair in pairs]\n",
    "valid_X = [pair[0] for pair in valid_pairs]\n",
    "valid_Y = [pair[1] for pair in valid_pairs]\n",
    "test_X = [pair[0] for pair in test_pairs]\n",
    "test_Y = [pair[1] for pair in test_pairs]\n",
    "\n",
    "\n",
    "# 形成训练集\n",
    "train_dataset = DataSet.TensorDataset(torch.LongTensor(pairs_X), torch.LongTensor(pairs_Y))\n",
    "# 形成数据加载器\n",
    "train_loader = DataSet.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "\n",
    "# 校验数据\n",
    "valid_dataset = DataSet.TensorDataset(torch.LongTensor(valid_X), torch.LongTensor(valid_Y))\n",
    "valid_loader = DataSet.DataLoader(valid_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "# 测试数据\n",
    "test_dataset = DataSet.TensorDataset(torch.LongTensor(test_X), torch.LongTensor(test_Y))\n",
    "test_loader = DataSet.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, num_workers = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义基于注意力的解码器RNN\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # 词嵌入层\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        # 注意力网络（一个前馈神经网络）\n",
    "        self.attn = nn.Linear(self.hidden_size * (2 * n_layers + 1), self.max_length)\n",
    "    \n",
    "        # 注意力机制作用完后的结果映射到后面的层\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
    "        \n",
    "        # dropout操作层\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        # 定义一个双向GRU，并设置batch_first为True以方便操作\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, bidirectional = True,\n",
    "                         num_layers = self.n_layers, batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_size * 2, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # 解码器的一步操作\n",
    "        # input大小：batch_size, length_seq\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded大小：batch_size, length_seq, hidden_size\n",
    "        embedded = embedded[:, 0, :]\n",
    "        # embedded大小：batch_size, hidden_size\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # 将hidden张量数据转化成batch_size排在第0维的形状\n",
    "        # hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "        temp_for_transpose = torch.transpose(hidden, 0, 1).contiguous()\n",
    "        temp_for_transpose = temp_for_transpose.view(temp_for_transpose.size()[0], -1)\n",
    "        hidden_attn = temp_for_transpose\n",
    "        \n",
    "        # 注意力层的输入\n",
    "        # hidden_attn大小：batch_size, direction*n_layers*hidden_size\n",
    "        input_to_attention = torch.cat((embedded, hidden_attn), 1)\n",
    "        # input_to_attention大小：batch_size, hidden_size * (1 + direction * n_layers)\n",
    "        \n",
    "        # 注意力层输出的权重\n",
    "        attn_weights = F.softmax(self.attn(input_to_attention))\n",
    "        # attn_weights大小：batch_size, max_length\n",
    "        \n",
    "        # 当输入数据不标准的时候，对weights截取必要的一段\n",
    "        attn_weights = attn_weights[:, : encoder_outputs.size()[1]]\n",
    "        # attn_weights大小：batch_size, length_seq_of_encoder\n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        # attn_weights大小：batch_size, 1, length_seq 中间的1是为了bmm乘法用的\n",
    "        \n",
    "        # 将attention的weights矩阵乘encoder_outputs以计算注意力完的结果\n",
    "        # encoder_outputs大小：batch_size, seq_length, hidden_size*direction\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs) \n",
    "        # attn_applied大小：batch_size, 1, hidden_size*direction\n",
    "        # bmm: 两个矩阵相乘。忽略第一个batch纬度，缩并时间维度\n",
    "        \n",
    "        # 将输入的词向量与注意力机制作用后的结果拼接成一个大的输入向量\n",
    "        output = torch.cat((embedded, attn_applied[:,0,:]), 1)\n",
    "        # output大小：batch_size, hidden_size * (direction + 1)\n",
    "        \n",
    "        # 将大输入向量映射为GRU的隐含层\n",
    "        output = self.attn_combine(output).unsqueeze(1)\n",
    "        # output大小：batch_size, length_seq, hidden_size\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # output的结果再dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # 开始解码器GRU的运算\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        \n",
    "        # output大小：batch_size, length_seq, hidden_size * directions\n",
    "        # hidden大小：n_layers * directions, batch_size, hidden_size\n",
    "        \n",
    "        #取出GRU运算最后一步的结果喂给最后一层全链接层\n",
    "        output = self.out(output[:, -1, :])\n",
    "        # output大小：batch_size * output_size\n",
    "        \n",
    "        # 取logsoftmax，计算输出结果\n",
    "        output = F.log_softmax(output)\n",
    "        # output大小：batch_size * output_size\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 初始化解码器隐单元，尺寸为n_layers * directions, batch_size, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进程：0% 训练损失：89.6669，校验损失：79.2543，词正确率：44.23%\n",
      "进程：1% 训练损失：74.8581，校验损失：67.2460，词正确率：46.35%\n",
      "进程：2% 训练损失：64.7946，校验损失：55.5135，词正确率：48.69%\n",
      "进程：3% 训练损失：54.2651，校验损失：48.5774，词正确率：49.04%\n",
      "进程：4% 训练损失：45.6932，校验损失：40.5560，词正确率：53.01%\n",
      "进程：5% 训练损失：39.3723，校验损失：36.4155，词正确率：55.50%\n",
      "进程：6% 训练损失：35.1993，校验损失：32.9861，词正确率：57.75%\n",
      "进程：7% 训练损失：32.0932，校验损失：29.8463，词正确率：60.23%\n",
      "进程：8% 训练损失：29.0793，校验损失：26.7694，词正确率：62.58%\n",
      "进程：9% 训练损失：26.2716，校验损失：25.6091，词正确率：64.27%\n",
      "进程：10% 训练损失：24.8974，校验损失：22.5243，词正确率：67.12%\n",
      "进程：11% 训练损失：22.0474，校验损失：21.1891，词正确率：68.76%\n",
      "进程：12% 训练损失：20.5010，校验损失：19.1615，词正确率：71.42%\n",
      "进程：13% 训练损失：19.2679，校验损失：18.7403，词正确率：71.50%\n",
      "进程：14% 训练损失：18.2607，校验损失：17.1220，词正确率：73.90%\n",
      "进程：15% 训练损失：17.0232，校验损失：16.1669，词正确率：75.39%\n",
      "进程：16% 训练损失：16.5166，校验损失：15.0679，词正确率：76.99%\n",
      "进程：17% 训练损失：15.0868，校验损失：14.7526，词正确率：77.27%\n",
      "进程：18% 训练损失：13.9732，校验损失：13.3596，词正确率：79.93%\n",
      "进程：19% 训练损失：14.1486，校验损失：12.7356，词正确率：80.41%\n",
      "进程：20% 训练损失：13.3840，校验损失：12.2194，词正确率：81.17%\n",
      "进程：21% 训练损失：13.1702，校验损失：11.2797，词正确率：82.30%\n",
      "进程：22% 训练损失：12.4909，校验损失：11.2673，词正确率：82.97%\n",
      "进程：23% 训练损失：11.8266，校验损失：10.9031，词正确率：83.89%\n",
      "进程：24% 训练损失：11.4997，校验损失：10.5409，词正确率：84.33%\n",
      "进程：25% 训练损失：10.8413，校验损失：9.2903，词正确率：85.76%\n",
      "进程：26% 训练损失：10.4766，校验损失：8.9163，词正确率：86.69%\n",
      "进程：27% 训练损失：10.0020，校验损失：8.7104，词正确率：87.04%\n",
      "进程：28% 训练损失：10.0676，校验损失：8.3438，词正确率：88.57%\n",
      "进程：28% 训练损失：9.9576，校验损失：7.9379，词正确率：88.39%\n",
      "进程：30% 训练损失：9.2678，校验损失：7.8831，词正确率：88.60%\n",
      "进程：31% 训练损失：8.8264，校验损失：7.3391，词正确率：89.41%\n",
      "进程：32% 训练损失：8.9541，校验损失：7.0666，词正确率：89.51%\n",
      "进程：33% 训练损失：8.4297，校验损失：7.1037，词正确率：89.85%\n",
      "进程：34% 训练损失：8.4342，校验损失：6.9194，词正确率：90.01%\n",
      "进程：35% 训练损失：8.7774，校验损失：6.8119，词正确率：89.89%\n",
      "进程：36% 训练损失：8.4603，校验损失：6.5479，词正确率：90.18%\n",
      "进程：37% 训练损失：7.7845，校验损失：5.9770，词正确率：91.63%\n",
      "进程：38% 训练损失：7.6211，校验损失：5.4062，词正确率：92.30%\n",
      "进程：39% 训练损失：7.4247，校验损失：6.1076，词正确率：91.17%\n",
      "进程：40% 训练损失：7.0546，校验损失：5.8023，词正确率：92.03%\n",
      "进程：41% 训练损失：7.5543，校验损失：5.7240，词正确率：92.04%\n",
      "进程：42% 训练损失：7.3090，校验损失：5.3772，词正确率：92.73%\n",
      "进程：43% 训练损失：7.0847，校验损失：5.3736，词正确率：92.41%\n",
      "进程：44% 训练损失：6.6455，校验损失：4.7111，词正确率：93.40%\n",
      "进程：45% 训练损失：6.6174，校验损失：4.4118，词正确率：93.82%\n",
      "进程：46% 训练损失：6.0971，校验损失：4.6046，词正确率：93.92%\n",
      "进程：47% 训练损失：6.5217，校验损失：4.8337，词正确率：93.46%\n",
      "进程：48% 训练损失：6.4342，校验损失：5.0569，词正确率：93.01%\n",
      "进程：49% 训练损失：6.8248，校验损失：5.0146，词正确率：93.16%\n",
      "进程：50% 训练损失：6.7347，校验损失：4.7396，词正确率：93.58%\n",
      "进程：51% 训练损失：6.6211，校验损失：4.5945，词正确率：93.67%\n",
      "进程：52% 训练损失：6.2874，校验损失：4.4743，词正确率：94.12%\n",
      "进程：53% 训练损失：6.2553，校验损失：4.6408，词正确率：93.59%\n",
      "进程：54% 训练损失：6.2155，校验损失：3.8962，词正确率：94.55%\n",
      "进程：55% 训练损失：5.7323，校验损失：4.0279，词正确率：94.39%\n",
      "进程：56% 训练损失：5.5396，校验损失：3.7844，词正确率：95.09%\n",
      "进程：56% 训练损失：5.6002，校验损失：4.0665，词正确率：94.28%\n",
      "进程：57% 训练损失：5.7555，校验损失：3.8975，词正确率：94.82%\n",
      "进程：59% 训练损失：5.7133，校验损失：3.6394，词正确率：94.98%\n",
      "进程：60% 训练损失：5.9161，校验损失：3.7131，词正确率：95.16%\n",
      "进程：61% 训练损失：5.3781，校验损失：3.7303，词正确率：95.16%\n",
      "进程：62% 训练损失：5.2828，校验损失：3.2557，词正确率：95.63%\n",
      "进程：63% 训练损失：5.5715，校验损失：3.3735，词正确率：95.60%\n",
      "进程：64% 训练损失：5.5557，校验损失：3.0932，词正确率：96.01%\n",
      "进程：65% 训练损失：5.1992，校验损失：3.1573，词正确率：95.99%\n",
      "进程：66% 训练损失：5.6073，校验损失：3.7790，词正确率：94.88%\n",
      "进程：67% 训练损失：5.5888，校验损失：3.5976，词正确率：95.38%\n",
      "进程：68% 训练损失：5.3647，校验损失：3.4114，词正确率：95.58%\n",
      "进程：69% 训练损失：5.1835，校验损失：3.2325，词正确率：95.69%\n",
      "进程：70% 训练损失：4.9639，校验损失：3.6286，词正确率：95.33%\n",
      "进程：71% 训练损失：5.1501，校验损失：3.1121，词正确率：95.85%\n",
      "进程：72% 训练损失：5.3315，校验损失：2.9514，词正确率：96.07%\n",
      "进程：73% 训练损失：5.2332，校验损失：2.9593，词正确率：96.10%\n",
      "进程：74% 训练损失：5.1398，校验损失：3.2003，词正确率：95.80%\n",
      "进程：75% 训练损失：5.1510，校验损失：3.5113，词正确率：95.53%\n",
      "进程：76% 训练损失：5.0883，校验损失：3.0001，词正确率：96.12%\n",
      "进程：77% 训练损失：5.0356，校验损失：3.0254，词正确率：96.10%\n",
      "进程：78% 训练损失：5.1487，校验损失：3.2843，词正确率：95.59%\n",
      "进程：79% 训练损失：4.9457，校验损失：2.9960，词正确率：96.08%\n",
      "进程：80% 训练损失：5.1405，校验损失：2.7970，词正确率：96.37%\n",
      "进程：81% 训练损失：5.1590，校验损失：2.7372，词正确率：96.54%\n",
      "进程：82% 训练损失：5.0949，校验损失：3.4122，词正确率：95.61%\n",
      "进程：83% 训练损失：4.8899，校验损失：2.7931，词正确率：96.55%\n",
      "进程：84% 训练损失：4.7795，校验损失：2.6878，词正确率：96.61%\n",
      "进程：85% 训练损失：4.9654，校验损失：2.9914，词正确率：96.16%\n",
      "进程：86% 训练损失：4.3562，校验损失：2.7543，词正确率：96.34%\n",
      "进程：87% 训练损失：4.4136，校验损失：2.3619，词正确率：97.05%\n",
      "进程：88% 训练损失：4.1356，校验损失：2.2241，词正确率：97.10%\n",
      "进程：89% 训练损失：4.1142，校验损失：2.6187，词正确率：96.78%\n",
      "进程：90% 训练损失：4.3638，校验损失：2.8109，词正确率：96.63%\n",
      "进程：91% 训练损失：4.8397，校验损失：2.7567，词正确率：96.55%\n",
      "进程：92% 训练损失：4.9861，校验损失：2.7469，词正确率：96.44%\n",
      "进程：93% 训练损失：5.5848，校验损失：3.6194，词正确率：95.29%\n",
      "进程：94% 训练损失：4.8042，校验损失：2.8652，词正确率：96.22%\n",
      "进程：95% 训练损失：5.1062，校验损失：3.0192，词正确率：96.23%\n",
      "进程：96% 训练损失：5.0399，校验损失：2.8923，词正确率：96.30%\n",
      "进程：97% 训练损失：4.7730，校验损失：2.9350，词正确率：96.53%\n",
      "进程：98% 训练损失：4.6652，校验损失：2.4807，词正确率：96.68%\n",
      "进程：99% 训练损失：4.6319，校验损失：2.5480，词正确率：96.68%\n"
     ]
    }
   ],
   "source": [
    "# 开始带有注意力机制的RNN训练\n",
    "\n",
    "#定义网络架构\n",
    "hidden_size = 512\n",
    "max_length = MAX_LENGTH\n",
    "n_layers = 1\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers = n_layers)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.5,\n",
    "                         max_length = max_length, n_layers = n_layers)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "print_loss_total = 0  # Reset every print_every\n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "#criterion = Batch_NLLLoss\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "# 开始训练周期循环\n",
    "plot_losses = []\n",
    "for epoch in range(num_epoch):\n",
    "    # 将解码器置于训练状态，让dropout工作\n",
    "    decoder.train()\n",
    "    print_loss_total = 0\n",
    "    # 对训练数据进行循环\n",
    "    for data in train_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "        \n",
    "        #清空梯度\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        #编码器开始工作\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 解码器开始工作\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        # 将编码器的隐含层单元取值作为编码的结果传递给解码器\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 同时按照两种方式训练解码器：用教师监督的信息作为下一时刻的输入和不用监督的信息，用自己预测结果作为下一时刻的输入\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        if use_teacher_forcing:\n",
    "            # 用监督信息作为下一时刻解码器的输入\n",
    "            # 开始时间不得循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 输入给解码器的信息包括输入的单词decoder_input, 解码器上一时刻的因曾单元状态，\n",
    "                # 编码器各个时间步的输出结果\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                #decoder_ouput大小：batch_size, output_size\n",
    "                #计算损失函数，得到下一时刻的解码器的输入\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "                decoder_input = target_variable[:, di].unsqueeze(1)  # Teacher forcing\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "        else:\n",
    "            # 没有教师监督，用解码器自己的预测作为下一时刻的输入\n",
    "\n",
    "            # 对时间步进行循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "                # 获取解码器的预测结果，并用它来作为下一时刻的输入\n",
    "                topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "                #topi 尺寸：batch_size, k\n",
    "                ni = topi[:, 0]\n",
    "\n",
    "                decoder_input = Variable(ni.unsqueeze(1))\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "                # 计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 反向传播开始\n",
    "        loss.backward()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 开始梯度下降\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        print_loss_total += loss.data.numpy()[0]\n",
    "\n",
    "    print_loss_avg = print_loss_total / len(train_loader)\n",
    "        \n",
    "    valid_loss = 0\n",
    "    rights = []\n",
    "    # 将解码器的training设置为False，以便关闭dropout\n",
    "    decoder.eval()\n",
    "    \n",
    "    #对所有的校验数据做循环\n",
    "    for data in valid_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 开始每一步的预测\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "            topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "            #topi 尺寸：batch_size, k\n",
    "            ni = topi[:, 0]\n",
    "\n",
    "            decoder_input = Variable(ni.unsqueeze(1))\n",
    "            # decoder_input大小：batch_size, length_seq\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "            rights.append(right)\n",
    "            loss += criterion(decoder_output, target_variable[:, di])\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        valid_loss += loss.data.numpy()[0]\n",
    "    # 计算平均损失、准确率等指标并打印输出\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('进程：%d%% 训练损失：%.4f，校验损失：%.4f，词正确率：%.2f%%' % (epoch * 1.0 / num_epoch * 100, \n",
    "                                                    print_loss_avg,\n",
    "                                                    valid_loss / len(valid_loader),\n",
    "                                                    100.0 * right_ratio))\n",
    "    plot_losses.append([print_loss_avg, valid_loss / len(valid_loader), right_ratio])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fuyang/Workspace/deep_learning_tutorial/p3ml-venv/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/fuyang/Workspace/deep_learning_tutorial/p3ml-venv/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2458310898>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrM91gyC/MXkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24d91f5160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制统计指标曲线图\n",
    "torch.save(encoder, 'encoder-final.mdl')\n",
    "torch.save(decoder, 'decoder-final.mdl')\n",
    "a = [i[0] for i in plot_losses]\n",
    "b = [i[1] for i in plot_losses]\n",
    "c = [i[2] * 100 for i in plot_losses]\n",
    "plt.plot(a, label = 'Training Loss')\n",
    "plt.plot(b, label = 'Validation Loss')\n",
    "plt.plot(c, label = 'Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "however this is only wishful thinking .\n",
      "机器翻译： 但 这 只是 一厢情愿 .\n",
      "标准翻译： 但 这 只是 一厢情愿 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "the overall situation in the past three months since macao s return to the motherland has been good .\n",
      "机器翻译： 澳门 回归祖国 近 3个 月 来 , 总的 形势 是 好的 .\n",
      "标准翻译： 澳门 回归祖国 近 3个 月 来 , 总的 形势 是 好的 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "li peng extended a warm welcome to bouteflika .\n",
      "机器翻译： 李鹏 对 布特弗利卡 访华 表示 热烈 欢迎 .\n",
      "标准翻译： 李鹏 对 布特弗利卡 访华 表示 热烈 欢迎 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "confrontation on the human rights issue will lead nowhere .\n",
      "机器翻译： 在 人权 问题 上 搞 对抗 , 是 没有 出路 的 .\n",
      "标准翻译： 在 人权 问题 上 搞 对抗 , 是 没有 出路 的 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "answer it should be said that we have done a lot of fruitful work in this regard .\n",
      "机器翻译： 答 : 应该说 , 我们 在 这 方面 做 了 大量 卓有成效 的 工作 .\n",
      "标准翻译： 答 : 应该说 , 我们 在 这 方面 做 了 大量 卓有成效 的 工作 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "since when china and the united states established diplomatic relations sino us relations has developed amid struggle .\n",
      "机器翻译： 从 一九七九年 中美 建交 至今 , 中美 关系 一直 在 中美 中 向前 发展 .\n",
      "标准翻译： 从 一九七九年 中美 建交 至今 , 中美 关系 一直 在 斗争 中 向前 发展 .\n",
      "词准确率： 95.0\n",
      "\n",
      "\n",
      "they symbolize the two broad trends in china s modernization .\n",
      "机器翻译： 这 两 件 事 , 标志 著 我国 现代化 发展 的 大趋势 大趋势 .\n",
      "标准翻译： 这 两 件 事 , 标志 著 我国 现代化 发展 的 两 大趋势 .\n",
      "词准确率： 95.0\n",
      "\n",
      "\n",
      "this major shift in the dprk s foreign policy has attracted wide attention in the international community .\n",
      "机器翻译： 朝鲜 对外 政策 的 这 一 重大 转变 , 引起 国际 社会 的 广泛 关注 .\n",
      "标准翻译： 朝鲜 对外 政策 的 这 一 重大 转变 , 引起 国际 社会 的 广泛 关注 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "in this way president jiang brought them closer together .\n",
      "机器翻译： \" 江主席 一 语 拉 近 了 彼此的 距离 .\n",
      "标准翻译： \" 江主席 一 语 拉 近 了 彼此的 距离 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "more than fishing boats were sent out on april .\n",
      "机器翻译： 七日 , 仅 渔船 就 出动 八百 多 艘 .\n",
      "标准翻译： 七日 , 仅 渔船 就 出动 八百 多 艘 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "the current level of enjoying human rights by the chinese people is higher than any period in history .\n",
      "机器翻译： 中国 人民 享受 人权 的 水平高 於 於 历史 上 任何 时期 .\n",
      "标准翻译： 中国 人民 享受 人权 的 水平高 於 历史 上 任何 一个 时期 .\n",
      "词准确率： 80.0\n",
      "\n",
      "\n",
      "industrial output is growing faster with the operating quality of industrial enterprises markedly improved .\n",
      "机器翻译： 生产 生产 增长 较快 , 工业 企业 运行 质量 明显 提高 .\n",
      "标准翻译： 工业 生产 增长 较快 , 工业 企业 运行 质量 明显 提高 .\n",
      "词准确率： 95.0\n",
      "\n",
      "\n",
      "there are many well known friends here today and all the seats are occupied by distinguished guests .\n",
      "机器翻译： 这里 , 这里 胜 友 如云 , 高朋满座 .\n",
      "标准翻译： 今天 , 这里 胜 友 如云 , 高朋满座 .\n",
      "词准确率： 95.0\n",
      "\n",
      "\n",
      "the spirit of struggling persistently is the spiritual backbone in advancing the great cause of socialist modernization construction .\n",
      "机器翻译： 不懈 奋斗 的 精神 , 就是 我们 推进 社会主义 现代化 建设 伟大 的 精神 支柱 .\n",
      "标准翻译： 不懈 奋斗 的 精神 , 就是 我们 推进 社会主义 现代化 建设 伟大 事业 的 精神 支柱 .\n",
      "词准确率： 75.0\n",
      "\n",
      "\n",
      "the guests and the hosts cordially talked with each other and toasted to the two countries friendship .\n",
      "机器翻译： 宾主 亲切 交谈 , 中 柬 柬 友谊 频频 举杯 .\n",
      "标准翻译： 宾主 亲切 交谈 , 为 中 柬 友谊 频频 举杯 .\n",
      "词准确率： 90.0\n",
      "\n",
      "\n",
      "sino foreign joint ventures are encouraged to market their products in overseas markets .\n",
      "机器翻译： 鼓励 合营 企业 向 中国 境外 销售 产品 .\n",
      "标准翻译： 鼓励 合营 企业 向 中国 境外 销售 产品 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "in addition the nato countries are reluctant to always be slavishly dependent on the united states .\n",
      "机器翻译： 还有 , 北约 18 国 不 愿意 总是 仰 美国 之 鼻息 过日子 .\n",
      "标准翻译： 还有 , 北约 18 国 不 愿意 总是 仰 美国 之 鼻息 过日子 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "it was the first visit of us state secretary to central asian countries since their independence .\n",
      "机器翻译： 这是 中亚 各国 独立 以来 美国 国务卿 的 首次 访问 .\n",
      "标准翻译： 这是 中亚 各国 独立 以来 美国 国务卿 的 首次 访问 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      " it is necessary to use the credit leverage to promote the adjustment of economic structure .\n",
      "机器翻译： ( 四 ) 运用 信贷 杠杆 促进 经济 结构 调整 .\n",
      "标准翻译： ( 四 ) 运用 信贷 杠杆 促进 经济 结构 调整 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "seventh educational and scientific undertakings should be developed .\n",
      "机器翻译： 第七 , 教育 教育 和 科学 事业 .\n",
      "标准翻译： 第七 , 发展 教育 和 科学 事业 .\n",
      "词准确率： 95.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从测试集中随机挑选20个句子来测试翻译的结果\n",
    "indices = np.random.choice(range(len(test_X)), 20)\n",
    "for ind in indices:\n",
    "    data = [test_X[ind]]\n",
    "    target = [test_Y[ind]]\n",
    "    print(SentenceFromList(input_lang, data[0]))\n",
    "    input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "    # input_variable的大小：batch_size, length_seq\n",
    "    target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "    # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "    loss = 0\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "    # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    output_sentence = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    rights = []\n",
    "    for di in range(MAX_LENGTH):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "        topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        #topi 尺寸：batch_size, k\n",
    "        ni = topi[:, 0]\n",
    "        decoder_input = Variable(ni.unsqueeze(1))\n",
    "        ni = ni.cpu().numpy()[0] if use_cuda else ni.numpy()[0]\n",
    "        output_sentence.append(ni)\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "        rights.append(right)\n",
    "    sentence = SentenceFromList(output_lang, output_sentence)\n",
    "    standard = SentenceFromList(output_lang, target[0])\n",
    "    print('机器翻译：', sentence)\n",
    "    print('标准翻译：', standard)\n",
    "    # 输出本句话的准确率\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('词准确率：', 100.0 * right_ratio)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器翻译： 他 表示 , 在 推动 这项 计划 方面 不会 作出 妥协 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 通过几个特殊的句子翻译，考察注意力机制关注的情况\n",
    "data = '人民币 汇率 继续 保持 稳定 .'\n",
    "#data = '五 是 干部 交流 工作 迈出 较大 步伐 .'\n",
    "data = 'he pledged that he would make no compromise when pushing ahead with this scheme .'\n",
    "data = np.array([indexFromSentence(input_lang, data)])\n",
    "\n",
    "input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "# input_variable的大小：batch_size, length_seq\n",
    "target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "# target_variable的大小：batch_size, length_seq\n",
    "\n",
    "encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "loss = 0\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "# encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "# encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "# decoder_input大小：batch_size, length_seq\n",
    "decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "decoder_hidden = encoder_hidden\n",
    "# decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "output_sentence = []\n",
    "decoder_attentions = torch.zeros(max_length, max_length)\n",
    "for di in range(MAX_LENGTH):\n",
    "    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "        decoder_input, decoder_hidden, encoder_outputs)\n",
    "    #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "    topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "    \n",
    "    # 在每一步，获取了注意力的权重向量，并将其存储到了decoder_attentions之中\n",
    "    decoder_attentions[di] = decoder_attention.data\n",
    "    #topi 尺寸：batch_size, k\n",
    "    ni = topi[:, 0]\n",
    "    decoder_input = Variable(ni.unsqueeze(1))\n",
    "    ni = ni.cpu().numpy()[0] if use_cuda else ni.numpy()[0]\n",
    "    output_sentence.append(ni)\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "    rights.append(right)\n",
    "sentence = SentenceFromList(output_lang, output_sentence)\n",
    "print('机器翻译：', sentence)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器翻译： 她 在 这 就 到 时候 , 就 不会 作出 得 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 通过几个特殊的句子翻译，考察注意力机制关注的情况\n",
    "data = '人民币 汇率 继续 保持 稳定 .'\n",
    "#data = '五 是 干部 交流 工作 迈出 较大 步伐 .'\n",
    "data = 'she pledged that she would make no compromise when pushing ahead with this scheme .'\n",
    "data = np.array([indexFromSentence(input_lang, data)])\n",
    "\n",
    "input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "# input_variable的大小：batch_size, length_seq\n",
    "target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "# target_variable的大小：batch_size, length_seq\n",
    "\n",
    "encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "loss = 0\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "# encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "# encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "# decoder_input大小：batch_size, length_seq\n",
    "decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "decoder_hidden = encoder_hidden\n",
    "# decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "output_sentence = []\n",
    "decoder_attentions = torch.zeros(max_length, max_length)\n",
    "for di in range(MAX_LENGTH):\n",
    "    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "        decoder_input, decoder_hidden, encoder_outputs)\n",
    "    #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "    topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "    \n",
    "    # 在每一步，获取了注意力的权重向量，并将其存储到了decoder_attentions之中\n",
    "    decoder_attentions[di] = decoder_attention.data\n",
    "    #topi 尺寸：batch_size, k\n",
    "    ni = topi[:, 0]\n",
    "    decoder_input = Variable(ni.unsqueeze(1))\n",
    "    ni = ni.cpu().numpy()[0] if use_cuda else ni.numpy()[0]\n",
    "    output_sentence.append(ni)\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "    rights.append(right)\n",
    "sentence = SentenceFromList(output_lang, output_sentence)\n",
    "print('机器翻译：', sentence)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x116bddda0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzaFZjhAANAECAUAgEAAEAgFAIBAAhP8CPVbUH4+urLEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117569e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将每一步存储的注意力权重组合到一起就形成了注意力矩阵，绘制为图\n",
    "plt.matshow(decoder_attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
