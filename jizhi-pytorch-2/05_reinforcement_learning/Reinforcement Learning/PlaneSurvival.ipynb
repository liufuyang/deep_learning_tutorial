{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度强化学习－用卷积神经网络实现AI玩Flappy Bird游戏\n",
    "\n",
    "本节课我们结合Flappy bird游戏，详细讲述了深度强化学习原理，以及如何训练一个神经网络来玩儿游戏\n",
    "\n",
    "整个代码包括了利用PyGame包实现一个Flappy Bird游戏，卷积神经网络的定义与实现，以及深度强化学习算法。\n",
    "\n",
    "本程序参考了AI玩Flappy Bird的TensorFlow版本：https://github.com/yenchenlin/DeepLearningFlappyBird\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第X课的配套源代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、PyGAME实现Flappy Bird游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这部分中，我们调用PyGame包实现了一个Flappy Bird游戏。通过PyGame，我们可以非常方便的加载图片、音频，来快速实现小游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载游戏所需的必要资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 实现Flappy Bird的游戏逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载游戏中的所有资源，包括图片以及音频\n",
    "# 调用PyGame包，关于该包的安装，请参看：http://www.pygame.org/wiki/GettingStarted\n",
    "import pygame\n",
    "\n",
    "# 需要获取操作系统类型，故而调用sys包\n",
    "import sys\n",
    "# 加载程序所需的包\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import pygame\n",
    "import pygame.surfarray as surfarray\n",
    "from pygame.locals import *\n",
    "from itertools import cycle\n",
    "\n",
    "FPS = 40 #帧率\n",
    "SCREENWIDTH  = 400 #屏幕的宽度\n",
    "SCREENHEIGHT = 300 #屏幕的高度\n",
    "\n",
    "pygame.init() #游戏初始化\n",
    "pygame.display.list_modes()\n",
    "FPSCLOCK = pygame.time.Clock() #定义程序时钟\n",
    "SCREEN = pygame.display.set_mode((SCREENWIDTH, SCREENHEIGHT)) #定义屏幕对象\n",
    "screen = SCREEN\n",
    "pygame.display.set_caption('PlaneSurvival') #设定窗口名称\n",
    "\n",
    "\n",
    "ENEMY_FREQ = 800\n",
    "\n",
    "# Define our player object and call super to give it all the properties and methods of pygame.sprite.Sprite\n",
    "# The surface we draw on the screen is now a property of 'player'\n",
    "class GameState(pygame.sprite.Sprite):\n",
    "    def __init__(self):\n",
    "        super(GameState, self).__init__()\n",
    "        self.surf = pygame.Surface((80, 30))\n",
    "        self.surf.fill((255, 255, 255))\n",
    "        self.rect = self.surf.get_rect()\n",
    "        self.rect.move_ip(0, 100)\n",
    "        \n",
    "        self.enemies = []\n",
    "        \n",
    "        self.background = pygame.Surface(screen.get_size())\n",
    "        self.background.fill((0, 0, 0))\n",
    "        \n",
    "        self.reward = 0.1\n",
    "        \n",
    "\n",
    "    def frame_step(self, input_actions):\n",
    "        # input_actions是一个行动数组，分别存储了3个动作的激活情况\n",
    "        # input_actions[0] == 1: 对应什么都不做\n",
    "        # input_actions[1] == 1: 对应UP\n",
    "        # input_actions[2] == 1: 对应DOWN\n",
    "        \n",
    "        pygame.event.pump()\n",
    "        \n",
    "        # 每一步的默认回报\n",
    "        self.reward = 0.1\n",
    "        terminal = False\n",
    "        \n",
    "        # 限定每一帧只能做一个动作\n",
    "        if sum(input_actions) != 1:\n",
    "            raise ValueError('Multiple input actions!')\n",
    "            \n",
    "            \n",
    "        if input_actions[1]:\n",
    "            self.rect.move_ip(0, -5)\n",
    "        if input_actions[2]:\n",
    "            self.rect.move_ip(0, 5)\n",
    "        # if pressed_keys[K_LEFT]:\n",
    "        #    self.rect.move_ip(-5, 0)\n",
    "        # if pressed_keys[K_RIGHT]:\n",
    "        #    self.rect.move_ip(5, 0)\n",
    "            \n",
    "        # Keep player on the screen\n",
    "        if self.rect.left < 0:\n",
    "            self.rect.left = 0\n",
    "        elif self.rect.right > SCREENWIDTH:\n",
    "            self.rect.right = SCREENWIDTH\n",
    "        if self.rect.top <= 0:\n",
    "            self.rect.top = 0\n",
    "        elif self.rect.bottom >= SCREENHEIGHT:\n",
    "            self.rect.bottom = SCREENHEIGHT\n",
    "            \n",
    "        ### Add enemies    \n",
    "        #for event in pygame.event.get():\n",
    "            #if event.type == KEYDOWN:\n",
    "            #    if event.key == K_ESCAPE:\n",
    "            #        terminal = True\n",
    "            #elif event.type == QUIT:\n",
    "            #    terminal = True\n",
    "        if(random.random() < 0.025):\n",
    "            new_enemy = Enemy(self)\n",
    "            self.enemies.append(new_enemy)\n",
    "        ####\n",
    "        \n",
    "        for e in self.enemies:\n",
    "            e.update()\n",
    "            \n",
    "        self.enemies = [e for e in self.enemies if e.dead == False ]\n",
    "        #print(len(self.enemies))\n",
    "        \n",
    "        if pygame.sprite.spritecollideany(self, self.enemies):\n",
    "            terminal = True\n",
    "            self.__init__()\n",
    "            self.reward = -1\n",
    "        \n",
    "        # Draw everything on screen\n",
    "        screen.blit(self.background, (0, 0))\n",
    "        # screen.blit(self.surf, self.rect)\n",
    "        for entity in self.enemies:\n",
    "            screen.blit(entity.surf, entity.rect)\n",
    "        screen.blit(self.surf, self.rect)\n",
    "        \n",
    "        \n",
    "        # 将当前的游戏屏幕生成一个二维画面返回\n",
    "        image_data = pygame.surfarray.array3d(pygame.display.get_surface())\n",
    "        pygame.display.update()\n",
    "        FPSCLOCK.tick(FPS)\n",
    "        #print(self.reward)\n",
    "        return image_data, self.reward, terminal\n",
    "\n",
    "class Enemy(pygame.sprite.Sprite):\n",
    "    def __init__(self, state):\n",
    "        super(Enemy, self).__init__()\n",
    "        self.surf = pygame.Surface((80, 20))\n",
    "        self.surf.fill((255,255,255))\n",
    "        self.rect = self.surf.get_rect(\n",
    "            center=(random.randint(400, 500), random.randint(0, 300))\n",
    "        )\n",
    "        self.speed = random.randint(2, 6)\n",
    "        \n",
    "        self.state = state\n",
    "        self.dead = False\n",
    "\n",
    "    def update(self):\n",
    "        self.rect.move_ip(-self.speed, 0)\n",
    "        if self.rect.right < 0:\n",
    "            self.state.reward = self.state.reward + 1\n",
    "            self.kill()\n",
    "            self.dead = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 对游戏做小测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhf0H0TeoaG+5rCEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9bc9672a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# 新建一个游戏\n",
    "game = GameState()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "axe = fig.add_subplot(111)\n",
    "dat = np.zeros((10, 10))\n",
    "img = axe.imshow(dat)\n",
    "\n",
    "\n",
    "# 进行100步循环，并将每一帧的画面打印出来\n",
    "for i in range(200):\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    image_data, reward, terminal = game.frame_step([0,1,0])\n",
    "    \n",
    "    image = np.transpose(image_data, (1, 0, 2))\n",
    "    img.set_data(image)\n",
    "    img.autoscale()\n",
    "    display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、训练神经网络玩游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  导入必需的包\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2 #需要安装OpenCV的包\n",
    "import sys\n",
    "sys.path.append(\"game/\")\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# 定义一系列常数，其中，epsilon为每周期随机输出一个动作的概率\n",
    "GAME = 'bird' # 游戏名称\n",
    "ACTIONS = 3 # 有效输出动作的个数\n",
    "GAMMA = 0.99 # 强化学习中未来的衰减率\n",
    "OBSERVE = 5000. # 训练之前的时间步，需要先观察10000帧\n",
    "EXPLORE = 3000000. # 退火所需的时间步，所谓的退火就是指随机选择率epsilon逐渐变小\n",
    "FINAL_EPSILON = 0.0001 # epsilon的最终值\n",
    "INITIAL_EPSILON = 0.2 # epsilon的初始值\n",
    "REPLAY_MEMORY = 30000 # 最多记忆多少帧训练数据 # 50000\n",
    "BATCH = 32 # 每一个批次的数据记录条数\n",
    "FRAME_PER_ACTION = 1 # 每间隔多少时间完成一次有效动作的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 创建一个多层CNN网络，该网络接收的输入为4帧画面，输出为每个可能动作对应的Q函数值\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 第一层卷积，从4通道到32通道，窗口大小8，跳跃间隔4，填空白2\n",
    "        self.conv1 = nn.Conv2d(4, 32, 8, 4, padding = 2)\n",
    "        # Pooling层，窗口2*2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 第二层卷积，从32通道到64通道，窗口大小4，跳跃间隔2，填空白1\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 2, padding = 1)\n",
    "        # 第二个Pooling层，窗口2＊2，空白1\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, padding = 1)\n",
    "        # 第三层卷积层，输入输出通道都是64，填空白为1\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1, padding = 1)\n",
    "        \n",
    "        # 最后有两层全链接层\n",
    "        self.fc_sz = 1600\n",
    "        self.fc1 = nn.Linear(self.fc_sz, 256)\n",
    "        self.fc2 = nn.Linear(256, ACTIONS)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入为一个batch的数据，每一个为前后相连的4张图像，每个图像为80*80的大小\n",
    "        # x的尺寸为：batch_size, 4, 80, 80\n",
    "        x = self.conv1(x)\n",
    "        # x的尺寸为：batch_size, 32, 20, 20\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # x的尺寸为：batch_size, 32, 10, 10\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # x的尺寸为：batch_size, 64, 5, 5\n",
    "        #x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # x的尺寸为：batch_size, 64, 5, 5\n",
    "        #x = self.pool2(x)\n",
    "        # 将x设为1600维的向量, batch_size, 1600\n",
    "        x = x.view(-1, self.fc_sz)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        readout = self.fc2(x)\n",
    "        return readout, x\n",
    "    def init(self):\n",
    "        # 初始化所有的网络权重\n",
    "        self.conv1.weight.data =  torch.abs(0.01 * torch.randn(self.conv1.weight.size()))\n",
    "        self.conv2.weight.data =  torch.abs(0.01 * torch.randn(self.conv2.weight.size()))\n",
    "        self.conv3.weight.data =  torch.abs(0.01 * torch.randn(self.conv3.weight.size()))\n",
    "        self.fc1.weight.data = torch.abs(0.01 * torch.randn(self.fc1.weight.size()))\n",
    "        self.fc2.weight.data = torch.abs(0.01 * torch.randn(self.fc2.weight.size()))\n",
    "        self.conv1.bias.data = torch.ones(self.conv1.bias.size()) * 0.01\n",
    "        self.conv2.bias.data = torch.ones(self.conv2.bias.size()) * 0.01\n",
    "        self.conv3.bias.data = torch.ones(self.conv3.bias.size()) * 0.01\n",
    "        self.fc1.bias.data = torch.ones(self.fc1.bias.size()) * 0.01\n",
    "        self.fc2.bias.data = torch.ones(self.fc2.bias.size()) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda True\n"
     ]
    }
   ],
   "source": [
    "# 开始在内存／GPU上定义一个网络\n",
    "use_cuda = torch.cuda.is_available() #检测本台机器中是否有GPU\n",
    "print('use_cuda', use_cuda)\n",
    "# 创建一个神经网络\n",
    "net = Net()\n",
    "# 初始化网络权重。之所以自定义初始化过程是为了增加神经网络权重的多样性\n",
    "net.init()\n",
    "# 如果有GPU，就把神经网络全部搬到GPU内存中做运算\n",
    "net = net.cuda() if use_cuda else net\n",
    "\n",
    "# 定义损失函数为MSE\n",
    "criterion = nn.MSELoss().cuda() if use_cuda else nn.MSELoss()\n",
    "# 定义优化器，并设置初始学习率维10^-6\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-6 )\n",
    "\n",
    "# 开启一个游戏进程，开始与游戏引擎通话\n",
    "game_state = GameState()\n",
    "\n",
    "\n",
    "# 学习样本的存储区域deque是一个类似于list的存储容器\n",
    "D = deque()\n",
    "\n",
    "# 状态打印log记录位置\n",
    "#a_file = open(\"logs_\" + GAME + \"/readout.txt\", 'w')\n",
    "#h_file = open(\"logs_\" + GAME + \"/hidden.txt\", 'w')\n",
    "\n",
    "# 将游戏设置为初始状态，并获得一个80*80的游戏湖面\n",
    "do_nothing = np.zeros(ACTIONS)\n",
    "do_nothing[0] = 1\n",
    "x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "x_t = cv2.cvtColor(cv2.resize(x_t, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# 将初始的游戏画面叠加成4张作为神经网络的初始输入状态s_t\n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 边做边学的核心算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该算法分为三个阶段：\n",
    "\n",
    "1、按照Epsilon贪婪算法采取一次行动；\n",
    "2、将选择好的行动输入给游戏引擎，得到下一帧的状态，并生成本帧的训练数据\n",
    "3、开始训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1000/ 状态 observe/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 9.948210e+00/ 轮得分 51.95\n",
      "时间步 2000/ 状态 observe/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 9.666224e+00/ 轮得分 44.90\n",
      "时间步 3000/ 状态 observe/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.112597e+01/ 轮得分 44.87\n",
      "时间步 4000/ 状态 observe/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 7.258551e+00/ 轮得分 44.87\n",
      "时间步 5000/ 状态 observe/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.307988e+01/ 轮得分 58.61\n",
      "时间步 6000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.102176e+01/ 轮得分 58.61\n",
      "损失函数： 0.0514011\n",
      "时间步 7000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 7.753469e+00/ 轮得分 60.57\n",
      "损失函数： 0.0514402\n",
      "时间步 8000/ 状态 explore/ Epsilon 0.20/ 行动 1/ 奖励 0.1/ Q_MAX 9.923781e+00/ 轮得分 46.65\n",
      "损失函数： 0.104612\n",
      "时间步 9000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.058077e+01/ 轮得分 42.68\n",
      "损失函数： 0.163438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fuyang/Workspace/deep_learning_tutorial/p3ml-venv/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 10000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.321112e+01/ 轮得分 40.32\n",
      "损失函数： 0.0907798\n",
      "时间步 11000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 8.017292e+00/ 轮得分 42.76\n",
      "损失函数： 0.0516603\n",
      "时间步 12000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.270808e+01/ 轮得分 40.65\n",
      "损失函数： 0.0749432\n",
      "时间步 13000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.171060e+01/ 轮得分 42.13\n",
      "损失函数： 0.120877\n",
      "时间步 14000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 8.742262e+00/ 轮得分 43.21\n",
      "损失函数： 0.103294\n",
      "时间步 15000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.115907e+01/ 轮得分 43.40\n",
      "损失函数： 0.0498901\n",
      "时间步 16000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.204202e+01/ 轮得分 43.62\n",
      "损失函数： 0.105298\n",
      "时间步 17000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.186220e+01/ 轮得分 44.58\n",
      "损失函数： 0.0976257\n",
      "时间步 18000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.056993e+01/ 轮得分 45.66\n",
      "损失函数： 0.135102\n",
      "时间步 19000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 7.150744e+00/ 轮得分 45.86\n",
      "损失函数： 0.089778\n",
      "时间步 20000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.263052e+01/ 轮得分 47.30\n",
      "损失函数： 0.0957436\n",
      "时间步 21000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 3.942497e+00/ 轮得分 48.81\n",
      "损失函数： 0.155979\n",
      "时间步 22000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.273421e+01/ 轮得分 48.14\n",
      "损失函数： 0.0571246\n",
      "时间步 23000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.381273e+01/ 轮得分 49.66\n",
      "损失函数： 0.089131\n",
      "时间步 24000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 8.403223e+00/ 轮得分 49.78\n",
      "损失函数： 0.0904379\n",
      "时间步 25000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.086623e+01/ 轮得分 49.48\n",
      "损失函数： 0.116815\n",
      "时间步 26000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.174075e+01/ 轮得分 49.04\n",
      "损失函数： 0.15327\n",
      "时间步 27000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.061028e+01/ 轮得分 48.51\n",
      "损失函数： 0.224184\n",
      "时间步 28000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.519723e+01/ 轮得分 48.51\n",
      "损失函数： 0.128541\n",
      "时间步 29000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 8.323594e+00/ 轮得分 49.58\n",
      "损失函数： 0.0939572\n",
      "时间步 30000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.003420e+01/ 轮得分 49.72\n",
      "损失函数： 0.154059\n",
      "时间步 31000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.175234e+01/ 轮得分 49.85\n",
      "损失函数： 0.0307511\n",
      "时间步 32000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.232991e+01/ 轮得分 50.35\n",
      "损失函数： 0.234209\n",
      "时间步 33000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.308821e+01/ 轮得分 49.42\n",
      "损失函数： 0.129013\n",
      "时间步 34000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.122215e+01/ 轮得分 49.79\n",
      "损失函数： 0.129779\n",
      "时间步 35000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.380709e+01/ 轮得分 50.30\n",
      "损失函数： 0.103446\n",
      "时间步 36000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.248988e+01/ 轮得分 52.15\n",
      "损失函数： 0.185942\n",
      "时间步 37000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.372545e+01/ 轮得分 52.02\n",
      "损失函数： 0.0400995\n",
      "时间步 38000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.162241e+01/ 轮得分 52.22\n",
      "损失函数： 1.9291\n",
      "时间步 39000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.043690e+01/ 轮得分 52.80\n",
      "损失函数： 0.0924286\n",
      "时间步 40000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.178882e+01/ 轮得分 52.57\n",
      "损失函数： 0.102793\n",
      "时间步 41000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.013394e+01/ 轮得分 51.61\n",
      "损失函数： 0.15942\n",
      "时间步 42000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.223734e+01/ 轮得分 53.05\n",
      "损失函数： 0.0925306\n",
      "时间步 43000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.009139e+01/ 轮得分 52.95\n",
      "损失函数： 0.0870069\n",
      "时间步 44000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 8.656145e+00/ 轮得分 52.94\n",
      "损失函数： 0.0780126\n",
      "时间步 45000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.163178e+01/ 轮得分 52.84\n",
      "损失函数： 1.09945\n",
      "时间步 46000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 8.837207e+00/ 轮得分 53.21\n",
      "损失函数： 0.0338509\n",
      "时间步 47000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.267019e+01/ 轮得分 52.32\n",
      "损失函数： 0.0689853\n",
      "时间步 48000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.401072e+01/ 轮得分 51.57\n",
      "损失函数： 0.0301473\n",
      "时间步 49000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.027910e+01/ 轮得分 51.24\n",
      "损失函数： 0.100644\n",
      "时间步 50000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.014958e+01/ 轮得分 52.38\n",
      "损失函数： 0.0803042\n",
      "时间步 51000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 4.564976e+00/ 轮得分 51.93\n",
      "损失函数： 0.784939\n",
      "时间步 52000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.206117e+01/ 轮得分 51.99\n",
      "损失函数： 0.0345998\n",
      "时间步 53000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.489329e+01/ 轮得分 51.67\n",
      "损失函数： 0.154951\n",
      "时间步 54000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.399775e+01/ 轮得分 50.59\n",
      "损失函数： 0.0491667\n",
      "时间步 55000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.177843e+01/ 轮得分 50.91\n",
      "损失函数： 0.0438544\n",
      "时间步 56000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 6.983829e+00/ 轮得分 50.71\n",
      "损失函数： 0.0752043\n",
      "时间步 57000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.037436e+01/ 轮得分 50.54\n",
      "损失函数： 0.0785666\n",
      "时间步 58000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.019016e+01/ 轮得分 51.04\n",
      "损失函数： 0.0643179\n",
      "时间步 59000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.076029e+01/ 轮得分 50.31\n",
      "损失函数： 0.0517953\n",
      "时间步 60000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.500254e+01/ 轮得分 49.84\n",
      "损失函数： 0.095828\n",
      "时间步 61000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 3.991109e+00/ 轮得分 49.94\n",
      "损失函数： 0.0342412\n",
      "时间步 62000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 8.026046e+00/ 轮得分 49.59\n",
      "损失函数： 0.138618\n",
      "时间步 63000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.052437e+01/ 轮得分 49.54\n",
      "损失函数： 0.0819859\n",
      "时间步 64000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.442077e+01/ 轮得分 49.61\n",
      "损失函数： 0.0398701\n",
      "时间步 65000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.247311e+01/ 轮得分 50.30\n",
      "损失函数： 0.138396\n",
      "时间步 66000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.229515e+01/ 轮得分 50.25\n",
      "损失函数： 0.0453526\n",
      "时间步 67000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.067780e+01/ 轮得分 50.39\n",
      "损失函数： 0.0817371\n",
      "时间步 68000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.260643e+01/ 轮得分 50.36\n",
      "损失函数： 0.172048\n",
      "时间步 69000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.018441e+01/ 轮得分 50.36\n",
      "损失函数： 0.170639\n",
      "时间步 70000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.261138e+01/ 轮得分 51.26\n",
      "损失函数： 0.141137\n",
      "时间步 71000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.137264e+01/ 轮得分 51.71\n",
      "损失函数： 1.18463\n",
      "时间步 72000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.421913e+01/ 轮得分 51.56\n",
      "损失函数： 0.07316\n",
      "时间步 73000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 9.387592e+00/ 轮得分 51.82\n",
      "损失函数： 0.137414\n",
      "时间步 74000/ 状态 explore/ Epsilon 0.20/ 行动 1/ 奖励 0.1/ Q_MAX 8.538734e+00/ 轮得分 51.20\n",
      "损失函数： 0.0704297\n",
      "时间步 75000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.385470e+01/ 轮得分 50.61\n",
      "损失函数： 0.155558\n",
      "时间步 76000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.501179e+01/ 轮得分 51.25\n",
      "损失函数： 0.193196\n",
      "时间步 77000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.003871e+01/ 轮得分 51.83\n",
      "损失函数： 0.225838\n",
      "时间步 78000/ 状态 explore/ Epsilon 0.20/ 行动 2/ 奖励 0.1/ Q_MAX 1.422074e+01/ 轮得分 51.69\n",
      "损失函数： 0.0880863\n",
      "时间步 79000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 1.197144e+01/ 轮得分 52.12\n",
      "损失函数： 0.057964\n",
      "时间步 80000/ 状态 explore/ Epsilon 0.20/ 行动 0/ 奖励 0.1/ Q_MAX 9.959383e+00/ 轮得分 52.09\n",
      "损失函数： 0.200689\n",
      "时间步 81000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.061825e+01/ 轮得分 52.19\n",
      "损失函数： 0.0584478\n",
      "时间步 82000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 8.074192e+00/ 轮得分 51.59\n",
      "损失函数： 0.0438965\n",
      "时间步 83000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.310603e+01/ 轮得分 51.38\n",
      "损失函数： 0.0923777\n",
      "时间步 84000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.274642e+01/ 轮得分 51.40\n",
      "损失函数： 0.0959519\n",
      "时间步 85000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.428659e+01/ 轮得分 51.64\n",
      "损失函数： 0.0621463\n",
      "时间步 86000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 7.404690e+00/ 轮得分 51.95\n",
      "损失函数： 0.0733384\n",
      "时间步 87000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.195720e+01/ 轮得分 51.40\n",
      "损失函数： 0.0755876\n",
      "时间步 88000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.204306e+01/ 轮得分 50.83\n",
      "损失函数： 0.0901899\n",
      "时间步 89000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.015462e+01/ 轮得分 51.14\n",
      "损失函数： 0.0559025\n",
      "时间步 90000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.022477e+01/ 轮得分 51.27\n",
      "损失函数： 0.119287\n",
      "时间步 91000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.243061e+01/ 轮得分 51.14\n",
      "损失函数： 0.0969725\n",
      "时间步 92000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 9.785648e+00/ 轮得分 50.84\n",
      "损失函数： 0.0539618\n",
      "时间步 93000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 9.920502e+00/ 轮得分 50.64\n",
      "损失函数： 0.0516023\n",
      "时间步 94000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.086481e+01/ 轮得分 50.34\n",
      "损失函数： 0.0990176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 95000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.317497e+01/ 轮得分 50.70\n",
      "损失函数： 0.0960017\n",
      "时间步 96000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 8.976020e+00/ 轮得分 50.65\n",
      "损失函数： 0.100324\n",
      "时间步 97000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.087120e+01/ 轮得分 50.49\n",
      "损失函数： 0.315624\n",
      "时间步 98000/ 状态 explore/ Epsilon 0.19/ 行动 1/ 奖励 0.1/ Q_MAX 1.046627e+01/ 轮得分 50.53\n",
      "损失函数： 0.107109\n",
      "时间步 99000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 6.860285e+00/ 轮得分 50.38\n",
      "损失函数： 0.0413301\n",
      "时间步 100000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 9.758416e+00/ 轮得分 50.14\n",
      "损失函数： 0.045304\n",
      "时间步 101000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.114892e+01/ 轮得分 49.80\n",
      "损失函数： 0.115859\n",
      "时间步 102000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 9.629707e+00/ 轮得分 49.86\n",
      "损失函数： 0.0358414\n",
      "时间步 103000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.155232e+01/ 轮得分 49.38\n",
      "损失函数： 0.147884\n",
      "时间步 104000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 9.809592e+00/ 轮得分 49.46\n",
      "损失函数： 0.0653663\n",
      "时间步 105000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.064287e+01/ 轮得分 49.08\n",
      "损失函数： 0.086216\n",
      "时间步 106000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 9.308532e+00/ 轮得分 49.04\n",
      "损失函数： 1.51848\n",
      "时间步 107000/ 状态 explore/ Epsilon 0.19/ 行动 1/ 奖励 0.1/ Q_MAX 1.249100e+01/ 轮得分 49.05\n",
      "损失函数： 0.0916216\n",
      "时间步 108000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.053421e+01/ 轮得分 48.87\n",
      "损失函数： 0.163117\n",
      "时间步 109000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.116374e+01/ 轮得分 48.63\n",
      "损失函数： 0.0924314\n",
      "时间步 110000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 9.346837e+00/ 轮得分 48.49\n",
      "损失函数： 0.140961\n",
      "时间步 111000/ 状态 explore/ Epsilon 0.19/ 行动 1/ 奖励 0.1/ Q_MAX 1.113494e+01/ 轮得分 48.21\n",
      "损失函数： 0.0878028\n",
      "时间步 112000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 7.763989e+00/ 轮得分 48.19\n",
      "损失函数： 0.0749129\n",
      "时间步 113000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.005054e+01/ 轮得分 47.98\n",
      "损失函数： 0.209553\n",
      "时间步 114000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.280276e+01/ 轮得分 47.63\n",
      "损失函数： 0.0815414\n",
      "时间步 115000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.215607e+01/ 轮得分 47.27\n",
      "损失函数： 0.0960017\n",
      "时间步 116000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.018436e+01/ 轮得分 47.22\n",
      "损失函数： 0.0618062\n",
      "时间步 117000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.084156e+01/ 轮得分 47.36\n",
      "损失函数： 0.0853002\n",
      "时间步 118000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.122666e+01/ 轮得分 47.36\n",
      "损失函数： 0.143799\n",
      "时间步 119000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 9.098978e+00/ 轮得分 47.40\n",
      "损失函数： 0.077943\n",
      "时间步 120000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 8.840495e+00/ 轮得分 47.34\n",
      "损失函数： 0.104022\n",
      "时间步 121000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.077377e+01/ 轮得分 47.51\n",
      "损失函数： 0.162255\n",
      "时间步 122000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.380859e+01/ 轮得分 47.66\n",
      "损失函数： 0.135568\n",
      "时间步 123000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.146656e+01/ 轮得分 47.62\n",
      "损失函数： 0.0364772\n",
      "时间步 124000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.185550e+01/ 轮得分 47.58\n",
      "损失函数： 0.130659\n",
      "时间步 125000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 5.040275e+00/ 轮得分 47.56\n",
      "损失函数： 0.092303\n",
      "时间步 126000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 6.718565e-01/ 轮得分 47.83\n",
      "损失函数： 0.0934014\n",
      "时间步 127000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 8.048288e+00/ 轮得分 47.76\n",
      "损失函数： 0.0889839\n",
      "时间步 128000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 6.607132e-01/ 轮得分 48.07\n",
      "损失函数： 0.198185\n",
      "时间步 129000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.128940e+01/ 轮得分 47.86\n",
      "损失函数： 0.0977398\n",
      "时间步 130000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.088398e+01/ 轮得分 47.85\n",
      "损失函数： 0.2493\n",
      "时间步 131000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 7.904830e+00/ 轮得分 48.08\n",
      "损失函数： 0.0591308\n",
      "时间步 132000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 8.705695e+00/ 轮得分 48.37\n",
      "损失函数： 0.0555833\n",
      "时间步 133000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 7.291177e+00/ 轮得分 48.37\n",
      "损失函数： 0.185566\n",
      "时间步 134000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.039715e+01/ 轮得分 48.29\n",
      "损失函数： 0.0806932\n",
      "时间步 135000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.210125e+01/ 轮得分 48.25\n",
      "损失函数： 0.0799439\n",
      "时间步 136000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.098617e+01/ 轮得分 48.16\n",
      "损失函数： 0.0496473\n",
      "时间步 137000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.699761e+00/ 轮得分 48.31\n",
      "损失函数： 0.0809228\n",
      "时间步 138000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.171328e+01/ 轮得分 48.30\n",
      "损失函数： 0.0683074\n",
      "时间步 139000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 9.200780e+00/ 轮得分 48.20\n",
      "损失函数： 0.0564569\n",
      "时间步 140000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.077527e+01/ 轮得分 48.25\n",
      "损失函数： 0.0726587\n",
      "时间步 141000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 8.455138e+00/ 轮得分 47.94\n",
      "损失函数： 0.0952333\n",
      "时间步 142000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.085383e+01/ 轮得分 47.70\n",
      "损失函数： 0.106218\n",
      "时间步 143000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.186231e+01/ 轮得分 47.54\n",
      "损失函数： 0.0532204\n",
      "时间步 144000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.129801e+01/ 轮得分 47.62\n",
      "损失函数： 0.103697\n",
      "时间步 145000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.150888e+01/ 轮得分 47.87\n",
      "损失函数： 0.0783721\n",
      "时间步 146000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.122889e+01/ 轮得分 48.07\n",
      "损失函数： 0.0508669\n",
      "时间步 147000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 7.184428e+00/ 轮得分 48.08\n",
      "损失函数： 0.133733\n",
      "时间步 148000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.229529e+01/ 轮得分 48.17\n",
      "损失函数： 0.0395937\n",
      "时间步 149000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 9.791152e+00/ 轮得分 48.19\n",
      "损失函数： 0.138965\n",
      "时间步 150000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.108434e+01/ 轮得分 48.19\n",
      "损失函数： 0.111966\n",
      "时间步 151000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.224034e+01/ 轮得分 48.67\n",
      "损失函数： 3.14812\n",
      "时间步 152000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.944476e+00/ 轮得分 48.44\n",
      "损失函数： 0.238676\n",
      "时间步 153000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.133168e+01/ 轮得分 48.43\n",
      "损失函数： 0.25447\n",
      "时间步 154000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.402003e+01/ 轮得分 48.78\n",
      "损失函数： 0.0327513\n",
      "时间步 155000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.125617e+01/ 轮得分 48.86\n",
      "损失函数： 0.118794\n",
      "时间步 156000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.199798e+01/ 轮得分 49.00\n",
      "损失函数： 0.0786437\n",
      "时间步 157000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.127119e+01/ 轮得分 48.82\n",
      "损失函数： 0.150988\n",
      "时间步 158000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.176438e+01/ 轮得分 48.74\n",
      "损失函数： 0.0368766\n",
      "时间步 159000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 8.954540e+00/ 轮得分 48.74\n",
      "损失函数： 0.212492\n",
      "时间步 160000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.228611e+01/ 轮得分 49.15\n",
      "损失函数： 0.163827\n",
      "时间步 161000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.199933e+01/ 轮得分 49.23\n",
      "损失函数： 0.187136\n",
      "时间步 162000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.144631e+01/ 轮得分 49.32\n",
      "损失函数： 2.83537\n",
      "时间步 163000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.041002e+01/ 轮得分 49.16\n",
      "损失函数： 0.0758132\n",
      "时间步 164000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.142371e+01/ 轮得分 49.34\n",
      "损失函数： 0.091425\n",
      "时间步 165000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.199461e+01/ 轮得分 49.43\n",
      "损失函数： 0.127837\n",
      "时间步 166000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.155884e+01/ 轮得分 49.35\n",
      "损失函数： 0.150566\n",
      "时间步 167000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.311391e+01/ 轮得分 49.33\n",
      "损失函数： 0.1199\n",
      "时间步 168000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.104117e+01/ 轮得分 49.27\n",
      "损失函数： 0.17998\n",
      "时间步 169000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.521372e+01/ 轮得分 49.42\n",
      "损失函数： 0.250053\n",
      "时间步 170000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.282423e+01/ 轮得分 49.50\n",
      "损失函数： 0.146486\n",
      "时间步 171000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.092638e+01/ 轮得分 49.51\n",
      "损失函数： 0.0542427\n",
      "时间步 172000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.045444e+01/ 轮得分 49.57\n",
      "损失函数： 0.131515\n",
      "时间步 173000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.120804e+01/ 轮得分 49.70\n",
      "损失函数： 0.0804773\n",
      "时间步 174000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.109844e+01/ 轮得分 49.76\n",
      "损失函数： 0.0448106\n",
      "时间步 175000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.129994e+01/ 轮得分 49.75\n",
      "损失函数： 0.145454\n",
      "时间步 176000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.365528e+01/ 轮得分 49.80\n",
      "损失函数： 0.0886085\n",
      "时间步 177000/ 状态 explore/ Epsilon 0.19/ 行动 1/ 奖励 0.1/ Q_MAX 1.205541e+01/ 轮得分 49.56\n",
      "损失函数： 0.108244\n",
      "时间步 178000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.290819e+01/ 轮得分 49.61\n",
      "损失函数： 0.0567034\n",
      "时间步 179000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.288648e+01/ 轮得分 49.65\n",
      "损失函数： 0.186766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 180000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.006668e+01/ 轮得分 49.59\n",
      "损失函数： 0.0868385\n",
      "时间步 181000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.070648e+01/ 轮得分 49.48\n",
      "损失函数： 0.76483\n",
      "时间步 182000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 1.1/ Q_MAX 9.950573e+00/ 轮得分 49.45\n",
      "损失函数： 0.0647567\n",
      "时间步 183000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 7.730804e+00/ 轮得分 49.12\n",
      "损失函数： 6.3157\n",
      "时间步 184000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.137236e+01/ 轮得分 48.92\n",
      "损失函数： 0.208313\n",
      "时间步 185000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.066272e+01/ 轮得分 48.83\n",
      "损失函数： 0.291029\n",
      "时间步 186000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.021597e+01/ 轮得分 48.76\n",
      "损失函数： 0.0663119\n",
      "时间步 187000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 7.228743e+00/ 轮得分 48.70\n",
      "损失函数： 0.21579\n",
      "时间步 188000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.105377e+01/ 轮得分 48.86\n",
      "损失函数： 0.0495094\n",
      "时间步 189000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX -1.041290e-01/ 轮得分 48.70\n",
      "损失函数： 0.126926\n",
      "时间步 190000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 8.422092e+00/ 轮得分 48.66\n",
      "损失函数： 0.209715\n",
      "时间步 191000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.055686e+01/ 轮得分 48.73\n",
      "损失函数： 0.0709985\n",
      "时间步 192000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.082218e+01/ 轮得分 48.77\n",
      "损失函数： 0.0322505\n",
      "时间步 193000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.080108e+01/ 轮得分 48.93\n",
      "损失函数： 0.0691208\n",
      "时间步 194000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.135743e+01/ 轮得分 48.81\n",
      "损失函数： 0.108726\n",
      "时间步 195000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.100099e+01/ 轮得分 48.81\n",
      "损失函数： 0.0969686\n",
      "时间步 196000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX -2.163756e-01/ 轮得分 48.80\n",
      "损失函数： 0.197437\n",
      "时间步 197000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 8.424786e+00/ 轮得分 48.86\n",
      "损失函数： 0.120295\n",
      "时间步 198000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.186633e+01/ 轮得分 48.91\n",
      "损失函数： 0.0476211\n",
      "时间步 199000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.137519e+01/ 轮得分 49.09\n",
      "损失函数： 0.0669486\n",
      "时间步 200000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 7.230271e+00/ 轮得分 49.00\n",
      "损失函数： 0.338126\n",
      "时间步 201000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.129181e+01/ 轮得分 49.18\n",
      "损失函数： 0.108512\n",
      "时间步 202000/ 状态 explore/ Epsilon 0.19/ 行动 1/ 奖励 0.1/ Q_MAX 8.536794e+00/ 轮得分 49.22\n",
      "损失函数： 0.14088\n",
      "时间步 203000/ 状态 explore/ Epsilon 0.19/ 行动 1/ 奖励 0.1/ Q_MAX 1.254668e+01/ 轮得分 49.18\n",
      "损失函数： 0.0806553\n",
      "时间步 204000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.012775e+01/ 轮得分 49.19\n",
      "损失函数： 0.136221\n",
      "时间步 205000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.113669e+01/ 轮得分 49.08\n",
      "损失函数： 0.0446285\n",
      "时间步 206000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 8.221246e+00/ 轮得分 49.12\n",
      "损失函数： 0.0834858\n",
      "时间步 207000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.085432e+01/ 轮得分 49.14\n",
      "损失函数： 0.0501901\n",
      "时间步 208000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.101874e+01/ 轮得分 49.03\n",
      "损失函数： 0.0535417\n",
      "时间步 209000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 8.963839e+00/ 轮得分 49.21\n",
      "损失函数： 0.292263\n",
      "时间步 210000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.172015e+01/ 轮得分 49.31\n",
      "损失函数： 0.208057\n",
      "时间步 211000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.097316e+01/ 轮得分 49.27\n",
      "损失函数： 0.0371189\n",
      "时间步 212000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 6.995631e-01/ 轮得分 49.18\n",
      "损失函数： 0.0664497\n",
      "时间步 213000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.038932e+01/ 轮得分 49.23\n",
      "损失函数： 0.125507\n",
      "时间步 214000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.530079e+01/ 轮得分 49.19\n",
      "损失函数： 0.196515\n",
      "时间步 215000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.220584e+01/ 轮得分 49.32\n",
      "损失函数： 0.0517264\n",
      "时间步 216000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.227580e+01/ 轮得分 49.53\n",
      "损失函数： 0.0495204\n",
      "时间步 217000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.075478e+01/ 轮得分 49.54\n",
      "损失函数： 0.111836\n",
      "时间步 218000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.304288e+01/ 轮得分 49.68\n",
      "损失函数： 0.063236\n",
      "时间步 219000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.115823e+01/ 轮得分 49.71\n",
      "损失函数： 0.230979\n",
      "时间步 220000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 6.736747e+00/ 轮得分 49.64\n",
      "损失函数： 0.0779761\n",
      "时间步 221000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.232660e+01/ 轮得分 49.56\n",
      "损失函数： 0.0770567\n",
      "时间步 222000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.087062e+01/ 轮得分 49.58\n",
      "损失函数： 0.0780116\n",
      "时间步 223000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.399725e+01/ 轮得分 49.68\n",
      "损失函数： 0.0529913\n",
      "时间步 224000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.085224e+01/ 轮得分 49.57\n",
      "损失函数： 0.0448317\n",
      "时间步 225000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.167007e+01/ 轮得分 49.47\n",
      "损失函数： 0.109007\n",
      "时间步 226000/ 状态 explore/ Epsilon 0.19/ 行动 2/ 奖励 0.1/ Q_MAX 1.323827e+01/ 轮得分 49.51\n",
      "损失函数： 0.0904463\n",
      "时间步 227000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.205588e+01/ 轮得分 49.42\n",
      "损失函数： 0.129956\n",
      "时间步 228000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 1.114389e+01/ 轮得分 49.57\n",
      "损失函数： 0.0662499\n",
      "时间步 229000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 0.1/ Q_MAX 9.210515e+00/ 轮得分 49.55\n",
      "损失函数： 0.101261\n",
      "时间步 230000/ 状态 explore/ Epsilon 0.19/ 行动 0/ 奖励 1.1/ Q_MAX 1.081527e+01/ 轮得分 49.41\n",
      "损失函数： 0.111805\n",
      "时间步 231000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.330429e+01/ 轮得分 49.42\n",
      "损失函数： 0.0819456\n",
      "时间步 232000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.178674e+01/ 轮得分 49.47\n",
      "损失函数： 0.0485363\n",
      "时间步 233000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 8.968788e+00/ 轮得分 49.44\n",
      "损失函数： 0.0345972\n",
      "时间步 234000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 6.073936e+00/ 轮得分 49.38\n",
      "损失函数： 0.0962777\n",
      "时间步 235000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.025245e+01/ 轮得分 49.43\n",
      "损失函数： 0.0624993\n",
      "时间步 236000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 8.484025e+00/ 轮得分 49.46\n",
      "损失函数： 0.0966177\n",
      "时间步 237000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.048599e+01/ 轮得分 49.42\n",
      "损失函数： 0.0762015\n",
      "时间步 238000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.372852e+01/ 轮得分 49.49\n",
      "损失函数： 0.108492\n",
      "时间步 239000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.033341e+01/ 轮得分 49.56\n",
      "损失函数： 0.0388665\n",
      "时间步 240000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.326346e+01/ 轮得分 49.68\n",
      "损失函数： 0.0494026\n",
      "时间步 241000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.229809e+01/ 轮得分 49.67\n",
      "损失函数： 0.0848413\n",
      "时间步 242000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.056807e+01/ 轮得分 49.74\n",
      "损失函数： 0.100789\n",
      "时间步 243000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.367323e+01/ 轮得分 49.63\n",
      "损失函数： 0.0476939\n",
      "时间步 244000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 8.756817e+00/ 轮得分 49.65\n",
      "损失函数： 0.106255\n",
      "时间步 245000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.223984e+01/ 轮得分 49.71\n",
      "损失函数： 0.183361\n",
      "时间步 246000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.168778e+01/ 轮得分 49.62\n",
      "损失函数： 0.0916465\n",
      "时间步 247000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.053063e+01/ 轮得分 49.57\n",
      "损失函数： 0.178686\n",
      "时间步 248000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.232743e+01/ 轮得分 49.79\n",
      "损失函数： 0.0549786\n",
      "时间步 249000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.049597e+01/ 轮得分 49.79\n",
      "损失函数： 0.0865962\n",
      "时间步 250000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 9.435033e+00/ 轮得分 50.14\n",
      "损失函数： 0.119127\n",
      "时间步 251000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.182006e+01/ 轮得分 50.13\n",
      "损失函数： 0.133949\n",
      "时间步 252000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.158361e+01/ 轮得分 50.28\n",
      "损失函数： 0.0292716\n",
      "时间步 253000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.236015e+01/ 轮得分 50.28\n",
      "损失函数： 0.131887\n",
      "时间步 254000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.250215e+01/ 轮得分 50.57\n",
      "损失函数： 0.0702498\n",
      "时间步 255000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.274544e+01/ 轮得分 50.57\n",
      "损失函数： 0.0380603\n",
      "时间步 256000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.148277e+01/ 轮得分 50.85\n",
      "损失函数： 0.0728273\n",
      "时间步 257000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.201222e+01/ 轮得分 50.77\n",
      "损失函数： 0.17721\n",
      "时间步 258000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.351806e+01/ 轮得分 50.68\n",
      "损失函数： 0.130808\n",
      "时间步 259000/ 状态 explore/ Epsilon 0.18/ 行动 1/ 奖励 0.1/ Q_MAX 4.456452e+00/ 轮得分 50.68\n",
      "损失函数： 0.115691\n",
      "时间步 260000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.130117e+01/ 轮得分 50.84\n",
      "损失函数： 0.187809\n",
      "时间步 261000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.315200e+01/ 轮得分 50.69\n",
      "损失函数： 0.522593\n",
      "时间步 262000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.147354e+01/ 轮得分 50.57\n",
      "损失函数： 0.079079\n",
      "时间步 263000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 8.792668e+00/ 轮得分 50.58\n",
      "损失函数： 0.0760653\n",
      "时间步 264000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.168392e+01/ 轮得分 50.53\n",
      "损失函数： 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 265000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 8.451674e+00/ 轮得分 50.49\n",
      "损失函数： 0.0606363\n",
      "时间步 266000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.135862e+01/ 轮得分 50.56\n",
      "损失函数： 0.073372\n",
      "时间步 267000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.118546e+01/ 轮得分 50.58\n",
      "损失函数： 0.0828719\n",
      "时间步 268000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.290794e+01/ 轮得分 50.51\n",
      "损失函数： 0.126261\n",
      "时间步 269000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 7.697596e+00/ 轮得分 50.47\n",
      "损失函数： 0.0681697\n",
      "时间步 270000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.215415e+01/ 轮得分 50.43\n",
      "损失函数： 0.0927714\n",
      "时间步 271000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.099031e+01/ 轮得分 50.45\n",
      "损失函数： 0.104789\n",
      "时间步 272000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 4.621116e+00/ 轮得分 50.45\n",
      "损失函数： 0.0572281\n",
      "时间步 273000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 9.918471e+00/ 轮得分 50.71\n",
      "损失函数： 0.103373\n",
      "时间步 274000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.289599e+01/ 轮得分 50.59\n",
      "损失函数： 0.0706506\n",
      "时间步 275000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.273255e+01/ 轮得分 50.77\n",
      "损失函数： 0.0431102\n",
      "时间步 276000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.211999e+01/ 轮得分 50.81\n",
      "损失函数： 0.192501\n",
      "时间步 277000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.204173e+01/ 轮得分 50.81\n",
      "损失函数： 0.0770719\n",
      "时间步 278000/ 状态 explore/ Epsilon 0.18/ 行动 1/ 奖励 0.1/ Q_MAX 9.917439e+00/ 轮得分 51.03\n",
      "损失函数： 1.65282\n",
      "时间步 279000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.139176e+01/ 轮得分 51.07\n",
      "损失函数： 0.107241\n",
      "时间步 280000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.089568e+01/ 轮得分 51.12\n",
      "损失函数： 0.174279\n",
      "时间步 281000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.042364e+01/ 轮得分 51.11\n",
      "损失函数： 0.211488\n",
      "时间步 282000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.100904e+01/ 轮得分 51.16\n",
      "损失函数： 0.0537735\n",
      "时间步 283000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.274001e+01/ 轮得分 51.18\n",
      "损失函数： 0.164823\n",
      "时间步 284000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 8.355537e+00/ 轮得分 51.14\n",
      "损失函数： 0.124394\n",
      "时间步 285000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 8.994301e+00/ 轮得分 50.94\n",
      "损失函数： 0.0508245\n",
      "时间步 286000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.034922e+01/ 轮得分 50.93\n",
      "损失函数： 0.164154\n",
      "时间步 287000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.190091e+01/ 轮得分 50.88\n",
      "损失函数： 0.138987\n",
      "时间步 288000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 -1/ Q_MAX 4.073489e+00/ 轮得分 51.08\n",
      "损失函数： 0.158924\n",
      "时间步 289000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.334714e+01/ 轮得分 51.08\n",
      "损失函数： 0.0823578\n",
      "时间步 290000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.238938e+01/ 轮得分 51.08\n",
      "损失函数： 0.0429202\n",
      "时间步 291000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.030829e+01/ 轮得分 51.46\n",
      "损失函数： 0.0941684\n",
      "时间步 292000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.162285e+01/ 轮得分 51.46\n",
      "损失函数： 0.041443\n",
      "时间步 293000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 7.608620e+00/ 轮得分 51.84\n",
      "损失函数： 0.233997\n",
      "时间步 294000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.261464e+01/ 轮得分 51.79\n",
      "损失函数： 0.0547463\n",
      "时间步 295000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.187849e+01/ 轮得分 51.78\n",
      "损失函数： 0.117196\n",
      "时间步 296000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.323432e+01/ 轮得分 51.80\n",
      "损失函数： 1.58451\n",
      "时间步 297000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.112053e+01/ 轮得分 51.84\n",
      "损失函数： 0.107611\n",
      "时间步 298000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.155995e+01/ 轮得分 51.83\n",
      "损失函数： 0.460372\n",
      "时间步 299000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.193213e+01/ 轮得分 51.87\n",
      "损失函数： 0.117785\n",
      "时间步 300000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 8.755836e+00/ 轮得分 51.86\n",
      "损失函数： 0.235211\n",
      "时间步 301000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.372364e+01/ 轮得分 52.06\n",
      "损失函数： 0.067752\n",
      "时间步 302000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.299145e+01/ 轮得分 52.09\n",
      "损失函数： 0.123691\n",
      "时间步 303000/ 状态 explore/ Epsilon 0.18/ 行动 1/ 奖励 0.1/ Q_MAX 1.374269e+01/ 轮得分 52.24\n",
      "损失函数： 0.0589198\n",
      "时间步 304000/ 状态 explore/ Epsilon 0.18/ 行动 1/ 奖励 0.1/ Q_MAX 1.004850e+01/ 轮得分 52.19\n",
      "损失函数： 0.103038\n",
      "时间步 305000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.156341e+01/ 轮得分 52.10\n",
      "损失函数： 0.0624859\n",
      "时间步 306000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.222941e+01/ 轮得分 52.10\n",
      "损失函数： 0.152609\n",
      "时间步 307000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.246690e+01/ 轮得分 52.46\n",
      "损失函数： 0.0671704\n",
      "时间步 308000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 9.775523e+00/ 轮得分 52.37\n",
      "损失函数： 0.069261\n",
      "时间步 309000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.226899e+01/ 轮得分 52.36\n",
      "损失函数： 0.161111\n",
      "时间步 310000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.303497e+01/ 轮得分 52.32\n",
      "损失函数： 0.0488616\n",
      "时间步 311000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.030049e+01/ 轮得分 52.37\n",
      "损失函数： 0.0889246\n",
      "时间步 312000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.289430e+01/ 轮得分 52.31\n",
      "损失函数： 0.0716018\n",
      "时间步 313000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.297674e+01/ 轮得分 52.39\n",
      "损失函数： 0.0770927\n",
      "时间步 314000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.238081e+01/ 轮得分 52.40\n",
      "损失函数： 0.215552\n",
      "时间步 315000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.170668e+01/ 轮得分 52.42\n",
      "损失函数： 0.0722551\n",
      "时间步 316000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.219333e+01/ 轮得分 52.39\n",
      "损失函数： 0.12282\n",
      "时间步 317000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.134771e+01/ 轮得分 52.44\n",
      "损失函数： 0.0361567\n",
      "时间步 318000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.578694e+01/ 轮得分 52.60\n",
      "损失函数： 0.0972\n",
      "时间步 319000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.158699e+01/ 轮得分 52.63\n",
      "损失函数： 0.0696921\n",
      "时间步 320000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.220367e+01/ 轮得分 52.76\n",
      "损失函数： 0.19114\n",
      "时间步 321000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.063564e+01/ 轮得分 52.81\n",
      "损失函数： 0.0760544\n",
      "时间步 322000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.077296e+01/ 轮得分 52.81\n",
      "损失函数： 0.130522\n",
      "时间步 323000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.091167e+01/ 轮得分 52.97\n",
      "损失函数： 0.193561\n",
      "时间步 324000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.147171e+01/ 轮得分 52.89\n",
      "损失函数： 0.0880299\n",
      "时间步 325000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 7.785426e+00/ 轮得分 52.89\n",
      "损失函数： 0.178032\n",
      "时间步 326000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.302675e+01/ 轮得分 53.06\n",
      "损失函数： 0.0340722\n",
      "时间步 327000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.421021e+01/ 轮得分 53.06\n",
      "损失函数： 0.0696529\n",
      "时间步 328000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.204091e+01/ 轮得分 53.25\n",
      "损失函数： 0.0903875\n",
      "时间步 329000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.396486e+01/ 轮得分 53.27\n",
      "损失函数： 0.0763655\n",
      "时间步 330000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.344624e+01/ 轮得分 53.17\n",
      "损失函数： 0.203886\n",
      "时间步 331000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.433623e+01/ 轮得分 53.24\n",
      "损失函数： 0.120504\n",
      "时间步 332000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.243850e+01/ 轮得分 53.24\n",
      "损失函数： 0.0932043\n",
      "时间步 333000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 8.407284e+00/ 轮得分 53.24\n",
      "损失函数： 0.038753\n",
      "时间步 334000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.071222e+01/ 轮得分 53.57\n",
      "损失函数： 0.108204\n",
      "时间步 335000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 9.416843e+00/ 轮得分 53.56\n",
      "损失函数： 0.0885438\n",
      "时间步 336000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.155818e+01/ 轮得分 53.50\n",
      "损失函数： 0.0673724\n",
      "时间步 337000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.320870e+01/ 轮得分 53.50\n",
      "损失函数： 0.213325\n",
      "时间步 338000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.439463e+01/ 轮得分 53.81\n",
      "损失函数： 0.184349\n",
      "时间步 339000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.229516e+01/ 轮得分 53.81\n",
      "损失函数： 0.0717703\n",
      "时间步 340000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.314928e+01/ 轮得分 53.81\n",
      "损失函数： 0.113789\n",
      "时间步 341000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.099713e+01/ 轮得分 53.99\n",
      "损失函数： 0.0818507\n",
      "时间步 342000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.219055e+01/ 轮得分 53.99\n",
      "损失函数： 0.0854202\n",
      "时间步 343000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.184585e+01/ 轮得分 54.05\n",
      "损失函数： 0.0838505\n",
      "时间步 344000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.146428e+01/ 轮得分 54.12\n",
      "损失函数： 0.0946671\n",
      "时间步 345000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.429864e+01/ 轮得分 54.18\n",
      "损失函数： 0.0899869\n",
      "时间步 346000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.238488e+01/ 轮得分 54.18\n",
      "损失函数： 0.0298463\n",
      "时间步 347000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.209776e+01/ 轮得分 54.18\n",
      "损失函数： 0.0854572\n",
      "时间步 348000/ 状态 explore/ Epsilon 0.18/ 行动 1/ 奖励 0.1/ Q_MAX 1.043587e+01/ 轮得分 54.57\n",
      "损失函数： 0.0386997\n",
      "时间步 349000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.163007e+01/ 轮得分 54.65\n",
      "损失函数： 0.049331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 350000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.180791e+01/ 轮得分 54.65\n",
      "损失函数： 0.114085\n",
      "时间步 351000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.265911e+01/ 轮得分 54.59\n",
      "损失函数： 0.104154\n",
      "时间步 352000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.252962e+01/ 轮得分 54.65\n",
      "损失函数： 0.0502789\n",
      "时间步 353000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 9.159765e+00/ 轮得分 54.57\n",
      "损失函数： 0.0790631\n",
      "时间步 354000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.281281e+01/ 轮得分 54.55\n",
      "损失函数： 0.0470721\n",
      "时间步 355000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.258810e+01/ 轮得分 54.47\n",
      "损失函数： 0.168296\n",
      "时间步 356000/ 状态 explore/ Epsilon 0.18/ 行动 1/ 奖励 0.1/ Q_MAX 7.658892e+00/ 轮得分 54.59\n",
      "损失函数： 0.085372\n",
      "时间步 357000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.273576e+01/ 轮得分 54.51\n",
      "损失函数： 0.099091\n",
      "时间步 358000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 8.557486e+00/ 轮得分 54.49\n",
      "损失函数： 0.290855\n",
      "时间步 359000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.208554e+01/ 轮得分 54.46\n",
      "损失函数： 0.0648329\n",
      "时间步 360000/ 状态 explore/ Epsilon 0.18/ 行动 1/ 奖励 0.1/ Q_MAX 1.107788e+01/ 轮得分 54.41\n",
      "损失函数： 0.0811763\n",
      "时间步 361000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.249840e+01/ 轮得分 54.52\n",
      "损失函数： 0.0661366\n",
      "时间步 362000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.237719e+01/ 轮得分 54.58\n",
      "损失函数： 0.0436944\n",
      "时间步 363000/ 状态 explore/ Epsilon 0.18/ 行动 1/ 奖励 0.1/ Q_MAX 6.965187e+00/ 轮得分 54.58\n",
      "损失函数： 0.130987\n",
      "时间步 364000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.250672e+01/ 轮得分 54.68\n",
      "损失函数： 0.0523586\n",
      "时间步 365000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 5.155485e+00/ 轮得分 54.68\n",
      "损失函数： 0.0219434\n",
      "时间步 366000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.056384e+01/ 轮得分 54.78\n",
      "损失函数： 0.127398\n",
      "时间步 367000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.283522e+01/ 轮得分 54.83\n",
      "损失函数： 0.19867\n",
      "时间步 368000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.322134e+01/ 轮得分 54.83\n",
      "损失函数： 0.0549655\n",
      "时间步 369000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 5.483337e-01/ 轮得分 54.91\n",
      "损失函数： 0.507388\n",
      "时间步 370000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.348448e+01/ 轮得分 54.98\n",
      "损失函数： 0.118563\n",
      "时间步 371000/ 状态 explore/ Epsilon 0.18/ 行动 1/ 奖励 0.1/ Q_MAX 1.399832e+01/ 轮得分 54.98\n",
      "损失函数： 0.131602\n",
      "时间步 372000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.209528e+01/ 轮得分 55.22\n",
      "损失函数： 0.144039\n",
      "时间步 373000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.073063e+01/ 轮得分 55.13\n",
      "损失函数： 0.0443269\n",
      "时间步 374000/ 状态 explore/ Epsilon 0.18/ 行动 2/ 奖励 0.1/ Q_MAX 1.007163e+01/ 轮得分 55.05\n",
      "损失函数： 0.117091\n",
      "时间步 375000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.392387e+01/ 轮得分 55.04\n",
      "损失函数： 0.0575654\n",
      "时间步 376000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.440075e+01/ 轮得分 55.06\n",
      "损失函数： 0.0519484\n",
      "时间步 377000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.325582e+01/ 轮得分 55.07\n",
      "损失函数： 0.0421941\n",
      "时间步 378000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.168386e+01/ 轮得分 55.07\n",
      "损失函数： 0.134801\n",
      "时间步 379000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.169423e+01/ 轮得分 55.06\n",
      "损失函数： 0.174985\n",
      "时间步 380000/ 状态 explore/ Epsilon 0.18/ 行动 0/ 奖励 0.1/ Q_MAX 1.258507e+01/ 轮得分 55.03\n",
      "损失函数： 0.042516\n",
      "时间步 381000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 1.202646e+01/ 轮得分 55.08\n",
      "损失函数： 0.0207249\n",
      "时间步 382000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 8.849933e+00/ 轮得分 55.11\n",
      "损失函数： 4.35757\n",
      "时间步 383000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.429239e+00/ 轮得分 55.16\n",
      "损失函数： 0.076091\n",
      "时间步 384000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.040149e+01/ 轮得分 55.17\n",
      "损失函数： 0.0531706\n",
      "时间步 385000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.184483e+01/ 轮得分 55.03\n",
      "损失函数： 0.0582057\n",
      "时间步 386000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.172326e+01/ 轮得分 54.98\n",
      "损失函数： 0.124603\n",
      "时间步 387000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.078123e+01/ 轮得分 55.09\n",
      "损失函数： 0.0760805\n",
      "时间步 388000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.186683e+01/ 轮得分 55.11\n",
      "损失函数： 0.137141\n",
      "时间步 389000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.178582e+01/ 轮得分 55.14\n",
      "损失函数： 0.0560634\n",
      "时间步 390000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.845348e+00/ 轮得分 55.24\n",
      "损失函数： 0.049942\n",
      "时间步 391000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.145200e+01/ 轮得分 55.28\n",
      "损失函数： 0.17611\n",
      "时间步 392000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.119960e+01/ 轮得分 55.29\n",
      "损失函数： 0.0393402\n",
      "时间步 393000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.187871e+01/ 轮得分 55.29\n",
      "损失函数： 0.0410335\n",
      "时间步 394000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 1.097249e+01/ 轮得分 55.41\n",
      "损失函数： 0.0881558\n",
      "时间步 395000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.329271e+01/ 轮得分 55.47\n",
      "损失函数： 0.182446\n",
      "时间步 396000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.070473e+01/ 轮得分 55.47\n",
      "损失函数： 0.0484267\n",
      "时间步 397000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.144964e+01/ 轮得分 55.58\n",
      "损失函数： 0.0720359\n",
      "时间步 398000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.113339e+01/ 轮得分 55.60\n",
      "损失函数： 0.0483354\n",
      "时间步 399000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.430201e+00/ 轮得分 55.64\n",
      "损失函数： 0.141524\n",
      "时间步 400000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.392589e+00/ 轮得分 55.70\n",
      "损失函数： 1.64727\n",
      "时间步 401000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.002779e+01/ 轮得分 55.81\n",
      "损失函数： 0.0615565\n",
      "时间步 402000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.072289e+01/ 轮得分 55.81\n",
      "损失函数： 0.0812042\n",
      "时间步 403000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.194711e+01/ 轮得分 55.79\n",
      "损失函数： 0.0295124\n",
      "时间步 404000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.024227e+01/ 轮得分 55.81\n",
      "损失函数： 0.0532013\n",
      "时间步 405000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.325385e+01/ 轮得分 55.82\n",
      "损失函数： 0.0778036\n",
      "时间步 406000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 8.337581e+00/ 轮得分 55.87\n",
      "损失函数： 0.0864731\n",
      "时间步 407000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.120230e+01/ 轮得分 55.89\n",
      "损失函数： 1.96006\n",
      "时间步 408000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.366977e+01/ 轮得分 55.91\n",
      "损失函数： 0.093291\n",
      "时间步 409000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.822403e+00/ 轮得分 55.91\n",
      "损失函数： 0.0497914\n",
      "时间步 410000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 8.100465e+00/ 轮得分 56.12\n",
      "损失函数： 0.0602447\n",
      "时间步 411000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.362441e+01/ 轮得分 56.13\n",
      "损失函数： 0.0494424\n",
      "时间步 412000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.113969e+01/ 轮得分 56.11\n",
      "损失函数： 0.144105\n",
      "时间步 413000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.201470e+01/ 轮得分 56.19\n",
      "损失函数： 0.0474375\n",
      "时间步 414000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.306738e+01/ 轮得分 56.26\n",
      "损失函数： 0.048917\n",
      "时间步 415000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.187487e+01/ 轮得分 56.26\n",
      "损失函数： 0.0877616\n",
      "时间步 416000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 1.1/ Q_MAX 8.567185e+00/ 轮得分 56.44\n",
      "损失函数： 0.144602\n",
      "时间步 417000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.386392e+01/ 轮得分 56.46\n",
      "损失函数： 0.0490653\n",
      "时间步 418000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.189415e+01/ 轮得分 56.48\n",
      "损失函数： 0.0353792\n",
      "时间步 419000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.648699e+00/ 轮得分 56.47\n",
      "损失函数： 0.219585\n",
      "时间步 420000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.313390e+01/ 轮得分 56.37\n",
      "损失函数： 0.0934826\n",
      "时间步 421000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 1.262246e+01/ 轮得分 56.33\n",
      "损失函数： 0.140737\n",
      "时间步 422000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.098667e+01/ 轮得分 56.33\n",
      "损失函数： 0.0245851\n",
      "时间步 423000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 1.540008e+01/ 轮得分 56.48\n",
      "损失函数： 0.0674689\n",
      "时间步 424000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.292419e+01/ 轮得分 56.40\n",
      "损失函数： 0.0902019\n",
      "时间步 425000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.294086e+01/ 轮得分 56.33\n",
      "损失函数： 0.0683423\n",
      "时间步 426000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.079163e+01/ 轮得分 56.38\n",
      "损失函数： 0.209654\n",
      "时间步 427000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.266833e+01/ 轮得分 56.32\n",
      "损失函数： 0.095659\n",
      "时间步 428000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.118301e+01/ 轮得分 56.34\n",
      "损失函数： 0.0403398\n",
      "时间步 429000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.452649e+01/ 轮得分 56.29\n",
      "损失函数： 0.088196\n",
      "时间步 430000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.247053e+01/ 轮得分 56.27\n",
      "损失函数： 0.0362007\n",
      "时间步 431000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.280937e+01/ 轮得分 56.28\n",
      "损失函数： 0.0425798\n",
      "时间步 432000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 1.1/ Q_MAX 6.938693e+00/ 轮得分 56.14\n",
      "损失函数： 0.0835186\n",
      "时间步 433000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.240675e+01/ 轮得分 56.14\n",
      "损失函数： 0.115541\n",
      "时间步 434000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.152578e+01/ 轮得分 56.23\n",
      "损失函数： 0.0679264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 435000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.251663e+01/ 轮得分 56.28\n",
      "损失函数： 0.121533\n",
      "时间步 436000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.189005e+01/ 轮得分 56.28\n",
      "损失函数： 0.0480011\n",
      "时间步 437000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.909526e+00/ 轮得分 56.50\n",
      "损失函数： 0.0597381\n",
      "时间步 438000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.133384e+01/ 轮得分 56.41\n",
      "损失函数： 0.19969\n",
      "时间步 439000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 9.497091e+00/ 轮得分 56.43\n",
      "损失函数： 0.0781317\n",
      "时间步 440000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.261323e+01/ 轮得分 56.47\n",
      "损失函数： 0.249061\n",
      "时间步 441000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.082611e+01/ 轮得分 56.47\n",
      "损失函数： 0.125534\n",
      "时间步 442000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.115681e+01/ 轮得分 56.72\n",
      "损失函数： 0.158249\n",
      "时间步 443000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.162790e+01/ 轮得分 56.71\n",
      "损失函数： 0.11709\n",
      "时间步 444000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.259031e+01/ 轮得分 56.77\n",
      "损失函数： 0.0847704\n",
      "时间步 445000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.126760e+01/ 轮得分 56.72\n",
      "损失函数： 0.0909659\n",
      "时间步 446000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 1.1/ Q_MAX 1.126215e+01/ 轮得分 56.69\n",
      "损失函数： 0.039014\n",
      "时间步 447000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.119160e+01/ 轮得分 56.75\n",
      "损失函数： 0.110228\n",
      "时间步 448000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.201172e+01/ 轮得分 56.83\n",
      "损失函数： 0.0582632\n",
      "时间步 449000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.988924e+00/ 轮得分 56.93\n",
      "损失函数： 0.0318663\n",
      "时间步 450000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.360948e+01/ 轮得分 56.89\n",
      "损失函数： 0.0616162\n",
      "时间步 451000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 1.156531e+01/ 轮得分 57.02\n",
      "损失函数： 0.0635777\n",
      "时间步 452000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.226764e+01/ 轮得分 57.02\n",
      "损失函数： 0.0501349\n",
      "时间步 453000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.139155e+01/ 轮得分 57.17\n",
      "损失函数： 0.0375245\n",
      "时间步 454000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.280405e+01/ 轮得分 57.20\n",
      "损失函数： 0.100597\n",
      "时间步 455000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.005927e+01/ 轮得分 57.19\n",
      "损失函数： 4.30948\n",
      "时间步 456000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.197132e+01/ 轮得分 57.12\n",
      "损失函数： 0.215467\n",
      "时间步 457000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.082706e+01/ 轮得分 57.16\n",
      "损失函数： 0.0780693\n",
      "时间步 458000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.288454e+01/ 轮得分 57.11\n",
      "损失函数： 0.0495063\n",
      "时间步 459000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.013577e+00/ 轮得分 57.11\n",
      "损失函数： 0.0691449\n",
      "时间步 460000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.167976e+01/ 轮得分 57.33\n",
      "损失函数： 0.074387\n",
      "时间步 461000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.076192e+00/ 轮得分 57.31\n",
      "损失函数： 0.0750926\n",
      "时间步 462000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.137992e+01/ 轮得分 57.38\n",
      "损失函数： 0.317052\n",
      "时间步 463000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.233505e+01/ 轮得分 57.47\n",
      "损失函数： 0.0971769\n",
      "时间步 464000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.191792e+01/ 轮得分 57.48\n",
      "损失函数： 0.109205\n",
      "时间步 465000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 1.187754e+01/ 轮得分 57.37\n",
      "损失函数： 0.185818\n",
      "时间步 466000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.148107e+01/ 轮得分 57.40\n",
      "损失函数： 0.0290766\n",
      "时间步 467000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.232962e+01/ 轮得分 57.36\n",
      "损失函数： 0.0737322\n",
      "时间步 468000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.372744e+01/ 轮得分 57.45\n",
      "损失函数： 0.0401609\n",
      "时间步 469000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.038968e+01/ 轮得分 57.46\n",
      "损失函数： 0.0847295\n",
      "时间步 470000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.409857e+01/ 轮得分 57.43\n",
      "损失函数： 0.0600649\n",
      "时间步 471000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.038470e+01/ 轮得分 57.45\n",
      "损失函数： 0.0647338\n",
      "时间步 472000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.250599e+01/ 轮得分 57.51\n",
      "损失函数： 0.0653335\n",
      "时间步 473000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.472596e+01/ 轮得分 57.50\n",
      "损失函数： 0.0438237\n",
      "时间步 474000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.224743e+01/ 轮得分 57.64\n",
      "损失函数： 0.182562\n",
      "时间步 475000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.339134e+01/ 轮得分 57.62\n",
      "损失函数： 0.0378796\n",
      "时间步 476000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.401442e+01/ 轮得分 57.60\n",
      "损失函数： 0.151572\n",
      "时间步 477000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.495209e+01/ 轮得分 57.59\n",
      "损失函数： 0.0777113\n",
      "时间步 478000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.512894e+01/ 轮得分 57.61\n",
      "损失函数： 3.19776\n",
      "时间步 479000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.228144e+01/ 轮得分 57.62\n",
      "损失函数： 0.0675778\n",
      "时间步 480000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.328708e+01/ 轮得分 57.62\n",
      "损失函数： 0.200726\n",
      "时间步 481000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.420117e+01/ 轮得分 57.80\n",
      "损失函数： 0.0686699\n",
      "时间步 482000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.096789e+01/ 轮得分 57.79\n",
      "损失函数： 0.149122\n",
      "时间步 483000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 1.224210e+01/ 轮得分 57.79\n",
      "损失函数： 0.0633899\n",
      "时间步 484000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.206274e+01/ 轮得分 57.86\n",
      "损失函数： 0.0624836\n",
      "时间步 485000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.424957e+01/ 轮得分 57.86\n",
      "损失函数： 0.117371\n",
      "时间步 486000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.179146e+01/ 轮得分 58.01\n",
      "损失函数： 0.0505778\n",
      "时间步 487000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.231279e+01/ 轮得分 57.99\n",
      "损失函数： 0.0504642\n",
      "时间步 488000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.356678e+01/ 轮得分 57.98\n",
      "损失函数： 0.103223\n",
      "时间步 489000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.254269e+01/ 轮得分 57.98\n",
      "损失函数： 0.0569401\n",
      "时间步 490000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 9.731813e+00/ 轮得分 58.07\n",
      "损失函数： 0.0978872\n",
      "时间步 491000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.171466e+01/ 轮得分 58.08\n",
      "损失函数： 0.0720388\n",
      "时间步 492000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.274187e+01/ 轮得分 58.08\n",
      "损失函数： 0.0960437\n",
      "时间步 493000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.434123e+01/ 轮得分 58.24\n",
      "损失函数： 0.071142\n",
      "时间步 494000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.338028e+01/ 轮得分 58.31\n",
      "损失函数： 0.0778025\n",
      "时间步 495000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.380186e+01/ 轮得分 58.31\n",
      "损失函数： 0.108349\n",
      "时间步 496000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.432300e+01/ 轮得分 58.41\n",
      "损失函数： 1.36788\n",
      "时间步 497000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.267589e+01/ 轮得分 58.47\n",
      "损失函数： 0.0310011\n",
      "时间步 498000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.310285e+01/ 轮得分 58.53\n",
      "损失函数： 0.11516\n",
      "时间步 499000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 1.157691e+01/ 轮得分 58.51\n",
      "损失函数： 0.151297\n",
      "时间步 500000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.140940e+01/ 轮得分 58.59\n",
      "损失函数： 0.0989709\n",
      "时间步 501000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.272758e+01/ 轮得分 58.59\n",
      "损失函数： 0.07296\n",
      "时间步 502000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.159366e+01/ 轮得分 58.59\n",
      "损失函数： 0.0975952\n",
      "时间步 503000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.191515e+01/ 轮得分 58.84\n",
      "损失函数： 0.077193\n",
      "时间步 504000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.090386e+01/ 轮得分 58.83\n",
      "损失函数： 0.0553964\n",
      "时间步 505000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 6.182002e+00/ 轮得分 58.86\n",
      "损失函数： 0.0462806\n",
      "时间步 506000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.283682e+01/ 轮得分 58.90\n",
      "损失函数： 0.0383185\n",
      "时间步 507000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.435685e+01/ 轮得分 58.86\n",
      "损失函数： 0.1152\n",
      "时间步 508000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.173823e+01/ 轮得分 58.92\n",
      "损失函数： 0.0637915\n",
      "时间步 509000/ 状态 explore/ Epsilon 0.17/ 行动 1/ 奖励 0.1/ Q_MAX 1.256586e+01/ 轮得分 59.01\n",
      "损失函数： 0.108739\n",
      "时间步 510000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 8.817407e+00/ 轮得分 58.99\n",
      "损失函数： 0.115445\n",
      "时间步 511000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 5.424275e+00/ 轮得分 59.02\n",
      "损失函数： 0.183122\n",
      "时间步 512000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.357814e+01/ 轮得分 59.00\n",
      "损失函数： 0.0648994\n",
      "时间步 513000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.227870e+01/ 轮得分 59.00\n",
      "损失函数： 0.10233\n",
      "时间步 514000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.211032e+01/ 轮得分 59.22\n",
      "损失函数： 0.124621\n",
      "时间步 515000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.263209e+01/ 轮得分 59.20\n",
      "损失函数： 0.199102\n",
      "时间步 516000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.266782e+01/ 轮得分 59.23\n",
      "损失函数： 0.0457583\n",
      "时间步 517000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.485250e+01/ 轮得分 59.23\n",
      "损失函数： 0.0506859\n",
      "时间步 518000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.286205e+01/ 轮得分 59.38\n",
      "损失函数： 0.103364\n",
      "时间步 519000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.202961e+01/ 轮得分 59.41\n",
      "损失函数： 0.061566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 520000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.162978e+01/ 轮得分 59.33\n",
      "损失函数： 0.0636938\n",
      "时间步 521000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.272748e+01/ 轮得分 59.28\n",
      "损失函数： 0.0619015\n",
      "时间步 522000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.145381e+01/ 轮得分 59.33\n",
      "损失函数： 0.0840973\n",
      "时间步 523000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.380659e+01/ 轮得分 59.33\n",
      "损失函数： 0.0749272\n",
      "时间步 524000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 9.272036e+00/ 轮得分 59.39\n",
      "损失函数： 0.101174\n",
      "时间步 525000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.331725e+01/ 轮得分 59.03\n",
      "损失函数： 0.105496\n",
      "时间步 526000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.168182e+01/ 轮得分 59.11\n",
      "损失函数： 0.145489\n",
      "时间步 527000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 9.961784e+00/ 轮得分 59.11\n",
      "损失函数： 0.0849767\n",
      "时间步 528000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.527157e+01/ 轮得分 59.28\n",
      "损失函数： 0.0814356\n",
      "时间步 529000/ 状态 explore/ Epsilon 0.17/ 行动 2/ 奖励 0.1/ Q_MAX 1.201305e+01/ 轮得分 59.38\n",
      "损失函数： 0.207249\n",
      "时间步 530000/ 状态 explore/ Epsilon 0.17/ 行动 0/ 奖励 0.1/ Q_MAX 1.219246e+01/ 轮得分 59.47\n",
      "损失函数： 0.132309\n",
      "时间步 531000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.163139e+01/ 轮得分 59.47\n",
      "损失函数： 0.0757515\n",
      "时间步 532000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.341420e+01/ 轮得分 59.47\n",
      "损失函数： 0.0950398\n",
      "时间步 533000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.179263e+01/ 轮得分 59.47\n",
      "损失函数： 0.0915637\n",
      "时间步 534000/ 状态 explore/ Epsilon 0.16/ 行动 2/ 奖励 0.1/ Q_MAX 1.314861e+01/ 轮得分 59.47\n",
      "损失函数： 0.168844\n",
      "时间步 535000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.284766e+01/ 轮得分 60.02\n",
      "损失函数： 0.081683\n",
      "时间步 536000/ 状态 explore/ Epsilon 0.16/ 行动 2/ 奖励 0.1/ Q_MAX 9.638294e+00/ 轮得分 60.02\n",
      "损失函数： 0.0611322\n",
      "时间步 537000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.171535e+01/ 轮得分 60.14\n",
      "损失函数： 0.0485086\n",
      "时间步 538000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.166179e+01/ 轮得分 60.11\n",
      "损失函数： 0.214095\n",
      "时间步 539000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 6.414386e+00/ 轮得分 60.20\n",
      "损失函数： 0.0729775\n",
      "时间步 540000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.120101e+01/ 轮得分 60.25\n",
      "损失函数： 0.11436\n",
      "时间步 541000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 9.524035e+00/ 轮得分 60.33\n",
      "损失函数： 0.0386583\n",
      "时间步 542000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 6.410907e+00/ 轮得分 60.28\n",
      "损失函数： 0.103576\n",
      "时间步 543000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.341556e+01/ 轮得分 60.25\n",
      "损失函数： 0.0990011\n",
      "时间步 544000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 6.506660e+00/ 轮得分 60.30\n",
      "损失函数： 0.0588306\n",
      "时间步 545000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.172215e+01/ 轮得分 60.31\n",
      "损失函数： 0.119344\n",
      "时间步 546000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 8.664433e+00/ 轮得分 60.31\n",
      "损失函数： 0.109711\n",
      "时间步 547000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.354289e+01/ 轮得分 60.40\n",
      "损失函数： 0.0559682\n",
      "时间步 548000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.185864e+01/ 轮得分 60.49\n",
      "损失函数： 0.0671441\n",
      "时间步 549000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.300140e+01/ 轮得分 60.54\n",
      "损失函数： 0.0834368\n",
      "时间步 550000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.370027e+01/ 轮得分 60.56\n",
      "损失函数： 0.0887184\n",
      "时间步 551000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.294667e+01/ 轮得分 60.46\n",
      "损失函数： 0.0379262\n",
      "时间步 552000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 9.818120e+00/ 轮得分 60.49\n",
      "损失函数： 0.0500123\n",
      "时间步 553000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.169057e+01/ 轮得分 60.52\n",
      "损失函数： 0.0703956\n",
      "时间步 554000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.172670e+01/ 轮得分 60.55\n",
      "损失函数： 0.0692229\n",
      "时间步 555000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.189811e+01/ 轮得分 60.55\n",
      "损失函数： 0.124184\n",
      "时间步 556000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 5.441541e+00/ 轮得分 60.69\n",
      "损失函数： 0.101631\n",
      "时间步 557000/ 状态 explore/ Epsilon 0.16/ 行动 2/ 奖励 0.1/ Q_MAX 1.105615e+01/ 轮得分 60.67\n",
      "损失函数： 0.0343912\n",
      "时间步 558000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.068664e+01/ 轮得分 60.63\n",
      "损失函数： 0.075229\n",
      "时间步 559000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.069188e+01/ 轮得分 60.63\n",
      "损失函数： 0.0223683\n",
      "时间步 560000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.070209e+01/ 轮得分 60.63\n",
      "损失函数： 0.0782192\n",
      "时间步 561000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.198145e+01/ 轮得分 60.81\n",
      "损失函数： 0.116984\n",
      "时间步 562000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.136090e+01/ 轮得分 60.87\n",
      "损失函数： 0.0416618\n",
      "时间步 563000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.186655e+01/ 轮得分 60.78\n",
      "损失函数： 0.0548524\n",
      "时间步 564000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.094136e+01/ 轮得分 60.71\n",
      "损失函数： 0.041315\n",
      "时间步 565000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.333444e+01/ 轮得分 60.73\n",
      "损失函数： 0.0829683\n",
      "时间步 566000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.137573e+01/ 轮得分 60.81\n",
      "损失函数： 0.0854475\n",
      "时间步 567000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.239466e+01/ 轮得分 60.81\n",
      "损失函数： 0.145393\n",
      "时间步 568000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.157779e+01/ 轮得分 60.75\n",
      "损失函数： 0.0547004\n",
      "时间步 569000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.135604e+01/ 轮得分 60.72\n",
      "损失函数： 0.0578582\n",
      "时间步 570000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.016080e+01/ 轮得分 60.72\n",
      "损失函数： 0.180351\n",
      "时间步 571000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.192795e+01/ 轮得分 60.72\n",
      "损失函数： 0.0680253\n",
      "时间步 572000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.197426e+01/ 轮得分 60.80\n",
      "损失函数： 0.210046\n",
      "时间步 573000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.218576e+01/ 轮得分 60.80\n",
      "损失函数： 0.0750209\n",
      "时间步 574000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 9.624605e+00/ 轮得分 60.95\n",
      "损失函数： 1.59499\n",
      "时间步 575000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.107402e+01/ 轮得分 60.83\n",
      "损失函数： 0.0684255\n",
      "时间步 576000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.299880e+01/ 轮得分 60.84\n",
      "损失函数： 0.0868532\n",
      "时间步 577000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.201408e+01/ 轮得分 60.83\n",
      "损失函数： 0.0404709\n",
      "时间步 578000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.045171e+01/ 轮得分 60.83\n",
      "损失函数： 0.0939409\n",
      "时间步 579000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.204040e+01/ 轮得分 61.15\n",
      "损失函数： 0.132143\n",
      "时间步 580000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 5.222367e+00/ 轮得分 61.16\n",
      "损失函数： 1.37392\n",
      "时间步 581000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.573533e+01/ 轮得分 61.12\n",
      "损失函数： 0.0630817\n",
      "时间步 582000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.114520e+01/ 轮得分 61.15\n",
      "损失函数： 0.132341\n",
      "时间步 583000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.043271e+01/ 轮得分 61.15\n",
      "损失函数： 0.160372\n",
      "时间步 584000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.222677e+01/ 轮得分 61.33\n",
      "损失函数： 0.0886488\n",
      "时间步 585000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.169889e+01/ 轮得分 61.43\n",
      "损失函数： 0.043245\n",
      "时间步 586000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.263461e+01/ 轮得分 61.49\n",
      "损失函数： 0.0744091\n",
      "时间步 587000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.283967e+01/ 轮得分 61.51\n",
      "损失函数： 0.132498\n",
      "时间步 588000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.294337e+01/ 轮得分 61.44\n",
      "损失函数： 0.0923377\n",
      "时间步 589000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 7.830261e+00/ 轮得分 61.43\n",
      "损失函数： 0.0572559\n",
      "时间步 590000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.105337e+01/ 轮得分 61.50\n",
      "损失函数： 0.0533437\n",
      "时间步 591000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.113904e+01/ 轮得分 61.55\n",
      "损失函数： 0.0757526\n",
      "时间步 592000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.076270e+01/ 轮得分 61.60\n",
      "损失函数： 0.0893319\n",
      "时间步 593000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.123148e+01/ 轮得分 61.68\n",
      "损失函数： 0.0458105\n",
      "时间步 594000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.046962e+01/ 轮得分 61.74\n",
      "损失函数： 0.151871\n",
      "时间步 595000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.166420e+01/ 轮得分 61.71\n",
      "损失函数： 0.149448\n",
      "时间步 596000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.183663e+01/ 轮得分 61.80\n",
      "损失函数： 0.0834076\n",
      "时间步 597000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.391981e+01/ 轮得分 61.82\n",
      "损失函数： 0.14524\n",
      "时间步 598000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.454426e+01/ 轮得分 61.92\n",
      "损失函数： 0.0878985\n",
      "时间步 599000/ 状态 explore/ Epsilon 0.16/ 行动 2/ 奖励 0.1/ Q_MAX 1.317183e+01/ 轮得分 61.90\n",
      "损失函数： 0.0730622\n",
      "时间步 600000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.213452e+01/ 轮得分 61.94\n",
      "损失函数： 0.13934\n",
      "时间步 601000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.273736e+01/ 轮得分 61.99\n",
      "损失函数： 0.0627186\n",
      "时间步 602000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 8.938454e-01/ 轮得分 62.07\n",
      "损失函数： 0.021587\n",
      "时间步 603000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.394001e+01/ 轮得分 62.05\n",
      "损失函数： 0.134971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 604000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.348151e+01/ 轮得分 62.05\n",
      "损失函数： 0.293931\n",
      "时间步 605000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.199772e+01/ 轮得分 62.20\n",
      "损失函数： 0.120806\n",
      "时间步 606000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.498890e+01/ 轮得分 62.27\n",
      "损失函数： 0.146966\n",
      "时间步 607000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.236236e+01/ 轮得分 62.32\n",
      "损失函数： 0.053422\n",
      "时间步 608000/ 状态 explore/ Epsilon 0.16/ 行动 2/ 奖励 0.1/ Q_MAX 1.213972e+01/ 轮得分 62.45\n",
      "损失函数： 0.141936\n",
      "时间步 609000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 9.544724e+00/ 轮得分 62.45\n",
      "损失函数： 0.151592\n",
      "时间步 610000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.371508e+01/ 轮得分 62.46\n",
      "损失函数： 0.47529\n",
      "时间步 611000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.147767e+01/ 轮得分 62.41\n",
      "损失函数： 0.138297\n",
      "时间步 612000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 5.210830e+00/ 轮得分 62.41\n",
      "损失函数： 0.0544126\n",
      "时间步 613000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.207579e+01/ 轮得分 62.47\n",
      "损失函数： 0.170075\n",
      "时间步 614000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.286614e+01/ 轮得分 62.48\n",
      "损失函数： 0.127747\n",
      "时间步 615000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.071424e+01/ 轮得分 62.20\n",
      "损失函数： 0.0487308\n",
      "时间步 616000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.032628e+01/ 轮得分 62.15\n",
      "损失函数： 1.06475\n",
      "时间步 617000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 6.717861e+00/ 轮得分 62.17\n",
      "损失函数： 0.325482\n",
      "时间步 618000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.291043e+01/ 轮得分 62.26\n",
      "损失函数： 0.0948774\n",
      "时间步 619000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.123398e+01/ 轮得分 62.26\n",
      "损失函数： 0.114708\n",
      "时间步 620000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.265448e+01/ 轮得分 62.42\n",
      "损失函数： 0.0416984\n",
      "时间步 621000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 9.950033e+00/ 轮得分 62.33\n",
      "损失函数： 0.0690977\n",
      "时间步 622000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.283384e+01/ 轮得分 62.32\n",
      "损失函数： 0.134079\n",
      "时间步 623000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 2.564789e+00/ 轮得分 62.35\n",
      "损失函数： 3.93412\n",
      "时间步 624000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.274797e+01/ 轮得分 62.24\n",
      "损失函数： 0.067564\n",
      "时间步 625000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.267430e+01/ 轮得分 62.24\n",
      "损失函数： 0.0823262\n",
      "时间步 626000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.236277e+01/ 轮得分 62.28\n",
      "损失函数： 0.265481\n",
      "时间步 627000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.310362e+01/ 轮得分 62.28\n",
      "损失函数： 0.0641765\n",
      "时间步 628000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.169751e+01/ 轮得分 62.50\n",
      "损失函数： 0.196719\n",
      "时间步 629000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.307302e+01/ 轮得分 62.52\n",
      "损失函数： 0.0855909\n",
      "时间步 630000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.021989e+01/ 轮得分 62.52\n",
      "损失函数： 0.120876\n",
      "时间步 631000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.367369e+01/ 轮得分 62.62\n",
      "损失函数： 0.1013\n",
      "时间步 632000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.011342e+01/ 轮得分 62.46\n",
      "损失函数： 0.105481\n",
      "时间步 633000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.020563e+01/ 轮得分 62.48\n",
      "损失函数： 0.161657\n",
      "时间步 634000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.325203e+01/ 轮得分 62.52\n",
      "损失函数： 0.058501\n",
      "时间步 635000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX -8.513296e-02/ 轮得分 62.68\n",
      "损失函数： 0.0239449\n",
      "时间步 636000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.180769e+01/ 轮得分 62.74\n",
      "损失函数： 0.0300541\n",
      "时间步 637000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 6.519922e+00/ 轮得分 62.78\n",
      "损失函数： 0.167272\n",
      "时间步 638000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.200439e+01/ 轮得分 62.87\n",
      "损失函数： 0.0650282\n",
      "时间步 639000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.236439e+01/ 轮得分 62.90\n",
      "损失函数： 0.168551\n",
      "时间步 640000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.227430e+01/ 轮得分 62.90\n",
      "损失函数： 0.107769\n",
      "时间步 641000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.312411e+01/ 轮得分 63.05\n",
      "损失函数： 0.14055\n",
      "时间步 642000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.291947e+01/ 轮得分 63.04\n",
      "损失函数： 0.0712542\n",
      "时间步 643000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.339834e+01/ 轮得分 63.04\n",
      "损失函数： 4.50385\n",
      "时间步 644000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.189538e+01/ 轮得分 63.27\n",
      "损失函数： 0.0582986\n",
      "时间步 645000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.204155e+01/ 轮得分 63.37\n",
      "损失函数： 0.147549\n",
      "时间步 646000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.029409e+01/ 轮得分 63.41\n",
      "损失函数： 0.0941808\n",
      "时间步 647000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.180378e+01/ 轮得分 63.41\n",
      "损失函数： 0.115475\n",
      "时间步 648000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.312305e+01/ 轮得分 63.41\n",
      "损失函数： 0.163481\n",
      "时间步 649000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.346552e+01/ 轮得分 63.41\n",
      "损失函数： 0.117253\n",
      "时间步 650000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 2.436475e+00/ 轮得分 63.77\n",
      "损失函数： 0.093237\n",
      "时间步 651000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.236927e+01/ 轮得分 63.88\n",
      "损失函数： 0.0289983\n",
      "时间步 652000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.369351e+01/ 轮得分 63.82\n",
      "损失函数： 0.0491636\n",
      "时间步 653000/ 状态 explore/ Epsilon 0.16/ 行动 2/ 奖励 0.1/ Q_MAX 6.964749e+00/ 轮得分 63.82\n",
      "损失函数： 0.0735623\n",
      "时间步 654000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 9.735080e+00/ 轮得分 63.98\n",
      "损失函数： 0.0620402\n",
      "时间步 655000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.177210e+01/ 轮得分 64.00\n",
      "损失函数： 0.0756125\n",
      "时间步 656000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.228164e+01/ 轮得分 64.08\n",
      "损失函数： 0.0916062\n",
      "时间步 657000/ 状态 explore/ Epsilon 0.16/ 行动 2/ 奖励 0.1/ Q_MAX 1.028564e+01/ 轮得分 64.05\n",
      "损失函数： 0.0940168\n",
      "时间步 658000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.300496e+01/ 轮得分 64.16\n",
      "损失函数： 0.1293\n",
      "时间步 659000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.164140e+01/ 轮得分 64.23\n",
      "损失函数： 0.11261\n",
      "时间步 660000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.249078e+01/ 轮得分 64.34\n",
      "损失函数： 0.0620679\n",
      "时间步 661000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.199747e+01/ 轮得分 64.34\n",
      "损失函数： 0.0710074\n",
      "时间步 662000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.132526e+01/ 轮得分 64.34\n",
      "损失函数： 0.198532\n",
      "时间步 663000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 8.675960e+00/ 轮得分 64.57\n",
      "损失函数： 0.0628927\n",
      "时间步 664000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.202337e+01/ 轮得分 64.63\n",
      "损失函数： 0.0862927\n",
      "时间步 665000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.326743e+01/ 轮得分 64.66\n",
      "损失函数： 0.103948\n",
      "时间步 666000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.527919e+01/ 轮得分 64.76\n",
      "损失函数： 0.0692446\n",
      "时间步 667000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.321548e+01/ 轮得分 64.76\n",
      "损失函数： 0.0932733\n",
      "时间步 668000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 7.262692e+00/ 轮得分 64.88\n",
      "损失函数： 0.038983\n",
      "时间步 669000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 5.766556e+00/ 轮得分 64.88\n",
      "损失函数： 0.0641298\n",
      "时间步 670000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.566440e+01/ 轮得分 65.02\n",
      "损失函数： 0.0598348\n",
      "时间步 671000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.332330e+01/ 轮得分 65.02\n",
      "损失函数： 0.0607291\n",
      "时间步 672000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.095917e+01/ 轮得分 65.29\n",
      "损失函数： 0.084488\n",
      "时间步 673000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.258163e+01/ 轮得分 65.36\n",
      "损失函数： 0.142376\n",
      "时间步 674000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.162717e+01/ 轮得分 65.35\n",
      "损失函数： 0.0524842\n",
      "时间步 675000/ 状态 explore/ Epsilon 0.16/ 行动 1/ 奖励 0.1/ Q_MAX 1.212436e+01/ 轮得分 65.49\n",
      "损失函数： 0.0731607\n",
      "时间步 676000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.140826e+01/ 轮得分 65.49\n",
      "损失函数： 0.130022\n",
      "时间步 677000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.091961e+01/ 轮得分 65.58\n",
      "损失函数： 0.0642923\n",
      "时间步 678000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.122823e+01/ 轮得分 65.56\n",
      "损失函数： 0.0420763\n",
      "时间步 679000/ 状态 explore/ Epsilon 0.16/ 行动 0/ 奖励 0.1/ Q_MAX 1.141865e+01/ 轮得分 65.55\n",
      "损失函数： 0.0700238\n",
      "时间步 680000/ 状态 explore/ Epsilon 0.16/ 行动 2/ 奖励 0.1/ Q_MAX 1.048796e+01/ 轮得分 65.62\n",
      "损失函数： 0.0499309\n",
      "时间步 681000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.174945e+01/ 轮得分 65.73\n",
      "损失函数： 0.067644\n",
      "时间步 682000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.214143e+01/ 轮得分 65.73\n",
      "损失函数： 0.0688444\n",
      "时间步 683000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.369628e+01/ 轮得分 65.75\n",
      "损失函数： 0.0480222\n",
      "时间步 684000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.113694e+01/ 轮得分 65.75\n",
      "损失函数： 0.0859821\n",
      "时间步 685000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.148295e+01/ 轮得分 66.03\n",
      "损失函数： 0.0517905\n",
      "时间步 686000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.126940e+01/ 轮得分 66.03\n",
      "损失函数： 0.085533\n",
      "时间步 687000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 8.387847e+00/ 轮得分 66.21\n",
      "损失函数： 0.0336846\n",
      "时间步 688000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.201792e+01/ 轮得分 66.22\n",
      "损失函数： 0.0297155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 689000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.410052e+01/ 轮得分 66.24\n",
      "损失函数： 0.0621908\n",
      "时间步 690000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.178969e+01/ 轮得分 66.24\n",
      "损失函数： 0.0817728\n",
      "时间步 691000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.133787e+01/ 轮得分 66.41\n",
      "损失函数： 0.0846862\n",
      "时间步 692000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.342494e+01/ 轮得分 66.43\n",
      "损失函数： 0.0639253\n",
      "时间步 693000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.163325e+01/ 轮得分 66.50\n",
      "损失函数： 0.0745035\n",
      "时间步 694000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.339214e+01/ 轮得分 66.50\n",
      "损失函数： 0.0967533\n",
      "时间步 695000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.350891e+01/ 轮得分 66.75\n",
      "损失函数： 0.0667428\n",
      "时间步 696000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.155343e+01/ 轮得分 66.84\n",
      "损失函数： 0.0329807\n",
      "时间步 697000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.458693e+01/ 轮得分 66.84\n",
      "损失函数： 0.0457414\n",
      "时间步 698000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.069197e+01/ 轮得分 66.84\n",
      "损失函数： 0.109136\n",
      "时间步 699000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.207117e+01/ 轮得分 67.14\n",
      "损失函数： 0.0931782\n",
      "时间步 700000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 8.055161e+00/ 轮得分 67.20\n",
      "损失函数： 0.119006\n",
      "时间步 701000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.261578e+01/ 轮得分 67.28\n",
      "损失函数： 0.119378\n",
      "时间步 702000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.140028e+01/ 轮得分 67.33\n",
      "损失函数： 0.132696\n",
      "时间步 703000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.268473e+01/ 轮得分 67.33\n",
      "损失函数： 0.137954\n",
      "时间步 704000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.244906e+01/ 轮得分 67.45\n",
      "损失函数： 0.028772\n",
      "时间步 705000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 9.273956e+00/ 轮得分 67.47\n",
      "损失函数： 0.0657161\n",
      "时间步 706000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.513759e+01/ 轮得分 67.47\n",
      "损失函数： 0.138645\n",
      "时间步 707000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.229081e+01/ 轮得分 67.63\n",
      "损失函数： 0.0543939\n",
      "时间步 708000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.391063e+01/ 轮得分 67.59\n",
      "损失函数： 0.0779442\n",
      "时间步 709000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.266276e+01/ 轮得分 67.59\n",
      "损失函数： 0.0316651\n",
      "时间步 710000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.248297e+01/ 轮得分 67.69\n",
      "损失函数： 0.0361119\n",
      "时间步 711000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.138515e+01/ 轮得分 67.62\n",
      "损失函数： 0.122653\n",
      "时间步 712000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 4.170299e+00/ 轮得分 67.64\n",
      "损失函数： 0.139606\n",
      "时间步 713000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.173915e+01/ 轮得分 67.73\n",
      "损失函数： 0.077981\n",
      "时间步 714000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.247422e+01/ 轮得分 67.76\n",
      "损失函数： 0.0837948\n",
      "时间步 715000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.240646e+01/ 轮得分 67.69\n",
      "损失函数： 0.0614128\n",
      "时间步 716000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.135835e+01/ 轮得分 67.69\n",
      "损失函数： 0.0654389\n",
      "时间步 717000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.244261e+01/ 轮得分 67.79\n",
      "损失函数： 0.0586828\n",
      "时间步 718000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.161389e+01/ 轮得分 67.81\n",
      "损失函数： 0.284361\n",
      "时间步 719000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.229817e+01/ 轮得分 67.84\n",
      "损失函数： 0.0423028\n",
      "时间步 720000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.253009e+01/ 轮得分 67.86\n",
      "损失函数： 0.0347144\n",
      "时间步 721000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.215639e+01/ 轮得分 68.02\n",
      "损失函数： 0.0648666\n",
      "时间步 722000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.229508e+01/ 轮得分 67.94\n",
      "损失函数： 0.0508706\n",
      "时间步 723000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 7.964190e+00/ 轮得分 67.90\n",
      "损失函数： 0.0684695\n",
      "时间步 724000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.076019e+01/ 轮得分 67.82\n",
      "损失函数： 0.214468\n",
      "时间步 725000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.216313e+01/ 轮得分 67.93\n",
      "损失函数： 0.0467294\n",
      "时间步 726000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.351127e+01/ 轮得分 68.01\n",
      "损失函数： 0.109816\n",
      "时间步 727000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.173525e+01/ 轮得分 68.10\n",
      "损失函数： 0.0672091\n",
      "时间步 728000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.458375e+01/ 轮得分 68.08\n",
      "损失函数： 0.151412\n",
      "时间步 729000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.122567e+01/ 轮得分 68.13\n",
      "损失函数： 0.0663346\n",
      "时间步 730000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.244354e+01/ 轮得分 68.13\n",
      "损失函数： 0.0773402\n",
      "时间步 731000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 1.1/ Q_MAX 1.448414e+01/ 轮得分 68.23\n",
      "损失函数： 0.085603\n",
      "时间步 732000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.521678e+01/ 轮得分 68.28\n",
      "损失函数： 0.0729455\n",
      "时间步 733000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.336212e+01/ 轮得分 68.21\n",
      "损失函数： 0.0378129\n",
      "时间步 734000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.591265e+01/ 轮得分 68.26\n",
      "损失函数： 0.0660687\n",
      "时间步 735000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.018617e+01/ 轮得分 68.26\n",
      "损失函数： 0.0476707\n",
      "时间步 736000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.217426e+01/ 轮得分 68.49\n",
      "损失函数： 0.0279721\n",
      "时间步 737000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.187069e+01/ 轮得分 68.51\n",
      "损失函数： 0.061863\n",
      "时间步 738000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.194468e+01/ 轮得分 68.55\n",
      "损失函数： 0.0643327\n",
      "时间步 739000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.199885e+01/ 轮得分 68.65\n",
      "损失函数： 0.0958611\n",
      "时间步 740000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.317656e+01/ 轮得分 68.65\n",
      "损失函数： 0.100917\n",
      "时间步 741000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.253146e+01/ 轮得分 68.81\n",
      "损失函数： 0.0675364\n",
      "时间步 742000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.219892e+01/ 轮得分 68.95\n",
      "损失函数： 1.1525\n",
      "时间步 743000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.208445e+01/ 轮得分 68.96\n",
      "损失函数： 0.047456\n",
      "时间步 744000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.260712e+01/ 轮得分 68.93\n",
      "损失函数： 0.0955642\n",
      "时间步 745000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.305524e+01/ 轮得分 68.99\n",
      "损失函数： 0.0979434\n",
      "时间步 746000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.515448e+01/ 轮得分 68.99\n",
      "损失函数： 0.0998689\n",
      "时间步 747000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 9.571944e+00/ 轮得分 69.09\n",
      "损失函数： 0.029966\n",
      "时间步 748000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 9.311283e+00/ 轮得分 69.11\n",
      "损失函数： 0.186328\n",
      "时间步 749000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.378793e+01/ 轮得分 69.05\n",
      "损失函数： 0.102147\n",
      "时间步 750000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.134997e+01/ 轮得分 68.91\n",
      "损失函数： 5.88804\n",
      "时间步 751000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 7.274982e+00/ 轮得分 68.91\n",
      "损失函数： 0.135245\n",
      "时间步 752000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.347122e+01/ 轮得分 68.91\n",
      "损失函数： 0.0479513\n",
      "时间步 753000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.164937e+01/ 轮得分 69.27\n",
      "损失函数： 0.0283148\n",
      "时间步 754000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.179819e+01/ 轮得分 69.34\n",
      "损失函数： 0.146071\n",
      "时间步 755000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.296012e+01/ 轮得分 69.19\n",
      "损失函数： 0.163559\n",
      "时间步 756000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.256300e+01/ 轮得分 69.30\n",
      "损失函数： 0.0364167\n",
      "时间步 757000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 7.111479e+00/ 轮得分 69.23\n",
      "损失函数： 0.0736237\n",
      "时间步 758000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.225500e+01/ 轮得分 69.21\n",
      "损失函数： 0.120852\n",
      "时间步 759000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.320287e+01/ 轮得分 69.21\n",
      "损失函数： 0.130444\n",
      "时间步 760000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.281276e+01/ 轮得分 69.21\n",
      "损失函数： 0.0961098\n",
      "时间步 761000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.403112e+01/ 轮得分 69.54\n",
      "损失函数： 0.150514\n",
      "时间步 762000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.674429e+01/ 轮得分 69.63\n",
      "损失函数： 0.206927\n",
      "时间步 763000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.333012e+01/ 轮得分 69.74\n",
      "损失函数： 0.165432\n",
      "时间步 764000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.384697e+01/ 轮得分 69.77\n",
      "损失函数： 0.0537553\n",
      "时间步 765000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.309740e+01/ 轮得分 69.65\n",
      "损失函数： 0.090955\n",
      "时间步 766000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.334776e+01/ 轮得分 69.65\n",
      "损失函数： 0.10479\n",
      "时间步 767000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.264198e+01/ 轮得分 69.85\n",
      "损失函数： 0.0831566\n",
      "时间步 768000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.438530e+01/ 轮得分 69.85\n",
      "损失函数： 0.0885655\n",
      "时间步 769000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.286432e+01/ 轮得分 70.00\n",
      "损失函数： 0.0995968\n",
      "时间步 770000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.292257e+01/ 轮得分 70.03\n",
      "损失函数： 0.0617148\n",
      "时间步 771000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.268416e+01/ 轮得分 70.07\n",
      "损失函数： 0.141372\n",
      "时间步 772000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.339198e+01/ 轮得分 70.10\n",
      "损失函数： 0.0686149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 773000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.369853e+01/ 轮得分 70.08\n",
      "损失函数： 0.102837\n",
      "时间步 774000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.356107e+01/ 轮得分 70.08\n",
      "损失函数： 0.115991\n",
      "时间步 775000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.230544e+01/ 轮得分 70.03\n",
      "损失函数： 0.19561\n",
      "时间步 776000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.272222e+01/ 轮得分 70.14\n",
      "损失函数： 0.0885586\n",
      "时间步 777000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.194715e+01/ 轮得分 70.18\n",
      "损失函数： 0.0470424\n",
      "时间步 778000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.352122e+01/ 轮得分 70.18\n",
      "损失函数： 0.0866979\n",
      "时间步 779000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 5.383481e+00/ 轮得分 70.27\n",
      "损失函数： 0.134591\n",
      "时间步 780000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.295649e+01/ 轮得分 70.24\n",
      "损失函数： 0.112282\n",
      "时间步 781000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.292576e+01/ 轮得分 70.24\n",
      "损失函数： 0.0632228\n",
      "时间步 782000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.351975e+01/ 轮得分 70.38\n",
      "损失函数： 0.0544903\n",
      "时间步 783000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.242992e+01/ 轮得分 70.35\n",
      "损失函数： 0.0627185\n",
      "时间步 784000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.091251e+01/ 轮得分 70.41\n",
      "损失函数： 0.0715421\n",
      "时间步 785000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.169135e+01/ 轮得分 70.33\n",
      "损失函数： 2.16454\n",
      "时间步 786000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.219352e+01/ 轮得分 70.35\n",
      "损失函数： 0.0842673\n",
      "时间步 787000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 9.195140e+00/ 轮得分 70.44\n",
      "损失函数： 0.076028\n",
      "时间步 788000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.223429e+01/ 轮得分 70.47\n",
      "损失函数： 0.0532435\n",
      "时间步 789000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.373508e+01/ 轮得分 70.55\n",
      "损失函数： 0.0316225\n",
      "时间步 790000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.230647e+01/ 轮得分 70.61\n",
      "损失函数： 0.131096\n",
      "时间步 791000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.105430e+01/ 轮得分 70.62\n",
      "损失函数： 0.125194\n",
      "时间步 792000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.367359e+01/ 轮得分 70.67\n",
      "损失函数： 0.0736696\n",
      "时间步 793000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.374446e+01/ 轮得分 70.67\n",
      "损失函数： 0.0987485\n",
      "时间步 794000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.280495e+01/ 轮得分 70.82\n",
      "损失函数： 0.0950564\n",
      "时间步 795000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.469937e+01/ 轮得分 70.98\n",
      "损失函数： 0.0780373\n",
      "时间步 796000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.390014e+01/ 轮得分 70.98\n",
      "损失函数： 0.0758226\n",
      "时间步 797000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.320726e+01/ 轮得分 71.12\n",
      "损失函数： 0.537347\n",
      "时间步 798000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.519972e+01/ 轮得分 71.12\n",
      "损失函数： 0.0909745\n",
      "时间步 799000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.226694e+01/ 轮得分 71.31\n",
      "损失函数： 0.185116\n",
      "时间步 800000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 9.439610e+00/ 轮得分 71.30\n",
      "损失函数： 0.11369\n",
      "时间步 801000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.259125e+01/ 轮得分 71.37\n",
      "损失函数： 2.98446\n",
      "时间步 802000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.357804e+01/ 轮得分 71.41\n",
      "损失函数： 0.033179\n",
      "时间步 803000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 7.576292e+00/ 轮得分 71.54\n",
      "损失函数： 0.0634021\n",
      "时间步 804000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 8.920747e+00/ 轮得分 71.56\n",
      "损失函数： 0.0868119\n",
      "时间步 805000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.295305e+01/ 轮得分 71.59\n",
      "损失函数： 0.0373402\n",
      "时间步 806000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.338212e+01/ 轮得分 71.75\n",
      "损失函数： 0.111198\n",
      "时间步 807000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.228555e+01/ 轮得分 71.77\n",
      "损失函数： 0.0553357\n",
      "时间步 808000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.390354e+01/ 轮得分 71.79\n",
      "损失函数： 0.0691191\n",
      "时间步 809000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.078488e+01/ 轮得分 71.87\n",
      "损失函数： 0.0566183\n",
      "时间步 810000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.052042e+01/ 轮得分 71.95\n",
      "损失函数： 0.0738384\n",
      "时间步 811000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.190085e+01/ 轮得分 72.06\n",
      "损失函数： 0.0439302\n",
      "时间步 812000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.138206e+01/ 轮得分 72.02\n",
      "损失函数： 0.0896701\n",
      "时间步 813000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.291753e+01/ 轮得分 72.06\n",
      "损失函数： 0.105947\n",
      "时间步 814000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.144906e+01/ 轮得分 72.06\n",
      "损失函数： 0.0756356\n",
      "时间步 815000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.200296e+01/ 轮得分 72.33\n",
      "损失函数： 0.0919068\n",
      "时间步 816000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.148724e+01/ 轮得分 72.40\n",
      "损失函数： 0.0346676\n",
      "时间步 817000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.327414e+01/ 轮得分 72.50\n",
      "损失函数： 0.0986368\n",
      "时间步 818000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.129641e+01/ 轮得分 72.50\n",
      "损失函数： 0.143963\n",
      "时间步 819000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.302245e+01/ 轮得分 72.60\n",
      "损失函数： 0.174083\n",
      "时间步 820000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.262393e+01/ 轮得分 72.60\n",
      "损失函数： 0.048408\n",
      "时间步 821000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.248854e+01/ 轮得分 72.81\n",
      "损失函数： 0.0455179\n",
      "时间步 822000/ 状态 explore/ Epsilon 0.15/ 行动 2/ 奖励 0.1/ Q_MAX 1.171476e+01/ 轮得分 72.84\n",
      "损失函数： 0.0948285\n",
      "时间步 823000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.242746e+01/ 轮得分 72.79\n",
      "损失函数： 0.086497\n",
      "时间步 824000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.210960e+01/ 轮得分 72.80\n",
      "损失函数： 0.106673\n",
      "时间步 825000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.372654e+01/ 轮得分 72.83\n",
      "损失函数： 0.151792\n",
      "时间步 826000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.292132e+01/ 轮得分 72.82\n",
      "损失函数： 0.172219\n",
      "时间步 827000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.364222e+01/ 轮得分 72.86\n",
      "损失函数： 0.0765561\n",
      "时间步 828000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.200990e+01/ 轮得分 72.92\n",
      "损失函数： 0.111172\n",
      "时间步 829000/ 状态 explore/ Epsilon 0.15/ 行动 0/ 奖励 0.1/ Q_MAX 1.363907e+01/ 轮得分 72.88\n",
      "损失函数： 0.0853856\n",
      "时间步 830000/ 状态 explore/ Epsilon 0.15/ 行动 1/ 奖励 0.1/ Q_MAX 1.299401e+01/ 轮得分 72.90\n",
      "损失函数： 0.0881936\n",
      "时间步 831000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.162766e+01/ 轮得分 72.98\n",
      "损失函数： 0.187217\n",
      "时间步 832000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.350383e+01/ 轮得分 73.00\n",
      "损失函数： 0.0671661\n",
      "时间步 833000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.182089e+01/ 轮得分 72.98\n",
      "损失函数： 0.0362649\n",
      "时间步 834000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.266688e+01/ 轮得分 72.98\n",
      "损失函数： 0.11613\n",
      "时间步 835000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.271759e+01/ 轮得分 73.21\n",
      "损失函数： 0.0723457\n",
      "时间步 836000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.199186e+01/ 轮得分 73.21\n",
      "损失函数： 0.0378084\n",
      "时间步 837000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.344583e+01/ 轮得分 73.34\n",
      "损失函数： 0.0888657\n",
      "时间步 838000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.065664e+01/ 轮得分 73.28\n",
      "损失函数： 0.0439325\n",
      "时间步 839000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.284578e+01/ 轮得分 73.32\n",
      "损失函数： 0.0625549\n",
      "时间步 840000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.324173e+01/ 轮得分 73.32\n",
      "损失函数： 0.909682\n",
      "时间步 841000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 5.890582e+00/ 轮得分 73.32\n",
      "损失函数： 0.108056\n",
      "时间步 842000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.285635e+01/ 轮得分 73.60\n",
      "损失函数： 0.0876531\n",
      "时间步 843000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.109712e+01/ 轮得分 73.75\n",
      "损失函数： 3.22285\n",
      "时间步 844000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.309464e+01/ 轮得分 73.75\n",
      "损失函数： 0.118202\n",
      "时间步 845000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.226341e+01/ 轮得分 73.78\n",
      "损失函数： 0.157717\n",
      "时间步 846000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 9.031550e+00/ 轮得分 73.78\n",
      "损失函数： 0.0777343\n",
      "时间步 847000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.228745e+01/ 轮得分 73.90\n",
      "损失函数： 0.1682\n",
      "时间步 848000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.106130e+01/ 轮得分 73.92\n",
      "损失函数： 4.30073\n",
      "时间步 849000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.232702e+01/ 轮得分 73.89\n",
      "损失函数： 0.0485734\n",
      "时间步 850000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.508264e+01/ 轮得分 73.89\n",
      "损失函数： 0.14277\n",
      "时间步 851000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.205048e+01/ 轮得分 74.07\n",
      "损失函数： 0.0483796\n",
      "时间步 852000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.206546e+01/ 轮得分 74.14\n",
      "损失函数： 0.0577955\n",
      "时间步 853000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.296456e+01/ 轮得分 74.14\n",
      "损失函数： 0.138213\n",
      "时间步 854000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.209438e+01/ 轮得分 74.36\n",
      "损失函数： 0.0967376\n",
      "时间步 855000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.350844e+01/ 轮得分 74.45\n",
      "损失函数： 0.0691932\n",
      "时间步 856000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.204864e+01/ 轮得分 74.50\n",
      "损失函数： 0.0441406\n",
      "时间步 857000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.279165e+01/ 轮得分 74.52\n",
      "损失函数： 0.150137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 858000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.334906e+01/ 轮得分 74.54\n",
      "损失函数： 0.10477\n",
      "时间步 859000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.175925e+01/ 轮得分 74.49\n",
      "损失函数： 0.101726\n",
      "时间步 860000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.164491e+01/ 轮得分 74.39\n",
      "损失函数： 0.077778\n",
      "时间步 861000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.207187e+01/ 轮得分 74.39\n",
      "损失函数： 0.0586616\n",
      "时间步 862000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.288317e+01/ 轮得分 74.33\n",
      "损失函数： 0.147888\n",
      "时间步 863000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 1.1/ Q_MAX 1.184246e+01/ 轮得分 74.40\n",
      "损失函数： 0.108845\n",
      "时间步 864000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.244195e+01/ 轮得分 74.46\n",
      "损失函数： 0.159387\n",
      "时间步 865000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.090382e+01/ 轮得分 74.53\n",
      "损失函数： 0.0764299\n",
      "时间步 866000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.239104e+01/ 轮得分 74.64\n",
      "损失函数： 0.035988\n",
      "时间步 867000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.358600e+01/ 轮得分 74.66\n",
      "损失函数： 0.133049\n",
      "时间步 868000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.215487e+01/ 轮得分 74.65\n",
      "损失函数： 0.0635371\n",
      "时间步 869000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.340800e+01/ 轮得分 74.65\n",
      "损失函数： 0.0521615\n",
      "时间步 870000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.061665e+01/ 轮得分 74.81\n",
      "损失函数： 0.082346\n",
      "时间步 871000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.148992e+01/ 轮得分 74.91\n",
      "损失函数： 0.0482596\n",
      "时间步 872000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.295266e+01/ 轮得分 74.91\n",
      "损失函数： 0.0773972\n",
      "时间步 873000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.381478e+01/ 轮得分 75.12\n",
      "损失函数： 0.101501\n",
      "时间步 874000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.314387e+01/ 轮得分 75.21\n",
      "损失函数： 0.0843733\n",
      "时间步 875000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.561389e+01/ 轮得分 75.28\n",
      "损失函数： 0.081769\n",
      "时间步 876000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.485535e+01/ 轮得分 75.28\n",
      "损失函数： 0.0641373\n",
      "时间步 877000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.192548e+01/ 轮得分 75.32\n",
      "损失函数： 0.0509736\n",
      "时间步 878000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.338208e+01/ 轮得分 75.39\n",
      "损失函数： 0.0923357\n",
      "时间步 879000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.209041e+01/ 轮得分 75.49\n",
      "损失函数： 0.105376\n",
      "时间步 880000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.271991e+01/ 轮得分 75.48\n",
      "损失函数： 0.126557\n",
      "时间步 881000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.559272e+01/ 轮得分 75.48\n",
      "损失函数： 0.17675\n",
      "时间步 882000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.124698e+01/ 轮得分 75.55\n",
      "损失函数： 0.187247\n",
      "时间步 883000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.321029e+01/ 轮得分 75.55\n",
      "损失函数： 0.0585987\n",
      "时间步 884000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.297494e+01/ 轮得分 75.76\n",
      "损失函数： 0.0304317\n",
      "时间步 885000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.382357e+01/ 轮得分 75.87\n",
      "损失函数： 0.128485\n",
      "时间步 886000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 1.1/ Q_MAX 1.308068e+01/ 轮得分 75.92\n",
      "损失函数： 0.244951\n",
      "时间步 887000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.231472e+01/ 轮得分 75.96\n",
      "损失函数： 0.0992818\n",
      "时间步 888000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.436526e+01/ 轮得分 75.97\n",
      "损失函数： 0.0975055\n",
      "时间步 889000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.121192e+01/ 轮得分 75.97\n",
      "损失函数： 0.27131\n",
      "时间步 890000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.364042e+01/ 轮得分 75.97\n",
      "损失函数： 0.0707387\n",
      "时间步 891000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.290668e+01/ 轮得分 76.24\n",
      "损失函数： 0.0877536\n",
      "时间步 892000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 9.593723e+00/ 轮得分 76.29\n",
      "损失函数： 0.117969\n",
      "时间步 893000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.063490e+01/ 轮得分 76.20\n",
      "损失函数： 0.0657074\n",
      "时间步 894000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.102438e+01/ 轮得分 76.31\n",
      "损失函数： 0.0396383\n",
      "时间步 895000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 9.568824e+00/ 轮得分 76.31\n",
      "损失函数： 0.048345\n",
      "时间步 896000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.071299e+01/ 轮得分 76.46\n",
      "损失函数： 0.14878\n",
      "时间步 897000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.268860e+01/ 轮得分 76.46\n",
      "损失函数： 0.07267\n",
      "时间步 898000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.432768e+01/ 轮得分 76.65\n",
      "损失函数： 0.0711882\n",
      "时间步 899000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.243834e+01/ 轮得分 76.65\n",
      "损失函数： 0.107194\n",
      "时间步 900000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.236665e+01/ 轮得分 76.79\n",
      "损失函数： 0.0322498\n",
      "时间步 901000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.506381e+01/ 轮得分 76.87\n",
      "损失函数： 0.0589922\n",
      "时间步 902000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.395041e+01/ 轮得分 76.87\n",
      "损失函数： 0.0455947\n",
      "时间步 903000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.322733e+01/ 轮得分 77.06\n",
      "损失函数： 0.0590269\n",
      "时间步 904000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.280235e+01/ 轮得分 77.06\n",
      "损失函数： 0.0556852\n",
      "时间步 905000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.496988e+01/ 轮得分 77.22\n",
      "损失函数： 0.076253\n",
      "时间步 906000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.248354e+01/ 轮得分 77.22\n",
      "损失函数： 0.0726724\n",
      "时间步 907000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.136008e+01/ 轮得分 77.22\n",
      "损失函数： 0.0911466\n",
      "时间步 908000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.394409e+01/ 轮得分 77.22\n",
      "损失函数： 0.0671054\n",
      "时间步 909000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.525363e+01/ 轮得分 77.49\n",
      "损失函数： 0.041723\n",
      "时间步 910000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.226945e+01/ 轮得分 77.48\n",
      "损失函数： 0.119563\n",
      "时间步 911000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.511776e+01/ 轮得分 77.47\n",
      "损失函数： 0.0544866\n",
      "时间步 912000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.475702e+01/ 轮得分 77.47\n",
      "损失函数： 0.0463286\n",
      "时间步 913000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.252865e+01/ 轮得分 77.75\n",
      "损失函数： 0.0527695\n",
      "时间步 914000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.342742e+01/ 轮得分 77.83\n",
      "损失函数： 0.138099\n",
      "时间步 915000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.476578e+01/ 轮得分 77.88\n",
      "损失函数： 0.0392472\n",
      "时间步 916000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.186183e+01/ 轮得分 77.87\n",
      "损失函数： 0.141331\n",
      "时间步 917000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.329774e+01/ 轮得分 77.92\n",
      "损失函数： 0.0488865\n",
      "时间步 918000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.507097e+01/ 轮得分 77.99\n",
      "损失函数： 0.0620782\n",
      "时间步 919000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.324158e+01/ 轮得分 78.02\n",
      "损失函数： 0.490644\n",
      "时间步 920000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.342939e+01/ 轮得分 78.08\n",
      "损失函数： 0.0459076\n",
      "时间步 921000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.490982e+01/ 轮得分 78.19\n",
      "损失函数： 1.93894\n",
      "时间步 922000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 1.1/ Q_MAX 8.021345e+00/ 轮得分 77.86\n",
      "损失函数： 0.0457481\n",
      "时间步 923000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.376263e+01/ 轮得分 77.65\n",
      "损失函数： 1.69242\n",
      "时间步 924000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.202502e+01/ 轮得分 77.47\n",
      "损失函数： 0.0729608\n",
      "时间步 925000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.446863e+01/ 轮得分 77.53\n",
      "损失函数： 0.0603644\n",
      "时间步 926000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.213350e+01/ 轮得分 77.59\n",
      "损失函数： 0.0253949\n",
      "时间步 927000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 5.475489e+00/ 轮得分 77.61\n",
      "损失函数： 0.0479426\n",
      "时间步 928000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.282561e+01/ 轮得分 77.65\n",
      "损失函数： 0.066282\n",
      "时间步 929000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.002891e+01/ 轮得分 77.65\n",
      "损失函数： 0.0581402\n",
      "时间步 930000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.229918e+01/ 轮得分 77.78\n",
      "损失函数： 0.128561\n",
      "时间步 931000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.627969e+01/ 轮得分 77.78\n",
      "损失函数： 0.0750363\n",
      "时间步 932000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.364729e+01/ 轮得分 77.89\n",
      "损失函数： 0.102902\n",
      "时间步 933000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.386152e+01/ 轮得分 77.96\n",
      "损失函数： 0.0681306\n",
      "时间步 934000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.338232e+01/ 轮得分 77.98\n",
      "损失函数： 0.0573286\n",
      "时间步 935000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.303654e+01/ 轮得分 78.15\n",
      "损失函数： 0.0700178\n",
      "时间步 936000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.248590e+01/ 轮得分 78.17\n",
      "损失函数： 0.0898271\n",
      "时间步 937000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.178989e+01/ 轮得分 78.20\n",
      "损失函数： 0.2216\n",
      "时间步 938000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 9.855039e+00/ 轮得分 78.26\n",
      "损失函数： 0.0555777\n",
      "时间步 939000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.089380e+01/ 轮得分 78.26\n",
      "损失函数： 0.204131\n",
      "时间步 940000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.173025e+01/ 轮得分 78.34\n",
      "损失函数： 0.085581\n",
      "时间步 941000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.199592e+01/ 轮得分 78.43\n",
      "损失函数： 0.0725864\n",
      "时间步 942000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.350285e+01/ 轮得分 78.36\n",
      "损失函数： 0.230384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 943000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.316153e+01/ 轮得分 78.36\n",
      "损失函数： 0.0608213\n",
      "时间步 944000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.031016e+01/ 轮得分 78.36\n",
      "损失函数： 0.517967\n",
      "时间步 945000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.412013e+01/ 轮得分 78.36\n",
      "损失函数： 0.0818253\n",
      "时间步 946000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.233823e+01/ 轮得分 78.36\n",
      "损失函数： 0.0718632\n",
      "时间步 947000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.320907e+01/ 轮得分 78.85\n",
      "损失函数： 0.0559026\n",
      "时间步 948000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.187706e+01/ 轮得分 78.92\n",
      "损失函数： 0.110227\n",
      "时间步 949000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.206014e+01/ 轮得分 78.92\n",
      "损失函数： 0.0838486\n",
      "时间步 950000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.369741e+01/ 轮得分 79.11\n",
      "损失函数： 0.0794409\n",
      "时间步 951000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.388435e+01/ 轮得分 79.17\n",
      "损失函数： 0.286847\n",
      "时间步 952000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.485643e+01/ 轮得分 79.27\n",
      "损失函数： 0.0443539\n",
      "时间步 953000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.298719e+01/ 轮得分 79.27\n",
      "损失函数： 0.0428966\n",
      "时间步 954000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.356679e+01/ 轮得分 79.46\n",
      "损失函数： 0.0965815\n",
      "时间步 955000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.472855e+01/ 轮得分 79.45\n",
      "损失函数： 0.174626\n",
      "时间步 956000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.315388e+01/ 轮得分 79.45\n",
      "损失函数： 0.154095\n",
      "时间步 957000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 9.010658e+00/ 轮得分 79.45\n",
      "损失函数： 0.0911864\n",
      "时间步 958000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.376773e+01/ 轮得分 79.45\n",
      "损失函数： 0.0720507\n",
      "时间步 959000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.492711e+01/ 轮得分 79.91\n",
      "损失函数： 0.12674\n",
      "时间步 960000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.331440e+01/ 轮得分 79.94\n",
      "损失函数： 0.0700587\n",
      "时间步 961000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.369456e+01/ 轮得分 79.90\n",
      "损失函数： 0.0499071\n",
      "时间步 962000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.244362e+01/ 轮得分 79.98\n",
      "损失函数： 0.0997801\n",
      "时间步 963000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.298190e+01/ 轮得分 80.05\n",
      "损失函数： 0.0566707\n",
      "时间步 964000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.294121e+01/ 轮得分 80.05\n",
      "损失函数： 3.4014\n",
      "时间步 965000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.375362e+01/ 轮得分 80.06\n",
      "损失函数： 0.0761934\n",
      "时间步 966000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.223524e+01/ 轮得分 80.06\n",
      "损失函数： 0.0533721\n",
      "时间步 967000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.262867e+01/ 轮得分 80.19\n",
      "损失函数： 0.156716\n",
      "时间步 968000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.429632e+01/ 轮得分 80.15\n",
      "损失函数： 0.0790222\n",
      "时间步 969000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.485469e+01/ 轮得分 80.14\n",
      "损失函数： 0.139843\n",
      "时间步 970000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.455692e+01/ 轮得分 80.11\n",
      "损失函数： 0.127674\n",
      "时间步 971000/ 状态 explore/ Epsilon 0.14/ 行动 2/ 奖励 0.1/ Q_MAX 1.027301e+01/ 轮得分 80.05\n",
      "损失函数： 0.0301727\n",
      "时间步 972000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 1.1/ Q_MAX 7.677270e+00/ 轮得分 79.98\n",
      "损失函数： 0.044898\n",
      "时间步 973000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.266453e+01/ 轮得分 80.02\n",
      "损失函数： 0.0613372\n",
      "时间步 974000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.360056e+01/ 轮得分 80.02\n",
      "损失函数： 0.0885288\n",
      "时间步 975000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.119855e+01/ 轮得分 80.22\n",
      "损失函数： 0.0478689\n",
      "时间步 976000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.437961e+01/ 轮得分 80.22\n",
      "损失函数： 0.105733\n",
      "时间步 977000/ 状态 explore/ Epsilon 0.14/ 行动 1/ 奖励 0.1/ Q_MAX 1.532368e+01/ 轮得分 80.22\n",
      "损失函数： 0.134384\n",
      "时间步 978000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.462879e+01/ 轮得分 80.54\n",
      "损失函数： 0.0809458\n",
      "时间步 979000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.215068e+01/ 轮得分 80.70\n",
      "损失函数： 0.173176\n",
      "时间步 980000/ 状态 explore/ Epsilon 0.14/ 行动 0/ 奖励 0.1/ Q_MAX 1.291321e+01/ 轮得分 80.74\n",
      "损失函数： 0.0339465\n",
      "时间步 981000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.313656e+01/ 轮得分 80.89\n",
      "损失函数： 0.0658833\n",
      "时间步 982000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.281035e+01/ 轮得分 80.91\n",
      "损失函数： 0.0912745\n",
      "时间步 983000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.162416e+01/ 轮得分 80.92\n",
      "损失函数： 0.0230261\n",
      "时间步 984000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.017757e+01/ 轮得分 80.89\n",
      "损失函数： 0.0658842\n",
      "时间步 985000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.075655e+01/ 轮得分 80.40\n",
      "损失函数： 0.0480951\n",
      "时间步 986000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.192753e+01/ 轮得分 80.36\n",
      "损失函数： 0.0378773\n",
      "时间步 987000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.368437e+01/ 轮得分 80.39\n",
      "损失函数： 0.0587955\n",
      "时间步 988000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 8.469484e+00/ 轮得分 80.37\n",
      "损失函数： 0.0789134\n",
      "时间步 989000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.194272e+01/ 轮得分 80.46\n",
      "损失函数： 0.0806461\n",
      "时间步 990000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.178226e+01/ 轮得分 80.46\n",
      "损失函数： 0.0504107\n",
      "时间步 991000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.225170e+01/ 轮得分 80.63\n",
      "损失函数： 0.0540502\n",
      "时间步 992000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.232763e+01/ 轮得分 80.63\n",
      "损失函数： 0.103333\n",
      "时间步 993000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.269816e+01/ 轮得分 80.63\n",
      "损失函数： 0.0378893\n",
      "时间步 994000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.256687e+01/ 轮得分 80.92\n",
      "损失函数： 0.100054\n",
      "时间步 995000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.308345e+01/ 轮得分 80.92\n",
      "损失函数： 0.0558677\n",
      "时间步 996000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.223414e+01/ 轮得分 81.05\n",
      "损失函数： 0.041421\n",
      "时间步 997000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.277899e+01/ 轮得分 81.05\n",
      "损失函数： 0.0436745\n",
      "时间步 998000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.446041e+01/ 轮得分 81.20\n",
      "损失函数： 0.0697782\n",
      "时间步 999000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.276915e+01/ 轮得分 81.13\n",
      "损失函数： 0.0701698\n",
      "时间步 1000000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.244487e+01/ 轮得分 81.13\n",
      "损失函数： 0.175414\n",
      "时间步 1001000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.392185e+01/ 轮得分 81.27\n",
      "损失函数： 0.113163\n",
      "时间步 1002000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.296099e+01/ 轮得分 81.19\n",
      "损失函数： 0.182913\n",
      "时间步 1003000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.266757e+01/ 轮得分 81.24\n",
      "损失函数： 0.0422326\n",
      "时间步 1004000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.223325e+01/ 轮得分 81.30\n",
      "损失函数： 0.0747599\n",
      "时间步 1005000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.312093e+01/ 轮得分 81.39\n",
      "损失函数： 0.0519678\n",
      "时间步 1006000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.181194e+01/ 轮得分 81.24\n",
      "损失函数： 0.0608515\n",
      "时间步 1007000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.378300e+01/ 轮得分 81.35\n",
      "损失函数： 0.0600068\n",
      "时间步 1008000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.134348e+01/ 轮得分 81.35\n",
      "损失函数： 0.0400228\n",
      "时间步 1009000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.414456e+01/ 轮得分 81.50\n",
      "损失函数： 0.0755718\n",
      "时间步 1010000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.275878e+01/ 轮得分 81.57\n",
      "损失函数： 0.0796777\n",
      "时间步 1011000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.336320e+01/ 轮得分 81.59\n",
      "损失函数： 1.311\n",
      "时间步 1012000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.210193e+01/ 轮得分 81.59\n",
      "损失函数： 0.0925658\n",
      "时间步 1013000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.142018e+01/ 轮得分 81.81\n",
      "损失函数： 0.0781159\n",
      "时间步 1014000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.446279e+01/ 轮得分 81.88\n",
      "损失函数： 0.145284\n",
      "时间步 1015000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 9.794686e+00/ 轮得分 81.88\n",
      "损失函数： 0.0731726\n",
      "时间步 1016000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.480268e+01/ 轮得分 81.88\n",
      "损失函数： 0.0538913\n",
      "时间步 1017000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.355590e+01/ 轮得分 81.88\n",
      "损失函数： 0.287047\n",
      "时间步 1018000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.351233e+01/ 轮得分 81.88\n",
      "损失函数： 0.0656292\n",
      "时间步 1019000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.192893e+01/ 轮得分 82.44\n",
      "损失函数： 0.185952\n",
      "时间步 1020000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 8.887473e+00/ 轮得分 82.41\n",
      "损失函数： 0.0356791\n",
      "时间步 1021000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.146485e+01/ 轮得分 82.44\n",
      "损失函数： 0.14279\n",
      "时间步 1022000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.332535e+01/ 轮得分 82.51\n",
      "损失函数： 0.0981501\n",
      "时间步 1023000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.296696e+01/ 轮得分 82.50\n",
      "损失函数： 0.0730253\n",
      "时间步 1024000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.213193e+01/ 轮得分 82.58\n",
      "损失函数： 0.119006\n",
      "时间步 1025000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.219739e+01/ 轮得分 82.58\n",
      "损失函数： 0.112403\n",
      "时间步 1026000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.186322e+01/ 轮得分 82.71\n",
      "损失函数： 0.0344614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1027000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.249859e+01/ 轮得分 82.71\n",
      "损失函数： 0.0722312\n",
      "时间步 1028000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.094027e+01/ 轮得分 82.89\n",
      "损失函数： 0.0904571\n",
      "时间步 1029000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.231176e+01/ 轮得分 82.89\n",
      "损失函数： 0.0983222\n",
      "时间步 1030000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.493482e+01/ 轮得分 82.89\n",
      "损失函数： 0.0518075\n",
      "时间步 1031000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.143054e+01/ 轮得分 83.16\n",
      "损失函数： 0.0460435\n",
      "时间步 1032000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 9.173899e+00/ 轮得分 83.16\n",
      "损失函数： 0.0943247\n",
      "时间步 1033000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.428678e+01/ 轮得分 83.19\n",
      "损失函数： 0.118099\n",
      "时间步 1034000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.641568e+01/ 轮得分 83.19\n",
      "损失函数： 0.0800422\n",
      "时间步 1035000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.223869e+01/ 轮得分 83.19\n",
      "损失函数： 0.0721144\n",
      "时间步 1036000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 1.1/ Q_MAX 1.273372e+01/ 轮得分 83.52\n",
      "损失函数： 0.0399221\n",
      "时间步 1037000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.706520e+01/ 轮得分 83.52\n",
      "损失函数： 0.0873703\n",
      "时间步 1038000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.549722e+01/ 轮得分 83.61\n",
      "损失函数： 0.0527936\n",
      "时间步 1039000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.316300e+01/ 轮得分 83.64\n",
      "损失函数： 0.0731487\n",
      "时间步 1040000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.406817e+01/ 轮得分 83.58\n",
      "损失函数： 0.0277285\n",
      "时间步 1041000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.425269e+01/ 轮得分 83.64\n",
      "损失函数： 0.042957\n",
      "时间步 1042000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.191354e+01/ 轮得分 83.64\n",
      "损失函数： 2.38965\n",
      "时间步 1043000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.260650e+01/ 轮得分 83.76\n",
      "损失函数： 0.111107\n",
      "时间步 1044000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.459306e+01/ 轮得分 83.90\n",
      "损失函数： 0.0699429\n",
      "时间步 1045000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.327062e+01/ 轮得分 83.81\n",
      "损失函数： 0.123878\n",
      "时间步 1046000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.480788e+01/ 轮得分 83.85\n",
      "损失函数： 0.0505851\n",
      "时间步 1047000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.213606e+01/ 轮得分 84.03\n",
      "损失函数： 0.148205\n",
      "时间步 1048000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.359885e+01/ 轮得分 83.89\n",
      "损失函数： 0.0755734\n",
      "时间步 1049000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.055582e+01/ 轮得分 83.86\n",
      "损失函数： 0.0433976\n",
      "时间步 1050000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.220841e+01/ 轮得分 83.98\n",
      "损失函数： 0.0931196\n",
      "时间步 1051000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.375884e+01/ 轮得分 84.08\n",
      "损失函数： 0.0591071\n",
      "时间步 1052000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.404194e+01/ 轮得分 84.08\n",
      "损失函数： 0.042273\n",
      "时间步 1053000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.241217e+01/ 轮得分 84.33\n",
      "损失函数： 0.0869963\n",
      "时间步 1054000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.410885e+01/ 轮得分 84.33\n",
      "损失函数： 0.0846673\n",
      "时间步 1055000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.462656e+01/ 轮得分 84.44\n",
      "损失函数： 0.0688971\n",
      "时间步 1056000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.429876e+01/ 轮得分 84.51\n",
      "损失函数： 0.0909388\n",
      "时间步 1057000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.170792e+01/ 轮得分 84.51\n",
      "损失函数： 0.0921209\n",
      "时间步 1058000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.363809e+01/ 轮得分 84.41\n",
      "损失函数： 0.0174403\n",
      "时间步 1059000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.245540e+01/ 轮得分 84.39\n",
      "损失函数： 0.0259797\n",
      "时间步 1060000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.200801e+01/ 轮得分 84.46\n",
      "损失函数： 0.113173\n",
      "时间步 1061000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.243168e+01/ 轮得分 84.31\n",
      "损失函数： 0.0452411\n",
      "时间步 1062000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.342799e+01/ 轮得分 84.34\n",
      "损失函数： 0.217754\n",
      "时间步 1063000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.142581e+01/ 轮得分 84.43\n",
      "损失函数： 0.022917\n",
      "时间步 1064000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.107582e+01/ 轮得分 84.31\n",
      "损失函数： 0.0641973\n",
      "时间步 1065000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.391492e+01/ 轮得分 84.42\n",
      "损失函数： 0.0465503\n",
      "时间步 1066000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.233930e+01/ 轮得分 84.39\n",
      "损失函数： 0.150578\n",
      "时间步 1067000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.220565e+01/ 轮得分 84.46\n",
      "损失函数： 0.0176763\n",
      "时间步 1068000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.251820e+01/ 轮得分 84.48\n",
      "损失函数： 0.0771233\n",
      "时间步 1069000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.511009e+01/ 轮得分 84.48\n",
      "损失函数： 0.0993482\n",
      "时间步 1070000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.218300e+01/ 轮得分 84.48\n",
      "损失函数： 0.0263732\n",
      "时间步 1071000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.103557e+01/ 轮得分 84.48\n",
      "损失函数： 0.1574\n",
      "时间步 1072000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.157209e+01/ 轮得分 84.80\n",
      "损失函数： 0.077732\n",
      "时间步 1073000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 1.1/ Q_MAX 1.501440e+01/ 轮得分 84.89\n",
      "损失函数： 0.209502\n",
      "时间步 1074000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.298270e+01/ 轮得分 84.72\n",
      "损失函数： 0.0794153\n",
      "时间步 1075000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.197156e+01/ 轮得分 84.72\n",
      "损失函数： 0.0635162\n",
      "时间步 1076000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.176689e+01/ 轮得分 84.86\n",
      "损失函数： 0.0310101\n",
      "时间步 1077000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.462794e+01/ 轮得分 84.89\n",
      "损失函数： 0.0793674\n",
      "时间步 1078000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.050047e+01/ 轮得分 84.89\n",
      "损失函数： 0.0616637\n",
      "时间步 1079000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.428344e+01/ 轮得分 84.89\n",
      "损失函数： 0.0617526\n",
      "时间步 1080000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.220193e+01/ 轮得分 85.17\n",
      "损失函数： 0.0657115\n",
      "时间步 1081000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 9.978627e+00/ 轮得分 85.24\n",
      "损失函数： 0.0720856\n",
      "时间步 1082000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.108235e+01/ 轮得分 85.24\n",
      "损失函数： 0.0342231\n",
      "时间步 1083000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.345169e+01/ 轮得分 85.37\n",
      "损失函数： 0.0440866\n",
      "时间步 1084000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.429888e+01/ 轮得分 85.37\n",
      "损失函数： 0.11752\n",
      "时间步 1085000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.236551e+01/ 轮得分 85.50\n",
      "损失函数： 0.142281\n",
      "时间步 1086000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.306993e+01/ 轮得分 85.57\n",
      "损失函数： 0.0705493\n",
      "时间步 1087000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.203933e+01/ 轮得分 85.69\n",
      "损失函数： 2.02249\n",
      "时间步 1088000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.299729e+01/ 轮得分 85.69\n",
      "损失函数： 0.0313313\n",
      "时间步 1089000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.455955e+01/ 轮得分 85.91\n",
      "损失函数： 0.0619446\n",
      "时间步 1090000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.224434e+01/ 轮得分 85.91\n",
      "损失函数： 0.0505465\n",
      "时间步 1091000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.075748e+01/ 轮得分 85.91\n",
      "损失函数： 0.0406237\n",
      "时间步 1092000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.342175e+01/ 轮得分 86.22\n",
      "损失函数： 0.0618533\n",
      "时间步 1093000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.227220e+01/ 轮得分 86.22\n",
      "损失函数： 0.0794284\n",
      "时间步 1094000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.336449e+01/ 轮得分 86.22\n",
      "损失函数： 0.0642757\n",
      "时间步 1095000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.029450e+01/ 轮得分 86.53\n",
      "损失函数： 0.119588\n",
      "时间步 1096000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.276079e+01/ 轮得分 86.59\n",
      "损失函数： 0.0612889\n",
      "时间步 1097000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.206255e+01/ 轮得分 86.62\n",
      "损失函数： 0.22853\n",
      "时间步 1098000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.293653e+01/ 轮得分 86.60\n",
      "损失函数： 0.0764736\n",
      "时间步 1099000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.193930e+01/ 轮得分 86.67\n",
      "损失函数： 0.057552\n",
      "时间步 1100000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.295540e+01/ 轮得分 86.67\n",
      "损失函数： 0.0530728\n",
      "时间步 1101000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.340012e+01/ 轮得分 86.95\n",
      "损失函数： 0.0415668\n",
      "时间步 1102000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.270541e+01/ 轮得分 86.97\n",
      "损失函数： 0.0547903\n",
      "时间步 1103000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.239364e+01/ 轮得分 87.00\n",
      "损失函数： 0.0956791\n",
      "时间步 1104000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.093930e+01/ 轮得分 87.04\n",
      "损失函数： 0.0430073\n",
      "时间步 1105000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.403617e+01/ 轮得分 86.88\n",
      "损失函数： 0.0719111\n",
      "时间步 1106000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.184481e+01/ 轮得分 86.96\n",
      "损失函数： 0.0926137\n",
      "时间步 1107000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.461386e+01/ 轮得分 86.89\n",
      "损失函数： 0.134829\n",
      "时间步 1108000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.260594e+01/ 轮得分 86.89\n",
      "损失函数： 0.0666017\n",
      "时间步 1109000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.309234e+01/ 轮得分 86.89\n",
      "损失函数： 0.0731102\n",
      "时间步 1110000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.097633e+01/ 轮得分 86.89\n",
      "损失函数： 0.118805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1111000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.240033e+01/ 轮得分 87.34\n",
      "损失函数： 0.0525977\n",
      "时间步 1112000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.244173e+01/ 轮得分 87.39\n",
      "损失函数： 0.0603417\n",
      "时间步 1113000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.579409e+01/ 轮得分 87.31\n",
      "损失函数： 0.0615994\n",
      "时间步 1114000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.312602e+01/ 轮得分 87.36\n",
      "损失函数： 0.134726\n",
      "时间步 1115000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.405972e+01/ 轮得分 87.45\n",
      "损失函数： 0.0591228\n",
      "时间步 1116000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 1.1/ Q_MAX 1.427259e+01/ 轮得分 87.36\n",
      "损失函数： 0.0767079\n",
      "时间步 1117000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.395984e+01/ 轮得分 87.45\n",
      "损失函数： 0.0538009\n",
      "时间步 1118000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.452869e+01/ 轮得分 87.53\n",
      "损失函数： 0.0775109\n",
      "时间步 1119000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.261998e+01/ 轮得分 87.32\n",
      "损失函数： 0.0428939\n",
      "时间步 1120000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.429109e+01/ 轮得分 87.35\n",
      "损失函数： 0.0998055\n",
      "时间步 1121000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.183552e+01/ 轮得分 87.48\n",
      "损失函数： 0.0911892\n",
      "时间步 1122000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.129947e+01/ 轮得分 87.54\n",
      "损失函数： 0.0539016\n",
      "时间步 1123000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.100933e+01/ 轮得分 87.60\n",
      "损失函数： 0.0746359\n",
      "时间步 1124000/ 状态 explore/ Epsilon 0.13/ 行动 1/ 奖励 0.1/ Q_MAX 1.165755e+01/ 轮得分 87.58\n",
      "损失函数： 0.0848407\n",
      "时间步 1125000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.231912e+01/ 轮得分 87.63\n",
      "损失函数： 0.0955867\n",
      "时间步 1126000/ 状态 explore/ Epsilon 0.13/ 行动 2/ 奖励 0.1/ Q_MAX 1.382335e+01/ 轮得分 87.63\n",
      "损失函数： 0.0313021\n",
      "时间步 1127000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.285458e+01/ 轮得分 87.72\n",
      "损失函数： 0.0849067\n",
      "时间步 1128000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.189719e+01/ 轮得分 87.66\n",
      "损失函数： 0.0410014\n",
      "时间步 1129000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.214965e+01/ 轮得分 87.78\n",
      "损失函数： 0.0732659\n",
      "时间步 1130000/ 状态 explore/ Epsilon 0.13/ 行动 0/ 奖励 0.1/ Q_MAX 1.251450e+01/ 轮得分 87.78\n",
      "损失函数： 0.189475\n",
      "时间步 1131000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.399510e+01/ 轮得分 87.92\n",
      "损失函数： 0.0541543\n",
      "时间步 1132000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.289938e+01/ 轮得分 87.95\n",
      "损失函数： 0.0721511\n",
      "时间步 1133000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.290682e+01/ 轮得分 87.98\n",
      "损失函数： 0.131517\n",
      "时间步 1134000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.228742e+01/ 轮得分 87.99\n",
      "损失函数： 0.0974076\n",
      "时间步 1135000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.214320e+01/ 轮得分 88.03\n",
      "损失函数： 0.118257\n",
      "时间步 1136000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.230035e+01/ 轮得分 88.03\n",
      "损失函数： 0.093131\n",
      "时间步 1137000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.290730e+01/ 轮得分 88.03\n",
      "损失函数： 0.0531372\n",
      "时间步 1138000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.261407e+01/ 轮得分 88.30\n",
      "损失函数： 0.0537947\n",
      "时间步 1139000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.197546e+01/ 轮得分 88.31\n",
      "损失函数： 0.0775202\n",
      "时间步 1140000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 7.941253e+00/ 轮得分 88.31\n",
      "损失函数： 0.0818987\n",
      "时间步 1141000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.218165e+01/ 轮得分 88.42\n",
      "损失函数： 0.117813\n",
      "时间步 1142000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.150716e+01/ 轮得分 88.42\n",
      "损失函数： 0.0681414\n",
      "时间步 1143000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.292677e+01/ 轮得分 88.61\n",
      "损失函数： 0.0506017\n",
      "时间步 1144000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.251239e+01/ 轮得分 88.48\n",
      "损失函数： 0.0718936\n",
      "时间步 1145000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.272506e+01/ 轮得分 88.48\n",
      "损失函数： 0.0673715\n",
      "时间步 1146000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.374857e+01/ 轮得分 88.45\n",
      "损失函数： 0.0745718\n",
      "时间步 1147000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.347054e+01/ 轮得分 88.45\n",
      "损失函数： 0.243556\n",
      "时间步 1148000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 5.196062e+00/ 轮得分 88.72\n",
      "损失函数： 0.143306\n",
      "时间步 1149000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.452205e+01/ 轮得分 88.71\n",
      "损失函数： 0.0906058\n",
      "时间步 1150000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.250879e+01/ 轮得分 88.71\n",
      "损失函数： 0.0591365\n",
      "时间步 1151000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.239578e+01/ 轮得分 88.64\n",
      "损失函数： 0.0914921\n",
      "时间步 1152000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.168150e+01/ 轮得分 88.64\n",
      "损失函数： 0.183796\n",
      "时间步 1153000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.185293e+01/ 轮得分 88.85\n",
      "损失函数： 0.133074\n",
      "时间步 1154000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.400460e+01/ 轮得分 88.85\n",
      "损失函数： 0.063635\n",
      "时间步 1155000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.319085e+01/ 轮得分 88.98\n",
      "损失函数： 0.400414\n",
      "时间步 1156000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 2.005175e+00/ 轮得分 89.05\n",
      "损失函数： 0.0445743\n",
      "时间步 1157000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.392008e+01/ 轮得分 89.06\n",
      "损失函数： 0.117718\n",
      "时间步 1158000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.248656e+01/ 轮得分 89.05\n",
      "损失函数： 0.0284859\n",
      "时间步 1159000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.166658e+01/ 轮得分 89.05\n",
      "损失函数： 0.11064\n",
      "时间步 1160000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.209040e+01/ 轮得分 89.05\n",
      "损失函数： 0.0839841\n",
      "时间步 1161000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.389705e+01/ 轮得分 89.34\n",
      "损失函数： 0.0868903\n",
      "时间步 1162000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.300575e+01/ 轮得分 89.30\n",
      "损失函数： 0.312057\n",
      "时间步 1163000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.426090e+01/ 轮得分 89.23\n",
      "损失函数： 0.0571932\n",
      "时间步 1164000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.411947e+01/ 轮得分 89.24\n",
      "损失函数： 0.158686\n",
      "时间步 1165000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.324991e+01/ 轮得分 89.24\n",
      "损失函数： 0.0458151\n",
      "时间步 1166000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.325731e+01/ 轮得分 89.24\n",
      "损失函数： 0.386476\n",
      "时间步 1167000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.486431e+01/ 轮得分 89.54\n",
      "损失函数： 0.0344646\n",
      "时间步 1168000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.213652e+01/ 轮得分 89.54\n",
      "损失函数： 0.0627363\n",
      "时间步 1169000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.371908e+01/ 轮得分 89.54\n",
      "损失函数： 0.142323\n",
      "时间步 1170000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.388350e+01/ 轮得分 89.54\n",
      "损失函数： 0.0287223\n",
      "时间步 1171000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.339140e+01/ 轮得分 89.88\n",
      "损失函数： 0.0810635\n",
      "时间步 1172000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.390495e+01/ 轮得分 89.96\n",
      "损失函数： 0.0636773\n",
      "时间步 1173000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.118750e+01/ 轮得分 89.98\n",
      "损失函数： 0.0850897\n",
      "时间步 1174000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.316235e+01/ 轮得分 90.11\n",
      "损失函数： 0.106054\n",
      "时间步 1175000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.278241e+01/ 轮得分 90.12\n",
      "损失函数： 0.0299514\n",
      "时间步 1176000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.417353e+01/ 轮得分 90.12\n",
      "损失函数： 0.0410362\n",
      "时间步 1177000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.215778e+01/ 轮得分 90.12\n",
      "损失函数： 0.074892\n",
      "时间步 1178000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.301457e+01/ 轮得分 90.35\n",
      "损失函数： 0.0627848\n",
      "时间步 1179000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.437004e+01/ 轮得分 90.45\n",
      "损失函数： 0.0717074\n",
      "时间步 1180000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.237841e+01/ 轮得分 90.22\n",
      "损失函数： 0.0569719\n",
      "时间步 1181000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.217614e+01/ 轮得分 90.23\n",
      "损失函数： 0.052493\n",
      "时间步 1182000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.401893e+01/ 轮得分 90.23\n",
      "损失函数： 0.0763413\n",
      "时间步 1183000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 1.1/ Q_MAX 1.523771e+01/ 轮得分 90.47\n",
      "损失函数： 0.0250494\n",
      "时间步 1184000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.009711e+01/ 轮得分 90.47\n",
      "损失函数： 0.0510499\n",
      "时间步 1185000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.321141e+01/ 轮得分 90.53\n",
      "损失函数： 0.0279134\n",
      "时间步 1186000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.182754e+01/ 轮得分 90.53\n",
      "损失函数： 0.0656992\n",
      "时间步 1187000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.293222e+01/ 轮得分 90.53\n",
      "损失函数： 0.084268\n",
      "时间步 1188000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.307461e+01/ 轮得分 90.53\n",
      "损失函数： 0.0903662\n",
      "时间步 1189000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.163839e+01/ 轮得分 90.90\n",
      "损失函数： 0.0473248\n",
      "时间步 1190000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 1.1/ Q_MAX 1.275839e+01/ 轮得分 90.77\n",
      "损失函数： 0.0420704\n",
      "时间步 1191000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.275232e+01/ 轮得分 90.86\n",
      "损失函数： 0.0569207\n",
      "时间步 1192000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.261898e+01/ 轮得分 90.86\n",
      "损失函数： 0.0385313\n",
      "时间步 1193000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.217254e+01/ 轮得分 90.86\n",
      "损失函数： 0.0492636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1194000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.391946e+01/ 轮得分 91.07\n",
      "损失函数： 0.0878164\n",
      "时间步 1195000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.113035e+01/ 轮得分 91.07\n",
      "损失函数： 0.038838\n",
      "时间步 1196000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.254456e+01/ 轮得分 91.07\n",
      "损失函数： 0.0813694\n",
      "时间步 1197000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 1.1/ Q_MAX 1.445440e+01/ 轮得分 91.07\n",
      "损失函数： 0.063241\n",
      "时间步 1198000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.205069e+01/ 轮得分 91.48\n",
      "损失函数： 0.0575028\n",
      "时间步 1199000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.540959e+01/ 轮得分 91.48\n",
      "损失函数： 0.0451421\n",
      "时间步 1200000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.280350e+01/ 轮得分 91.73\n",
      "损失函数： 0.0264919\n",
      "时间步 1201000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.370280e+01/ 轮得分 91.73\n",
      "损失函数： 0.24141\n",
      "时间步 1202000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.412186e+01/ 轮得分 91.73\n",
      "损失函数： 0.0325002\n",
      "时间步 1203000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.453163e+01/ 轮得分 91.89\n",
      "损失函数： 0.0313082\n",
      "时间步 1204000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.189730e+01/ 轮得分 91.94\n",
      "损失函数： 0.0469899\n",
      "时间步 1205000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.280769e+01/ 轮得分 91.94\n",
      "损失函数： 0.0424032\n",
      "时间步 1206000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.334707e+01/ 轮得分 92.21\n",
      "损失函数： 0.0627468\n",
      "时间步 1207000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.370962e+01/ 轮得分 92.28\n",
      "损失函数： 0.0660488\n",
      "时间步 1208000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.208142e+01/ 轮得分 92.13\n",
      "损失函数： 0.0440365\n",
      "时间步 1209000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.305707e+01/ 轮得分 92.24\n",
      "损失函数： 0.0327476\n",
      "时间步 1210000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.451422e+01/ 轮得分 92.24\n",
      "损失函数： 0.0327259\n",
      "时间步 1211000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.264152e+01/ 轮得分 92.44\n",
      "损失函数： 0.144496\n",
      "时间步 1212000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.243287e+01/ 轮得分 92.46\n",
      "损失函数： 1.46936\n",
      "时间步 1213000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.319096e+01/ 轮得分 92.49\n",
      "损失函数： 0.0909041\n",
      "时间步 1214000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.445006e+01/ 轮得分 92.59\n",
      "损失函数： 0.0739625\n",
      "时间步 1215000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.112868e+01/ 轮得分 92.63\n",
      "损失函数： 0.021768\n",
      "时间步 1216000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.505220e+01/ 轮得分 92.61\n",
      "损失函数： 0.0577332\n",
      "时间步 1217000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.809940e+01/ 轮得分 92.61\n",
      "损失函数： 0.100467\n",
      "时间步 1218000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 1.1/ Q_MAX 1.240985e+01/ 轮得分 92.78\n",
      "损失函数： 0.0938081\n",
      "时间步 1219000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.417618e+01/ 轮得分 92.85\n",
      "损失函数： 0.0561812\n",
      "时间步 1220000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.347991e+01/ 轮得分 92.87\n",
      "损失函数： 0.0547693\n",
      "时间步 1221000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.411641e+01/ 轮得分 92.98\n",
      "损失函数： 0.113314\n",
      "时间步 1222000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.239307e+01/ 轮得分 92.98\n",
      "损失函数： 0.0592184\n",
      "时间步 1223000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.418285e+01/ 轮得分 93.16\n",
      "损失函数： 0.0330733\n",
      "时间步 1224000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.396395e+01/ 轮得分 93.16\n",
      "损失函数： 0.0418377\n",
      "时间步 1225000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.373939e+01/ 轮得分 93.27\n",
      "损失函数： 0.0408222\n",
      "时间步 1226000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.328144e+01/ 轮得分 93.27\n",
      "损失函数： 0.0600588\n",
      "时间步 1227000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.247123e+01/ 轮得分 93.27\n",
      "损失函数： 0.0481263\n",
      "时间步 1228000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.539652e+01/ 轮得分 93.27\n",
      "损失函数： 0.0800584\n",
      "时间步 1229000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.253257e+01/ 轮得分 93.64\n",
      "损失函数： 0.0461443\n",
      "时间步 1230000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.224860e+01/ 轮得分 93.64\n",
      "损失函数： 0.137545\n",
      "时间步 1231000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.166495e+01/ 轮得分 93.86\n",
      "损失函数： 0.0917719\n",
      "时间步 1232000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.333607e+01/ 轮得分 93.96\n",
      "损失函数： 0.0251916\n",
      "时间步 1233000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.182576e+01/ 轮得分 94.06\n",
      "损失函数： 0.099334\n",
      "时间步 1234000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.345919e+01/ 轮得分 94.03\n",
      "损失函数： 0.0539966\n",
      "时间步 1235000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.218108e+01/ 轮得分 94.04\n",
      "损失函数： 0.12968\n",
      "时间步 1236000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.282620e+01/ 轮得分 94.06\n",
      "损失函数： 0.032935\n",
      "时间步 1237000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.065241e+01/ 轮得分 93.92\n",
      "损失函数： 0.21849\n",
      "时间步 1238000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.043524e+01/ 轮得分 93.95\n",
      "损失函数： 0.0275612\n",
      "时间步 1239000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.156278e+01/ 轮得分 93.95\n",
      "损失函数： 0.0482327\n",
      "时间步 1240000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.126144e+01/ 轮得分 94.21\n",
      "损失函数： 0.0883033\n",
      "时间步 1241000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.429134e+01/ 轮得分 94.21\n",
      "损失函数： 0.0470144\n",
      "时间步 1242000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.231139e+01/ 轮得分 94.31\n",
      "损失函数： 0.174278\n",
      "时间步 1243000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.274225e+01/ 轮得分 94.36\n",
      "损失函数： 0.0347939\n",
      "时间步 1244000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.236923e+01/ 轮得分 94.18\n",
      "损失函数： 0.134322\n",
      "时间步 1245000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.220764e+01/ 轮得分 94.18\n",
      "损失函数： 0.0513822\n",
      "时间步 1246000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.379297e+01/ 轮得分 94.36\n",
      "损失函数： 0.0386465\n",
      "时间步 1247000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.378456e+01/ 轮得分 94.36\n",
      "损失函数： 1.72499\n",
      "时间步 1248000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.129763e+01/ 轮得分 94.39\n",
      "损失函数： 0.0188481\n",
      "时间步 1249000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.228109e+01/ 轮得分 94.39\n",
      "损失函数： 0.0852448\n",
      "时间步 1250000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.317405e+01/ 轮得分 94.44\n",
      "损失函数： 0.100172\n",
      "时间步 1251000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.340596e+01/ 轮得分 94.44\n",
      "损失函数： 0.0255999\n",
      "时间步 1252000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.177082e+01/ 轮得分 94.74\n",
      "损失函数： 0.110953\n",
      "时间步 1253000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.131464e+01/ 轮得分 94.74\n",
      "损失函数： 0.025115\n",
      "时间步 1254000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.212593e+01/ 轮得分 94.88\n",
      "损失函数： 0.0257645\n",
      "时间步 1255000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.167731e+01/ 轮得分 94.68\n",
      "损失函数： 0.0382801\n",
      "时间步 1256000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.257183e+01/ 轮得分 94.68\n",
      "损失函数： 0.072823\n",
      "时间步 1257000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.090276e+01/ 轮得分 94.88\n",
      "损失函数： 0.0418078\n",
      "时间步 1258000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 1.1/ Q_MAX 1.346925e+01/ 轮得分 94.88\n",
      "损失函数： 0.0662477\n",
      "时间步 1259000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 9.787951e+00/ 轮得分 94.89\n",
      "损失函数： 0.121351\n",
      "时间步 1260000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.465301e+01/ 轮得分 94.93\n",
      "损失函数： 0.0904216\n",
      "时间步 1261000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.192272e+01/ 轮得分 94.88\n",
      "损失函数： 0.0981433\n",
      "时间步 1262000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.214877e+01/ 轮得分 95.02\n",
      "损失函数： 0.0769306\n",
      "时间步 1263000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.462596e+01/ 轮得分 95.02\n",
      "损失函数： 0.761315\n",
      "时间步 1264000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.506067e+01/ 轮得分 95.02\n",
      "损失函数： 0.0589481\n",
      "时间步 1265000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.592677e+01/ 轮得分 95.02\n",
      "损失函数： 0.0694854\n",
      "时间步 1266000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.074220e+01/ 轮得分 95.02\n",
      "损失函数： 0.0731335\n",
      "时间步 1267000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.270957e+01/ 轮得分 95.44\n",
      "损失函数： 0.072737\n",
      "时间步 1268000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.365220e+01/ 轮得分 95.44\n",
      "损失函数： 0.149387\n",
      "时间步 1269000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.360208e+01/ 轮得分 95.69\n",
      "损失函数： 0.0683016\n",
      "时间步 1270000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.425349e+01/ 轮得分 95.67\n",
      "损失函数： 0.0658955\n",
      "时间步 1271000/ 状态 explore/ Epsilon 0.12/ 行动 2/ 奖励 0.1/ Q_MAX 1.360373e+01/ 轮得分 95.78\n",
      "损失函数： 1.82166\n",
      "时间步 1272000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 9.260202e+00/ 轮得分 95.78\n",
      "损失函数： 0.0854343\n",
      "时间步 1273000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.364197e+01/ 轮得分 95.99\n",
      "损失函数： 0.0434187\n",
      "时间步 1274000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.216146e+01/ 轮得分 96.01\n",
      "损失函数： 0.0625196\n",
      "时间步 1275000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.367677e+01/ 轮得分 96.01\n",
      "损失函数： 0.0631621\n",
      "时间步 1276000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.438006e+01/ 轮得分 96.01\n",
      "损失函数： 0.0885566\n",
      "时间步 1277000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.241186e+01/ 轮得分 96.32\n",
      "损失函数： 0.0517758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1278000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.358973e+01/ 轮得分 96.18\n",
      "损失函数： 0.0504764\n",
      "时间步 1279000/ 状态 explore/ Epsilon 0.12/ 行动 0/ 奖励 0.1/ Q_MAX 1.379589e+01/ 轮得分 96.24\n",
      "损失函数： 0.0421305\n",
      "时间步 1280000/ 状态 explore/ Epsilon 0.12/ 行动 1/ 奖励 0.1/ Q_MAX 1.195481e+01/ 轮得分 96.24\n",
      "损失函数： 0.117847\n",
      "时间步 1281000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.076113e+01/ 轮得分 96.24\n",
      "损失函数： 0.0504565\n",
      "时间步 1282000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.140175e+01/ 轮得分 96.41\n",
      "损失函数： 0.0435501\n",
      "时间步 1283000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.415590e+01/ 轮得分 96.36\n",
      "损失函数： 0.0907662\n",
      "时间步 1284000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.329599e+01/ 轮得分 96.36\n",
      "损失函数： 0.110513\n",
      "时间步 1285000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.189691e+01/ 轮得分 96.55\n",
      "损失函数： 0.183652\n",
      "时间步 1286000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.471955e+01/ 轮得分 96.55\n",
      "损失函数： 0.0378933\n",
      "时间步 1287000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.533553e+01/ 轮得分 96.78\n",
      "损失函数： 0.0265768\n",
      "时间步 1288000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.316892e+01/ 轮得分 96.84\n",
      "损失函数： 0.0878178\n",
      "时间步 1289000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.351921e+01/ 轮得分 96.84\n",
      "损失函数： 0.11573\n",
      "时间步 1290000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.545259e+01/ 轮得分 97.08\n",
      "损失函数： 0.079417\n",
      "时间步 1291000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.147269e+01/ 轮得分 97.11\n",
      "损失函数： 0.13214\n",
      "时间步 1292000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.254527e+01/ 轮得分 97.10\n",
      "损失函数： 0.0608321\n",
      "时间步 1293000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.382064e+01/ 轮得分 97.22\n",
      "损失函数： 0.0932727\n",
      "时间步 1294000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.197970e+01/ 轮得分 97.22\n",
      "损失函数： 0.0584364\n",
      "时间步 1295000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.341995e+01/ 轮得分 97.28\n",
      "损失函数： 0.0691064\n",
      "时间步 1296000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.593221e+01/ 轮得分 97.37\n",
      "损失函数： 0.0719104\n",
      "时间步 1297000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.311723e+01/ 轮得分 97.37\n",
      "损失函数： 0.0812884\n",
      "时间步 1298000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.483779e+01/ 轮得分 97.45\n",
      "损失函数： 0.0883344\n",
      "时间步 1299000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.339510e+01/ 轮得分 97.45\n",
      "损失函数： 0.0800307\n",
      "时间步 1300000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.293064e+01/ 轮得分 97.66\n",
      "损失函数： 0.0741477\n",
      "时间步 1301000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.305889e+01/ 轮得分 97.65\n",
      "损失函数： 0.0460529\n",
      "时间步 1302000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.454968e+01/ 轮得分 97.65\n",
      "损失函数： 0.0421094\n",
      "时间步 1303000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.323110e+01/ 轮得分 97.65\n",
      "损失函数： 0.0957168\n",
      "时间步 1304000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.202975e+01/ 轮得分 97.92\n",
      "损失函数： 0.0522899\n",
      "时间步 1305000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.236654e+01/ 轮得分 97.94\n",
      "损失函数： 0.0384036\n",
      "时间步 1306000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.283696e+01/ 轮得分 97.85\n",
      "损失函数： 0.0959038\n",
      "时间步 1307000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.383613e+01/ 轮得分 97.88\n",
      "损失函数： 0.0995843\n",
      "时间步 1308000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.382801e+01/ 轮得分 97.99\n",
      "损失函数： 0.0446192\n",
      "时间步 1309000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.143964e+01/ 轮得分 98.02\n",
      "损失函数： 0.0651192\n",
      "时间步 1310000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.254262e+01/ 轮得分 97.90\n",
      "损失函数： 0.103805\n",
      "时间步 1311000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.515085e+01/ 轮得分 98.02\n",
      "损失函数： 0.0403992\n",
      "时间步 1312000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.063421e+01/ 轮得分 98.08\n",
      "损失函数： 0.0737397\n",
      "时间步 1313000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.330011e+01/ 轮得分 98.07\n",
      "损失函数： 0.0587268\n",
      "时间步 1314000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.204463e+01/ 轮得分 98.07\n",
      "损失函数： 0.0378168\n",
      "时间步 1315000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.119682e+01/ 轮得分 98.05\n",
      "损失函数： 0.121754\n",
      "时间步 1316000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.113465e+01/ 轮得分 98.13\n",
      "损失函数： 0.117293\n",
      "时间步 1317000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.474928e+01/ 轮得分 98.02\n",
      "损失函数： 0.0658863\n",
      "时间步 1318000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.186863e+01/ 轮得分 98.02\n",
      "损失函数： 0.0759945\n",
      "时间步 1319000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.315075e+01/ 轮得分 98.32\n",
      "损失函数： 0.0487462\n",
      "时间步 1320000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.280001e+01/ 轮得分 98.24\n",
      "损失函数： 0.0737449\n",
      "时间步 1321000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.097718e+01/ 轮得分 98.24\n",
      "损失函数： 0.0778597\n",
      "时间步 1322000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.407986e+01/ 轮得分 98.36\n",
      "损失函数： 0.0811093\n",
      "时间步 1323000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.361646e+01/ 轮得分 98.36\n",
      "损失函数： 0.0576502\n",
      "时间步 1324000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.276236e+01/ 轮得分 98.59\n",
      "损失函数： 0.0249057\n",
      "时间步 1325000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.318378e+01/ 轮得分 98.59\n",
      "损失函数： 0.112885\n",
      "时间步 1326000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.321604e+01/ 轮得分 98.72\n",
      "损失函数： 0.0439893\n",
      "时间步 1327000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 9.085359e+00/ 轮得分 98.72\n",
      "损失函数： 0.0528896\n",
      "时间步 1328000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.324452e+01/ 轮得分 98.75\n",
      "损失函数： 0.0986522\n",
      "时间步 1329000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.294531e+01/ 轮得分 98.87\n",
      "损失函数： 0.0876594\n",
      "时间步 1330000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 4.664791e+00/ 轮得分 98.87\n",
      "损失函数： 0.0401163\n",
      "时间步 1331000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.549044e+01/ 轮得分 98.97\n",
      "损失函数： 0.10283\n",
      "时间步 1332000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.204522e+01/ 轮得分 98.97\n",
      "损失函数： 0.10379\n",
      "时间步 1333000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.218591e+01/ 轮得分 98.96\n",
      "损失函数： 0.070116\n",
      "时间步 1334000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.196646e+01/ 轮得分 98.76\n",
      "损失函数： 0.0678035\n",
      "时间步 1335000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.235226e+01/ 轮得分 98.72\n",
      "损失函数： 0.0593125\n",
      "时间步 1336000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.231630e+01/ 轮得分 98.71\n",
      "损失函数： 0.207437\n",
      "时间步 1337000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.394725e+01/ 轮得分 98.71\n",
      "损失函数： 0.104471\n",
      "时间步 1338000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.159910e+01/ 轮得分 98.71\n",
      "损失函数： 0.0653233\n",
      "时间步 1339000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.296472e+01/ 轮得分 98.71\n",
      "损失函数： 0.151489\n",
      "时间步 1340000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.218703e+01/ 轮得分 98.71\n",
      "损失函数： 0.0311644\n",
      "时间步 1341000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.413956e+01/ 轮得分 98.71\n",
      "损失函数： 0.115573\n",
      "时间步 1342000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.324577e+01/ 轮得分 99.27\n",
      "损失函数： 0.0754307\n",
      "时间步 1343000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.327230e+01/ 轮得分 99.28\n",
      "损失函数： 0.0644887\n",
      "时间步 1344000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.257065e+01/ 轮得分 99.28\n",
      "损失函数： 0.0739232\n",
      "时间步 1345000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.286874e+01/ 轮得分 99.28\n",
      "损失函数： 0.0421098\n",
      "时间步 1346000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.518619e+01/ 轮得分 99.33\n",
      "损失函数： 0.0567361\n",
      "时间步 1347000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.303546e+01/ 轮得分 99.37\n",
      "损失函数： 0.0585054\n",
      "时间步 1348000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.242156e+01/ 轮得分 99.37\n",
      "损失函数： 0.0459596\n",
      "时间步 1349000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.592830e+01/ 轮得分 99.37\n",
      "损失函数： 0.0954572\n",
      "时间步 1350000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 9.025076e+00/ 轮得分 99.63\n",
      "损失函数： 0.0378516\n",
      "时间步 1351000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.349539e+01/ 轮得分 99.65\n",
      "损失函数： 0.0302596\n",
      "时间步 1352000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.342237e+01/ 轮得分 99.65\n",
      "损失函数： 0.0399268\n",
      "时间步 1353000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.303343e+01/ 轮得分 99.75\n",
      "损失函数： 0.099235\n",
      "时间步 1354000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.354083e+01/ 轮得分 99.83\n",
      "损失函数： 0.100246\n",
      "时间步 1355000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.536308e+01/ 轮得分 99.77\n",
      "损失函数： 0.0521953\n",
      "时间步 1356000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.295303e+01/ 轮得分 99.77\n",
      "损失函数： 0.0869396\n",
      "时间步 1357000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.255134e+01/ 轮得分 99.86\n",
      "损失函数： 0.0605904\n",
      "时间步 1358000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.264518e+01/ 轮得分 99.85\n",
      "损失函数： 0.0425686\n",
      "时间步 1359000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.480106e+01/ 轮得分 99.85\n",
      "损失函数： 0.0898731\n",
      "时间步 1360000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.183406e+01/ 轮得分 99.98\n",
      "损失函数： 0.0353784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1361000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.305912e+01/ 轮得分 99.82\n",
      "损失函数： 0.0476227\n",
      "时间步 1362000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.238261e+01/ 轮得分 99.82\n",
      "损失函数： 0.0657006\n",
      "时间步 1363000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.250243e+01/ 轮得分 99.82\n",
      "损失函数： 0.172607\n",
      "时间步 1364000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.328145e+01/ 轮得分 99.82\n",
      "损失函数： 0.0275381\n",
      "时间步 1365000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 7.157476e+00/ 轮得分 100.28\n",
      "损失函数： 0.0398727\n",
      "时间步 1366000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.308750e+01/ 轮得分 100.25\n",
      "损失函数： 0.129123\n",
      "时间步 1367000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.068071e+01/ 轮得分 100.10\n",
      "损失函数： 0.0185822\n",
      "时间步 1368000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.384814e+01/ 轮得分 100.06\n",
      "损失函数： 0.0703423\n",
      "时间步 1369000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.267357e+01/ 轮得分 100.24\n",
      "损失函数： 0.0282128\n",
      "时间步 1370000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.550286e+01/ 轮得分 100.24\n",
      "损失函数： 0.0724802\n",
      "时间步 1371000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.438958e+01/ 轮得分 100.24\n",
      "损失函数： 0.0708572\n",
      "时间步 1372000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.414063e+01/ 轮得分 100.24\n",
      "损失函数： 0.0648041\n",
      "时间步 1373000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.053353e+01/ 轮得分 100.24\n",
      "损失函数： 0.0635075\n",
      "时间步 1374000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.377165e+01/ 轮得分 100.24\n",
      "损失函数： 0.0348227\n",
      "时间步 1375000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.306344e+01/ 轮得分 100.24\n",
      "损失函数： 0.0495162\n",
      "时间步 1376000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.160610e+01/ 轮得分 100.24\n",
      "损失函数： 0.0462361\n",
      "时间步 1377000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.404140e+01/ 轮得分 100.24\n",
      "损失函数： 0.043012\n",
      "时间步 1378000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.008495e+01/ 轮得分 101.21\n",
      "损失函数： 0.0579759\n",
      "时间步 1379000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 9.085936e+00/ 轮得分 101.31\n",
      "损失函数： 0.117675\n",
      "时间步 1380000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.466064e+01/ 轮得分 101.27\n",
      "损失函数： 0.0622329\n",
      "时间步 1381000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.238894e+01/ 轮得分 101.40\n",
      "损失函数： 0.141534\n",
      "时间步 1382000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.447378e+01/ 轮得分 101.41\n",
      "损失函数： 0.0923963\n",
      "时间步 1383000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.261171e+01/ 轮得分 101.50\n",
      "损失函数： 0.0516154\n",
      "时间步 1384000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.555922e+01/ 轮得分 101.50\n",
      "损失函数： 0.0692861\n",
      "时间步 1385000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.509674e+01/ 轮得分 101.56\n",
      "损失函数： 0.0412533\n",
      "时间步 1386000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.436693e+01/ 轮得分 101.64\n",
      "损失函数： 0.133001\n",
      "时间步 1387000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.497799e+01/ 轮得分 101.68\n",
      "损失函数： 0.26477\n",
      "时间步 1388000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.543102e+01/ 轮得分 101.79\n",
      "损失函数： 0.0913716\n",
      "时间步 1389000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.089847e+01/ 轮得分 101.77\n",
      "损失函数： 0.183427\n",
      "时间步 1390000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.469737e+01/ 轮得分 101.85\n",
      "损失函数： 0.056045\n",
      "时间步 1391000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.344920e+01/ 轮得分 101.87\n",
      "损失函数： 0.03984\n",
      "时间步 1392000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.250585e+01/ 轮得分 101.87\n",
      "损失函数： 0.0382426\n",
      "时间步 1393000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.344157e+01/ 轮得分 101.87\n",
      "损失函数： 0.0428562\n",
      "时间步 1394000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.395712e+01/ 轮得分 101.87\n",
      "损失函数： 2.39307\n",
      "时间步 1395000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.387942e+01/ 轮得分 102.27\n",
      "损失函数： 0.111537\n",
      "时间步 1396000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.423477e+01/ 轮得分 102.27\n",
      "损失函数： 0.0448059\n",
      "时间步 1397000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.316426e+01/ 轮得分 102.47\n",
      "损失函数： 0.0481883\n",
      "时间步 1398000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.493973e+01/ 轮得分 102.45\n",
      "损失函数： 0.0529367\n",
      "时间步 1399000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.286010e+01/ 轮得分 102.45\n",
      "损失函数： 0.0413388\n",
      "时间步 1400000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.342402e+01/ 轮得分 102.45\n",
      "损失函数： 0.0266634\n",
      "时间步 1401000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 7.613674e+00/ 轮得分 102.45\n",
      "损失函数： 0.0484954\n",
      "时间步 1402000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.307953e+01/ 轮得分 102.84\n",
      "损失函数： 0.0343441\n",
      "时间步 1403000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.311644e+01/ 轮得分 102.46\n",
      "损失函数： 0.0322449\n",
      "时间步 1404000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.564794e+01/ 轮得分 102.46\n",
      "损失函数： 0.0338092\n",
      "时间步 1405000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.315425e+01/ 轮得分 102.67\n",
      "损失函数： 0.113865\n",
      "时间步 1406000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.021801e+01/ 轮得分 102.77\n",
      "损失函数： 0.086655\n",
      "时间步 1407000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.183727e+01/ 轮得分 102.88\n",
      "损失函数： 0.0357363\n",
      "时间步 1408000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.101575e+01/ 轮得分 102.77\n",
      "损失函数： 0.0551538\n",
      "时间步 1409000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.180699e+01/ 轮得分 102.77\n",
      "损失函数： 0.0837146\n",
      "时间步 1410000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.268426e+01/ 轮得分 103.02\n",
      "损失函数： 0.0362012\n",
      "时间步 1411000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.235326e+01/ 轮得分 102.93\n",
      "损失函数： 0.125697\n",
      "时间步 1412000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.172778e+01/ 轮得分 102.97\n",
      "损失函数： 0.0802499\n",
      "时间步 1413000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.260521e+01/ 轮得分 103.08\n",
      "损失函数： 0.0449496\n",
      "时间步 1414000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.272295e+01/ 轮得分 103.08\n",
      "损失函数： 0.0438796\n",
      "时间步 1415000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.185871e+01/ 轮得分 103.08\n",
      "损失函数： 0.0354825\n",
      "时间步 1416000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.367492e+01/ 轮得分 103.08\n",
      "损失函数： 0.0235461\n",
      "时间步 1417000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.272977e+01/ 轮得分 103.08\n",
      "损失函数： 0.0820255\n",
      "时间步 1418000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.336994e+01/ 轮得分 103.41\n",
      "损失函数： 0.0360717\n",
      "时间步 1419000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.398051e+01/ 轮得分 103.51\n",
      "损失函数： 0.0798133\n",
      "时间步 1420000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.463478e+01/ 轮得分 103.53\n",
      "损失函数： 0.0588243\n",
      "时间步 1421000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.211090e+01/ 轮得分 103.53\n",
      "损失函数： 0.0984147\n",
      "时间步 1422000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.278388e+01/ 轮得分 103.53\n",
      "损失函数： 0.0830273\n",
      "时间步 1423000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.667109e+01/ 轮得分 103.53\n",
      "损失函数： 0.0674653\n",
      "时间步 1424000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.485425e+01/ 轮得分 103.53\n",
      "损失函数： 0.0876457\n",
      "时间步 1425000/ 状态 explore/ Epsilon 0.11/ 行动 1/ 奖励 0.1/ Q_MAX 1.445286e+01/ 轮得分 103.53\n",
      "损失函数： 0.0629575\n",
      "时间步 1426000/ 状态 explore/ Epsilon 0.11/ 行动 2/ 奖励 0.1/ Q_MAX 1.224216e+01/ 轮得分 103.53\n",
      "损失函数： 0.044627\n",
      "时间步 1427000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.310808e+01/ 轮得分 103.53\n",
      "损失函数： 0.0558598\n",
      "时间步 1428000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.102629e+01/ 轮得分 104.45\n",
      "损失函数： 0.0641241\n",
      "时间步 1429000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 7.355435e+00/ 轮得分 104.45\n",
      "损失函数： 0.0433149\n",
      "时间步 1430000/ 状态 explore/ Epsilon 0.11/ 行动 0/ 奖励 0.1/ Q_MAX 1.286837e+01/ 轮得分 104.62\n",
      "损失函数： 0.0289279\n",
      "时间步 1431000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.335112e+01/ 轮得分 104.73\n",
      "损失函数： 0.0687516\n",
      "时间步 1432000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.356373e+01/ 轮得分 104.73\n",
      "损失函数： 0.0852824\n",
      "时间步 1433000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.257344e+01/ 轮得分 104.73\n",
      "损失函数： 0.0533161\n",
      "时间步 1434000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.477371e+01/ 轮得分 105.02\n",
      "损失函数： 0.0596036\n",
      "时间步 1435000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.472950e+01/ 轮得分 105.02\n",
      "损失函数： 0.119915\n",
      "时间步 1436000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.243505e+01/ 轮得分 105.02\n",
      "损失函数： 0.0278326\n",
      "时间步 1437000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.427200e+01/ 轮得分 105.32\n",
      "损失函数： 0.0409154\n",
      "时间步 1438000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.308783e+01/ 轮得分 105.24\n",
      "损失函数： 0.0569312\n",
      "时间步 1439000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.297593e+01/ 轮得分 105.24\n",
      "损失函数： 2.54379\n",
      "时间步 1440000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.212921e+01/ 轮得分 105.24\n",
      "损失函数： 0.038761\n",
      "时间步 1441000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.379639e+01/ 轮得分 105.41\n",
      "损失函数： 0.0638804\n",
      "时间步 1442000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.289923e+01/ 轮得分 105.41\n",
      "损失函数： 0.0615981\n",
      "时间步 1443000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.323721e+01/ 轮得分 105.41\n",
      "损失函数： 0.0443546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1444000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.256164e+01/ 轮得分 105.41\n",
      "损失函数： 0.0748717\n",
      "时间步 1445000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.316381e+01/ 轮得分 105.84\n",
      "损失函数： 0.04542\n",
      "时间步 1446000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 1.1/ Q_MAX 1.101685e+01/ 轮得分 105.84\n",
      "损失函数： 0.0500666\n",
      "时间步 1447000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.327942e+01/ 轮得分 105.94\n",
      "损失函数： 0.0282651\n",
      "时间步 1448000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.258719e+01/ 轮得分 105.94\n",
      "损失函数： 0.0538292\n",
      "时间步 1449000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.682613e+01/ 轮得分 106.12\n",
      "损失函数： 0.0536583\n",
      "时间步 1450000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.469804e+01/ 轮得分 106.12\n",
      "损失函数： 0.0597434\n",
      "时间步 1451000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.265964e+01/ 轮得分 106.26\n",
      "损失函数： 0.0460751\n",
      "时间步 1452000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.238431e+01/ 轮得分 106.28\n",
      "损失函数： 0.166353\n",
      "时间步 1453000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.267278e+01/ 轮得分 106.30\n",
      "损失函数： 0.0463221\n",
      "时间步 1454000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.231930e+01/ 轮得分 106.30\n",
      "损失函数： 0.0492251\n",
      "时间步 1455000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.425264e+01/ 轮得分 106.30\n",
      "损失函数： 0.0271726\n",
      "时间步 1456000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.282467e+01/ 轮得分 106.30\n",
      "损失函数： 0.0599542\n",
      "时间步 1457000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.259937e+01/ 轮得分 106.30\n",
      "损失函数： 0.0521867\n",
      "时间步 1458000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.171035e+01/ 轮得分 106.61\n",
      "损失函数： 0.0248261\n",
      "时间步 1459000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.436957e+01/ 轮得分 106.63\n",
      "损失函数： 0.043353\n",
      "时间步 1460000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.192150e+01/ 轮得分 106.79\n",
      "损失函数： 0.0937738\n",
      "时间步 1461000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.067819e+01/ 轮得分 106.79\n",
      "损失函数： 0.071253\n",
      "时间步 1462000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.254994e+01/ 轮得分 106.95\n",
      "损失函数： 0.0558239\n",
      "时间步 1463000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.304522e+01/ 轮得分 106.95\n",
      "损失函数： 0.0756613\n",
      "时间步 1464000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.444360e+01/ 轮得分 107.14\n",
      "损失函数： 0.137817\n",
      "时间步 1465000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.216101e+01/ 轮得分 107.14\n",
      "损失函数： 0.142856\n",
      "时间步 1466000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.331752e+01/ 轮得分 107.34\n",
      "损失函数： 0.128184\n",
      "时间步 1467000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.166689e+01/ 轮得分 107.09\n",
      "损失函数： 0.0428854\n",
      "时间步 1468000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.214296e+01/ 轮得分 107.13\n",
      "损失函数： 0.0889123\n",
      "时间步 1469000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.315053e+01/ 轮得分 107.13\n",
      "损失函数： 0.0244562\n",
      "时间步 1470000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.349607e+01/ 轮得分 107.13\n",
      "损失函数： 0.0628474\n",
      "时间步 1471000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.239529e+01/ 轮得分 107.13\n",
      "损失函数： 0.0645863\n",
      "时间步 1472000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.290380e+01/ 轮得分 107.50\n",
      "损失函数： 0.0277435\n",
      "时间步 1473000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.312334e+01/ 轮得分 107.60\n",
      "损失函数： 0.0631923\n",
      "时间步 1474000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.241430e+01/ 轮得分 107.63\n",
      "损失函数： 0.0548494\n",
      "时间步 1475000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.200050e+01/ 轮得分 107.63\n",
      "损失函数： 0.0664276\n",
      "时间步 1476000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.277651e+01/ 轮得分 107.77\n",
      "损失函数： 0.204692\n",
      "时间步 1477000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.266329e+01/ 轮得分 107.87\n",
      "损失函数： 0.0590885\n",
      "时间步 1478000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.035464e+01/ 轮得分 107.87\n",
      "损失函数： 0.0897504\n",
      "时间步 1479000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.235770e+01/ 轮得分 108.12\n",
      "损失函数： 0.0529735\n",
      "时间步 1480000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.204468e+01/ 轮得分 108.21\n",
      "损失函数： 0.0537631\n",
      "时间步 1481000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.020468e+01/ 轮得分 108.21\n",
      "损失函数： 0.0242383\n",
      "时间步 1482000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.307413e+01/ 轮得分 108.26\n",
      "损失函数： 0.0259217\n",
      "时间步 1483000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.145115e+01/ 轮得分 108.37\n",
      "损失函数： 0.0569179\n",
      "时间步 1484000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.112106e+01/ 轮得分 108.37\n",
      "损失函数： 0.0484635\n",
      "时间步 1485000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.442595e+01/ 轮得分 108.47\n",
      "损失函数： 0.0477194\n",
      "时间步 1486000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.249378e+01/ 轮得分 108.44\n",
      "损失函数： 0.0550537\n",
      "时间步 1487000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.355782e+01/ 轮得分 108.65\n",
      "损失函数： 0.726911\n",
      "时间步 1488000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.460269e+01/ 轮得分 108.70\n",
      "损失函数： 0.0540193\n",
      "时间步 1489000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.390691e+01/ 轮得分 108.70\n",
      "损失函数： 0.147744\n",
      "时间步 1490000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.419712e+01/ 轮得分 108.70\n",
      "损失函数： 0.0298608\n",
      "时间步 1491000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.349147e+01/ 轮得分 108.88\n",
      "损失函数： 0.0789803\n",
      "时间步 1492000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.278245e+01/ 轮得分 108.88\n",
      "损失函数： 0.0619702\n",
      "时间步 1493000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.492205e+01/ 轮得分 108.88\n",
      "损失函数： 0.0366092\n",
      "时间步 1494000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.219534e+01/ 轮得分 109.20\n",
      "损失函数： 0.0473068\n",
      "时间步 1495000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.292840e+01/ 轮得分 109.25\n",
      "损失函数： 0.0489959\n",
      "时间步 1496000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.307274e+01/ 轮得分 109.25\n",
      "损失函数： 0.0506398\n",
      "时间步 1497000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.244520e+01/ 轮得分 109.25\n",
      "损失函数： 0.0519909\n",
      "时间步 1498000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.213439e+01/ 轮得分 109.25\n",
      "损失函数： 0.0412286\n",
      "时间步 1499000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.160079e+01/ 轮得分 109.52\n",
      "损失函数： 0.0982324\n",
      "时间步 1500000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.328920e+01/ 轮得分 109.52\n",
      "损失函数： 0.033677\n",
      "时间步 1501000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.054985e+01/ 轮得分 109.52\n",
      "损失函数： 0.0515151\n",
      "时间步 1502000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.427635e+01/ 轮得分 109.67\n",
      "损失函数： 0.0573731\n",
      "时间步 1503000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.277096e+01/ 轮得分 109.79\n",
      "损失函数： 0.0702917\n",
      "时间步 1504000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.299612e+01/ 轮得分 109.79\n",
      "损失函数： 0.0344913\n",
      "时间步 1505000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.344034e+01/ 轮得分 109.79\n",
      "损失函数： 0.0534946\n",
      "时间步 1506000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.357588e+01/ 轮得分 109.79\n",
      "损失函数： 0.0272317\n",
      "时间步 1507000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.328489e+01/ 轮得分 109.79\n",
      "损失函数： 0.0772691\n",
      "时间步 1508000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.279816e+01/ 轮得分 110.31\n",
      "损失函数： 0.0761298\n",
      "时间步 1509000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.327128e+01/ 轮得分 110.31\n",
      "损失函数： 0.0647317\n",
      "时间步 1510000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.286129e+01/ 轮得分 110.31\n",
      "损失函数： 0.0527496\n",
      "时间步 1511000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.464043e+01/ 轮得分 110.31\n",
      "损失函数： 0.0623383\n",
      "时间步 1512000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.418050e+01/ 轮得分 110.68\n",
      "损失函数： 0.0697123\n",
      "时间步 1513000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 9.579255e+00/ 轮得分 110.42\n",
      "损失函数： 0.0268697\n",
      "时间步 1514000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.462642e+01/ 轮得分 110.42\n",
      "损失函数： 0.0706822\n",
      "时间步 1515000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.400337e+01/ 轮得分 110.42\n",
      "损失函数： 0.0394165\n",
      "时间步 1516000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 5.423655e+00/ 轮得分 110.42\n",
      "损失函数： 0.0438827\n",
      "时间步 1517000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.509412e+01/ 轮得分 110.76\n",
      "损失函数： 0.0966592\n",
      "时间步 1518000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.464869e+01/ 轮得分 110.82\n",
      "损失函数： 0.0497354\n",
      "时间步 1519000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.284189e+01/ 轮得分 110.99\n",
      "损失函数： 0.0208395\n",
      "时间步 1520000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.619004e+01/ 轮得分 111.07\n",
      "损失函数： 0.049123\n",
      "时间步 1521000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.372634e+01/ 轮得分 110.88\n",
      "损失函数： 0.0832623\n",
      "时间步 1522000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.606949e+01/ 轮得分 111.03\n",
      "损失函数： 0.0439013\n",
      "时间步 1523000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.439790e+01/ 轮得分 111.03\n",
      "损失函数： 0.0668247\n",
      "时间步 1524000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.373319e+01/ 轮得分 111.03\n",
      "损失函数： 0.0830176\n",
      "时间步 1525000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.622772e+01/ 轮得分 111.28\n",
      "损失函数： 0.0241608\n",
      "时间步 1526000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 1.1/ Q_MAX 1.769415e+01/ 轮得分 111.28\n",
      "损失函数： 0.0655043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1527000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.212098e+01/ 轮得分 111.28\n",
      "损失函数： 0.0284017\n",
      "时间步 1528000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.477379e+01/ 轮得分 111.48\n",
      "损失函数： 0.0579233\n",
      "时间步 1529000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.544437e+01/ 轮得分 111.56\n",
      "损失函数： 0.0372977\n",
      "时间步 1530000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.356043e+01/ 轮得分 111.56\n",
      "损失函数： 0.067225\n",
      "时间步 1531000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 1.1/ Q_MAX 1.507102e+01/ 轮得分 111.79\n",
      "损失函数： 0.0436451\n",
      "时间步 1532000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.459286e+01/ 轮得分 111.79\n",
      "损失函数： 0.0311986\n",
      "时间步 1533000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.288943e+01/ 轮得分 111.97\n",
      "损失函数： 0.0847481\n",
      "时间步 1534000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.286893e+01/ 轮得分 111.97\n",
      "损失函数： 0.0629764\n",
      "时间步 1535000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.368026e+01/ 轮得分 112.15\n",
      "损失函数： 0.153414\n",
      "时间步 1536000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.420902e+01/ 轮得分 112.17\n",
      "损失函数： 0.0412768\n",
      "时间步 1537000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.355293e+01/ 轮得分 112.17\n",
      "损失函数： 0.0643812\n",
      "时间步 1538000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.390163e+01/ 轮得分 112.17\n",
      "损失函数： 0.0725996\n",
      "时间步 1539000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.490100e+01/ 轮得分 112.59\n",
      "损失函数： 0.0558779\n",
      "时间步 1540000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.428261e+01/ 轮得分 112.59\n",
      "损失函数： 0.0299863\n",
      "时间步 1541000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.244346e+01/ 轮得分 112.59\n",
      "损失函数： 0.0823548\n",
      "时间步 1542000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.457127e+01/ 轮得分 112.59\n",
      "损失函数： 0.0525805\n",
      "时间步 1543000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.507115e+01/ 轮得分 112.95\n",
      "损失函数： 0.0547914\n",
      "时间步 1544000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.299703e+01/ 轮得分 112.95\n",
      "损失函数： 0.186994\n",
      "时间步 1545000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.299765e+01/ 轮得分 113.03\n",
      "损失函数： 0.0694041\n",
      "时间步 1546000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.270655e+01/ 轮得分 113.02\n",
      "损失函数： 0.0475791\n",
      "时间步 1547000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.293613e+01/ 轮得分 113.05\n",
      "损失函数： 0.0614084\n",
      "时间步 1548000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.388487e+01/ 轮得分 113.05\n",
      "损失函数： 0.064383\n",
      "时间步 1549000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.392938e+01/ 轮得分 113.14\n",
      "损失函数： 0.0406898\n",
      "时间步 1550000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.450821e+01/ 轮得分 113.14\n",
      "损失函数： 0.0361526\n",
      "时间步 1551000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.388136e+01/ 轮得分 113.14\n",
      "损失函数： 0.0299251\n",
      "时间步 1552000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.176915e+01/ 轮得分 113.14\n",
      "损失函数： 0.0711144\n",
      "时间步 1553000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.213565e+01/ 轮得分 113.14\n",
      "损失函数： 0.0915989\n",
      "时间步 1554000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.354564e+01/ 轮得分 113.72\n",
      "损失函数： 0.0472375\n",
      "时间步 1555000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 1.1/ Q_MAX 1.491615e+01/ 轮得分 113.80\n",
      "损失函数： 0.0934194\n",
      "时间步 1556000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 5.325418e+00/ 轮得分 113.86\n",
      "损失函数： 0.0457398\n",
      "时间步 1557000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.329484e+01/ 轮得分 113.72\n",
      "损失函数： 0.0506382\n",
      "时间步 1558000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.290611e+01/ 轮得分 113.72\n",
      "损失函数： 0.118154\n",
      "时间步 1559000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.299568e+01/ 轮得分 113.72\n",
      "损失函数： 0.0586707\n",
      "时间步 1560000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.242813e+01/ 轮得分 113.72\n",
      "损失函数： 0.124232\n",
      "时间步 1561000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.485098e+01/ 轮得分 113.72\n",
      "损失函数： 0.0496098\n",
      "时间步 1562000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.422853e+01/ 轮得分 113.72\n",
      "损失函数： 0.0598814\n",
      "时间步 1563000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.342124e+01/ 轮得分 114.39\n",
      "损失函数： 0.0544026\n",
      "时间步 1564000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.259232e+01/ 轮得分 114.39\n",
      "损失函数： 0.0664053\n",
      "时间步 1565000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.259172e+01/ 轮得分 114.40\n",
      "损失函数： 0.0704464\n",
      "时间步 1566000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.258477e+01/ 轮得分 114.50\n",
      "损失函数： 0.0327184\n",
      "时间步 1567000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.367695e+01/ 轮得分 114.59\n",
      "损失函数： 0.0590103\n",
      "时间步 1568000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.473085e+01/ 轮得分 114.59\n",
      "损失函数： 0.0388623\n",
      "时间步 1569000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.529078e+01/ 轮得分 114.59\n",
      "损失函数： 0.0400065\n",
      "时间步 1570000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.420026e+01/ 轮得分 114.84\n",
      "损失函数： 0.0580597\n",
      "时间步 1571000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.372278e+01/ 轮得分 114.84\n",
      "损失函数： 0.0863595\n",
      "时间步 1572000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.337955e+01/ 轮得分 114.91\n",
      "损失函数： 0.0617334\n",
      "时间步 1573000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.323796e+01/ 轮得分 115.02\n",
      "损失函数： 0.044601\n",
      "时间步 1574000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.509645e+01/ 轮得分 115.02\n",
      "损失函数： 0.0349549\n",
      "时间步 1575000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.281417e+01/ 轮得分 115.26\n",
      "损失函数： 0.0592119\n",
      "时间步 1576000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.378362e+01/ 轮得分 115.26\n",
      "损失函数： 0.0631095\n",
      "时间步 1577000/ 状态 explore/ Epsilon 0.10/ 行动 2/ 奖励 0.1/ Q_MAX 1.273062e+01/ 轮得分 115.26\n",
      "损失函数： 0.0262424\n",
      "时间步 1578000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.332440e+01/ 轮得分 115.26\n",
      "损失函数： 0.0858398\n",
      "时间步 1579000/ 状态 explore/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 1.177337e+01/ 轮得分 115.58\n",
      "损失函数： 0.0249382\n",
      "时间步 1580000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 1.321120e+01/ 轮得分 115.58\n",
      "损失函数： 0.0304358\n",
      "时间步 1581000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.239191e+01/ 轮得分 115.57\n",
      "损失函数： 0.0216634\n",
      "时间步 1582000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.363327e+01/ 轮得分 115.57\n",
      "损失函数： 0.0552378\n",
      "时间步 1583000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.388583e+01/ 轮得分 115.84\n",
      "损失函数： 0.0551745\n",
      "时间步 1584000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.153454e+01/ 轮得分 115.84\n",
      "损失函数： 0.0834585\n",
      "时间步 1585000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 1.1/ Q_MAX 1.240854e+01/ 轮得分 115.84\n",
      "损失函数： 0.0347983\n",
      "时间步 1586000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.468785e+01/ 轮得分 115.97\n",
      "损失函数： 0.0497019\n",
      "时间步 1587000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.509827e+01/ 轮得分 115.97\n",
      "损失函数： 0.054907\n",
      "时间步 1588000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.412622e+01/ 轮得分 116.11\n",
      "损失函数： 0.0492198\n",
      "时间步 1589000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.600574e+01/ 轮得分 116.15\n",
      "损失函数： 0.0415479\n",
      "时间步 1590000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.318167e+01/ 轮得分 116.18\n",
      "损失函数： 0.026581\n",
      "时间步 1591000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.373995e+01/ 轮得分 116.18\n",
      "损失函数： 0.117819\n",
      "时间步 1592000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.276286e+01/ 轮得分 116.36\n",
      "损失函数： 0.0926202\n",
      "时间步 1593000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.297264e+01/ 轮得分 116.43\n",
      "损失函数： 0.0768356\n",
      "时间步 1594000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.417333e+01/ 轮得分 116.43\n",
      "损失函数： 0.136029\n",
      "时间步 1595000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.352847e+01/ 轮得分 116.50\n",
      "损失函数： 0.059872\n",
      "时间步 1596000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.383916e+01/ 轮得分 116.50\n",
      "损失函数： 0.144431\n",
      "时间步 1597000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.344224e+01/ 轮得分 116.50\n",
      "损失函数： 0.0273311\n",
      "时间步 1598000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.354337e+01/ 轮得分 116.50\n",
      "损失函数： 0.0639441\n",
      "时间步 1599000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.372135e+01/ 轮得分 116.85\n",
      "损失函数： 0.0453598\n",
      "时间步 1600000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.208847e+01/ 轮得分 116.85\n",
      "损失函数： 0.0486142\n",
      "时间步 1601000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.381061e+01/ 轮得分 117.13\n",
      "损失函数： 0.0321585\n",
      "时间步 1602000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.243305e+01/ 轮得分 117.13\n",
      "损失函数： 0.110462\n",
      "时间步 1603000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.499156e+01/ 轮得分 117.13\n",
      "损失函数： 0.0527734\n",
      "时间步 1604000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.346968e+01/ 轮得分 117.54\n",
      "损失函数： 0.0452735\n",
      "时间步 1605000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.465079e+01/ 轮得分 117.54\n",
      "损失函数： 0.0406213\n",
      "时间步 1606000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.390232e+01/ 轮得分 117.54\n",
      "损失函数： 0.0343659\n",
      "时间步 1607000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.289981e+01/ 轮得分 117.84\n",
      "损失函数： 2.95064\n",
      "时间步 1608000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.422910e+01/ 轮得分 117.88\n",
      "损失函数： 0.0497614\n",
      "时间步 1609000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.453047e+01/ 轮得分 118.01\n",
      "损失函数： 0.0387091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1610000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.264137e+01/ 轮得分 118.09\n",
      "损失函数： 0.0267039\n",
      "时间步 1611000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.225400e+01/ 轮得分 118.09\n",
      "损失函数： 0.0250753\n",
      "时间步 1612000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.428955e+01/ 轮得分 118.21\n",
      "损失函数： 0.0375098\n",
      "时间步 1613000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.460993e+01/ 轮得分 118.28\n",
      "损失函数： 0.0664571\n",
      "时间步 1614000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.060568e+01/ 轮得分 118.25\n",
      "损失函数： 0.0781761\n",
      "时间步 1615000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.173647e+01/ 轮得分 118.36\n",
      "损失函数： 0.0882949\n",
      "时间步 1616000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.274908e+01/ 轮得分 118.31\n",
      "损失函数： 0.0397267\n",
      "时间步 1617000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.305898e+01/ 轮得分 118.31\n",
      "损失函数： 0.0321339\n",
      "时间步 1618000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.243285e+01/ 轮得分 118.31\n",
      "损失函数： 0.0483162\n",
      "时间步 1619000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.332818e+01/ 轮得分 118.31\n",
      "损失函数： 0.0342545\n",
      "时间步 1620000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.435480e+01/ 轮得分 118.31\n",
      "损失函数： 0.0781456\n",
      "时间步 1621000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.351945e+01/ 轮得分 118.82\n",
      "损失函数： 0.0390876\n",
      "时间步 1622000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.383086e+01/ 轮得分 118.94\n",
      "损失函数： 0.0759273\n",
      "时间步 1623000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 1.1/ Q_MAX 1.203685e+01/ 轮得分 118.84\n",
      "损失函数： 0.0989694\n",
      "时间步 1624000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.402029e+01/ 轮得分 118.84\n",
      "损失函数： 0.0693295\n",
      "时间步 1625000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.219633e+01/ 轮得分 119.03\n",
      "损失函数： 0.0996526\n",
      "时间步 1626000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.460813e+01/ 轮得分 119.03\n",
      "损失函数： 0.0381752\n",
      "时间步 1627000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.514633e+01/ 轮得分 119.03\n",
      "损失函数： 0.155683\n",
      "时间步 1628000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.442609e+01/ 轮得分 119.28\n",
      "损失函数： 0.0230386\n",
      "时间步 1629000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.402058e+01/ 轮得分 119.34\n",
      "损失函数： 0.108983\n",
      "时间步 1630000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.308680e+01/ 轮得分 119.34\n",
      "损失函数： 0.0905557\n",
      "时间步 1631000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.322065e+01/ 轮得分 119.34\n",
      "损失函数： 0.0502984\n",
      "时间步 1632000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.384570e+01/ 轮得分 119.74\n",
      "损失函数： 0.0661051\n",
      "时间步 1633000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.388714e+01/ 轮得分 119.74\n",
      "损失函数： 0.0569298\n",
      "时间步 1634000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.178738e+01/ 轮得分 119.74\n",
      "损失函数： 0.0513706\n",
      "时间步 1635000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.326270e+01/ 轮得分 119.74\n",
      "损失函数： 0.0353567\n",
      "时间步 1636000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.532405e+01/ 轮得分 119.74\n",
      "损失函数： 1.75384\n",
      "时间步 1637000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.379554e+01/ 轮得分 119.74\n",
      "损失函数： 0.0582402\n",
      "时间步 1638000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.435542e+01/ 轮得分 120.45\n",
      "损失函数： 0.0651602\n",
      "时间步 1639000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.418267e+01/ 轮得分 120.45\n",
      "损失函数： 0.0250032\n",
      "时间步 1640000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.250490e+01/ 轮得分 120.60\n",
      "损失函数： 0.03504\n",
      "时间步 1641000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.373029e+01/ 轮得分 120.65\n",
      "损失函数： 0.0684352\n",
      "时间步 1642000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.520103e+01/ 轮得分 120.68\n",
      "损失函数： 0.0716926\n",
      "时间步 1643000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.326015e+01/ 轮得分 120.58\n",
      "损失函数： 0.0994887\n",
      "时间步 1644000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.399260e+01/ 轮得分 120.58\n",
      "损失函数： 0.0987478\n",
      "时间步 1645000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.144060e+01/ 轮得分 120.68\n",
      "损失函数： 0.0525381\n",
      "时间步 1646000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.531015e+01/ 轮得分 120.68\n",
      "损失函数： 0.0387844\n",
      "时间步 1647000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.340504e+01/ 轮得分 120.95\n",
      "损失函数： 0.0487944\n",
      "时间步 1648000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.289809e+01/ 轮得分 120.90\n",
      "损失函数： 0.0830634\n",
      "时间步 1649000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.255231e+01/ 轮得分 120.95\n",
      "损失函数： 0.0618133\n",
      "时间步 1650000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.322780e+01/ 轮得分 120.97\n",
      "损失函数： 0.14331\n",
      "时间步 1651000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.425526e+01/ 轮得分 121.15\n",
      "损失函数： 0.172661\n",
      "时间步 1652000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.304694e+01/ 轮得分 121.15\n",
      "损失函数： 0.0277909\n",
      "时间步 1653000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.299720e+01/ 轮得分 121.15\n",
      "损失函数： 0.0431452\n",
      "时间步 1654000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.228828e+01/ 轮得分 121.38\n",
      "损失函数： 0.044917\n",
      "时间步 1655000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.263047e+01/ 轮得分 121.46\n",
      "损失函数： 0.0577214\n",
      "时间步 1656000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.249748e+01/ 轮得分 121.46\n",
      "损失函数： 0.0904852\n",
      "时间步 1657000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.386332e+01/ 轮得分 121.46\n",
      "损失函数： 0.0385956\n",
      "时间步 1658000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.308274e+01/ 轮得分 121.83\n",
      "损失函数： 0.0302161\n",
      "时间步 1659000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.218155e+01/ 轮得分 121.89\n",
      "损失函数： 0.0610831\n",
      "时间步 1660000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.384776e+01/ 轮得分 121.77\n",
      "损失函数： 0.0599361\n",
      "时间步 1661000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.244739e+01/ 轮得分 121.77\n",
      "损失函数： 0.0600667\n",
      "时间步 1662000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 1.1/ Q_MAX 1.346131e+01/ 轮得分 121.87\n",
      "损失函数： 0.0373623\n",
      "时间步 1663000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.427224e+01/ 轮得分 121.85\n",
      "损失函数： 0.101266\n",
      "时间步 1664000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.238922e+01/ 轮得分 121.79\n",
      "损失函数： 0.047298\n",
      "时间步 1665000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.116096e+01/ 轮得分 121.92\n",
      "损失函数： 0.0580942\n",
      "时间步 1666000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.098460e+01/ 轮得分 121.92\n",
      "损失函数： 0.0315863\n",
      "时间步 1667000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.567181e+01/ 轮得分 121.89\n",
      "损失函数： 0.0924349\n",
      "时间步 1668000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.499336e+01/ 轮得分 121.99\n",
      "损失函数： 0.0622874\n",
      "时间步 1669000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.384703e+01/ 轮得分 121.99\n",
      "损失函数： 0.0831121\n",
      "时间步 1670000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.660920e+01/ 轮得分 121.99\n",
      "损失函数： 0.145646\n",
      "时间步 1671000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.335410e+01/ 轮得分 121.99\n",
      "损失函数： 0.0385811\n",
      "时间步 1672000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.154233e+01/ 轮得分 121.99\n",
      "损失函数： 0.0988102\n",
      "时间步 1673000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 1.1/ Q_MAX 1.587111e+01/ 轮得分 121.99\n",
      "损失函数： 0.0695467\n",
      "时间步 1674000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.354967e+01/ 轮得分 121.99\n",
      "损失函数： 0.190919\n",
      "时间步 1675000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.335002e+01/ 轮得分 122.80\n",
      "损失函数： 0.040626\n",
      "时间步 1676000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.260813e+01/ 轮得分 122.64\n",
      "损失函数： 0.0503281\n",
      "时间步 1677000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.238321e+01/ 轮得分 122.59\n",
      "损失函数： 0.108227\n",
      "时间步 1678000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.246039e+01/ 轮得分 122.71\n",
      "损失函数： 0.0756456\n",
      "时间步 1679000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.172812e+01/ 轮得分 122.40\n",
      "损失函数： 0.0561894\n",
      "时间步 1680000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.334997e+01/ 轮得分 122.40\n",
      "损失函数： 0.0700049\n",
      "时间步 1681000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.208158e+01/ 轮得分 122.52\n",
      "损失函数： 0.0846542\n",
      "时间步 1682000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.032978e+01/ 轮得分 122.52\n",
      "损失函数： 0.048946\n",
      "时间步 1683000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.242780e+01/ 轮得分 122.64\n",
      "损失函数： 0.103716\n",
      "时间步 1684000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 1.1/ Q_MAX 1.269708e+01/ 轮得分 122.64\n",
      "损失函数： 0.072662\n",
      "时间步 1685000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.457832e+01/ 轮得分 122.64\n",
      "损失函数： 0.0380445\n",
      "时间步 1686000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.360496e+01/ 轮得分 122.64\n",
      "损失函数： 0.0598212\n",
      "时间步 1687000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.315136e+01/ 轮得分 123.11\n",
      "损失函数： 0.0229661\n",
      "时间步 1688000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 9.387547e+00/ 轮得分 123.11\n",
      "损失函数： 0.060512\n",
      "时间步 1689000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.264353e+01/ 轮得分 123.11\n",
      "损失函数： 0.0413197\n",
      "时间步 1690000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.258555e+01/ 轮得分 123.11\n",
      "损失函数： 0.0404416\n",
      "时间步 1691000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 1.1/ Q_MAX 1.424912e+01/ 轮得分 123.11\n",
      "损失函数： 0.0436289\n",
      "时间步 1692000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.316418e+01/ 轮得分 123.45\n",
      "损失函数： 0.035366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1693000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.342506e+01/ 轮得分 123.45\n",
      "损失函数： 0.0256635\n",
      "时间步 1694000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.239077e+01/ 轮得分 123.60\n",
      "损失函数： 0.068042\n",
      "时间步 1695000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.385916e+01/ 轮得分 123.65\n",
      "损失函数： 0.0335703\n",
      "时间步 1696000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.360406e+01/ 轮得分 123.65\n",
      "损失函数： 0.0527105\n",
      "时间步 1697000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.301744e+01/ 轮得分 123.65\n",
      "损失函数： 0.0212681\n",
      "时间步 1698000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.390217e+01/ 轮得分 123.65\n",
      "损失函数： 0.0256756\n",
      "时间步 1699000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.330849e+01/ 轮得分 123.65\n",
      "损失函数： 0.0447126\n",
      "时间步 1700000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.299353e+01/ 轮得分 123.65\n",
      "损失函数： 0.0685304\n",
      "时间步 1701000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.257161e+01/ 轮得分 124.26\n",
      "损失函数： 0.0792919\n",
      "时间步 1702000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 9.731001e+00/ 轮得分 124.26\n",
      "损失函数： 0.03626\n",
      "时间步 1703000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.567434e+01/ 轮得分 124.27\n",
      "损失函数： 0.0599598\n",
      "时间步 1704000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.391129e+01/ 轮得分 124.27\n",
      "损失函数： 4.15676\n",
      "时间步 1705000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.289982e+01/ 轮得分 124.27\n",
      "损失函数： 0.0506098\n",
      "时间步 1706000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.317968e+01/ 轮得分 124.27\n",
      "损失函数： 0.034209\n",
      "时间步 1707000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.355752e+01/ 轮得分 124.70\n",
      "损失函数： 0.033698\n",
      "时间步 1708000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.437069e+01/ 轮得分 124.70\n",
      "损失函数： 0.191298\n",
      "时间步 1709000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.441809e+01/ 轮得分 124.71\n",
      "损失函数： 0.0443421\n",
      "时间步 1710000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.022464e+01/ 轮得分 124.71\n",
      "损失函数： 0.0836471\n",
      "时间步 1711000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.365409e+01/ 轮得分 124.68\n",
      "损失函数： 0.172293\n",
      "时间步 1712000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.360508e+01/ 轮得分 124.73\n",
      "损失函数： 0.0454453\n",
      "时间步 1713000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.504058e+01/ 轮得分 124.82\n",
      "损失函数： 0.0403349\n",
      "时间步 1714000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 1.1/ Q_MAX 1.388566e+01/ 轮得分 124.82\n",
      "损失函数： 0.0656934\n",
      "时间步 1715000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.437272e+01/ 轮得分 124.92\n",
      "损失函数： 0.0629899\n",
      "时间步 1716000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.276782e+01/ 轮得分 124.92\n",
      "损失函数： 0.0721312\n",
      "时间步 1717000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.049792e+01/ 轮得分 124.92\n",
      "损失函数： 0.025305\n",
      "时间步 1718000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.452717e+01/ 轮得分 125.26\n",
      "损失函数： 0.0165984\n",
      "时间步 1719000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.237090e+01/ 轮得分 125.32\n",
      "损失函数： 0.151087\n",
      "时间步 1720000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.243527e+01/ 轮得分 125.32\n",
      "损失函数： 0.0568642\n",
      "时间步 1721000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.302647e+01/ 轮得分 125.39\n",
      "损失函数： 0.104607\n",
      "时间步 1722000/ 状态 explore/ Epsilon 0.09/ 行动 1/ 奖励 0.1/ Q_MAX 1.252039e+01/ 轮得分 125.39\n",
      "损失函数： 0.0229547\n",
      "时间步 1723000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.126732e+01/ 轮得分 125.56\n",
      "损失函数： 0.0350888\n",
      "时间步 1724000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.318183e+01/ 轮得分 125.69\n",
      "损失函数： 0.0563158\n",
      "时间步 1725000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.313179e+01/ 轮得分 125.69\n",
      "损失函数： 0.0762975\n",
      "时间步 1726000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.467381e+01/ 轮得分 125.69\n",
      "损失函数： 0.0345825\n",
      "时间步 1727000/ 状态 explore/ Epsilon 0.09/ 行动 2/ 奖励 0.1/ Q_MAX 1.248231e+01/ 轮得分 125.60\n",
      "损失函数： 0.0841859\n",
      "时间步 1728000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.474082e+01/ 轮得分 125.67\n",
      "损失函数： 0.0562304\n",
      "时间步 1729000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.361400e+01/ 轮得分 125.67\n",
      "损失函数： 0.0598589\n",
      "时间步 1730000/ 状态 explore/ Epsilon 0.09/ 行动 0/ 奖励 0.1/ Q_MAX 1.405033e+01/ 轮得分 125.80\n",
      "损失函数： 0.0446565\n",
      "时间步 1731000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.261646e+01/ 轮得分 125.80\n",
      "损失函数： 0.0307598\n",
      "时间步 1732000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.310817e+01/ 轮得分 125.97\n",
      "损失函数： 0.0297229\n",
      "时间步 1733000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.322803e+01/ 轮得分 125.97\n",
      "损失函数： 0.0461966\n",
      "时间步 1734000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.091732e+01/ 轮得分 125.97\n",
      "损失函数： 0.182038\n",
      "时间步 1735000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.221599e+01/ 轮得分 125.97\n",
      "损失函数： 0.0315466\n",
      "时间步 1736000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.179313e+01/ 轮得分 126.46\n",
      "损失函数： 0.0559973\n",
      "时间步 1737000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.193555e+01/ 轮得分 126.34\n",
      "损失函数： 0.0796428\n",
      "时间步 1738000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.309921e+01/ 轮得分 126.34\n",
      "损失函数： 0.0599046\n",
      "时间步 1739000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.329868e+01/ 轮得分 126.58\n",
      "损失函数： 0.041249\n",
      "时间步 1740000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.633323e+01/ 轮得分 126.58\n",
      "损失函数： 0.0509683\n",
      "时间步 1741000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.263027e+01/ 轮得分 126.72\n",
      "损失函数： 0.0473961\n",
      "时间步 1742000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.259985e+01/ 轮得分 126.72\n",
      "损失函数： 0.0292136\n",
      "时间步 1743000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.311255e+01/ 轮得分 126.72\n",
      "损失函数： 0.0351911\n",
      "时间步 1744000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.333318e+01/ 轮得分 126.72\n",
      "损失函数： 0.0181993\n",
      "时间步 1745000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.410995e+01/ 轮得分 126.72\n",
      "损失函数： 0.0771656\n",
      "时间步 1746000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.268749e+01/ 轮得分 126.72\n",
      "损失函数： 0.0941175\n",
      "时间步 1747000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.259871e+01/ 轮得分 126.72\n",
      "损失函数： 0.0278985\n",
      "时间步 1748000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.378609e+01/ 轮得分 126.72\n",
      "损失函数： 0.0270358\n",
      "时间步 1749000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.334869e+01/ 轮得分 127.59\n",
      "损失函数： 0.0933815\n",
      "时间步 1750000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.220346e+01/ 轮得分 127.59\n",
      "损失函数： 0.0449037\n",
      "时间步 1751000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.396629e+01/ 轮得分 127.59\n",
      "损失函数： 0.0740358\n",
      "时间步 1752000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.415891e+01/ 轮得分 127.59\n",
      "损失函数： 0.0364735\n",
      "时间步 1753000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.399996e+01/ 轮得分 127.59\n",
      "损失函数： 0.0632801\n",
      "时间步 1754000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.298343e+01/ 轮得分 128.18\n",
      "损失函数： 0.0224176\n",
      "时间步 1755000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.537527e+01/ 轮得分 128.18\n",
      "损失函数： 0.0646073\n",
      "时间步 1756000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.252497e+01/ 轮得分 128.40\n",
      "损失函数： 0.0525701\n",
      "时间步 1757000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.319609e+01/ 轮得分 128.40\n",
      "损失函数： 0.0386729\n",
      "时间步 1758000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.324137e+01/ 轮得分 128.57\n",
      "损失函数： 0.0789494\n",
      "时间步 1759000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.308337e+01/ 轮得分 128.70\n",
      "损失函数： 0.040408\n",
      "时间步 1760000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.276474e+01/ 轮得分 128.68\n",
      "损失函数： 0.0948729\n",
      "时间步 1761000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.249930e+01/ 轮得分 128.68\n",
      "损失函数： 0.0646217\n",
      "时间步 1762000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.353353e+01/ 轮得分 128.68\n",
      "损失函数： 0.0295981\n",
      "时间步 1763000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.369154e+01/ 轮得分 128.89\n",
      "损失函数： 0.0829365\n",
      "时间步 1764000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 6.560850e+00/ 轮得分 128.89\n",
      "损失函数： 0.0464732\n",
      "时间步 1765000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.392974e+01/ 轮得分 128.99\n",
      "损失函数： 0.0392168\n",
      "时间步 1766000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.274831e+01/ 轮得分 128.88\n",
      "损失函数： 0.0824677\n",
      "时间步 1767000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.402566e+01/ 轮得分 128.88\n",
      "损失函数： 0.0356753\n",
      "时间步 1768000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.258951e+01/ 轮得分 128.88\n",
      "损失函数： 0.0809967\n",
      "时间步 1769000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.388678e+01/ 轮得分 128.88\n",
      "损失函数： 0.0895754\n",
      "时间步 1770000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.290470e+01/ 轮得分 129.25\n",
      "损失函数： 0.0608547\n",
      "时间步 1771000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.337786e+01/ 轮得分 129.17\n",
      "损失函数： 0.0364575\n",
      "时间步 1772000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.279384e+01/ 轮得分 129.26\n",
      "损失函数： 0.0496002\n",
      "时间步 1773000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.395693e+01/ 轮得分 129.26\n",
      "损失函数： 0.101874\n",
      "时间步 1774000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.158130e+01/ 轮得分 129.40\n",
      "损失函数： 0.0362263\n",
      "时间步 1775000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.295847e+01/ 轮得分 129.49\n",
      "损失函数： 0.0361103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1776000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.300018e+01/ 轮得分 129.49\n",
      "损失函数： 0.0487005\n",
      "时间步 1777000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.322101e+01/ 轮得分 129.70\n",
      "损失函数： 0.0452155\n",
      "时间步 1778000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.379661e+01/ 轮得分 129.70\n",
      "损失函数： 0.0535428\n",
      "时间步 1779000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.212801e+01/ 轮得分 129.70\n",
      "损失函数： 0.0660854\n",
      "时间步 1780000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.190316e+01/ 轮得分 129.70\n",
      "损失函数： 0.0554627\n",
      "时间步 1781000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.540499e+01/ 轮得分 130.21\n",
      "损失函数： 0.0334603\n",
      "时间步 1782000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.203664e+01/ 轮得分 130.09\n",
      "损失函数： 0.0375897\n",
      "时间步 1783000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 1.1/ Q_MAX 1.400755e+01/ 轮得分 130.09\n",
      "损失函数： 0.082746\n",
      "时间步 1784000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.355492e+01/ 轮得分 130.28\n",
      "损失函数： 0.0352009\n",
      "时间步 1785000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.267133e+01/ 轮得分 130.28\n",
      "损失函数： 0.0488701\n",
      "时间步 1786000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.146224e+01/ 轮得分 130.54\n",
      "损失函数： 0.0385155\n",
      "时间步 1787000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.318128e+01/ 轮得分 130.59\n",
      "损失函数： 0.0514097\n",
      "时间步 1788000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.531561e+01/ 轮得分 130.59\n",
      "损失函数： 0.0585551\n",
      "时间步 1789000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.366880e+01/ 轮得分 130.64\n",
      "损失函数： 0.0397579\n",
      "时间步 1790000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.478894e+01/ 轮得分 130.64\n",
      "损失函数： 0.0375578\n",
      "时间步 1791000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.285820e+01/ 轮得分 130.64\n",
      "损失函数： 0.032804\n",
      "时间步 1792000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.212915e+01/ 轮得分 130.64\n",
      "损失函数： 0.0643779\n",
      "时间步 1793000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 9.423687e+00/ 轮得分 130.64\n",
      "损失函数： 0.200193\n",
      "时间步 1794000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.389363e+01/ 轮得分 130.64\n",
      "损失函数： 1.04221\n",
      "时间步 1795000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.375057e+01/ 轮得分 131.08\n",
      "损失函数： 0.0301988\n",
      "时间步 1796000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.262059e+01/ 轮得分 130.88\n",
      "损失函数： 0.0391871\n",
      "时间步 1797000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.281444e+01/ 轮得分 130.85\n",
      "损失函数： 0.0393288\n",
      "时间步 1798000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.186531e+01/ 轮得分 130.85\n",
      "损失函数： 0.0863251\n",
      "时间步 1799000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.347168e+01/ 轮得分 130.85\n",
      "损失函数： 0.0301157\n",
      "时间步 1800000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.322840e+01/ 轮得分 130.85\n",
      "损失函数： 0.0926175\n",
      "时间步 1801000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.248823e+01/ 轮得分 131.34\n",
      "损失函数： 0.0493438\n",
      "时间步 1802000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.403154e+01/ 轮得分 131.34\n",
      "损失函数： 0.102966\n",
      "时间步 1803000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.209125e+01/ 轮得分 131.51\n",
      "损失函数： 0.0555592\n",
      "时间步 1804000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.322746e+01/ 轮得分 131.47\n",
      "损失函数： 0.047503\n",
      "时间步 1805000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.538740e+01/ 轮得分 131.38\n",
      "损失函数： 0.0447798\n",
      "时间步 1806000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.224367e+01/ 轮得分 131.38\n",
      "损失函数： 0.10336\n",
      "时间步 1807000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.338641e+01/ 轮得分 131.38\n",
      "损失函数： 0.0308485\n",
      "时间步 1808000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.190056e+01/ 轮得分 131.38\n",
      "损失函数： 0.0475042\n",
      "时间步 1809000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.390980e+01/ 轮得分 131.76\n",
      "损失函数： 0.582523\n",
      "时间步 1810000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.205719e+01/ 轮得分 131.89\n",
      "损失函数： 0.179173\n",
      "时间步 1811000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.480915e+01/ 轮得分 131.79\n",
      "损失函数： 0.17789\n",
      "时间步 1812000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.429085e+01/ 轮得分 131.79\n",
      "损失函数： 0.142984\n",
      "时间步 1813000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.331814e+01/ 轮得分 131.94\n",
      "损失函数： 0.0605875\n",
      "时间步 1814000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.254368e+01/ 轮得分 131.94\n",
      "损失函数： 0.0757722\n",
      "时间步 1815000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.351827e+01/ 轮得分 132.14\n",
      "损失函数： 0.0744711\n",
      "时间步 1816000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.227623e+01/ 轮得分 132.29\n",
      "损失函数： 0.0842689\n",
      "时间步 1817000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.504797e+01/ 轮得分 132.29\n",
      "损失函数： 0.0479219\n",
      "时间步 1818000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.604963e+01/ 轮得分 132.29\n",
      "损失函数： 0.0311639\n",
      "时间步 1819000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.038863e+01/ 轮得分 132.43\n",
      "损失函数： 0.0279716\n",
      "时间步 1820000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.357043e+01/ 轮得分 132.43\n",
      "损失函数： 0.0958337\n",
      "时间步 1821000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.267683e+01/ 轮得分 132.43\n",
      "损失函数： 0.0863265\n",
      "时间步 1822000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.729370e+01/ 轮得分 132.43\n",
      "损失函数： 0.812991\n",
      "时间步 1823000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 1.1/ Q_MAX 1.321290e+01/ 轮得分 132.43\n",
      "损失函数： 0.0545377\n",
      "时间步 1824000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.441841e+01/ 轮得分 132.43\n",
      "损失函数： 0.0296767\n",
      "时间步 1825000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.216780e+01/ 轮得分 133.10\n",
      "损失函数： 0.0777849\n",
      "时间步 1826000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.309796e+01/ 轮得分 133.10\n",
      "损失函数： 0.0307662\n",
      "时间步 1827000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.540184e+01/ 轮得分 133.10\n",
      "损失函数： 0.0367469\n",
      "时间步 1828000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.340396e+01/ 轮得分 133.10\n",
      "损失函数： 0.0423639\n",
      "时间步 1829000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.397682e+01/ 轮得分 133.10\n",
      "损失函数： 0.0605175\n",
      "时间步 1830000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.334611e+01/ 轮得分 133.59\n",
      "损失函数： 0.048281\n",
      "时间步 1831000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 1.1/ Q_MAX 1.474421e+01/ 轮得分 133.59\n",
      "损失函数： 0.0299238\n",
      "时间步 1832000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.303983e+01/ 轮得分 133.59\n",
      "损失函数： 0.0506496\n",
      "时间步 1833000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.231104e+01/ 轮得分 133.59\n",
      "损失函数： 0.0608621\n",
      "时间步 1834000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.419126e+01/ 轮得分 134.02\n",
      "损失函数： 0.0305399\n",
      "时间步 1835000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.340477e+01/ 轮得分 134.02\n",
      "损失函数： 0.0488344\n",
      "时间步 1836000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.368873e+01/ 轮得分 134.02\n",
      "损失函数： 0.064992\n",
      "时间步 1837000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.206630e+01/ 轮得分 134.02\n",
      "损失函数： 0.0714287\n",
      "时间步 1838000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.225933e+01/ 轮得分 134.38\n",
      "损失函数： 0.0604827\n",
      "时间步 1839000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.347501e+01/ 轮得分 134.37\n",
      "损失函数： 0.0396395\n",
      "时间步 1840000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.309917e+01/ 轮得分 134.37\n",
      "损失函数： 0.0322833\n",
      "时间步 1841000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.284356e+01/ 轮得分 134.62\n",
      "损失函数： 0.044011\n",
      "时间步 1842000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.299590e+01/ 轮得分 134.62\n",
      "损失函数： 0.0384197\n",
      "时间步 1843000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.425025e+01/ 轮得分 134.62\n",
      "损失函数： 0.027744\n",
      "时间步 1844000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.328150e+01/ 轮得分 134.73\n",
      "损失函数： 0.0484745\n",
      "时间步 1845000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.361696e+01/ 轮得分 134.76\n",
      "损失函数： 0.0471089\n",
      "时间步 1846000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.232023e+01/ 轮得分 134.85\n",
      "损失函数： 0.0381553\n",
      "时间步 1847000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.219533e+01/ 轮得分 134.85\n",
      "损失函数： 0.0313162\n",
      "时间步 1848000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.260427e+01/ 轮得分 134.93\n",
      "损失函数： 0.102066\n",
      "时间步 1849000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.373595e+01/ 轮得分 134.78\n",
      "损失函数： 0.0962255\n",
      "时间步 1850000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.369427e+01/ 轮得分 134.80\n",
      "损失函数： 0.0372042\n",
      "时间步 1851000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.213427e+01/ 轮得分 134.79\n",
      "损失函数： 0.102537\n",
      "时间步 1852000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.333771e+01/ 轮得分 134.79\n",
      "损失函数： 0.0624945\n",
      "时间步 1853000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 1.1/ Q_MAX 1.404580e+01/ 轮得分 134.79\n",
      "损失函数： 0.0636346\n",
      "时间步 1854000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.448296e+01/ 轮得分 134.79\n",
      "损失函数： 0.162102\n",
      "时间步 1855000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.280106e+01/ 轮得分 135.24\n",
      "损失函数： 0.0659203\n",
      "时间步 1856000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.215978e+01/ 轮得分 135.24\n",
      "损失函数： 0.0407474\n",
      "时间步 1857000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.242630e+01/ 轮得分 135.24\n",
      "损失函数： 0.0600214\n",
      "时间步 1858000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.362022e+01/ 轮得分 135.24\n",
      "损失函数： 0.0351677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1859000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.285979e+01/ 轮得分 135.24\n",
      "损失函数： 0.060773\n",
      "时间步 1860000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.250181e+01/ 轮得分 135.24\n",
      "损失函数： 0.0512971\n",
      "时间步 1861000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.385436e+01/ 轮得分 136.00\n",
      "损失函数： 0.088028\n",
      "时间步 1862000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.212548e+01/ 轮得分 136.10\n",
      "损失函数： 0.0519163\n",
      "时间步 1863000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.255871e+01/ 轮得分 136.10\n",
      "损失函数： 0.0472782\n",
      "时间步 1864000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.351802e+01/ 轮得分 136.33\n",
      "损失函数： 0.0251462\n",
      "时间步 1865000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.350211e+01/ 轮得分 136.33\n",
      "损失函数： 0.0505028\n",
      "时间步 1866000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.071355e+01/ 轮得分 136.33\n",
      "损失函数： 0.0378917\n",
      "时间步 1867000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.230608e+01/ 轮得分 136.48\n",
      "损失函数： 0.0554197\n",
      "时间步 1868000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.305366e+01/ 轮得分 136.48\n",
      "损失函数： 0.0183656\n",
      "时间步 1869000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.497951e+01/ 轮得分 136.48\n",
      "损失函数： 0.0219831\n",
      "时间步 1870000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.381929e+01/ 轮得分 136.48\n",
      "损失函数： 0.108889\n",
      "时间步 1871000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.302975e+01/ 轮得分 136.48\n",
      "损失函数： 0.0219454\n",
      "时间步 1872000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.239993e+01/ 轮得分 136.86\n",
      "损失函数： 0.0480953\n",
      "时间步 1873000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.276499e+01/ 轮得分 136.95\n",
      "损失函数： 0.0221656\n",
      "时间步 1874000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.213885e+01/ 轮得分 136.95\n",
      "损失函数： 0.0375561\n",
      "时间步 1875000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.361656e+01/ 轮得分 137.15\n",
      "损失函数： 0.0750516\n",
      "时间步 1876000/ 状态 explore/ Epsilon 0.08/ 行动 0/ 奖励 0.1/ Q_MAX 1.227772e+01/ 轮得分 137.15\n",
      "损失函数： 0.0364812\n",
      "时间步 1877000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.384288e+01/ 轮得分 137.41\n",
      "损失函数： 0.0370721\n",
      "时间步 1878000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.264255e+01/ 轮得分 137.41\n",
      "损失函数： 0.0476179\n",
      "时间步 1879000/ 状态 explore/ Epsilon 0.08/ 行动 1/ 奖励 0.1/ Q_MAX 1.348413e+01/ 轮得分 137.55\n",
      "损失函数： 0.0841832\n",
      "时间步 1880000/ 状态 explore/ Epsilon 0.08/ 行动 2/ 奖励 0.1/ Q_MAX 1.379566e+01/ 轮得分 137.42\n",
      "损失函数： 0.0435893\n",
      "时间步 1881000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.116569e+01/ 轮得分 137.42\n",
      "损失函数： 0.0295088\n",
      "时间步 1882000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.313057e+01/ 轮得分 137.42\n",
      "损失函数： 0.133912\n",
      "时间步 1883000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.306557e+01/ 轮得分 137.42\n",
      "损失函数： 0.0471414\n",
      "时间步 1884000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.378527e+01/ 轮得分 137.42\n",
      "损失函数： 0.0274779\n",
      "时间步 1885000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.369385e+01/ 轮得分 137.42\n",
      "损失函数： 0.0855752\n",
      "时间步 1886000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.638664e+01/ 轮得分 138.14\n",
      "损失函数： 0.0958593\n",
      "时间步 1887000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.326318e+01/ 轮得分 138.08\n",
      "损失函数： 0.0558917\n",
      "时间步 1888000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.578930e+01/ 轮得分 138.12\n",
      "损失函数： 0.0617447\n",
      "时间步 1889000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.477356e+01/ 轮得分 138.12\n",
      "损失函数： 0.215508\n",
      "时间步 1890000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.293231e+01/ 轮得分 138.36\n",
      "损失函数： 0.0597154\n",
      "时间步 1891000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.238362e+01/ 轮得分 138.35\n",
      "损失函数： 0.0399189\n",
      "时间步 1892000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.379521e+01/ 轮得分 138.28\n",
      "损失函数： 0.082922\n",
      "时间步 1893000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.493347e+01/ 轮得分 138.28\n",
      "损失函数： 0.0337128\n",
      "时间步 1894000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 1.1/ Q_MAX 1.541089e+01/ 轮得分 138.45\n",
      "损失函数： 0.0800037\n",
      "时间步 1895000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.309116e+01/ 轮得分 138.49\n",
      "损失函数： 0.0391834\n",
      "时间步 1896000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.467882e+01/ 轮得分 138.49\n",
      "损失函数： 0.0608743\n",
      "时间步 1897000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.346998e+01/ 轮得分 138.69\n",
      "损失函数： 0.0359052\n",
      "时间步 1898000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.598049e+01/ 轮得分 138.76\n",
      "损失函数： 0.0422577\n",
      "时间步 1899000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.208207e+01/ 轮得分 138.76\n",
      "损失函数： 0.0612515\n",
      "时间步 1900000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.242728e+01/ 轮得分 138.76\n",
      "损失函数： 0.0618978\n",
      "时间步 1901000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.247694e+01/ 轮得分 138.96\n",
      "损失函数： 0.0958922\n",
      "时间步 1902000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.140284e+01/ 轮得分 138.88\n",
      "损失函数： 0.0337553\n",
      "时间步 1903000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.347182e+01/ 轮得分 138.84\n",
      "损失函数： 0.0950448\n",
      "时间步 1904000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.151008e+01/ 轮得分 138.84\n",
      "损失函数： 0.0372133\n",
      "时间步 1905000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.200752e+01/ 轮得分 139.02\n",
      "损失函数： 0.0234651\n",
      "时间步 1906000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.849290e+01/ 轮得分 139.08\n",
      "损失函数： 0.0626107\n",
      "时间步 1907000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.178704e+01/ 轮得分 139.08\n",
      "损失函数： 0.0395818\n",
      "时间步 1908000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.473393e+01/ 轮得分 139.08\n",
      "损失函数： 0.0405461\n",
      "时间步 1909000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.326022e+01/ 轮得分 139.27\n",
      "损失函数： 0.0491858\n",
      "时间步 1910000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.228899e+01/ 轮得分 139.18\n",
      "损失函数： 0.0270359\n",
      "时间步 1911000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.628942e+01/ 轮得分 139.18\n",
      "损失函数： 0.0233666\n",
      "时间步 1912000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.250787e+01/ 轮得分 139.18\n",
      "损失函数： 0.0402707\n",
      "时间步 1913000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.298081e+01/ 轮得分 139.43\n",
      "损失函数： 0.0466468\n",
      "时间步 1914000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.448112e+01/ 轮得分 139.43\n",
      "损失函数： 0.0501933\n",
      "时间步 1915000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.449839e+01/ 轮得分 139.43\n",
      "损失函数： 0.143608\n",
      "时间步 1916000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 1.1/ Q_MAX 1.268200e+01/ 轮得分 139.43\n",
      "损失函数： 0.0486911\n",
      "时间步 1917000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.334934e+01/ 轮得分 139.43\n",
      "损失函数： 0.0235597\n",
      "时间步 1918000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.510403e+01/ 轮得分 139.43\n",
      "损失函数： 0.170531\n",
      "时间步 1919000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.259910e+01/ 轮得分 140.03\n",
      "损失函数： 0.0414466\n",
      "时间步 1920000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.289064e+01/ 轮得分 140.20\n",
      "损失函数： 0.086782\n",
      "时间步 1921000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.257213e+01/ 轮得分 140.20\n",
      "损失函数： 0.115363\n",
      "时间步 1922000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.400530e+01/ 轮得分 140.35\n",
      "损失函数： 0.0631869\n",
      "时间步 1923000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.262214e+01/ 轮得分 140.42\n",
      "损失函数： 0.0460175\n",
      "时间步 1924000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.343149e+01/ 轮得分 140.42\n",
      "损失函数： 0.0293425\n",
      "时间步 1925000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.368079e+01/ 轮得分 140.20\n",
      "损失函数： 0.0301403\n",
      "时间步 1926000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.332071e+01/ 轮得分 140.20\n",
      "损失函数： 0.0831606\n",
      "时间步 1927000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.232693e+01/ 轮得分 140.40\n",
      "损失函数： 0.042259\n",
      "时间步 1928000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.289518e+01/ 轮得分 140.49\n",
      "损失函数： 0.0326991\n",
      "时间步 1929000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.332432e+01/ 轮得分 140.49\n",
      "损失函数： 0.0752939\n",
      "时间步 1930000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.223221e+01/ 轮得分 140.66\n",
      "损失函数： 0.0430632\n",
      "时间步 1931000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.256466e+01/ 轮得分 140.66\n",
      "损失函数： 0.073293\n",
      "时间步 1932000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.334398e+01/ 轮得分 140.66\n",
      "损失函数： 0.0360404\n",
      "时间步 1933000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.335558e+01/ 轮得分 140.66\n",
      "损失函数： 0.0233266\n",
      "时间步 1934000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.484168e+01/ 轮得分 141.08\n",
      "损失函数： 0.249182\n",
      "时间步 1935000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.379204e+01/ 轮得分 141.02\n",
      "损失函数： 0.0437254\n",
      "时间步 1936000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.252443e+01/ 轮得分 141.02\n",
      "损失函数： 0.0882405\n",
      "时间步 1937000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.295788e+01/ 轮得分 141.02\n",
      "损失函数： 0.0389491\n",
      "时间步 1938000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.402845e+01/ 轮得分 141.02\n",
      "损失函数： 0.0201763\n",
      "时间步 1939000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.462859e+01/ 轮得分 141.02\n",
      "损失函数： 0.0683194\n",
      "时间步 1940000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.398558e+01/ 轮得分 141.02\n",
      "损失函数： 0.0420137\n",
      "时间步 1941000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.312283e+01/ 轮得分 141.02\n",
      "损失函数： 0.0372142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1942000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.321928e+01/ 轮得分 141.88\n",
      "损失函数： 0.0783012\n",
      "时间步 1943000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.348077e+01/ 轮得分 141.88\n",
      "损失函数： 0.0574105\n",
      "时间步 1944000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 7.823918e+00/ 轮得分 141.88\n",
      "损失函数： 0.0989989\n",
      "时间步 1945000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.226041e+01/ 轮得分 142.13\n",
      "损失函数： 0.0833356\n",
      "时间步 1946000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.296174e+01/ 轮得分 141.91\n",
      "损失函数： 0.0437559\n",
      "时间步 1947000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.344848e+01/ 轮得分 141.96\n",
      "损失函数： 0.0766499\n",
      "时间步 1948000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.533364e+01/ 轮得分 141.96\n",
      "损失函数： 0.0677272\n",
      "时间步 1949000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.290021e+01/ 轮得分 142.07\n",
      "损失函数： 0.0421573\n",
      "时间步 1950000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.355912e+01/ 轮得分 142.04\n",
      "损失函数： 0.0840855\n",
      "时间步 1951000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.356286e+01/ 轮得分 142.07\n",
      "损失函数： 0.0662048\n",
      "时间步 1952000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.095925e+01/ 轮得分 142.07\n",
      "损失函数： 0.0152322\n",
      "时间步 1953000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.196900e+01/ 轮得分 142.07\n",
      "损失函数： 0.0248366\n",
      "时间步 1954000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.379296e+01/ 轮得分 142.33\n",
      "损失函数： 0.050559\n",
      "时间步 1955000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.266732e+01/ 轮得分 142.25\n",
      "损失函数： 0.0398263\n",
      "时间步 1956000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.244196e+01/ 轮得分 142.34\n",
      "损失函数： 0.0576368\n",
      "时间步 1957000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.340933e+01/ 轮得分 142.34\n",
      "损失函数： 0.0756223\n",
      "时间步 1958000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.265746e+01/ 轮得分 142.34\n",
      "损失函数： 0.0471171\n",
      "时间步 1959000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.351089e+01/ 轮得分 142.42\n",
      "损失函数： 0.0337696\n",
      "时间步 1960000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.340090e+01/ 轮得分 142.42\n",
      "损失函数： 0.0486217\n",
      "时间步 1961000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.199135e+01/ 轮得分 142.48\n",
      "损失函数： 0.0465314\n",
      "时间步 1962000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.416778e+01/ 轮得分 142.48\n",
      "损失函数： 0.0251912\n",
      "时间步 1963000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.097725e+01/ 轮得分 142.75\n",
      "损失函数： 0.0193672\n",
      "时间步 1964000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.285128e+01/ 轮得分 142.69\n",
      "损失函数： 0.0308402\n",
      "时间步 1965000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.283808e+01/ 轮得分 142.69\n",
      "损失函数： 0.0654397\n",
      "时间步 1966000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.323203e+01/ 轮得分 142.69\n",
      "损失函数： 0.0835758\n",
      "时间步 1967000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.321800e+01/ 轮得分 142.69\n",
      "损失函数： 0.0469811\n",
      "时间步 1968000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.197168e+01/ 轮得分 143.12\n",
      "损失函数： 0.0589852\n",
      "时间步 1969000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 1.1/ Q_MAX 1.367049e+01/ 轮得分 143.12\n",
      "损失函数： 0.112234\n",
      "时间步 1970000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.245794e+01/ 轮得分 143.25\n",
      "损失函数： 0.0219366\n",
      "时间步 1971000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.306190e+01/ 轮得分 143.25\n",
      "损失函数： 0.0809179\n",
      "时间步 1972000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.200201e+01/ 轮得分 143.41\n",
      "损失函数： 0.0323425\n",
      "时间步 1973000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.145377e+01/ 轮得分 143.41\n",
      "损失函数： 0.0495093\n",
      "时间步 1974000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.338061e+01/ 轮得分 143.41\n",
      "损失函数： 0.033847\n",
      "时间步 1975000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.389847e+01/ 轮得分 143.81\n",
      "损失函数： 0.0586943\n",
      "时间步 1976000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.561793e+01/ 轮得分 143.81\n",
      "损失函数： 0.0302914\n",
      "时间步 1977000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.185186e+01/ 轮得分 143.92\n",
      "损失函数： 0.0766143\n",
      "时间步 1978000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.294663e+01/ 轮得分 144.01\n",
      "损失函数： 0.018828\n",
      "时间步 1979000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.220499e+01/ 轮得分 144.01\n",
      "损失函数： 0.0396649\n",
      "时间步 1980000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.391704e+01/ 轮得分 143.85\n",
      "损失函数： 0.0297938\n",
      "时间步 1981000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.479422e+01/ 轮得分 143.85\n",
      "损失函数： 0.924712\n",
      "时间步 1982000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.317735e+01/ 轮得分 143.85\n",
      "损失函数： 0.033219\n",
      "时间步 1983000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.455371e+01/ 轮得分 144.23\n",
      "损失函数： 0.0308508\n",
      "时间步 1984000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.367873e+01/ 轮得分 144.30\n",
      "损失函数： 0.0613349\n",
      "时间步 1985000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 9.054481e+00/ 轮得分 144.30\n",
      "损失函数： 0.0615781\n",
      "时间步 1986000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.379505e+01/ 轮得分 144.51\n",
      "损失函数： 0.120155\n",
      "时间步 1987000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.283192e+01/ 轮得分 144.51\n",
      "损失函数： 0.0774574\n",
      "时间步 1988000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.225019e+01/ 轮得分 144.63\n",
      "损失函数： 0.059808\n",
      "时间步 1989000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.415576e+01/ 轮得分 144.63\n",
      "损失函数： 0.0555907\n",
      "时间步 1990000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.431298e+01/ 轮得分 144.66\n",
      "损失函数： 0.0624402\n",
      "时间步 1991000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.232360e+01/ 轮得分 144.78\n",
      "损失函数： 0.0277348\n",
      "时间步 1992000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.354293e+01/ 轮得分 144.78\n",
      "损失函数： 0.0493004\n",
      "时间步 1993000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.349401e+01/ 轮得分 144.81\n",
      "损失函数： 0.0345442\n",
      "时间步 1994000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.233072e+01/ 轮得分 144.94\n",
      "损失函数： 0.0955178\n",
      "时间步 1995000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.238396e+01/ 轮得分 144.94\n",
      "损失函数： 0.0544005\n",
      "时间步 1996000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.382925e+01/ 轮得分 144.94\n",
      "损失函数： 0.0722194\n",
      "时间步 1997000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.189409e+01/ 轮得分 144.94\n",
      "损失函数： 0.0339986\n",
      "时间步 1998000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.521216e+01/ 轮得分 145.33\n",
      "损失函数： 0.0476269\n",
      "时间步 1999000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.066900e+01/ 轮得分 145.33\n",
      "损失函数： 0.0224358\n",
      "时间步 2000000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.307550e+01/ 轮得分 145.33\n",
      "损失函数： 0.0264733\n",
      "时间步 2001000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.386008e+01/ 轮得分 145.33\n",
      "损失函数： 0.0453889\n",
      "时间步 2002000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.462301e+01/ 轮得分 145.33\n",
      "损失函数： 0.196086\n",
      "时间步 2003000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.379155e+01/ 轮得分 145.33\n",
      "损失函数： 0.0559321\n",
      "时间步 2004000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.391982e+01/ 轮得分 145.33\n",
      "损失函数： 0.0661962\n",
      "时间步 2005000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.282835e+01/ 轮得分 145.33\n",
      "损失函数： 0.0248692\n",
      "时间步 2006000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.304674e+01/ 轮得分 146.20\n",
      "损失函数： 0.0380016\n",
      "时间步 2007000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.373578e+01/ 轮得分 146.20\n",
      "损失函数： 0.0359783\n",
      "时间步 2008000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.330635e+01/ 轮得分 146.20\n",
      "损失函数： 0.0955157\n",
      "时间步 2009000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.336908e+01/ 轮得分 146.20\n",
      "损失函数： 0.0295052\n",
      "时间步 2010000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.230593e+01/ 轮得分 146.20\n",
      "损失函数： 0.0904724\n",
      "时间步 2011000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.359989e+01/ 轮得分 146.20\n",
      "损失函数： 0.029412\n",
      "时间步 2012000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.361204e+01/ 轮得分 146.20\n",
      "损失函数： 0.0260786\n",
      "时间步 2013000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.441639e+01/ 轮得分 146.20\n",
      "损失函数： 0.052322\n",
      "时间步 2014000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.084741e+01/ 轮得分 147.06\n",
      "损失函数： 0.0419936\n",
      "时间步 2015000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.335463e+01/ 轮得分 147.06\n",
      "损失函数： 0.0268484\n",
      "时间步 2016000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.319753e+01/ 轮得分 147.17\n",
      "损失函数： 0.0550231\n",
      "时间步 2017000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.458779e+01/ 轮得分 147.17\n",
      "损失函数： 0.048\n",
      "时间步 2018000/ 状态 explore/ Epsilon 0.07/ 行动 2/ 奖励 0.1/ Q_MAX 1.386041e+01/ 轮得分 147.45\n",
      "损失函数： 0.0284165\n",
      "时间步 2019000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.336184e+01/ 轮得分 147.45\n",
      "损失函数： 0.0206507\n",
      "时间步 2020000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.015882e+01/ 轮得分 147.45\n",
      "损失函数： 0.0387684\n",
      "时间步 2021000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.208689e+01/ 轮得分 147.64\n",
      "损失函数： 0.0588174\n",
      "时间步 2022000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.313899e+01/ 轮得分 147.64\n",
      "损失函数： 0.0525953\n",
      "时间步 2023000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.281823e+01/ 轮得分 147.82\n",
      "损失函数： 0.050846\n",
      "时间步 2024000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.028476e+01/ 轮得分 147.82\n",
      "损失函数： 0.0396397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2025000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.506032e+01/ 轮得分 147.82\n",
      "损失函数： 0.0984451\n",
      "时间步 2026000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.376904e+01/ 轮得分 147.82\n",
      "损失函数： 0.0239901\n",
      "时间步 2027000/ 状态 explore/ Epsilon 0.07/ 行动 1/ 奖励 0.1/ Q_MAX 1.046403e+01/ 轮得分 148.13\n",
      "损失函数： 0.0295152\n",
      "时间步 2028000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.401220e+01/ 轮得分 148.07\n",
      "损失函数： 0.0255696\n",
      "时间步 2029000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.335923e+01/ 轮得分 148.05\n",
      "损失函数： 0.0382256\n",
      "时间步 2030000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.146350e+01/ 轮得分 148.05\n",
      "损失函数： 0.0390828\n",
      "时间步 2031000/ 状态 explore/ Epsilon 0.07/ 行动 0/ 奖励 0.1/ Q_MAX 1.243685e+01/ 轮得分 148.05\n",
      "损失函数： 0.0451894\n",
      "时间步 2032000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.337761e+01/ 轮得分 148.22\n",
      "损失函数： 0.0376648\n",
      "时间步 2033000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.562070e+01/ 轮得分 148.22\n",
      "损失函数： 0.0526841\n",
      "时间步 2034000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.121347e+01/ 轮得分 148.29\n",
      "损失函数： 0.0611402\n",
      "时间步 2035000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.213272e+01/ 轮得分 148.29\n",
      "损失函数： 0.068628\n",
      "时间步 2036000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.355660e+01/ 轮得分 148.48\n",
      "损失函数： 0.0224755\n",
      "时间步 2037000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.379294e+01/ 轮得分 148.48\n",
      "损失函数： 0.0830476\n",
      "时间步 2038000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.504199e+01/ 轮得分 148.48\n",
      "损失函数： 0.0568725\n",
      "时间步 2039000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.527612e+01/ 轮得分 148.48\n",
      "损失函数： 0.0312838\n",
      "时间步 2040000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.436327e+01/ 轮得分 148.79\n",
      "损失函数： 0.0438744\n",
      "时间步 2041000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 7.913923e+00/ 轮得分 148.79\n",
      "损失函数： 0.0859005\n",
      "时间步 2042000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.341799e+01/ 轮得分 148.97\n",
      "损失函数： 0.0401168\n",
      "时间步 2043000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.331249e+01/ 轮得分 148.97\n",
      "损失函数： 0.0376826\n",
      "时间步 2044000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.309347e+01/ 轮得分 149.15\n",
      "损失函数： 0.0250026\n",
      "时间步 2045000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 1.1/ Q_MAX 1.151959e+01/ 轮得分 149.19\n",
      "损失函数： 4.4417\n",
      "时间步 2046000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.353618e+01/ 轮得分 149.19\n",
      "损失函数： 0.0198502\n",
      "时间步 2047000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.412066e+01/ 轮得分 149.19\n",
      "损失函数： 0.0221062\n",
      "时间步 2048000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.358129e+01/ 轮得分 149.19\n",
      "损失函数： 0.156036\n",
      "时间步 2049000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.393107e+01/ 轮得分 149.63\n",
      "损失函数： 0.0720555\n",
      "时间步 2050000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.421180e+01/ 轮得分 149.63\n",
      "损失函数： 0.0284601\n",
      "时间步 2051000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.556411e+01/ 轮得分 149.63\n",
      "损失函数： 0.028294\n",
      "时间步 2052000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.445853e+01/ 轮得分 149.63\n",
      "损失函数： 0.0835658\n",
      "时间步 2053000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.306142e+01/ 轮得分 149.85\n",
      "损失函数： 0.112154\n",
      "时间步 2054000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.499683e+01/ 轮得分 149.85\n",
      "损失函数： 0.0526136\n",
      "时间步 2055000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.593069e+01/ 轮得分 150.10\n",
      "损失函数： 0.0437899\n",
      "时间步 2056000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.402356e+01/ 轮得分 150.10\n",
      "损失函数： 0.142065\n",
      "时间步 2057000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.345994e+01/ 轮得分 150.10\n",
      "损失函数： 0.0559019\n",
      "时间步 2058000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.651957e+01/ 轮得分 150.42\n",
      "损失函数： 0.100464\n",
      "时间步 2059000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.473824e+01/ 轮得分 150.51\n",
      "损失函数： 0.0682553\n",
      "时间步 2060000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.224441e+01/ 轮得分 150.63\n",
      "损失函数： 0.0297526\n",
      "时间步 2061000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.276741e+01/ 轮得分 150.63\n",
      "损失函数： 0.0439164\n",
      "时间步 2062000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.412283e+01/ 轮得分 150.77\n",
      "损失函数： 0.0363941\n",
      "时间步 2063000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.403587e+01/ 轮得分 150.67\n",
      "损失函数： 0.0394403\n",
      "时间步 2064000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.388569e+01/ 轮得分 150.78\n",
      "损失函数： 0.0566964\n",
      "时间步 2065000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.050985e+01/ 轮得分 150.88\n",
      "损失函数： 0.0327076\n",
      "时间步 2066000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.347386e+01/ 轮得分 150.87\n",
      "损失函数： 0.0538491\n",
      "时间步 2067000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.600982e+01/ 轮得分 150.87\n",
      "损失函数： 0.0643\n",
      "时间步 2068000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.261436e+01/ 轮得分 151.00\n",
      "损失函数： 0.0215427\n",
      "时间步 2069000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.349335e+01/ 轮得分 151.00\n",
      "损失函数： 0.100918\n",
      "时间步 2070000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.309713e+01/ 轮得分 151.00\n",
      "损失函数： 0.0454672\n",
      "时间步 2071000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.358940e+01/ 轮得分 151.33\n",
      "损失函数： 0.0637128\n",
      "时间步 2072000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.440598e+01/ 轮得分 151.33\n",
      "损失函数： 0.0267519\n",
      "时间步 2073000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.276589e+01/ 轮得分 151.42\n",
      "损失函数： 0.192516\n",
      "时间步 2074000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.226834e+01/ 轮得分 151.40\n",
      "损失函数： 0.0352499\n",
      "时间步 2075000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.598869e+01/ 轮得分 151.40\n",
      "损失函数： 0.100554\n",
      "时间步 2076000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.306201e+01/ 轮得分 151.40\n",
      "损失函数： 0.0577225\n",
      "时间步 2077000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.366142e+01/ 轮得分 151.40\n",
      "损失函数： 0.109674\n",
      "时间步 2078000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.250767e+01/ 轮得分 151.80\n",
      "损失函数： 0.0866188\n",
      "时间步 2079000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.040252e+01/ 轮得分 151.48\n",
      "损失函数： 0.065766\n",
      "时间步 2080000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.361949e+01/ 轮得分 151.48\n",
      "损失函数： 0.0198089\n",
      "时间步 2081000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.259645e+01/ 轮得分 151.39\n",
      "损失函数： 0.144787\n",
      "时间步 2082000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.302083e+01/ 轮得分 151.39\n",
      "损失函数： 0.0598831\n",
      "时间步 2083000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.487795e+01/ 轮得分 151.63\n",
      "损失函数： 0.0561557\n",
      "时间步 2084000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.241160e+01/ 轮得分 151.63\n",
      "损失函数： 0.0409681\n",
      "时间步 2085000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 1.1/ Q_MAX 1.469977e+01/ 轮得分 151.58\n",
      "损失函数： 0.0495228\n",
      "时间步 2086000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.474530e+01/ 轮得分 151.63\n",
      "损失函数： 0.0389173\n",
      "时间步 2087000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.278645e+01/ 轮得分 151.64\n",
      "损失函数： 0.0776325\n",
      "时间步 2088000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.224907e+01/ 轮得分 151.69\n",
      "损失函数： 0.0537971\n",
      "时间步 2089000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.393919e+01/ 轮得分 151.69\n",
      "损失函数： 0.0856078\n",
      "时间步 2090000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.319526e+01/ 轮得分 151.78\n",
      "损失函数： 0.0572884\n",
      "时间步 2091000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.270336e+01/ 轮得分 151.78\n",
      "损失函数： 0.0604265\n",
      "时间步 2092000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.294365e+01/ 轮得分 151.78\n",
      "损失函数： 0.023576\n",
      "时间步 2093000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.171812e+01/ 轮得分 151.78\n",
      "损失函数： 0.027723\n",
      "时间步 2094000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.331896e+01/ 轮得分 152.32\n",
      "损失函数： 0.0516743\n",
      "时间步 2095000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.017915e+01/ 轮得分 152.32\n",
      "损失函数： 0.0535767\n",
      "时间步 2096000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.147487e+01/ 轮得分 152.32\n",
      "损失函数： 0.0647392\n",
      "时间步 2097000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.291435e+01/ 轮得分 152.32\n",
      "损失函数： 0.0536734\n",
      "时间步 2098000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.468312e+01/ 轮得分 152.70\n",
      "损失函数： 0.069012\n",
      "时间步 2099000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.496887e+01/ 轮得分 152.73\n",
      "损失函数： 0.024328\n",
      "时间步 2100000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.369625e+01/ 轮得分 152.73\n",
      "损失函数： 0.0306012\n",
      "时间步 2101000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.386422e+01/ 轮得分 152.99\n",
      "损失函数： 0.0364958\n",
      "时间步 2102000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.389733e+01/ 轮得分 152.92\n",
      "损失函数： 0.0314905\n",
      "时间步 2103000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.146885e+01/ 轮得分 152.92\n",
      "损失函数： 0.0409979\n",
      "时间步 2104000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.203598e+01/ 轮得分 153.05\n",
      "损失函数： 0.0470757\n",
      "时间步 2105000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.118694e+01/ 轮得分 153.10\n",
      "损失函数： 0.0319009\n",
      "时间步 2106000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.157267e+01/ 轮得分 153.10\n",
      "损失函数： 0.0854301\n",
      "时间步 2107000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.544005e+01/ 轮得分 153.10\n",
      "损失函数： 0.0255754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2108000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.204389e+01/ 轮得分 153.48\n",
      "损失函数： 0.0367999\n",
      "时间步 2109000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.368275e+01/ 轮得分 153.48\n",
      "损失函数： 0.0924212\n",
      "时间步 2110000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.052539e+01/ 轮得分 153.48\n",
      "损失函数： 0.0619834\n",
      "时间步 2111000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 8.250131e+00/ 轮得分 153.48\n",
      "损失函数： 0.0326219\n",
      "时间步 2112000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.354275e+01/ 轮得分 153.75\n",
      "损失函数： 0.0269308\n",
      "时间步 2113000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.431282e+01/ 轮得分 153.75\n",
      "损失函数： 0.0330763\n",
      "时间步 2114000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.311168e+01/ 轮得分 154.03\n",
      "损失函数： 0.0416286\n",
      "时间步 2115000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.333890e+01/ 轮得分 153.99\n",
      "损失函数： 0.0372197\n",
      "时间步 2116000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.367407e+01/ 轮得分 154.01\n",
      "损失函数： 0.116642\n",
      "时间步 2117000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.352257e+01/ 轮得分 154.01\n",
      "损失函数： 0.049745\n",
      "时间步 2118000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.194362e+01/ 轮得分 154.01\n",
      "损失函数： 0.0443916\n",
      "时间步 2119000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.340062e+01/ 轮得分 154.28\n",
      "损失函数： 0.0470224\n",
      "时间步 2120000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.604645e+01/ 轮得分 154.16\n",
      "损失函数： 0.115913\n",
      "时间步 2121000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.301374e+01/ 轮得分 154.08\n",
      "损失函数： 0.0497159\n",
      "时间步 2122000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.218279e+01/ 轮得分 154.08\n",
      "损失函数： 0.0620085\n",
      "时间步 2123000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.299146e+01/ 轮得分 154.08\n",
      "损失函数： 0.0369092\n",
      "时间步 2124000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.334792e+01/ 轮得分 154.08\n",
      "损失函数： 0.0365349\n",
      "时间步 2125000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.196260e+01/ 轮得分 154.08\n",
      "损失函数： 0.0396584\n",
      "时间步 2126000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.158103e+01/ 轮得分 154.60\n",
      "损失函数： 0.0248531\n",
      "时间步 2127000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.343143e+01/ 轮得分 154.60\n",
      "损失函数： 0.0366469\n",
      "时间步 2128000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.384348e+01/ 轮得分 154.86\n",
      "损失函数： 0.0579694\n",
      "时间步 2129000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.444470e+01/ 轮得分 154.86\n",
      "损失函数： 0.0672143\n",
      "时间步 2130000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.196667e+01/ 轮得分 155.01\n",
      "损失函数： 0.0587381\n",
      "时间步 2131000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.368042e+01/ 轮得分 155.09\n",
      "损失函数： 0.0520816\n",
      "时间步 2132000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.277291e+01/ 轮得分 155.11\n",
      "损失函数： 0.0393215\n",
      "时间步 2133000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.373551e+01/ 轮得分 154.99\n",
      "损失函数： 0.0310613\n",
      "时间步 2134000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.155180e+01/ 轮得分 154.99\n",
      "损失函数： 0.0315611\n",
      "时间步 2135000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.322929e+01/ 轮得分 155.14\n",
      "损失函数： 0.0183418\n",
      "时间步 2136000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.416156e+01/ 轮得分 155.14\n",
      "损失函数： 0.0340105\n",
      "时间步 2137000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.314878e+01/ 轮得分 155.14\n",
      "损失函数： 0.0805459\n",
      "时间步 2138000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.494497e+01/ 轮得分 155.14\n",
      "损失函数： 0.0738679\n",
      "时间步 2139000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.406522e+01/ 轮得分 155.14\n",
      "损失函数： 0.0322184\n",
      "时间步 2140000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.433910e+01/ 轮得分 155.66\n",
      "损失函数： 0.0405933\n",
      "时间步 2141000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.219029e+01/ 轮得分 155.69\n",
      "损失函数： 0.0161297\n",
      "时间步 2142000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.274727e+01/ 轮得分 155.74\n",
      "损失函数： 0.0321873\n",
      "时间步 2143000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.188350e+01/ 轮得分 155.74\n",
      "损失函数： 1.09905\n",
      "时间步 2144000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.193232e+01/ 轮得分 155.74\n",
      "损失函数： 0.075634\n",
      "时间步 2145000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.461514e+01/ 轮得分 155.74\n",
      "损失函数： 0.0292281\n",
      "时间步 2146000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.389060e+01/ 轮得分 155.74\n",
      "损失函数： 0.0439673\n",
      "时间步 2147000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.295853e+01/ 轮得分 156.34\n",
      "损失函数： 0.0492172\n",
      "时间步 2148000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.197420e+01/ 轮得分 156.28\n",
      "损失函数： 0.034504\n",
      "时间步 2149000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.315808e+01/ 轮得分 156.28\n",
      "损失函数： 0.105913\n",
      "时间步 2150000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.266201e+01/ 轮得分 156.28\n",
      "损失函数： 0.034075\n",
      "时间步 2151000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.362318e+01/ 轮得分 156.28\n",
      "损失函数： 0.112724\n",
      "时间步 2152000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.402652e+01/ 轮得分 156.28\n",
      "损失函数： 0.0328966\n",
      "时间步 2153000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.268967e+01/ 轮得分 156.28\n",
      "损失函数： 0.055826\n",
      "时间步 2154000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.235679e+01/ 轮得分 156.95\n",
      "损失函数： 0.0324751\n",
      "时间步 2155000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.318083e+01/ 轮得分 156.95\n",
      "损失函数： 0.0881137\n",
      "时间步 2156000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.514320e+01/ 轮得分 157.15\n",
      "损失函数： 0.0425029\n",
      "时间步 2157000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.561101e+01/ 轮得分 157.15\n",
      "损失函数： 0.0365635\n",
      "时间步 2158000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.484848e+01/ 轮得分 157.15\n",
      "损失函数： 0.0506971\n",
      "时间步 2159000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.359471e+01/ 轮得分 157.43\n",
      "损失函数： 0.0270921\n",
      "时间步 2160000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.300307e+01/ 轮得分 157.54\n",
      "损失函数： 0.0428485\n",
      "时间步 2161000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.175010e+01/ 轮得分 157.54\n",
      "损失函数： 0.0538302\n",
      "时间步 2162000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 2.1/ Q_MAX 1.558566e+01/ 轮得分 157.54\n",
      "损失函数： 0.0782477\n",
      "时间步 2163000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.392886e+01/ 轮得分 157.55\n",
      "损失函数： 0.0332793\n",
      "时间步 2164000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.152823e+01/ 轮得分 157.64\n",
      "损失函数： 0.0385838\n",
      "时间步 2165000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.331416e+01/ 轮得分 157.64\n",
      "损失函数： 0.0189396\n",
      "时间步 2166000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.333732e+01/ 轮得分 157.64\n",
      "损失函数： 0.0271141\n",
      "时间步 2167000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.277960e+01/ 轮得分 157.64\n",
      "损失函数： 0.0581425\n",
      "时间步 2168000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.359150e+01/ 轮得分 157.64\n",
      "损失函数： 0.0385235\n",
      "时间步 2169000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.336482e+01/ 轮得分 157.64\n",
      "损失函数： 0.0716217\n",
      "时间步 2170000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.252133e+01/ 轮得分 157.64\n",
      "损失函数： 0.0399714\n",
      "时间步 2171000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.322604e+01/ 轮得分 157.64\n",
      "损失函数： 0.0480591\n",
      "时间步 2172000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 1.1/ Q_MAX 1.262968e+01/ 轮得分 157.64\n",
      "损失函数： 0.0511213\n",
      "时间步 2173000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.161107e+01/ 轮得分 158.42\n",
      "损失函数： 0.0351861\n",
      "时间步 2174000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.287222e+01/ 轮得分 158.42\n",
      "损失函数： 0.0276123\n",
      "时间步 2175000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.527435e+01/ 轮得分 158.42\n",
      "损失函数： 0.0198344\n",
      "时间步 2176000/ 状态 explore/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.500139e+01/ 轮得分 158.42\n",
      "损失函数： 0.0665598\n",
      "时间步 2177000/ 状态 explore/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.290520e+01/ 轮得分 158.42\n",
      "损失函数： 0.0422993\n",
      "时间步 2178000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.284327e+01/ 轮得分 158.42\n",
      "损失函数： 0.0399181\n",
      "时间步 2179000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.187856e+01/ 轮得分 159.07\n",
      "损失函数： 0.0301933\n",
      "时间步 2180000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.204377e+01/ 轮得分 159.07\n",
      "损失函数： 0.0178881\n",
      "时间步 2181000/ 状态 explore/ Epsilon 0.06/ 行动 0/ 奖励 2.1/ Q_MAX 1.461655e+01/ 轮得分 159.07\n",
      "损失函数： 0.0730766\n",
      "时间步 2182000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.643124e+01/ 轮得分 159.07\n",
      "损失函数： 0.038244\n",
      "时间步 2183000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.500654e+01/ 轮得分 159.07\n",
      "损失函数： 0.0339738\n",
      "时间步 2184000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.242587e+01/ 轮得分 159.07\n",
      "损失函数： 0.0344006\n",
      "时间步 2185000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.164555e+01/ 轮得分 159.58\n",
      "损失函数： 0.0259715\n",
      "时间步 2186000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.435578e+01/ 轮得分 159.58\n",
      "损失函数： 0.0476894\n",
      "时间步 2187000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.490549e+01/ 轮得分 159.58\n",
      "损失函数： 0.0857492\n",
      "时间步 2188000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.338130e+01/ 轮得分 159.58\n",
      "损失函数： 0.0323472\n",
      "时间步 2189000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 1.1/ Q_MAX 1.484944e+01/ 轮得分 159.58\n",
      "损失函数： 0.0745956\n",
      "时间步 2190000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.412023e+01/ 轮得分 159.58\n",
      "损失函数： 0.0536653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2191000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.263416e+01/ 轮得分 159.58\n",
      "损失函数： 0.0394724\n",
      "时间步 2192000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.620625e+01/ 轮得分 159.58\n",
      "损失函数： 0.0306378\n",
      "时间步 2193000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.400438e+01/ 轮得分 159.58\n",
      "损失函数： 0.049521\n",
      "时间步 2194000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.448561e+01/ 轮得分 159.58\n",
      "损失函数： 0.0127164\n",
      "时间步 2195000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.391741e+01/ 轮得分 160.68\n",
      "损失函数： 0.103034\n",
      "时间步 2196000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.341262e+01/ 轮得分 160.68\n",
      "损失函数： 0.053965\n",
      "时间步 2197000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.462647e+01/ 轮得分 160.85\n",
      "损失函数： 0.0392416\n",
      "时间步 2198000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.335392e+01/ 轮得分 160.85\n",
      "损失函数： 0.0184533\n",
      "时间步 2199000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.082922e+01/ 轮得分 160.85\n",
      "损失函数： 0.124592\n",
      "时间步 2200000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.281178e+01/ 轮得分 160.85\n",
      "损失函数： 0.0689086\n",
      "时间步 2201000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.365865e+01/ 轮得分 160.85\n",
      "损失函数： 0.0246956\n",
      "时间步 2202000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.277978e+01/ 轮得分 160.85\n",
      "损失函数： 0.0842265\n",
      "时间步 2203000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.452153e+01/ 轮得分 161.54\n",
      "损失函数： 0.0388598\n",
      "时间步 2204000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.364914e+01/ 轮得分 161.54\n",
      "损失函数： 0.0429294\n",
      "时间步 2205000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 1.1/ Q_MAX 1.631327e+01/ 轮得分 161.54\n",
      "损失函数： 0.138512\n",
      "时间步 2206000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.173657e+01/ 轮得分 161.82\n",
      "损失函数： 0.0578207\n",
      "时间步 2207000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.427460e+01/ 轮得分 161.82\n",
      "损失函数： 0.122176\n",
      "时间步 2208000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.375414e+01/ 轮得分 161.82\n",
      "损失函数： 0.0223621\n",
      "时间步 2209000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.240465e+01/ 轮得分 162.15\n",
      "损失函数： 0.031317\n",
      "时间步 2210000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.133139e+01/ 轮得分 162.16\n",
      "损失函数： 0.0491614\n",
      "时间步 2211000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.392300e+01/ 轮得分 162.22\n",
      "损失函数： 0.0178039\n",
      "时间步 2212000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.361342e+01/ 轮得分 162.22\n",
      "损失函数： 0.0390767\n",
      "时间步 2213000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.419301e+01/ 轮得分 162.22\n",
      "损失函数： 0.0213588\n",
      "时间步 2214000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.287411e+01/ 轮得分 162.51\n",
      "损失函数： 0.0192178\n",
      "时间步 2215000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.416218e+01/ 轮得分 162.59\n",
      "损失函数： 0.0428576\n",
      "时间步 2216000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.196444e+01/ 轮得分 162.63\n",
      "损失函数： 0.047289\n",
      "时间步 2217000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.377091e+01/ 轮得分 162.62\n",
      "损失函数： 0.0605804\n",
      "时间步 2218000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.231970e+01/ 轮得分 162.72\n",
      "损失函数： 0.0350439\n",
      "时间步 2219000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.509345e+01/ 轮得分 162.72\n",
      "损失函数： 0.0210489\n",
      "时间步 2220000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.305547e+01/ 轮得分 162.85\n",
      "损失函数： 0.0202115\n",
      "时间步 2221000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.254981e+01/ 轮得分 162.85\n",
      "损失函数： 0.0471321\n",
      "时间步 2222000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.476090e+01/ 轮得分 162.91\n",
      "损失函数： 0.0300339\n",
      "时间步 2223000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.191428e+01/ 轮得分 162.91\n",
      "损失函数： 0.0176367\n",
      "时间步 2224000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.268116e+01/ 轮得分 163.19\n",
      "损失函数： 0.0386175\n",
      "时间步 2225000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.302060e+01/ 轮得分 163.11\n",
      "损失函数： 0.0377003\n",
      "时间步 2226000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.204701e+01/ 轮得分 163.22\n",
      "损失函数： 0.0655097\n",
      "时间步 2227000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.265609e+01/ 轮得分 163.22\n",
      "损失函数： 0.0554505\n",
      "时间步 2228000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.268656e+01/ 轮得分 163.25\n",
      "损失函数： 0.0654613\n",
      "时间步 2229000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.388088e+01/ 轮得分 163.29\n",
      "损失函数： 0.0380378\n",
      "时间步 2230000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.574298e+01/ 轮得分 163.29\n",
      "损失函数： 0.029341\n",
      "时间步 2231000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.266351e+01/ 轮得分 163.29\n",
      "损失函数： 0.0253276\n",
      "时间步 2232000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.220137e+01/ 轮得分 163.49\n",
      "损失函数： 0.0285633\n",
      "时间步 2233000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.353565e+01/ 轮得分 163.49\n",
      "损失函数： 0.0957528\n",
      "时间步 2234000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.388425e+01/ 轮得分 163.49\n",
      "损失函数： 0.0203018\n",
      "时间步 2235000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 9.174959e+00/ 轮得分 163.68\n",
      "损失函数： 0.052127\n",
      "时间步 2236000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.187134e+01/ 轮得分 163.61\n",
      "损失函数： 0.0459303\n",
      "时间步 2237000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.236264e+01/ 轮得分 163.82\n",
      "损失函数： 0.0248229\n",
      "时间步 2238000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.191409e+01/ 轮得分 163.82\n",
      "损失函数： 1.1457\n",
      "时间步 2239000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.272680e+01/ 轮得分 163.82\n",
      "损失函数： 0.0276459\n",
      "时间步 2240000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.405401e+01/ 轮得分 163.97\n",
      "损失函数： 0.0343713\n",
      "时间步 2241000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.205281e+01/ 轮得分 164.07\n",
      "损失函数： 0.00966312\n",
      "时间步 2242000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.304689e+01/ 轮得分 164.07\n",
      "损失函数： 0.0529698\n",
      "时间步 2243000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.240164e+01/ 轮得分 164.07\n",
      "损失函数： 0.0953178\n",
      "时间步 2244000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.254709e+01/ 轮得分 164.47\n",
      "损失函数： 0.140643\n",
      "时间步 2245000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.323133e+01/ 轮得分 164.47\n",
      "损失函数： 0.0670506\n",
      "时间步 2246000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.169783e+01/ 轮得分 164.43\n",
      "损失函数： 0.0293722\n",
      "时间步 2247000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.252572e+01/ 轮得分 164.43\n",
      "损失函数： 0.0235073\n",
      "时间步 2248000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.147055e+01/ 轮得分 164.43\n",
      "损失函数： 0.0539781\n",
      "时间步 2249000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.279994e+01/ 轮得分 164.43\n",
      "损失函数： 0.046662\n",
      "时间步 2250000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.270413e+01/ 轮得分 164.73\n",
      "损失函数： 0.110492\n",
      "时间步 2251000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.302794e+01/ 轮得分 164.73\n",
      "损失函数： 0.0724775\n",
      "时间步 2252000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.214294e+01/ 轮得分 165.05\n",
      "损失函数： 0.0679674\n",
      "时间步 2253000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.317087e+01/ 轮得分 165.05\n",
      "损失函数： 0.0420714\n",
      "时间步 2254000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.431195e+01/ 轮得分 165.05\n",
      "损失函数： 0.0311232\n",
      "时间步 2255000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.320417e+01/ 轮得分 165.05\n",
      "损失函数： 0.0548124\n",
      "时间步 2256000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.428821e+01/ 轮得分 165.05\n",
      "损失函数： 0.0612762\n",
      "时间步 2257000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.464018e+01/ 轮得分 165.05\n",
      "损失函数： 0.0563122\n",
      "时间步 2258000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.456124e+01/ 轮得分 165.05\n",
      "损失函数： 0.0272614\n",
      "时间步 2259000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.366248e+01/ 轮得分 165.05\n",
      "损失函数： 0.0237497\n",
      "时间步 2260000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.470562e+01/ 轮得分 165.05\n",
      "损失函数： 0.0838869\n",
      "时间步 2261000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.379438e+01/ 轮得分 165.05\n",
      "损失函数： 0.0562281\n",
      "时间步 2262000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.203496e+01/ 轮得分 165.05\n",
      "损失函数： 0.0416332\n",
      "时间步 2263000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 1.1/ Q_MAX 1.344802e+01/ 轮得分 165.05\n",
      "损失函数： 0.030491\n",
      "时间步 2264000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.451122e+01/ 轮得分 166.40\n",
      "损失函数： 0.0370947\n",
      "时间步 2265000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.260921e+01/ 轮得分 166.48\n",
      "损失函数： 0.0269606\n",
      "时间步 2266000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 9.840861e+00/ 轮得分 166.48\n",
      "损失函数： 0.067546\n",
      "时间步 2267000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.289477e+01/ 轮得分 166.41\n",
      "损失函数： 0.0184173\n",
      "时间步 2268000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.471110e+01/ 轮得分 166.41\n",
      "损失函数： 0.0455235\n",
      "时间步 2269000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.348026e+01/ 轮得分 166.57\n",
      "损失函数： 0.0306437\n",
      "时间步 2270000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.273574e+01/ 轮得分 166.57\n",
      "损失函数： 0.0320409\n",
      "时间步 2271000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.572572e+01/ 轮得分 166.57\n",
      "损失函数： 0.0516521\n",
      "时间步 2272000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.048975e+01/ 轮得分 166.57\n",
      "损失函数： 0.0505607\n",
      "时间步 2273000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 6.681721e+00/ 轮得分 166.97\n",
      "损失函数： 0.0786658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2274000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.211472e+01/ 轮得分 166.97\n",
      "损失函数： 0.0445661\n",
      "时间步 2275000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.182452e+01/ 轮得分 166.97\n",
      "损失函数： 0.0295255\n",
      "时间步 2276000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.514001e+01/ 轮得分 167.28\n",
      "损失函数： 0.0231626\n",
      "时间步 2277000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.370673e+01/ 轮得分 167.28\n",
      "损失函数： 0.049974\n",
      "时间步 2278000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.499598e+01/ 轮得分 167.28\n",
      "损失函数： 0.0346704\n",
      "时间步 2279000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.294560e+01/ 轮得分 167.54\n",
      "损失函数： 0.0799746\n",
      "时间步 2280000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.436666e+01/ 轮得分 167.53\n",
      "损失函数： 0.0338183\n",
      "时间步 2281000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.343466e+01/ 轮得分 167.67\n",
      "损失函数： 0.0740861\n",
      "时间步 2282000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.388507e+01/ 轮得分 167.67\n",
      "损失函数： 0.013072\n",
      "时间步 2283000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.289629e+01/ 轮得分 167.56\n",
      "损失函数： 0.040223\n",
      "时间步 2284000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.544258e+01/ 轮得分 167.56\n",
      "损失函数： 0.0462279\n",
      "时间步 2285000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.527495e+01/ 轮得分 167.56\n",
      "损失函数： 0.0443351\n",
      "时间步 2286000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.537088e+01/ 轮得分 167.56\n",
      "损失函数： 0.0586893\n",
      "时间步 2287000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.037094e+01/ 轮得分 167.56\n",
      "损失函数： 0.0571504\n",
      "时间步 2288000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.171302e+01/ 轮得分 168.20\n",
      "损失函数： 0.0317019\n",
      "时间步 2289000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.211107e+01/ 轮得分 168.20\n",
      "损失函数： 0.0629282\n",
      "时间步 2290000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.236602e+01/ 轮得分 168.35\n",
      "损失函数： 0.0429147\n",
      "时间步 2291000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.374459e+01/ 轮得分 168.35\n",
      "损失函数： 0.0587315\n",
      "时间步 2292000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.184844e+01/ 轮得分 168.35\n",
      "损失函数： 0.0289787\n",
      "时间步 2293000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.215323e+01/ 轮得分 168.35\n",
      "损失函数： 0.0348791\n",
      "时间步 2294000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.218427e+01/ 轮得分 168.35\n",
      "损失函数： 0.0603074\n",
      "时间步 2295000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.255590e+01/ 轮得分 168.35\n",
      "损失函数： 0.02859\n",
      "时间步 2296000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.102982e+01/ 轮得分 168.35\n",
      "损失函数： 0.0592825\n",
      "时间步 2297000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.372514e+01/ 轮得分 169.11\n",
      "损失函数： 0.0645091\n",
      "时间步 2298000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.193322e+01/ 轮得分 169.10\n",
      "损失函数： 0.0511463\n",
      "时间步 2299000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.240182e+01/ 轮得分 169.10\n",
      "损失函数： 0.0841011\n",
      "时间步 2300000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.197442e+01/ 轮得分 169.36\n",
      "损失函数： 0.0829074\n",
      "时间步 2301000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.399023e+01/ 轮得分 169.36\n",
      "损失函数： 0.043058\n",
      "时间步 2302000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.396558e+01/ 轮得分 169.36\n",
      "损失函数： 0.0690289\n",
      "时间步 2303000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.174276e+01/ 轮得分 169.05\n",
      "损失函数： 0.0639931\n",
      "时间步 2304000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.374119e+01/ 轮得分 169.05\n",
      "损失函数： 0.0459901\n",
      "时间步 2305000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.291903e+01/ 轮得分 169.14\n",
      "损失函数： 0.0419326\n",
      "时间步 2306000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.381610e+01/ 轮得分 169.14\n",
      "损失函数： 0.0406871\n",
      "时间步 2307000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.128934e+01/ 轮得分 169.05\n",
      "损失函数： 0.0468109\n",
      "时间步 2308000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.280920e+01/ 轮得分 169.05\n",
      "损失函数： 0.0415784\n",
      "时间步 2309000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.451895e+01/ 轮得分 169.05\n",
      "损失函数： 0.0601618\n",
      "时间步 2310000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.369629e+01/ 轮得分 169.40\n",
      "损失函数： 0.0602908\n",
      "时间步 2311000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.303971e+01/ 轮得分 169.40\n",
      "损失函数： 0.074674\n",
      "时间步 2312000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.380304e+01/ 轮得分 169.40\n",
      "损失函数： 0.0439398\n",
      "时间步 2313000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.363276e+01/ 轮得分 169.40\n",
      "损失函数： 0.165244\n",
      "时间步 2314000/ 状态 explore/ Epsilon 0.05/ 行动 1/ 奖励 0.1/ Q_MAX 1.347787e+01/ 轮得分 169.40\n",
      "损失函数： 0.0380466\n",
      "时间步 2315000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.402804e+01/ 轮得分 169.79\n",
      "损失函数： 0.0452862\n",
      "时间步 2316000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.258484e+01/ 轮得分 169.79\n",
      "损失函数： 0.0521331\n",
      "时间步 2317000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.258300e+01/ 轮得分 169.97\n",
      "损失函数： 0.0362584\n",
      "时间步 2318000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.309354e+01/ 轮得分 169.70\n",
      "损失函数： 0.0255104\n",
      "时间步 2319000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.394215e+01/ 轮得分 169.64\n",
      "损失函数： 0.0525836\n",
      "时间步 2320000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.250658e+01/ 轮得分 169.76\n",
      "损失函数： 0.0162771\n",
      "时间步 2321000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.196819e+01/ 轮得分 169.76\n",
      "损失函数： 0.0152\n",
      "时间步 2322000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.417321e+01/ 轮得分 169.76\n",
      "损失函数： 0.0464069\n",
      "时间步 2323000/ 状态 explore/ Epsilon 0.05/ 行动 2/ 奖励 0.1/ Q_MAX 1.186476e+01/ 轮得分 169.81\n",
      "损失函数： 0.0544409\n",
      "时间步 2324000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 9.061226e+00/ 轮得分 169.86\n",
      "损失函数： 0.0227969\n",
      "时间步 2325000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.269363e+01/ 轮得分 169.86\n",
      "损失函数： 0.0585136\n",
      "时间步 2326000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.188864e+01/ 轮得分 169.86\n",
      "损失函数： 0.0516561\n",
      "时间步 2327000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.353590e+01/ 轮得分 170.15\n",
      "损失函数： 0.0592953\n",
      "时间步 2328000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.335276e+01/ 轮得分 170.15\n",
      "损失函数： 0.0186418\n",
      "时间步 2329000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.394356e+01/ 轮得分 170.15\n",
      "损失函数： 0.0164862\n",
      "时间步 2330000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.184158e+01/ 轮得分 170.35\n",
      "损失函数： 0.0275751\n",
      "时间步 2331000/ 状态 explore/ Epsilon 0.05/ 行动 0/ 奖励 0.1/ Q_MAX 1.243241e+01/ 轮得分 170.35\n",
      "损失函数： 0.07029\n",
      "时间步 2332000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.596784e+01/ 轮得分 170.35\n",
      "损失函数： 0.0229439\n",
      "时间步 2333000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.319319e+01/ 轮得分 170.35\n",
      "损失函数： 0.0244487\n",
      "时间步 2334000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.378299e+01/ 轮得分 170.73\n",
      "损失函数： 0.0377069\n",
      "时间步 2335000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.255923e+01/ 轮得分 170.72\n",
      "损失函数： 0.0319262\n",
      "时间步 2336000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.236843e+01/ 轮得分 170.72\n",
      "损失函数： 0.0635163\n",
      "时间步 2337000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.409934e+01/ 轮得分 170.72\n",
      "损失函数： 0.0295279\n",
      "时间步 2338000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.487181e+01/ 轮得分 170.72\n",
      "损失函数： 0.0266421\n",
      "时间步 2339000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.333304e+01/ 轮得分 170.72\n",
      "损失函数： 0.0322623\n",
      "时间步 2340000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.240248e+01/ 轮得分 171.17\n",
      "损失函数： 0.0485871\n",
      "时间步 2341000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.337489e+01/ 轮得分 171.17\n",
      "损失函数： 0.022679\n",
      "时间步 2342000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.154041e+01/ 轮得分 171.17\n",
      "损失函数： 0.0361317\n",
      "时间步 2343000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.031388e+01/ 轮得分 171.52\n",
      "损失函数： 0.0443159\n",
      "时间步 2344000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.235863e+01/ 轮得分 171.48\n",
      "损失函数： 0.0557609\n",
      "时间步 2345000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.339036e+01/ 轮得分 171.48\n",
      "损失函数： 0.0794542\n",
      "时间步 2346000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.453761e+01/ 轮得分 171.48\n",
      "损失函数： 0.026524\n",
      "时间步 2347000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.479224e+01/ 轮得分 171.48\n",
      "损失函数： 0.0610898\n",
      "时间步 2348000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.474353e+01/ 轮得分 171.94\n",
      "损失函数： 0.0811316\n",
      "时间步 2349000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.601271e+01/ 轮得分 171.96\n",
      "损失函数： 0.0244923\n",
      "时间步 2350000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.483704e+01/ 轮得分 171.96\n",
      "损失函数： 0.0487526\n",
      "时间步 2351000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.518766e+01/ 轮得分 172.18\n",
      "损失函数： 0.0229191\n",
      "时间步 2352000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.438236e+01/ 轮得分 172.18\n",
      "损失函数： 0.0423277\n",
      "时间步 2353000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.303005e+01/ 轮得分 172.18\n",
      "损失函数： 0.125707\n",
      "时间步 2354000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.334535e+01/ 轮得分 172.49\n",
      "损失函数： 0.0689081\n",
      "时间步 2355000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.397806e+01/ 轮得分 172.49\n",
      "损失函数： 0.026292\n",
      "时间步 2356000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.456726e+01/ 轮得分 172.49\n",
      "损失函数： 0.0712761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2357000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.385898e+01/ 轮得分 172.77\n",
      "损失函数： 0.139981\n",
      "时间步 2358000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.353954e+01/ 轮得分 172.77\n",
      "损失函数： 0.0611661\n",
      "时间步 2359000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.374085e+01/ 轮得分 172.77\n",
      "损失函数： 0.089584\n",
      "时间步 2360000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.434931e+01/ 轮得分 172.77\n",
      "损失函数： 0.633978\n",
      "时间步 2361000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.365463e+01/ 轮得分 172.77\n",
      "损失函数： 0.030695\n",
      "时间步 2362000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.579419e+01/ 轮得分 172.77\n",
      "损失函数： 0.0247621\n",
      "时间步 2363000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.235112e+01/ 轮得分 173.51\n",
      "损失函数： 0.0324315\n",
      "时间步 2364000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.353739e+01/ 轮得分 173.51\n",
      "损失函数： 0.0235434\n",
      "时间步 2365000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.184070e+01/ 轮得分 173.51\n",
      "损失函数： 0.0515252\n",
      "时间步 2366000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.528496e+01/ 轮得分 173.51\n",
      "损失函数： 0.0262008\n",
      "时间步 2367000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.324511e+01/ 轮得分 173.76\n",
      "损失函数： 0.0243754\n",
      "时间步 2368000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.337363e+01/ 轮得分 173.76\n",
      "损失函数： 0.0155319\n",
      "时间步 2369000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.355755e+01/ 轮得分 173.76\n",
      "损失函数： 0.0468677\n",
      "时间步 2370000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.352105e+01/ 轮得分 173.76\n",
      "损失函数： 0.0416082\n",
      "时间步 2371000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.222485e+01/ 轮得分 174.20\n",
      "损失函数： 0.0623069\n",
      "时间步 2372000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.513721e+01/ 轮得分 174.20\n",
      "损失函数： 0.0279288\n",
      "时间步 2373000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.447884e+01/ 轮得分 174.30\n",
      "损失函数： 0.0330834\n",
      "时间步 2374000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.346721e+01/ 轮得分 174.33\n",
      "损失函数： 0.049109\n",
      "时间步 2375000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.426693e+01/ 轮得分 174.33\n",
      "损失函数： 0.0289406\n",
      "时间步 2376000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.490751e+01/ 轮得分 174.33\n",
      "损失函数： 0.0389473\n",
      "时间步 2377000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.386518e+01/ 轮得分 174.33\n",
      "损失函数： 0.0412991\n",
      "时间步 2378000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.303846e+01/ 轮得分 174.33\n",
      "损失函数： 0.0288395\n",
      "时间步 2379000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 8.653407e+00/ 轮得分 174.33\n",
      "损失函数： 0.0223935\n",
      "时间步 2380000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.400550e+01/ 轮得分 174.77\n",
      "损失函数： 0.0180165\n",
      "时间步 2381000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.243415e+01/ 轮得分 174.77\n",
      "损失函数： 0.0330139\n",
      "时间步 2382000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.381812e+01/ 轮得分 174.77\n",
      "损失函数： 0.0492557\n",
      "时间步 2383000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.343966e+01/ 轮得分 174.77\n",
      "损失函数： 0.0945158\n",
      "时间步 2384000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.336649e+01/ 轮得分 175.29\n",
      "损失函数： 0.0270669\n",
      "时间步 2385000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 5.260021e+00/ 轮得分 175.29\n",
      "损失函数： 0.0672492\n",
      "时间步 2386000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.535752e+01/ 轮得分 175.45\n",
      "损失函数： 0.132405\n",
      "时间步 2387000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.184749e+01/ 轮得分 175.47\n",
      "损失函数： 0.0216201\n",
      "时间步 2388000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.213080e+01/ 轮得分 175.49\n",
      "损失函数： 0.0145072\n",
      "时间步 2389000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 1.1/ Q_MAX 1.436428e+01/ 轮得分 175.49\n",
      "损失函数： 0.017618\n",
      "时间步 2390000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.313228e+01/ 轮得分 175.72\n",
      "损失函数： 0.0291622\n",
      "时间步 2391000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.391473e+01/ 轮得分 175.66\n",
      "损失函数： 0.0415184\n",
      "时间步 2392000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.240433e+01/ 轮得分 175.66\n",
      "损失函数： 0.117317\n",
      "时间步 2393000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.352690e+01/ 轮得分 175.66\n",
      "损失函数： 0.0234857\n",
      "时间步 2394000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.124827e+01/ 轮得分 175.66\n",
      "损失函数： 0.0464336\n",
      "时间步 2395000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.354267e+01/ 轮得分 176.13\n",
      "损失函数： 0.03514\n",
      "时间步 2396000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.284403e+01/ 轮得分 176.13\n",
      "损失函数： 0.0274359\n",
      "时间步 2397000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.294573e+01/ 轮得分 176.13\n",
      "损失函数： 0.0425771\n",
      "时间步 2398000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.397199e+01/ 轮得分 176.13\n",
      "损失函数： 0.0220281\n",
      "时间步 2399000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.307569e+01/ 轮得分 176.39\n",
      "损失函数： 0.0733527\n",
      "时间步 2400000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.344300e+01/ 轮得分 176.39\n",
      "损失函数： 0.0824977\n",
      "时间步 2401000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.449816e+01/ 轮得分 176.39\n",
      "损失函数： 0.0333184\n",
      "时间步 2402000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.195645e+01/ 轮得分 176.74\n",
      "损失函数： 0.0229332\n",
      "时间步 2403000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.293401e+01/ 轮得分 176.74\n",
      "损失函数： 0.0310857\n",
      "时间步 2404000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.173318e+01/ 轮得分 176.74\n",
      "损失函数： 0.0243643\n",
      "时间步 2405000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.359123e+01/ 轮得分 176.74\n",
      "损失函数： 0.0530104\n",
      "时间步 2406000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.335246e+01/ 轮得分 177.10\n",
      "损失函数： 0.0211761\n",
      "时间步 2407000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.531013e+01/ 轮得分 177.10\n",
      "损失函数： 0.0640114\n",
      "时间步 2408000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.138162e+01/ 轮得分 177.10\n",
      "损失函数： 0.0124532\n",
      "时间步 2409000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.289040e+01/ 轮得分 177.35\n",
      "损失函数： 0.0483157\n",
      "时间步 2410000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.323775e+01/ 轮得分 177.41\n",
      "损失函数： 0.0315734\n",
      "时间步 2411000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.105036e+01/ 轮得分 177.57\n",
      "损失函数： 0.017482\n",
      "时间步 2412000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.218016e+01/ 轮得分 177.47\n",
      "损失函数： 0.0821875\n",
      "时间步 2413000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.287801e+01/ 轮得分 177.46\n",
      "损失函数： 0.0314167\n",
      "时间步 2414000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.390860e+01/ 轮得分 177.46\n",
      "损失函数： 0.0175268\n",
      "时间步 2415000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.103753e+01/ 轮得分 177.71\n",
      "损失函数： 0.0342833\n",
      "时间步 2416000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.126792e+01/ 轮得分 177.71\n",
      "损失函数： 0.0676386\n",
      "时间步 2417000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.381022e+01/ 轮得分 177.88\n",
      "损失函数： 0.0457746\n",
      "时间步 2418000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.349601e+01/ 轮得分 177.88\n",
      "损失函数： 0.0757131\n",
      "时间步 2419000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 9.381609e+00/ 轮得分 177.88\n",
      "损失函数： 0.0347184\n",
      "时间步 2420000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.275316e+01/ 轮得分 178.16\n",
      "损失函数： 0.036188\n",
      "时间步 2421000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.350794e+01/ 轮得分 177.71\n",
      "损失函数： 0.0471189\n",
      "时间步 2422000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.098482e+01/ 轮得分 177.76\n",
      "损失函数： 0.0539152\n",
      "时间步 2423000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.442674e+01/ 轮得分 177.59\n",
      "损失函数： 0.0192646\n",
      "时间步 2424000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 1.1/ Q_MAX 1.265780e+01/ 轮得分 177.59\n",
      "损失函数： 0.00990228\n",
      "时间步 2425000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.444236e+01/ 轮得分 177.80\n",
      "损失函数： 0.0273433\n",
      "时间步 2426000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.304069e+01/ 轮得分 177.80\n",
      "损失函数： 0.0642026\n",
      "时间步 2427000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.224768e+01/ 轮得分 177.80\n",
      "损失函数： 0.0465684\n",
      "时间步 2428000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.258852e+01/ 轮得分 178.13\n",
      "损失函数： 0.0390613\n",
      "时间步 2429000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.033568e+01/ 轮得分 178.09\n",
      "损失函数： 0.0197043\n",
      "时间步 2430000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.230624e+01/ 轮得分 178.09\n",
      "损失函数： 0.0439994\n",
      "时间步 2431000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.351351e+01/ 轮得分 178.09\n",
      "损失函数： 0.0115245\n",
      "时间步 2432000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.445283e+01/ 轮得分 178.09\n",
      "损失函数： 0.0300515\n",
      "时间步 2433000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.315589e+01/ 轮得分 178.09\n",
      "损失函数： 0.0636072\n",
      "时间步 2434000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.265460e+01/ 轮得分 178.09\n",
      "损失函数： 0.0389308\n",
      "时间步 2435000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.244798e+01/ 轮得分 178.09\n",
      "损失函数： 0.0203016\n",
      "时间步 2436000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.428652e+01/ 轮得分 178.73\n",
      "损失函数： 0.0405427\n",
      "时间步 2437000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.381424e+01/ 轮得分 178.73\n",
      "损失函数： 0.022964\n",
      "时间步 2438000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.313331e+01/ 轮得分 178.88\n",
      "损失函数： 0.0161591\n",
      "时间步 2439000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.524287e+01/ 轮得分 178.88\n",
      "损失函数： 0.0480415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2440000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.128150e+01/ 轮得分 178.88\n",
      "损失函数： 0.0236288\n",
      "时间步 2441000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.289122e+01/ 轮得分 178.88\n",
      "损失函数： 0.0360464\n",
      "时间步 2442000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 1.1/ Q_MAX 1.438115e+01/ 轮得分 178.88\n",
      "损失函数： 0.0292495\n",
      "时间步 2443000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.344465e+01/ 轮得分 178.88\n",
      "损失函数： 0.0402132\n",
      "时间步 2444000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.347677e+01/ 轮得分 178.88\n",
      "损失函数： 0.0295222\n",
      "时间步 2445000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.358548e+01/ 轮得分 178.88\n",
      "损失函数： 0.0520438\n",
      "时间步 2446000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.206822e+01/ 轮得分 179.89\n",
      "损失函数： 0.0305528\n",
      "时间步 2447000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.420592e+01/ 轮得分 179.41\n",
      "损失函数： 0.0283864\n",
      "时间步 2448000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.409800e+01/ 轮得分 179.41\n",
      "损失函数： 0.0315901\n",
      "时间步 2449000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.237486e+01/ 轮得分 179.49\n",
      "损失函数： 0.0479384\n",
      "时间步 2450000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.467249e+01/ 轮得分 179.49\n",
      "损失函数： 0.027744\n",
      "时间步 2451000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.361118e+01/ 轮得分 179.49\n",
      "损失函数： 0.0202254\n",
      "时间步 2452000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.333365e+01/ 轮得分 179.82\n",
      "损失函数： 0.0429417\n",
      "时间步 2453000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.499531e+01/ 轮得分 179.82\n",
      "损失函数： 0.0336194\n",
      "时间步 2454000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.264730e+01/ 轮得分 179.82\n",
      "损失函数： 0.0787293\n",
      "时间步 2455000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.283163e+01/ 轮得分 180.10\n",
      "损失函数： 0.131503\n",
      "时间步 2456000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.251345e+01/ 轮得分 180.13\n",
      "损失函数： 0.0209113\n",
      "时间步 2457000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.322816e+01/ 轮得分 179.99\n",
      "损失函数： 0.11907\n",
      "时间步 2458000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.373384e+01/ 轮得分 179.99\n",
      "损失函数： 0.0415216\n",
      "时间步 2459000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 1.1/ Q_MAX 1.422321e+01/ 轮得分 180.18\n",
      "损失函数： 0.0307517\n",
      "时间步 2460000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.325022e+01/ 轮得分 180.18\n",
      "损失函数： 0.0381894\n",
      "时间步 2461000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.351101e+01/ 轮得分 180.18\n",
      "损失函数： 0.0464892\n",
      "时间步 2462000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.400864e+01/ 轮得分 180.18\n",
      "损失函数： 0.0923048\n",
      "时间步 2463000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.260823e+01/ 轮得分 180.55\n",
      "损失函数： 0.0610199\n",
      "时间步 2464000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.282678e+01/ 轮得分 180.47\n",
      "损失函数： 0.0359316\n",
      "时间步 2465000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.160768e+01/ 轮得分 180.55\n",
      "损失函数： 0.0415023\n",
      "时间步 2466000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.200522e+01/ 轮得分 180.55\n",
      "损失函数： 0.0317456\n",
      "时间步 2467000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.073393e+01/ 轮得分 180.64\n",
      "损失函数： 0.0389157\n",
      "时间步 2468000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.339324e+01/ 轮得分 180.65\n",
      "损失函数： 0.0441334\n",
      "时间步 2469000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.301322e+01/ 轮得分 180.76\n",
      "损失函数： 0.106066\n",
      "时间步 2470000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.138077e+01/ 轮得分 180.76\n",
      "损失函数： 0.0164369\n",
      "时间步 2471000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.374745e+01/ 轮得分 180.76\n",
      "损失函数： 0.0291223\n",
      "时间步 2472000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.283675e+01/ 轮得分 180.76\n",
      "损失函数： 0.052013\n",
      "时间步 2473000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.406493e+01/ 轮得分 181.12\n",
      "损失函数： 0.0666765\n",
      "时间步 2474000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.114953e+01/ 轮得分 181.25\n",
      "损失函数： 0.0598196\n",
      "时间步 2475000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.382353e+01/ 轮得分 181.33\n",
      "损失函数： 0.0432667\n",
      "时间步 2476000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.149416e+01/ 轮得分 181.34\n",
      "损失函数： 0.0202089\n",
      "时间步 2477000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.231882e+01/ 轮得分 180.88\n",
      "损失函数： 0.0251034\n",
      "时间步 2478000/ 状态 explore/ Epsilon 0.04/ 行动 2/ 奖励 0.1/ Q_MAX 1.247029e+01/ 轮得分 180.77\n",
      "损失函数： 0.054372\n",
      "时间步 2479000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.292344e+01/ 轮得分 180.77\n",
      "损失函数： 0.0708435\n",
      "时间步 2480000/ 状态 explore/ Epsilon 0.04/ 行动 0/ 奖励 0.1/ Q_MAX 1.241126e+01/ 轮得分 180.77\n",
      "损失函数： 1.51923\n",
      "时间步 2481000/ 状态 explore/ Epsilon 0.04/ 行动 1/ 奖励 0.1/ Q_MAX 1.262480e+01/ 轮得分 180.77\n",
      "损失函数： 0.0584425\n",
      "时间步 2482000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.399959e+01/ 轮得分 181.20\n",
      "损失函数： 0.0712429\n",
      "时间步 2483000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.052767e+01/ 轮得分 181.13\n",
      "损失函数： 0.08572\n",
      "时间步 2484000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.266187e+01/ 轮得分 181.13\n",
      "损失函数： 0.0783367\n",
      "时间步 2485000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.230048e+01/ 轮得分 181.13\n",
      "损失函数： 0.0707693\n",
      "时间步 2486000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.242040e+01/ 轮得分 181.13\n",
      "损失函数： 0.134795\n",
      "时间步 2487000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.408287e+01/ 轮得分 181.63\n",
      "损失函数： 0.0501273\n",
      "时间步 2488000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.263658e+01/ 轮得分 181.63\n",
      "损失函数： 0.0206053\n",
      "时间步 2489000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.345348e+01/ 轮得分 181.63\n",
      "损失函数： 0.0444904\n",
      "时间步 2490000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.418106e+01/ 轮得分 181.63\n",
      "损失函数： 0.145039\n",
      "时间步 2491000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.351206e+01/ 轮得分 182.00\n",
      "损失函数： 1.94369\n",
      "时间步 2492000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.156607e+01/ 轮得分 182.00\n",
      "损失函数： 0.125425\n",
      "时间步 2493000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.186773e+01/ 轮得分 182.25\n",
      "损失函数： 0.0581217\n",
      "时间步 2494000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.493225e+01/ 轮得分 182.25\n",
      "损失函数： 0.0382502\n",
      "时间步 2495000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.552187e+01/ 轮得分 182.27\n",
      "损失函数： 0.0674777\n",
      "时间步 2496000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.191198e+01/ 轮得分 182.27\n",
      "损失函数： 0.0512367\n",
      "时间步 2497000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.237212e+01/ 轮得分 182.27\n",
      "损失函数： 0.0481742\n",
      "时间步 2498000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.604066e+01/ 轮得分 182.27\n",
      "损失函数： 0.0178525\n",
      "时间步 2499000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.303851e+01/ 轮得分 182.75\n",
      "损失函数： 0.0408111\n",
      "时间步 2500000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.229751e+01/ 轮得分 182.75\n",
      "损失函数： 0.0439263\n",
      "时间步 2501000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.404406e+01/ 轮得分 182.75\n",
      "损失函数： 0.0591879\n",
      "时间步 2502000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.274961e+01/ 轮得分 182.75\n",
      "损失函数： 0.0417444\n",
      "时间步 2503000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.214874e+01/ 轮得分 183.15\n",
      "损失函数： 0.0562376\n",
      "时间步 2504000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.117048e+01/ 轮得分 183.15\n",
      "损失函数： 0.0356724\n",
      "时间步 2505000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.267232e+01/ 轮得分 183.15\n",
      "损失函数： 0.0287075\n",
      "时间步 2506000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.248252e+01/ 轮得分 183.15\n",
      "损失函数： 0.0499806\n",
      "时间步 2507000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.387389e+01/ 轮得分 183.15\n",
      "损失函数： 0.0556486\n",
      "时间步 2508000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.238914e+01/ 轮得分 183.68\n",
      "损失函数： 0.0360193\n",
      "时间步 2509000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.313732e+01/ 轮得分 183.81\n",
      "损失函数： 0.0233606\n",
      "时间步 2510000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.367996e+01/ 轮得分 183.81\n",
      "损失函数： 0.0658696\n",
      "时间步 2511000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.273472e+01/ 轮得分 183.81\n",
      "损失函数： 0.0656584\n",
      "时间步 2512000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.338475e+01/ 轮得分 183.81\n",
      "损失函数： 0.108837\n",
      "时间步 2513000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.348785e+01/ 轮得分 183.81\n",
      "损失函数： 0.101234\n",
      "时间步 2514000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.321826e+01/ 轮得分 184.35\n",
      "损失函数： 0.0413303\n",
      "时间步 2515000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.265221e+01/ 轮得分 184.46\n",
      "损失函数： 0.0694453\n",
      "时间步 2516000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.365243e+01/ 轮得分 184.46\n",
      "损失函数： 0.0742307\n",
      "时间步 2517000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.413614e+01/ 轮得分 184.46\n",
      "损失函数： 0.030093\n",
      "时间步 2518000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.335097e+01/ 轮得分 184.46\n",
      "损失函数： 0.0428734\n",
      "时间步 2519000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.187235e+01/ 轮得分 184.71\n",
      "损失函数： 0.0262043\n",
      "时间步 2520000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.245340e+01/ 轮得分 184.71\n",
      "损失函数： 0.042399\n",
      "时间步 2521000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.222576e+01/ 轮得分 184.93\n",
      "损失函数： 0.0784801\n",
      "时间步 2522000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.282131e+01/ 轮得分 184.81\n",
      "损失函数： 0.0350438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2523000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.278840e+01/ 轮得分 184.81\n",
      "损失函数： 0.0529141\n",
      "时间步 2524000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.391157e+01/ 轮得分 184.81\n",
      "损失函数： 0.0222389\n",
      "时间步 2525000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.146894e+01/ 轮得分 184.58\n",
      "损失函数： 0.0334767\n",
      "时间步 2526000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.173913e+01/ 轮得分 184.70\n",
      "损失函数： 0.0939451\n",
      "时间步 2527000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.316395e+01/ 轮得分 184.70\n",
      "损失函数： 0.034918\n",
      "时间步 2528000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.491153e+01/ 轮得分 184.70\n",
      "损失函数： 0.0437926\n",
      "时间步 2529000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.248080e+01/ 轮得分 184.70\n",
      "损失函数： 0.158528\n",
      "时间步 2530000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.255747e+01/ 轮得分 184.89\n",
      "损失函数： 0.0357487\n",
      "时间步 2531000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 9.559653e+00/ 轮得分 184.89\n",
      "损失函数： 0.071975\n",
      "时间步 2532000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.434319e+01/ 轮得分 185.09\n",
      "损失函数： 0.0403191\n",
      "时间步 2533000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.430841e+01/ 轮得分 185.09\n",
      "损失函数： 0.0723738\n",
      "时间步 2534000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.194335e+01/ 轮得分 185.09\n",
      "损失函数： 0.0592759\n",
      "时间步 2535000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.250881e+01/ 轮得分 185.43\n",
      "损失函数： 0.0235921\n",
      "时间步 2536000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.357866e+01/ 轮得分 185.26\n",
      "损失函数： 0.526917\n",
      "时间步 2537000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 9.943540e+00/ 轮得分 185.26\n",
      "损失函数： 0.0194185\n",
      "时间步 2538000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.174484e+01/ 轮得分 185.26\n",
      "损失函数： 0.0385751\n",
      "时间步 2539000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.503873e+01/ 轮得分 185.26\n",
      "损失函数： 0.0104649\n",
      "时间步 2540000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.435985e+01/ 轮得分 185.26\n",
      "损失函数： 0.0676135\n",
      "时间步 2541000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.371737e+01/ 轮得分 185.83\n",
      "损失函数： 0.0430426\n",
      "时间步 2542000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.206180e+01/ 轮得分 185.83\n",
      "损失函数： 0.102474\n",
      "时间步 2543000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.146073e+01/ 轮得分 185.83\n",
      "损失函数： 0.0358705\n",
      "时间步 2544000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.148351e+01/ 轮得分 186.07\n",
      "损失函数： 0.0362562\n",
      "时间步 2545000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.120818e+01/ 轮得分 186.07\n",
      "损失函数： 0.0296507\n",
      "时间步 2546000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.295040e+01/ 轮得分 186.07\n",
      "损失函数： 0.0168687\n",
      "时间步 2547000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.208337e+01/ 轮得分 186.07\n",
      "损失函数： 0.0249336\n",
      "时间步 2548000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.011687e+01/ 轮得分 186.07\n",
      "损失函数： 0.0420798\n",
      "时间步 2549000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.183430e+01/ 轮得分 186.58\n",
      "损失函数： 0.0173977\n",
      "时间步 2550000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.236686e+01/ 轮得分 186.58\n",
      "损失函数： 0.0341729\n",
      "时间步 2551000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.355595e+01/ 轮得分 186.73\n",
      "损失函数： 0.0312552\n",
      "时间步 2552000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.212706e+01/ 轮得分 186.73\n",
      "损失函数： 0.0239519\n",
      "时间步 2553000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.333732e+01/ 轮得分 186.73\n",
      "损失函数： 0.0442945\n",
      "时间步 2554000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.366217e+01/ 轮得分 186.73\n",
      "损失函数： 0.0272732\n",
      "时间步 2555000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.155632e+01/ 轮得分 187.08\n",
      "损失函数： 0.0318388\n",
      "时间步 2556000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.181359e+01/ 轮得分 187.13\n",
      "损失函数： 0.0179734\n",
      "时间步 2557000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.167360e+01/ 轮得分 187.10\n",
      "损失函数： 0.0225097\n",
      "时间步 2558000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.445006e+01/ 轮得分 187.10\n",
      "损失函数： 0.0522178\n",
      "时间步 2559000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.460336e+01/ 轮得分 187.10\n",
      "损失函数： 0.7391\n",
      "时间步 2560000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.382651e+01/ 轮得分 187.17\n",
      "损失函数： 0.0194592\n",
      "时间步 2561000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.432351e+01/ 轮得分 187.20\n",
      "损失函数： 0.0242722\n",
      "时间步 2562000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.300924e+01/ 轮得分 187.20\n",
      "损失函数： 0.0525569\n",
      "时间步 2563000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.254416e+01/ 轮得分 187.11\n",
      "损失函数： 0.0439628\n",
      "时间步 2564000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.292834e+01/ 轮得分 187.11\n",
      "损失函数： 0.0523053\n",
      "时间步 2565000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.200878e+01/ 轮得分 187.11\n",
      "损失函数： 0.0489598\n",
      "时间步 2566000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.238954e+01/ 轮得分 187.11\n",
      "损失函数： 0.017972\n",
      "时间步 2567000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.028628e+01/ 轮得分 187.11\n",
      "损失函数： 0.0329597\n",
      "时间步 2568000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.550473e+01/ 轮得分 187.65\n",
      "损失函数： 0.0663185\n",
      "时间步 2569000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.289715e+01/ 轮得分 187.65\n",
      "损失函数： 0.075309\n",
      "时间步 2570000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.429115e+01/ 轮得分 187.27\n",
      "损失函数： 0.0275117\n",
      "时间步 2571000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 9.573451e+00/ 轮得分 187.32\n",
      "损失函数： 0.0521513\n",
      "时间步 2572000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.462970e+01/ 轮得分 187.32\n",
      "损失函数： 0.0586955\n",
      "时间步 2573000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.244756e+01/ 轮得分 187.60\n",
      "损失函数： 0.0589294\n",
      "时间步 2574000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.464084e+01/ 轮得分 187.60\n",
      "损失函数： 0.0457489\n",
      "时间步 2575000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.296337e+01/ 轮得分 187.60\n",
      "损失函数： 0.0646199\n",
      "时间步 2576000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 9.235795e+00/ 轮得分 187.70\n",
      "损失函数： 0.0304833\n",
      "时间步 2577000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.376518e+01/ 轮得分 187.70\n",
      "损失函数： 0.0346279\n",
      "时间步 2578000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.521284e+01/ 轮得分 187.89\n",
      "损失函数： 0.0413268\n",
      "时间步 2579000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.239692e+01/ 轮得分 187.89\n",
      "损失函数： 0.0453176\n",
      "时间步 2580000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.645181e+01/ 轮得分 187.89\n",
      "损失函数： 0.0561748\n",
      "时间步 2581000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.424532e+01/ 轮得分 187.89\n",
      "损失函数： 0.0251121\n",
      "时间步 2582000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.333225e+01/ 轮得分 187.89\n",
      "损失函数： 0.0452037\n",
      "时间步 2583000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.180169e+01/ 轮得分 187.89\n",
      "损失函数： 0.0414715\n",
      "时间步 2584000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.558949e+01/ 轮得分 188.55\n",
      "损失函数： 0.0634219\n",
      "时间步 2585000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.206353e+01/ 轮得分 188.55\n",
      "损失函数： 0.0230982\n",
      "时间步 2586000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.471319e+01/ 轮得分 188.55\n",
      "损失函数： 0.0656059\n",
      "时间步 2587000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.237405e+01/ 轮得分 188.55\n",
      "损失函数： 0.0443413\n",
      "时间步 2588000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.176087e+01/ 轮得分 188.88\n",
      "损失函数： 0.287101\n",
      "时间步 2589000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.290866e+01/ 轮得分 188.88\n",
      "损失函数： 0.1161\n",
      "时间步 2590000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.271658e+01/ 轮得分 188.88\n",
      "损失函数： 0.0221\n",
      "时间步 2591000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.184082e+01/ 轮得分 189.06\n",
      "损失函数： 0.0420477\n",
      "时间步 2592000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.213463e+01/ 轮得分 189.06\n",
      "损失函数： 0.0396016\n",
      "时间步 2593000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.360346e+01/ 轮得分 189.06\n",
      "损失函数： 0.0659614\n",
      "时间步 2594000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.075447e+01/ 轮得分 189.06\n",
      "损失函数： 0.0398228\n",
      "时间步 2595000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.200953e+01/ 轮得分 189.06\n",
      "损失函数： 0.0384253\n",
      "时间步 2596000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.359766e+01/ 轮得分 189.06\n",
      "损失函数： 0.0678671\n",
      "时间步 2597000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.329333e+01/ 轮得分 189.06\n",
      "损失函数： 0.0428114\n",
      "时间步 2598000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.199152e+01/ 轮得分 189.06\n",
      "损失函数： 0.0699001\n",
      "时间步 2599000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.328702e+01/ 轮得分 189.06\n",
      "损失函数： 0.0326976\n",
      "时间步 2600000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.200616e+01/ 轮得分 190.03\n",
      "损失函数： 0.02278\n",
      "时间步 2601000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.411423e+01/ 轮得分 190.03\n",
      "损失函数： 0.0282747\n",
      "时间步 2602000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.309635e+01/ 轮得分 189.72\n",
      "损失函数： 0.0492195\n",
      "时间步 2603000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.560310e+01/ 轮得分 189.72\n",
      "损失函数： 0.0370256\n",
      "时间步 2604000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 3.811461e+00/ 轮得分 189.72\n",
      "损失函数： 0.0326055\n",
      "时间步 2605000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.488488e+01/ 轮得分 189.83\n",
      "损失函数： 0.0402134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2606000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.554414e+01/ 轮得分 189.83\n",
      "损失函数： 0.0197578\n",
      "时间步 2607000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.422494e+01/ 轮得分 189.83\n",
      "损失函数： 0.0159027\n",
      "时间步 2608000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 1.1/ Q_MAX 1.472761e+01/ 轮得分 189.83\n",
      "损失函数： 0.0140514\n",
      "时间步 2609000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.284346e+01/ 轮得分 190.04\n",
      "损失函数： 0.0622567\n",
      "时间步 2610000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.416669e+01/ 轮得分 190.04\n",
      "损失函数： 0.0401507\n",
      "时间步 2611000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.199172e+01/ 轮得分 189.94\n",
      "损失函数： 0.0220727\n",
      "时间步 2612000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.411146e+01/ 轮得分 189.94\n",
      "损失函数： 0.0184176\n",
      "时间步 2613000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.447860e+01/ 轮得分 189.94\n",
      "损失函数： 0.035617\n",
      "时间步 2614000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.453986e+01/ 轮得分 190.18\n",
      "损失函数： 0.0222347\n",
      "时间步 2615000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.356616e+01/ 轮得分 190.18\n",
      "损失函数： 0.0462658\n",
      "时间步 2616000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.309006e+01/ 轮得分 190.48\n",
      "损失函数： 0.0539782\n",
      "时间步 2617000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.510074e+01/ 轮得分 190.48\n",
      "损失函数： 0.0286412\n",
      "时间步 2618000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.371772e+01/ 轮得分 190.56\n",
      "损失函数： 0.0290571\n",
      "时间步 2619000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.229827e+01/ 轮得分 190.56\n",
      "损失函数： 0.0271213\n",
      "时间步 2620000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.288870e+01/ 轮得分 190.56\n",
      "损失函数： 0.052514\n",
      "时间步 2621000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.381418e+01/ 轮得分 190.79\n",
      "损失函数： 0.0286694\n",
      "时间步 2622000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.444443e+01/ 轮得分 190.79\n",
      "损失函数： 0.0457369\n",
      "时间步 2623000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.208565e+01/ 轮得分 190.79\n",
      "损失函数： 0.0935127\n",
      "时间步 2624000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.302639e+01/ 轮得分 191.04\n",
      "损失函数： 0.0228542\n",
      "时间步 2625000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.336657e+01/ 轮得分 191.04\n",
      "损失函数： 0.0383355\n",
      "时间步 2626000/ 状态 explore/ Epsilon 0.03/ 行动 1/ 奖励 0.1/ Q_MAX 1.401050e+01/ 轮得分 191.04\n",
      "损失函数： 0.0275677\n",
      "时间步 2627000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.337882e+01/ 轮得分 191.04\n",
      "损失函数： 0.0775034\n",
      "时间步 2628000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.216574e+01/ 轮得分 191.32\n",
      "损失函数： 0.0440521\n",
      "时间步 2629000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.223250e+01/ 轮得分 191.32\n",
      "损失函数： 0.0280509\n",
      "时间步 2630000/ 状态 explore/ Epsilon 0.03/ 行动 2/ 奖励 0.1/ Q_MAX 1.251704e+01/ 轮得分 191.43\n",
      "损失函数： 0.0592729\n",
      "时间步 2631000/ 状态 explore/ Epsilon 0.03/ 行动 0/ 奖励 0.1/ Q_MAX 1.387667e+01/ 轮得分 191.43\n",
      "损失函数： 0.040227\n",
      "时间步 2632000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.466339e+01/ 轮得分 191.40\n",
      "损失函数： 0.0710312\n",
      "时间步 2633000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.198518e+01/ 轮得分 191.46\n",
      "损失函数： 0.0720429\n",
      "时间步 2634000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.351518e+01/ 轮得分 191.46\n",
      "损失函数： 0.0238397\n",
      "时间步 2635000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 1.1/ Q_MAX 1.419780e+01/ 轮得分 191.46\n",
      "损失函数： 0.0585584\n",
      "时间步 2636000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.214269e+01/ 轮得分 191.46\n",
      "损失函数： 0.0393965\n",
      "时间步 2637000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.392237e+01/ 轮得分 191.46\n",
      "损失函数： 0.0334021\n",
      "时间步 2638000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.236885e+01/ 轮得分 192.03\n",
      "损失函数： 0.0256301\n",
      "时间步 2639000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.232407e+01/ 轮得分 192.03\n",
      "损失函数： 0.0629217\n",
      "时间步 2640000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.188786e+01/ 轮得分 192.05\n",
      "损失函数： 0.565875\n",
      "时间步 2641000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.256351e+01/ 轮得分 192.04\n",
      "损失函数： 0.0776908\n",
      "时间步 2642000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.142857e+01/ 轮得分 192.04\n",
      "损失函数： 0.0469521\n",
      "时间步 2643000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.390628e+01/ 轮得分 191.92\n",
      "损失函数： 0.0670786\n",
      "时间步 2644000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.329734e+01/ 轮得分 191.82\n",
      "损失函数： 0.0656302\n",
      "时间步 2645000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.280846e+01/ 轮得分 191.73\n",
      "损失函数： 0.0311871\n",
      "时间步 2646000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.369413e+01/ 轮得分 191.73\n",
      "损失函数： 0.123346\n",
      "时间步 2647000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 8.447293e+00/ 轮得分 191.73\n",
      "损失函数： 0.0654456\n",
      "时间步 2648000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.111458e+01/ 轮得分 191.99\n",
      "损失函数： 0.020944\n",
      "时间步 2649000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.172494e+01/ 轮得分 191.99\n",
      "损失函数： 0.0245731\n",
      "时间步 2650000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.375067e+01/ 轮得分 191.99\n",
      "损失函数： 0.037708\n",
      "时间步 2651000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.170443e+01/ 轮得分 191.99\n",
      "损失函数： 0.0592251\n",
      "时间步 2652000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.310420e+01/ 轮得分 191.99\n",
      "损失函数： 0.141069\n",
      "时间步 2653000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.149200e+01/ 轮得分 192.59\n",
      "损失函数： 0.0499455\n",
      "时间步 2654000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.010299e+01/ 轮得分 192.59\n",
      "损失函数： 0.0573414\n",
      "时间步 2655000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.256236e+01/ 轮得分 192.85\n",
      "损失函数： 0.0509888\n",
      "时间步 2656000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.379562e+01/ 轮得分 192.85\n",
      "损失函数： 0.202627\n",
      "时间步 2657000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.291246e+01/ 轮得分 193.01\n",
      "损失函数： 0.063549\n",
      "时间步 2658000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.223047e+01/ 轮得分 193.01\n",
      "损失函数： 0.0698526\n",
      "时间步 2659000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.251960e+01/ 轮得分 193.13\n",
      "损失函数： 0.0583739\n",
      "时间步 2660000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.231546e+01/ 轮得分 193.13\n",
      "损失函数： 0.0154139\n",
      "时间步 2661000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.302230e+01/ 轮得分 193.13\n",
      "损失函数： 0.0787851\n",
      "时间步 2662000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.418341e+01/ 轮得分 193.13\n",
      "损失函数： 0.0273281\n",
      "时间步 2663000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.393348e+01/ 轮得分 193.13\n",
      "损失函数： 0.0842052\n",
      "时间步 2664000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.157269e+01/ 轮得分 193.65\n",
      "损失函数： 0.0313509\n",
      "时间步 2665000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.415588e+01/ 轮得分 193.65\n",
      "损失函数： 0.104535\n",
      "时间步 2666000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.400371e+01/ 轮得分 193.79\n",
      "损失函数： 0.0189656\n",
      "时间步 2667000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.270655e+01/ 轮得分 193.79\n",
      "损失函数： 0.07301\n",
      "时间步 2668000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.220055e+01/ 轮得分 193.79\n",
      "损失函数： 0.0213892\n",
      "时间步 2669000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.239138e+01/ 轮得分 193.99\n",
      "损失函数： 0.0382372\n",
      "时间步 2670000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.355795e+01/ 轮得分 194.03\n",
      "损失函数： 0.0432487\n",
      "时间步 2671000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.297375e+01/ 轮得分 194.03\n",
      "损失函数： 0.0427001\n",
      "时间步 2672000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.482189e+01/ 轮得分 194.03\n",
      "损失函数： 0.0222543\n",
      "时间步 2673000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.332501e+01/ 轮得分 194.03\n",
      "损失函数： 0.101288\n",
      "时间步 2674000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.219568e+01/ 轮得分 194.03\n",
      "损失函数： 0.0500532\n",
      "时间步 2675000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.507882e+01/ 轮得分 194.03\n",
      "损失函数： 0.0497953\n",
      "时间步 2676000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.217022e+01/ 轮得分 194.03\n",
      "损失函数： 0.0269804\n",
      "时间步 2677000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.360807e+01/ 轮得分 194.73\n",
      "损失函数： 0.0382208\n",
      "时间步 2678000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.127962e+01/ 轮得分 194.75\n",
      "损失函数： 0.0336723\n",
      "时间步 2679000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.437449e+01/ 轮得分 194.75\n",
      "损失函数： 0.0445264\n",
      "时间步 2680000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.276838e+01/ 轮得分 194.75\n",
      "损失函数： 0.0789277\n",
      "时间步 2681000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.309361e+01/ 轮得分 194.75\n",
      "损失函数： 0.0699732\n",
      "时间步 2682000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.222336e+01/ 轮得分 195.15\n",
      "损失函数： 0.0178971\n",
      "时间步 2683000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.331683e+01/ 轮得分 195.15\n",
      "损失函数： 0.0475723\n",
      "时间步 2684000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.098636e+01/ 轮得分 195.15\n",
      "损失函数： 0.0160527\n",
      "时间步 2685000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.304091e+01/ 轮得分 195.15\n",
      "损失函数： 0.0266394\n",
      "时间步 2686000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 9.380637e+00/ 轮得分 195.15\n",
      "损失函数： 0.0329446\n",
      "时间步 2687000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.453884e+01/ 轮得分 195.15\n",
      "损失函数： 0.0532735\n",
      "时间步 2688000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.292447e+01/ 轮得分 195.83\n",
      "损失函数： 0.0458163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2689000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.202365e+01/ 轮得分 195.83\n",
      "损失函数： 0.0133146\n",
      "时间步 2690000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.347569e+01/ 轮得分 195.83\n",
      "损失函数： 0.0698573\n",
      "时间步 2691000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.096673e+01/ 轮得分 196.11\n",
      "损失函数： 0.0655409\n",
      "时间步 2692000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.187008e+01/ 轮得分 195.81\n",
      "损失函数： 0.0287237\n",
      "时间步 2693000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.283877e+01/ 轮得分 195.81\n",
      "损失函数： 0.0386301\n",
      "时间步 2694000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.510884e+01/ 轮得分 195.81\n",
      "损失函数： 0.0464167\n",
      "时间步 2695000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.202860e+01/ 轮得分 195.81\n",
      "损失函数： 0.0397496\n",
      "时间步 2696000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.127129e+01/ 轮得分 196.00\n",
      "损失函数： 0.0542789\n",
      "时间步 2697000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.336119e+01/ 轮得分 196.00\n",
      "损失函数： 0.0862802\n",
      "时间步 2698000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.190124e+01/ 轮得分 196.00\n",
      "损失函数： 0.055672\n",
      "时间步 2699000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.599954e+01/ 轮得分 196.05\n",
      "损失函数： 0.034647\n",
      "时间步 2700000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.162871e+01/ 轮得分 196.05\n",
      "损失函数： 0.0279337\n",
      "时间步 2701000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.481552e+01/ 轮得分 196.05\n",
      "损失函数： 0.0491725\n",
      "时间步 2702000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.384878e+01/ 轮得分 196.14\n",
      "损失函数： 0.0769508\n",
      "时间步 2703000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.239942e+01/ 轮得分 196.14\n",
      "损失函数： 0.0722619\n",
      "时间步 2704000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.427340e+01/ 轮得分 196.14\n",
      "损失函数： 0.029431\n",
      "时间步 2705000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.358938e+01/ 轮得分 196.14\n",
      "损失函数： 0.0499672\n",
      "时间步 2706000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.252090e+01/ 轮得分 196.48\n",
      "损失函数： 0.0319161\n",
      "时间步 2707000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.265474e+01/ 轮得分 196.48\n",
      "损失函数： 0.0715562\n",
      "时间步 2708000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.451851e+01/ 轮得分 196.48\n",
      "损失函数： 0.0678143\n",
      "时间步 2709000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.416928e+01/ 轮得分 196.71\n",
      "损失函数： 0.0170945\n",
      "时间步 2710000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.337267e+01/ 轮得分 196.75\n",
      "损失函数： 0.0379033\n",
      "时间步 2711000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.285415e+01/ 轮得分 196.75\n",
      "损失函数： 0.0294118\n",
      "时间步 2712000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.364469e+01/ 轮得分 196.75\n",
      "损失函数： 0.0525536\n",
      "时间步 2713000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.168380e+01/ 轮得分 196.80\n",
      "损失函数： 0.0237901\n",
      "时间步 2714000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.190853e+01/ 轮得分 196.75\n",
      "损失函数： 0.0562008\n",
      "时间步 2715000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.327713e+01/ 轮得分 196.51\n",
      "损失函数： 0.0782168\n",
      "时间步 2716000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.409686e+01/ 轮得分 196.51\n",
      "损失函数： 0.0484908\n",
      "时间步 2717000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.241963e+01/ 轮得分 196.51\n",
      "损失函数： 0.0269562\n",
      "时间步 2718000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.342937e+01/ 轮得分 196.95\n",
      "损失函数： 0.0279299\n",
      "时间步 2719000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.177743e+01/ 轮得分 196.74\n",
      "损失函数： 0.0321559\n",
      "时间步 2720000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.508817e+01/ 轮得分 196.74\n",
      "损失函数： 0.0476786\n",
      "时间步 2721000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.257981e+01/ 轮得分 196.74\n",
      "损失函数： 0.0228576\n",
      "时间步 2722000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.309081e+01/ 轮得分 196.74\n",
      "损失函数： 0.0413769\n",
      "时间步 2723000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.273487e+01/ 轮得分 196.76\n",
      "损失函数： 0.0467416\n",
      "时间步 2724000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.312331e+01/ 轮得分 196.80\n",
      "损失函数： 0.0461464\n",
      "时间步 2725000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.443472e+01/ 轮得分 196.80\n",
      "损失函数： 0.0342093\n",
      "时间步 2726000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.398386e+01/ 轮得分 196.80\n",
      "损失函数： 0.0261629\n",
      "时间步 2727000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.251179e+01/ 轮得分 197.15\n",
      "损失函数： 0.0205547\n",
      "时间步 2728000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.251184e+01/ 轮得分 197.15\n",
      "损失函数： 0.186501\n",
      "时间步 2729000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.480999e+01/ 轮得分 197.15\n",
      "损失函数： 0.0285632\n",
      "时间步 2730000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.040515e+01/ 轮得分 197.27\n",
      "损失函数： 0.0333228\n",
      "时间步 2731000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.360039e+01/ 轮得分 196.96\n",
      "损失函数： 0.0179947\n",
      "时间步 2732000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.241582e+01/ 轮得分 196.96\n",
      "损失函数： 0.0365905\n",
      "时间步 2733000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.334150e+01/ 轮得分 196.96\n",
      "损失函数： 0.0741666\n",
      "时间步 2734000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.402882e+01/ 轮得分 196.96\n",
      "损失函数： 0.045415\n",
      "时间步 2735000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.288437e+01/ 轮得分 197.38\n",
      "损失函数： 0.0493683\n",
      "时间步 2736000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.382167e+01/ 轮得分 197.38\n",
      "损失函数： 0.170848\n",
      "时间步 2737000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.286584e+01/ 轮得分 197.38\n",
      "损失函数： 0.0337985\n",
      "时间步 2738000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.386603e+01/ 轮得分 197.38\n",
      "损失函数： 0.0372019\n",
      "时间步 2739000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.473562e+01/ 轮得分 197.38\n",
      "损失函数： 0.0655746\n",
      "时间步 2740000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.424210e+01/ 轮得分 197.38\n",
      "损失函数： 0.0293284\n",
      "时间步 2741000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.397993e+01/ 轮得分 198.03\n",
      "损失函数： 0.0359443\n",
      "时间步 2742000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.372330e+01/ 轮得分 198.03\n",
      "损失函数： 0.0366076\n",
      "时间步 2743000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.364540e+01/ 轮得分 198.03\n",
      "损失函数： 0.0335794\n",
      "时间步 2744000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.445021e+01/ 轮得分 198.03\n",
      "损失函数： 0.0472653\n",
      "时间步 2745000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.253247e+01/ 轮得分 198.03\n",
      "损失函数： 0.0701147\n",
      "时间步 2746000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.135098e+01/ 轮得分 198.60\n",
      "损失函数： 0.0529747\n",
      "时间步 2747000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.281409e+01/ 轮得分 198.58\n",
      "损失函数： 0.0974325\n",
      "时间步 2748000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.216662e+01/ 轮得分 198.73\n",
      "损失函数： 0.103077\n",
      "时间步 2749000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.369351e+01/ 轮得分 198.75\n",
      "损失函数： 0.0206799\n",
      "时间步 2750000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.480515e+01/ 轮得分 198.75\n",
      "损失函数： 0.0242066\n",
      "时间步 2751000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.374053e+01/ 轮得分 198.75\n",
      "损失函数： 0.0448028\n",
      "时间步 2752000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.353156e+01/ 轮得分 198.75\n",
      "损失函数： 0.0473802\n",
      "时间步 2753000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.421491e+01/ 轮得分 198.75\n",
      "损失函数： 0.0965169\n",
      "时间步 2754000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.541166e+01/ 轮得分 199.44\n",
      "损失函数： 0.109455\n",
      "时间步 2755000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.290658e+01/ 轮得分 199.44\n",
      "损失函数： 0.0575295\n",
      "时间步 2756000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.402854e+01/ 轮得分 199.44\n",
      "损失函数： 0.0352389\n",
      "时间步 2757000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.457310e+01/ 轮得分 199.44\n",
      "损失函数： 0.0432137\n",
      "时间步 2758000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.353280e+01/ 轮得分 199.44\n",
      "损失函数： 0.037356\n",
      "时间步 2759000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.575436e+01/ 轮得分 199.44\n",
      "损失函数： 0.0333236\n",
      "时间步 2760000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.413301e+01/ 轮得分 199.44\n",
      "损失函数： 0.0382991\n",
      "时间步 2761000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.508612e+01/ 轮得分 200.10\n",
      "损失函数： 0.0261364\n",
      "时间步 2762000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.332227e+01/ 轮得分 200.17\n",
      "损失函数： 0.0310725\n",
      "时间步 2763000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.393214e+01/ 轮得分 199.79\n",
      "损失函数： 0.0438386\n",
      "时间步 2764000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.422980e+01/ 轮得分 199.79\n",
      "损失函数： 0.0385343\n",
      "时间步 2765000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.445217e+01/ 轮得分 199.79\n",
      "损失函数： 0.0259936\n",
      "时间步 2766000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.163284e+01/ 轮得分 199.79\n",
      "损失函数： 0.0396927\n",
      "时间步 2767000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.472758e+01/ 轮得分 199.79\n",
      "损失函数： 0.0761564\n",
      "时间步 2768000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 9.356921e+00/ 轮得分 200.35\n",
      "损失函数： 0.0870987\n",
      "时间步 2769000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.359197e+01/ 轮得分 200.34\n",
      "损失函数： 0.0383766\n",
      "时间步 2770000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.578343e+01/ 轮得分 200.34\n",
      "损失函数： 0.0462919\n",
      "时间步 2771000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.393373e+01/ 轮得分 200.45\n",
      "损失函数： 0.0351744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2772000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.252944e+01/ 轮得分 200.40\n",
      "损失函数： 0.0517714\n",
      "时间步 2773000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.250777e+01/ 轮得分 200.41\n",
      "损失函数： 0.0371606\n",
      "时间步 2774000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 1.1/ Q_MAX 1.474187e+01/ 轮得分 200.41\n",
      "损失函数： 0.0670501\n",
      "时间步 2775000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.379781e+01/ 轮得分 200.41\n",
      "损失函数： 0.0517046\n",
      "时间步 2776000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 1.135363e+01/ 轮得分 200.41\n",
      "损失函数： 0.0379089\n",
      "时间步 2777000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 6.711117e+00/ 轮得分 200.41\n",
      "损失函数： 0.0194428\n",
      "时间步 2778000/ 状态 explore/ Epsilon 0.02/ 行动 2/ 奖励 0.1/ Q_MAX 8.179871e+00/ 轮得分 200.41\n",
      "损失函数： 0.0619632\n",
      "时间步 2779000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.530321e+01/ 轮得分 201.01\n",
      "损失函数： 0.0347617\n",
      "时间步 2780000/ 状态 explore/ Epsilon 0.02/ 行动 0/ 奖励 0.1/ Q_MAX 1.390390e+01/ 轮得分 201.05\n",
      "损失函数： 0.0207689\n",
      "时间步 2781000/ 状态 explore/ Epsilon 0.02/ 行动 1/ 奖励 0.1/ Q_MAX 1.222926e+01/ 轮得分 201.05\n",
      "损失函数： 0.0243949\n",
      "时间步 2782000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.111945e+01/ 轮得分 201.22\n",
      "损失函数： 0.0661513\n",
      "时间步 2783000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.398585e+01/ 轮得分 201.22\n",
      "损失函数： 0.0329899\n",
      "时间步 2784000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.365086e+01/ 轮得分 201.22\n",
      "损失函数： 0.0432309\n",
      "时间步 2785000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.224756e+01/ 轮得分 201.22\n",
      "损失函数： 0.0548518\n",
      "时间步 2786000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.173453e+01/ 轮得分 201.22\n",
      "损失函数： 0.0451804\n",
      "时间步 2787000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.099529e+01/ 轮得分 201.22\n",
      "损失函数： 0.12093\n",
      "时间步 2788000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.227531e+01/ 轮得分 201.22\n",
      "损失函数： 0.0788597\n",
      "时间步 2789000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.240231e+01/ 轮得分 202.10\n",
      "损失函数： 0.0544926\n",
      "时间步 2790000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.311045e+01/ 轮得分 202.10\n",
      "损失函数： 0.0262132\n",
      "时间步 2791000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.359048e+01/ 轮得分 202.10\n",
      "损失函数： 0.10806\n",
      "时间步 2792000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.482996e+01/ 轮得分 202.10\n",
      "损失函数： 0.0437646\n",
      "时间步 2793000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.470854e+01/ 轮得分 202.10\n",
      "损失函数： 0.0714404\n",
      "时间步 2794000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.255273e+01/ 轮得分 202.10\n",
      "损失函数： 0.0297013\n",
      "时间步 2795000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.347939e+01/ 轮得分 202.10\n",
      "损失函数： 0.0535361\n",
      "时间步 2796000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.416030e+01/ 轮得分 202.82\n",
      "损失函数： 0.0190752\n",
      "时间步 2797000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.150183e+01/ 轮得分 202.82\n",
      "损失函数： 0.0749538\n",
      "时间步 2798000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.290367e+01/ 轮得分 203.02\n",
      "损失函数： 0.0630425\n",
      "时间步 2799000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.304679e+01/ 轮得分 203.02\n",
      "损失函数： 0.0528353\n",
      "时间步 2800000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.313337e+01/ 轮得分 203.02\n",
      "损失函数： 0.0820099\n",
      "时间步 2801000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.196953e+01/ 轮得分 203.13\n",
      "损失函数： 0.0581167\n",
      "时间步 2802000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.185567e+01/ 轮得分 203.13\n",
      "损失函数： 0.0113211\n",
      "时间步 2803000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.444199e+01/ 轮得分 203.13\n",
      "损失函数： 0.0303084\n",
      "时间步 2804000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.343878e+01/ 轮得分 203.13\n",
      "损失函数： 0.0406782\n",
      "时间步 2805000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.352910e+01/ 轮得分 203.47\n",
      "损失函数： 0.0505341\n",
      "时间步 2806000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.454918e+01/ 轮得分 203.63\n",
      "损失函数： 0.0408182\n",
      "时间步 2807000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.149285e+01/ 轮得分 203.69\n",
      "损失函数： 0.0597307\n",
      "时间步 2808000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.226871e+01/ 轮得分 203.69\n",
      "损失函数： 0.0140582\n",
      "时间步 2809000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.460639e+01/ 轮得分 203.69\n",
      "损失函数： 0.022573\n",
      "时间步 2810000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.199957e+01/ 轮得分 203.69\n",
      "损失函数： 0.0348003\n",
      "时间步 2811000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.146154e+01/ 轮得分 204.11\n",
      "损失函数： 0.0388805\n",
      "时间步 2812000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.212461e+01/ 轮得分 204.11\n",
      "损失函数： 0.0847123\n",
      "时间步 2813000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.257125e+01/ 轮得分 204.11\n",
      "损失函数： 0.0348983\n",
      "时间步 2814000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.310829e+01/ 轮得分 204.29\n",
      "损失函数： 0.052602\n",
      "时间步 2815000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.156361e+01/ 轮得分 204.29\n",
      "损失函数： 0.0335711\n",
      "时间步 2816000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 9.406714e+00/ 轮得分 204.55\n",
      "损失函数： 0.0333099\n",
      "时间步 2817000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.353684e+01/ 轮得分 204.56\n",
      "损失函数： 0.032323\n",
      "时间步 2818000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.339176e+01/ 轮得分 204.56\n",
      "损失函数： 0.00942107\n",
      "时间步 2819000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.424178e+01/ 轮得分 204.56\n",
      "损失函数： 0.0647545\n",
      "时间步 2820000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.287724e+01/ 轮得分 204.56\n",
      "损失函数： 0.0237553\n",
      "时间步 2821000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.293913e+01/ 轮得分 204.56\n",
      "损失函数： 0.0140862\n",
      "时间步 2822000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.208673e+01/ 轮得分 204.56\n",
      "损失函数： 0.0548001\n",
      "时间步 2823000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.359352e+01/ 轮得分 204.56\n",
      "损失函数： 0.0228079\n",
      "时间步 2824000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.309878e+01/ 轮得分 204.56\n",
      "损失函数： 0.0523506\n",
      "时间步 2825000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.246274e+01/ 轮得分 204.56\n",
      "损失函数： 0.0306294\n",
      "时间步 2826000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.298766e+01/ 轮得分 205.49\n",
      "损失函数： 0.0670563\n",
      "时间步 2827000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.159006e+01/ 轮得分 205.49\n",
      "损失函数： 0.0486102\n",
      "时间步 2828000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.298002e+01/ 轮得分 205.80\n",
      "损失函数： 0.0200489\n",
      "时间步 2829000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.180402e+01/ 轮得分 205.80\n",
      "损失函数： 0.0859612\n",
      "时间步 2830000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.337878e+01/ 轮得分 205.92\n",
      "损失函数： 0.0333\n",
      "时间步 2831000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.186588e+01/ 轮得分 205.92\n",
      "损失函数： 0.0785712\n",
      "时间步 2832000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.441497e+01/ 轮得分 205.92\n",
      "损失函数： 0.0252449\n",
      "时间步 2833000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.350604e+01/ 轮得分 205.92\n",
      "损失函数： 0.0857898\n",
      "时间步 2834000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.233851e+01/ 轮得分 206.31\n",
      "损失函数： 0.0463942\n",
      "时间步 2835000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.446954e+01/ 轮得分 206.31\n",
      "损失函数： 0.0525775\n",
      "时间步 2836000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.372238e+01/ 轮得分 206.31\n",
      "损失函数： 0.0499409\n",
      "时间步 2837000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.498651e+01/ 轮得分 206.31\n",
      "损失函数： 0.0862227\n",
      "时间步 2838000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.447529e+01/ 轮得分 206.31\n",
      "损失函数： 0.0486901\n",
      "时间步 2839000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 1.1/ Q_MAX 1.183423e+01/ 轮得分 206.31\n",
      "损失函数： 0.0612599\n",
      "时间步 2840000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.488938e+01/ 轮得分 206.90\n",
      "损失函数： 0.0316183\n",
      "时间步 2841000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.343653e+01/ 轮得分 206.90\n",
      "损失函数： 0.055136\n",
      "时间步 2842000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.413054e+01/ 轮得分 206.90\n",
      "损失函数： 0.016999\n",
      "时间步 2843000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.344301e+01/ 轮得分 206.90\n",
      "损失函数： 0.0328003\n",
      "时间步 2844000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.287253e+01/ 轮得分 207.30\n",
      "损失函数： 0.103428\n",
      "时间步 2845000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.328127e+01/ 轮得分 207.30\n",
      "损失函数： 0.0341184\n",
      "时间步 2846000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.205094e+01/ 轮得分 207.38\n",
      "损失函数： 0.0414333\n",
      "时间步 2847000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.293929e+01/ 轮得分 207.38\n",
      "损失函数： 0.0229623\n",
      "时间步 2848000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.507058e+01/ 轮得分 207.38\n",
      "损失函数： 0.0371022\n",
      "时间步 2849000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.447271e+01/ 轮得分 207.72\n",
      "损失函数： 0.0402109\n",
      "时间步 2850000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.189243e+01/ 轮得分 207.72\n",
      "损失函数： 0.0562662\n",
      "时间步 2851000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.268427e+01/ 轮得分 207.72\n",
      "损失函数： 0.0379545\n",
      "时间步 2852000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.276411e+01/ 轮得分 208.03\n",
      "损失函数： 0.0487097\n",
      "时间步 2853000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.303548e+01/ 轮得分 208.03\n",
      "损失函数： 0.0240315\n",
      "时间步 2854000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.186509e+01/ 轮得分 208.13\n",
      "损失函数： 0.00870661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2855000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.356046e+01/ 轮得分 208.13\n",
      "损失函数： 0.0733161\n",
      "时间步 2856000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.379044e+01/ 轮得分 208.13\n",
      "损失函数： 0.0605468\n",
      "时间步 2857000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.179810e+01/ 轮得分 208.13\n",
      "损失函数： 0.0538567\n",
      "时间步 2858000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.260260e+01/ 轮得分 208.22\n",
      "损失函数： 0.0846724\n",
      "时间步 2859000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.251220e+01/ 轮得分 208.22\n",
      "损失函数： 0.0550281\n",
      "时间步 2860000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.317897e+01/ 轮得分 208.22\n",
      "损失函数： 0.0198065\n",
      "时间步 2861000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.394957e+01/ 轮得分 208.22\n",
      "损失函数： 0.0262328\n",
      "时间步 2862000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.465123e+01/ 轮得分 208.22\n",
      "损失函数： 0.0351908\n",
      "时间步 2863000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.402210e+01/ 轮得分 208.22\n",
      "损失函数： 0.0238366\n",
      "时间步 2864000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.381646e+01/ 轮得分 208.22\n",
      "损失函数： 0.0339972\n",
      "时间步 2865000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.266655e+01/ 轮得分 208.22\n",
      "损失函数： 0.0573229\n",
      "时间步 2866000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.214025e+01/ 轮得分 209.13\n",
      "损失函数： 0.0461739\n",
      "时间步 2867000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.229626e+01/ 轮得分 209.13\n",
      "损失函数： 0.0380559\n",
      "时间步 2868000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.114844e+01/ 轮得分 209.33\n",
      "损失函数： 0.0182643\n",
      "时间步 2869000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.351710e+01/ 轮得分 209.33\n",
      "损失函数： 0.0164261\n",
      "时间步 2870000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.440846e+01/ 轮得分 209.33\n",
      "损失函数： 0.0518408\n",
      "时间步 2871000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.352033e+01/ 轮得分 209.33\n",
      "损失函数： 0.032493\n",
      "时间步 2872000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.557049e+01/ 轮得分 209.33\n",
      "损失函数： 0.0247515\n",
      "时间步 2873000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.401997e+01/ 轮得分 209.96\n",
      "损失函数： 0.0221573\n",
      "时间步 2874000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.274376e+01/ 轮得分 209.88\n",
      "损失函数： 0.0514796\n",
      "时间步 2875000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.253146e+01/ 轮得分 209.88\n",
      "损失函数： 0.0263832\n",
      "时间步 2876000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.297931e+01/ 轮得分 209.88\n",
      "损失函数： 0.02985\n",
      "时间步 2877000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.241899e+01/ 轮得分 210.23\n",
      "损失函数： 0.0471154\n",
      "时间步 2878000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.434974e+01/ 轮得分 210.23\n",
      "损失函数： 0.058536\n",
      "时间步 2879000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.229034e+01/ 轮得分 210.23\n",
      "损失函数： 0.0648192\n",
      "时间步 2880000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 1.1/ Q_MAX 1.515512e+01/ 轮得分 210.23\n",
      "损失函数： 0.0125167\n",
      "时间步 2881000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.181600e+01/ 轮得分 210.60\n",
      "损失函数： 0.03873\n",
      "时间步 2882000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.367644e+01/ 轮得分 210.60\n",
      "损失函数： 0.0610407\n",
      "时间步 2883000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.446023e+01/ 轮得分 210.60\n",
      "损失函数： 0.0204139\n",
      "时间步 2884000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.377710e+01/ 轮得分 210.85\n",
      "损失函数： 0.132573\n",
      "时间步 2885000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.362646e+01/ 轮得分 210.89\n",
      "损失函数： 0.0288863\n",
      "时间步 2886000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.288222e+01/ 轮得分 210.89\n",
      "损失函数： 0.0241113\n",
      "时间步 2887000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.228451e+01/ 轮得分 211.09\n",
      "损失函数： 0.0170532\n",
      "时间步 2888000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.383317e+01/ 轮得分 211.09\n",
      "损失函数： 0.0185374\n",
      "时间步 2889000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.630955e+01/ 轮得分 211.31\n",
      "损失函数： 0.0735018\n",
      "时间步 2890000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.343545e+01/ 轮得分 211.29\n",
      "损失函数： 0.0183642\n",
      "时间步 2891000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.177581e+01/ 轮得分 211.29\n",
      "损失函数： 0.028686\n",
      "时间步 2892000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.267481e+01/ 轮得分 211.29\n",
      "损失函数： 0.0126769\n",
      "时间步 2893000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.277540e+01/ 轮得分 211.29\n",
      "损失函数： 0.110028\n",
      "时间步 2894000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 1.1/ Q_MAX 1.440485e+01/ 轮得分 211.29\n",
      "损失函数： 0.0407847\n",
      "时间步 2895000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.437235e+01/ 轮得分 211.29\n",
      "损失函数： 0.0208805\n",
      "时间步 2896000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.239756e+01/ 轮得分 211.29\n",
      "损失函数： 0.0394938\n",
      "时间步 2897000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.485131e+01/ 轮得分 211.29\n",
      "损失函数： 0.0731386\n",
      "时间步 2898000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.338655e+01/ 轮得分 211.29\n",
      "损失函数： 0.031884\n",
      "时间步 2899000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.285154e+01/ 轮得分 211.29\n",
      "损失函数： 0.0375137\n",
      "时间步 2900000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.353685e+01/ 轮得分 211.29\n",
      "损失函数： 0.0692792\n",
      "时间步 2901000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.319989e+01/ 轮得分 211.29\n",
      "损失函数： 0.0643183\n",
      "时间步 2902000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.411693e+01/ 轮得分 212.45\n",
      "损失函数： 0.0550906\n",
      "时间步 2903000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.218641e+01/ 轮得分 212.44\n",
      "损失函数： 0.0211537\n",
      "时间步 2904000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.333138e+01/ 轮得分 212.54\n",
      "损失函数： 0.0276459\n",
      "时间步 2905000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.255485e+01/ 轮得分 212.59\n",
      "损失函数： 0.0465707\n",
      "时间步 2906000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.284238e+01/ 轮得分 212.59\n",
      "损失函数： 0.0381615\n",
      "时间步 2907000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.348672e+01/ 轮得分 212.59\n",
      "损失函数： 0.0324818\n",
      "时间步 2908000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.268604e+01/ 轮得分 212.64\n",
      "损失函数： 0.0382367\n",
      "时间步 2909000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.338620e+01/ 轮得分 212.64\n",
      "损失函数： 0.0117077\n",
      "时间步 2910000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.248016e+01/ 轮得分 212.62\n",
      "损失函数： 0.105002\n",
      "时间步 2911000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.400462e+01/ 轮得分 212.64\n",
      "损失函数： 0.0491429\n",
      "时间步 2912000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.166656e+01/ 轮得分 212.64\n",
      "损失函数： 0.0194323\n",
      "时间步 2913000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.080041e+01/ 轮得分 212.64\n",
      "损失函数： 0.0663011\n",
      "时间步 2914000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.483793e+01/ 轮得分 212.88\n",
      "损失函数： 0.0181435\n",
      "时间步 2915000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.109976e+01/ 轮得分 212.90\n",
      "损失函数： 0.0686358\n",
      "时间步 2916000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.047295e+01/ 轮得分 212.90\n",
      "损失函数： 0.0302355\n",
      "时间步 2917000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.257687e+01/ 轮得分 212.90\n",
      "损失函数： 0.0390566\n",
      "时间步 2918000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.272318e+01/ 轮得分 212.96\n",
      "损失函数： 0.144997\n",
      "时间步 2919000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.328181e+01/ 轮得分 212.96\n",
      "损失函数： 0.0291133\n",
      "时间步 2920000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.326656e+01/ 轮得分 212.96\n",
      "损失函数： 0.0326194\n",
      "时间步 2921000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.427923e+01/ 轮得分 212.96\n",
      "损失函数： 0.0347748\n",
      "时间步 2922000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.036712e+01/ 轮得分 213.34\n",
      "损失函数： 0.0372616\n",
      "时间步 2923000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.066792e+01/ 轮得分 213.37\n",
      "损失函数： 0.0388\n",
      "时间步 2924000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.233565e+01/ 轮得分 213.37\n",
      "损失函数： 0.0192051\n",
      "时间步 2925000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.302306e+01/ 轮得分 213.59\n",
      "损失函数： 0.0432248\n",
      "时间步 2926000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.421525e+01/ 轮得分 213.59\n",
      "损失函数： 0.0732497\n",
      "时间步 2927000/ 状态 explore/ Epsilon 0.01/ 行动 0/ 奖励 0.1/ Q_MAX 1.537437e+01/ 轮得分 213.70\n",
      "损失函数： 0.0571788\n",
      "时间步 2928000/ 状态 explore/ Epsilon 0.01/ 行动 2/ 奖励 0.1/ Q_MAX 1.236702e+01/ 轮得分 213.70\n",
      "损失函数： 0.0303965\n",
      "时间步 2929000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.172497e+01/ 轮得分 213.55\n",
      "损失函数： 0.0577853\n",
      "时间步 2930000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.376616e+01/ 轮得分 213.58\n",
      "损失函数： 0.0516923\n",
      "时间步 2931000/ 状态 explore/ Epsilon 0.01/ 行动 1/ 奖励 0.1/ Q_MAX 1.184086e+01/ 轮得分 213.58\n",
      "损失函数： 0.062337\n",
      "时间步 2932000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289250e+01/ 轮得分 213.39\n",
      "损失函数： 0.0290306\n",
      "时间步 2933000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349700e+01/ 轮得分 213.39\n",
      "损失函数： 0.0268415\n",
      "时间步 2934000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361292e+01/ 轮得分 213.39\n",
      "损失函数： 0.0378694\n",
      "时间步 2935000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321482e+01/ 轮得分 213.39\n",
      "损失函数： 0.0746257\n",
      "时间步 2936000/ 状态 explore/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.306627e+01/ 轮得分 213.39\n",
      "损失函数： 0.0314957\n",
      "时间步 2937000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.467408e+01/ 轮得分 213.39\n",
      "损失函数： 0.0507804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 2938000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.395846e+01/ 轮得分 214.07\n",
      "损失函数： 0.0500178\n",
      "时间步 2939000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347741e+01/ 轮得分 214.07\n",
      "损失函数： 0.0259548\n",
      "时间步 2940000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.499692e+01/ 轮得分 214.07\n",
      "损失函数： 0.0774098\n",
      "时间步 2941000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.324662e+01/ 轮得分 214.07\n",
      "损失函数： 0.0180282\n",
      "时间步 2942000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.347703e+01/ 轮得分 214.07\n",
      "损失函数： 0.013867\n",
      "时间步 2943000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.197448e+01/ 轮得分 214.07\n",
      "损失函数： 0.0780981\n",
      "时间步 2944000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.096283e+01/ 轮得分 214.07\n",
      "损失函数： 0.0353232\n",
      "时间步 2945000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212869e+01/ 轮得分 214.73\n",
      "损失函数： 0.0351977\n",
      "时间步 2946000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448922e+01/ 轮得分 214.73\n",
      "损失函数： 0.0279438\n",
      "时间步 2947000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.455542e+01/ 轮得分 214.73\n",
      "损失函数： 0.0435562\n",
      "时间步 2948000/ 状态 explore/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.192115e+01/ 轮得分 214.73\n",
      "损失函数： 0.0553212\n",
      "时间步 2949000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325220e+01/ 轮得分 214.73\n",
      "损失函数： 4.01975\n",
      "时间步 2950000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.490295e+01/ 轮得分 214.73\n",
      "损失函数： 0.0167901\n",
      "时间步 2951000/ 状态 explore/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.385119e+01/ 轮得分 214.73\n",
      "损失函数： 0.0321469\n",
      "时间步 2952000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.445825e+01/ 轮得分 214.73\n",
      "损失函数： 0.0148702\n",
      "时间步 2953000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.382990e+01/ 轮得分 214.73\n",
      "损失函数： 0.0365639\n",
      "时间步 2954000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400401e+01/ 轮得分 214.73\n",
      "损失函数： 0.112969\n",
      "时间步 2955000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340119e+01/ 轮得分 215.81\n",
      "损失函数： 0.0450179\n",
      "时间步 2956000/ 状态 explore/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.235544e+01/ 轮得分 215.81\n",
      "损失函数： 0.0363221\n",
      "时间步 2957000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229282e+01/ 轮得分 215.81\n",
      "损失函数： 0.0283074\n",
      "时间步 2958000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.218741e+01/ 轮得分 215.81\n",
      "损失函数： 0.029536\n",
      "时间步 2959000/ 状态 explore/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.284448e+01/ 轮得分 215.65\n",
      "损失函数： 0.0471183\n",
      "时间步 2960000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373229e+01/ 轮得分 215.79\n",
      "损失函数： 0.0349328\n",
      "时间步 2961000/ 状态 explore/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.339151e+01/ 轮得分 215.79\n",
      "损失函数： 0.0353117\n",
      "时间步 2962000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.271887e+01/ 轮得分 215.90\n",
      "损失函数： 0.0811911\n",
      "时间步 2963000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258465e+01/ 轮得分 215.90\n",
      "损失函数： 0.0205361\n",
      "时间步 2964000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343356e+01/ 轮得分 215.90\n",
      "损失函数： 0.0362053\n",
      "时间步 2965000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324665e+01/ 轮得分 216.04\n",
      "损失函数： 0.0268814\n",
      "时间步 2966000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.156204e+01/ 轮得分 215.92\n",
      "损失函数： 0.0679811\n",
      "时间步 2967000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.308240e+01/ 轮得分 216.02\n",
      "损失函数： 0.0509706\n",
      "时间步 2968000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346432e+01/ 轮得分 215.54\n",
      "损失函数： 0.046344\n",
      "时间步 2969000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230648e+01/ 轮得分 215.54\n",
      "损失函数： 0.0282472\n",
      "时间步 2970000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.112845e+01/ 轮得分 215.54\n",
      "损失函数： 0.0765978\n",
      "时间步 2971000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.296726e+01/ 轮得分 215.54\n",
      "损失函数： 0.0302849\n",
      "时间步 2972000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.452092e+01/ 轮得分 215.54\n",
      "损失函数： 0.0565556\n",
      "时间步 2973000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303847e+01/ 轮得分 215.54\n",
      "损失函数： 0.0454557\n",
      "时间步 2974000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.249210e+01/ 轮得分 216.11\n",
      "损失函数： 0.0562728\n",
      "时间步 2975000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.424328e+01/ 轮得分 216.11\n",
      "损失函数： 0.044175\n",
      "时间步 2976000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287421e+01/ 轮得分 216.04\n",
      "损失函数： 0.0719212\n",
      "时间步 2977000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400229e+01/ 轮得分 216.04\n",
      "损失函数： 0.0433945\n",
      "时间步 2978000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.223798e+01/ 轮得分 215.77\n",
      "损失函数： 0.128448\n",
      "时间步 2979000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288667e+01/ 轮得分 215.61\n",
      "损失函数： 0.0232388\n",
      "时间步 2980000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.176249e+01/ 轮得分 215.71\n",
      "损失函数： 0.0297338\n",
      "时间步 2981000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.276646e+01/ 轮得分 215.71\n",
      "损失函数： 0.0295073\n",
      "时间步 2982000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212497e+01/ 轮得分 215.73\n",
      "损失函数： 0.0300645\n",
      "时间步 2983000/ 状态 explore/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.336716e+01/ 轮得分 215.69\n",
      "损失函数： 0.0388397\n",
      "时间步 2984000/ 状态 explore/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.254797e+01/ 轮得分 215.69\n",
      "损失函数： 0.0621851\n",
      "时间步 2985000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216915e+01/ 轮得分 215.69\n",
      "损失函数： 0.0432735\n",
      "时间步 2986000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.177652e+01/ 轮得分 215.88\n",
      "损失函数： 0.138841\n",
      "时间步 2987000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268842e+01/ 轮得分 215.88\n",
      "损失函数： 0.04674\n",
      "时间步 2988000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273007e+01/ 轮得分 215.88\n",
      "损失函数： 0.0432367\n",
      "时间步 2989000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.369557e+01/ 轮得分 215.88\n",
      "损失函数： 0.0258719\n",
      "时间步 2990000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192189e+01/ 轮得分 216.29\n",
      "损失函数： 0.0592238\n",
      "时间步 2991000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396021e+01/ 轮得分 216.26\n",
      "损失函数： 0.0304217\n",
      "时间步 2992000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265676e+01/ 轮得分 216.26\n",
      "损失函数： 0.019037\n",
      "时间步 2993000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.501419e+01/ 轮得分 216.26\n",
      "损失函数： 0.0568298\n",
      "时间步 2994000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.164818e+01/ 轮得分 216.50\n",
      "损失函数： 0.0286404\n",
      "时间步 2995000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294394e+01/ 轮得分 216.32\n",
      "损失函数： 0.075376\n",
      "时间步 2996000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.072355e+00/ 轮得分 216.36\n",
      "损失函数： 0.0498072\n",
      "时间步 2997000/ 状态 explore/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.254649e+01/ 轮得分 216.36\n",
      "损失函数： 0.0673113\n",
      "时间步 2998000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.409921e+01/ 轮得分 216.36\n",
      "损失函数： 0.0251483\n",
      "时间步 2999000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184546e+01/ 轮得分 216.36\n",
      "损失函数： 0.0333389\n",
      "时间步 3000000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277826e+01/ 轮得分 216.36\n",
      "损失函数： 0.0303818\n",
      "时间步 3001000/ 状态 explore/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.433718e+01/ 轮得分 216.36\n",
      "损失函数： 0.0522848\n",
      "时间步 3002000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201647e+01/ 轮得分 216.36\n",
      "损失函数： 0.035476\n",
      "时间步 3003000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.444067e+01/ 轮得分 217.08\n",
      "损失函数： 0.0318387\n",
      "时间步 3004000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208250e+01/ 轮得分 217.08\n",
      "损失函数： 0.0562144\n",
      "时间步 3005000/ 状态 explore/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315880e+01/ 轮得分 217.08\n",
      "损失函数： 0.0286193\n",
      "时间步 3006000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180537e+01/ 轮得分 217.53\n",
      "损失函数： 0.0204318\n",
      "时间步 3007000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321453e+01/ 轮得分 217.53\n",
      "损失函数： 0.0897027\n",
      "时间步 3008000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.218971e+01/ 轮得分 217.53\n",
      "损失函数： 0.0233619\n",
      "时间步 3009000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 6.711187e+00/ 轮得分 217.53\n",
      "损失函数： 0.0397443\n",
      "时间步 3010000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.164064e+01/ 轮得分 217.75\n",
      "损失函数： 0.0231649\n",
      "时间步 3011000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418120e+01/ 轮得分 217.75\n",
      "损失函数： 0.590912\n",
      "时间步 3012000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192042e+01/ 轮得分 217.91\n",
      "损失函数： 0.0261128\n",
      "时间步 3013000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165959e+01/ 轮得分 218.05\n",
      "损失函数： 0.0436283\n",
      "时间步 3014000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.369186e+01/ 轮得分 218.05\n",
      "损失函数： 0.0527364\n",
      "时间步 3015000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.182346e+01/ 轮得分 217.96\n",
      "损失函数： 0.0722152\n",
      "时间步 3016000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238279e+01/ 轮得分 217.96\n",
      "损失函数： 0.0204807\n",
      "时间步 3017000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.109577e+01/ 轮得分 217.96\n",
      "损失函数： 0.0395905\n",
      "时间步 3018000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.294119e+01/ 轮得分 218.29\n",
      "损失函数： 0.0300505\n",
      "时间步 3019000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.468134e+01/ 轮得分 218.33\n",
      "损失函数： 0.0623236\n",
      "时间步 3020000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280327e+01/ 轮得分 218.33\n",
      "损失函数： 0.0348032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3021000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407887e+01/ 轮得分 218.49\n",
      "损失函数： 0.0327606\n",
      "时间步 3022000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.435697e+01/ 轮得分 218.49\n",
      "损失函数： 0.0248732\n",
      "时间步 3023000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.195714e+01/ 轮得分 218.54\n",
      "损失函数： 0.0932885\n",
      "时间步 3024000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.460126e+01/ 轮得分 218.54\n",
      "损失函数： 0.044389\n",
      "时间步 3025000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407014e+01/ 轮得分 218.54\n",
      "损失函数： 0.0423002\n",
      "时间步 3026000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.553816e+01/ 轮得分 218.54\n",
      "损失函数： 0.0426783\n",
      "时间步 3027000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.706436e+01/ 轮得分 218.54\n",
      "损失函数： 0.490545\n",
      "时间步 3028000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264301e+01/ 轮得分 218.95\n",
      "损失函数： 0.0162057\n",
      "时间步 3029000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.337770e+01/ 轮得分 218.95\n",
      "损失函数： 0.0148374\n",
      "时间步 3030000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271894e+01/ 轮得分 218.95\n",
      "损失函数： 0.0784091\n",
      "时间步 3031000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.399973e+01/ 轮得分 219.15\n",
      "损失函数： 0.0265961\n",
      "时间步 3032000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363367e+01/ 轮得分 219.32\n",
      "损失函数： 0.0265786\n",
      "时间步 3033000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.371021e+01/ 轮得分 219.32\n",
      "损失函数： 0.0362644\n",
      "时间步 3034000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347336e+01/ 轮得分 219.46\n",
      "损失函数： 0.0314492\n",
      "时间步 3035000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259473e+01/ 轮得分 219.46\n",
      "损失函数： 0.0508045\n",
      "时间步 3036000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170962e+01/ 轮得分 219.46\n",
      "损失函数： 0.0255286\n",
      "时间步 3037000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.140209e+01/ 轮得分 219.46\n",
      "损失函数： 0.0414798\n",
      "时间步 3038000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.206023e+01/ 轮得分 219.47\n",
      "损失函数： 0.0250382\n",
      "时间步 3039000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 7.159407e+00/ 轮得分 219.47\n",
      "损失函数： 0.0573961\n",
      "时间步 3040000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390165e+01/ 轮得分 219.43\n",
      "损失函数： 0.042005\n",
      "时间步 3041000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.266583e+01/ 轮得分 219.43\n",
      "损失函数： 0.0489287\n",
      "时间步 3042000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.461033e+01/ 轮得分 219.65\n",
      "损失函数： 0.0204275\n",
      "时间步 3043000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.371817e+01/ 轮得分 219.65\n",
      "损失函数： 0.0386338\n",
      "时间步 3044000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.504592e+01/ 轮得分 219.65\n",
      "损失函数： 0.0244019\n",
      "时间步 3045000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.475624e+01/ 轮得分 219.90\n",
      "损失函数： 0.0419521\n",
      "时间步 3046000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357297e+01/ 轮得分 219.90\n",
      "损失函数： 0.0276174\n",
      "时间步 3047000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.338864e+01/ 轮得分 219.90\n",
      "损失函数： 0.143169\n",
      "时间步 3048000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.338884e+01/ 轮得分 219.90\n",
      "损失函数： 0.0559541\n",
      "时间步 3049000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.324659e+01/ 轮得分 219.90\n",
      "损失函数： 0.0559904\n",
      "时间步 3050000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.492654e+01/ 轮得分 219.90\n",
      "损失函数： 0.295892\n",
      "时间步 3051000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.557950e+01/ 轮得分 219.90\n",
      "损失函数： 0.0293534\n",
      "时间步 3052000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.287689e+01/ 轮得分 220.64\n",
      "损失函数： 0.0320244\n",
      "时间步 3053000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263710e+01/ 轮得分 220.64\n",
      "损失函数： 0.0445215\n",
      "时间步 3054000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415727e+01/ 轮得分 220.64\n",
      "损失函数： 0.0386243\n",
      "时间步 3055000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273534e+01/ 轮得分 220.64\n",
      "损失函数： 0.0147793\n",
      "时间步 3056000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.475144e+01/ 轮得分 220.64\n",
      "损失函数： 0.022073\n",
      "时间步 3057000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340951e+01/ 轮得分 220.64\n",
      "损失函数： 0.0522791\n",
      "时间步 3058000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400166e+01/ 轮得分 220.64\n",
      "损失函数： 0.24649\n",
      "时间步 3059000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181903e+01/ 轮得分 220.64\n",
      "损失函数： 0.0494914\n",
      "时间步 3060000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277034e+01/ 轮得分 221.55\n",
      "损失函数： 0.0126765\n",
      "时间步 3061000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.404886e+01/ 轮得分 221.55\n",
      "损失函数： 0.0349994\n",
      "时间步 3062000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330111e+01/ 轮得分 221.55\n",
      "损失函数： 0.0332003\n",
      "时间步 3063000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.732156e+01/ 轮得分 221.84\n",
      "损失函数： 0.0732613\n",
      "时间步 3064000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.209507e+01/ 轮得分 221.84\n",
      "损失函数： 0.0349937\n",
      "时间步 3065000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387249e+01/ 轮得分 221.84\n",
      "损失函数： 0.0355763\n",
      "时间步 3066000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210772e+01/ 轮得分 222.15\n",
      "损失函数： 0.0736233\n",
      "时间步 3067000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.210971e+01/ 轮得分 222.15\n",
      "损失函数： 0.0187934\n",
      "时间步 3068000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365754e+01/ 轮得分 222.15\n",
      "损失函数： 0.037028\n",
      "时间步 3069000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.179411e+01/ 轮得分 222.15\n",
      "损失函数： 0.0457588\n",
      "时间步 3070000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356974e+01/ 轮得分 222.59\n",
      "损失函数： 0.0442759\n",
      "时间步 3071000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249043e+01/ 轮得分 222.59\n",
      "损失函数： 0.0322551\n",
      "时间步 3072000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375503e+01/ 轮得分 222.59\n",
      "损失函数： 0.0292473\n",
      "时间步 3073000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.418571e+01/ 轮得分 222.81\n",
      "损失函数： 0.0253471\n",
      "时间步 3074000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.363081e+01/ 轮得分 222.81\n",
      "损失函数： 0.0211322\n",
      "时间步 3075000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186029e+01/ 轮得分 222.81\n",
      "损失函数： 0.0103466\n",
      "时间步 3076000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243211e+01/ 轮得分 222.81\n",
      "损失函数： 0.0583296\n",
      "时间步 3077000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226716e+01/ 轮得分 222.81\n",
      "损失函数： 0.0588691\n",
      "时间步 3078000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.278165e+01/ 轮得分 222.81\n",
      "损失函数： 0.0609563\n",
      "时间步 3079000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.475239e+01/ 轮得分 223.51\n",
      "损失函数： 0.0351239\n",
      "时间步 3080000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.486783e+01/ 轮得分 223.56\n",
      "损失函数： 0.0275122\n",
      "时间步 3081000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348243e+01/ 轮得分 223.56\n",
      "损失函数： 0.0555067\n",
      "时间步 3082000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.265372e+01/ 轮得分 223.56\n",
      "损失函数： 0.0284351\n",
      "时间步 3083000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.402615e+01/ 轮得分 223.63\n",
      "损失函数： 0.0157928\n",
      "时间步 3084000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299652e+01/ 轮得分 223.63\n",
      "损失函数： 0.0531987\n",
      "时间步 3085000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267222e+01/ 轮得分 223.63\n",
      "损失函数： 0.0413631\n",
      "时间步 3086000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.085000e+01/ 轮得分 223.80\n",
      "损失函数： 5.65894\n",
      "时间步 3087000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331189e+01/ 轮得分 223.79\n",
      "损失函数： 0.0276087\n",
      "时间步 3088000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.175084e+01/ 轮得分 223.79\n",
      "损失函数： 0.0344342\n",
      "时间步 3089000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376507e+01/ 轮得分 223.96\n",
      "损失函数： 0.0244048\n",
      "时间步 3090000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177344e+01/ 轮得分 223.97\n",
      "损失函数： 0.0253838\n",
      "时间步 3091000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.174920e+01/ 轮得分 223.97\n",
      "损失函数： 0.00970537\n",
      "时间步 3092000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.422224e+01/ 轮得分 223.97\n",
      "损失函数： 0.0198174\n",
      "时间步 3093000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.270780e+01/ 轮得分 223.97\n",
      "损失函数： 0.0325426\n",
      "时间步 3094000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.291369e+01/ 轮得分 223.97\n",
      "损失函数： 0.0328669\n",
      "时间步 3095000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244694e+01/ 轮得分 223.97\n",
      "损失函数： 0.0300431\n",
      "时间步 3096000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.264453e+01/ 轮得分 223.97\n",
      "损失函数： 0.0729038\n",
      "时间步 3097000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189811e+01/ 轮得分 223.97\n",
      "损失函数： 0.0711486\n",
      "时间步 3098000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.326081e+01/ 轮得分 223.97\n",
      "损失函数： 0.0342416\n",
      "时间步 3099000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289151e+01/ 轮得分 224.91\n",
      "损失函数： 0.0294457\n",
      "时间步 3100000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.085444e+01/ 轮得分 224.91\n",
      "损失函数： 0.083412\n",
      "时间步 3101000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365864e+01/ 轮得分 225.11\n",
      "损失函数： 0.0302334\n",
      "时间步 3102000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273686e+01/ 轮得分 225.08\n",
      "损失函数： 0.051883\n",
      "时间步 3103000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315478e+01/ 轮得分 225.08\n",
      "损失函数： 0.0205635\n",
      "时间步 3104000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297308e+01/ 轮得分 225.08\n",
      "损失函数： 0.0335005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3105000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.327048e+01/ 轮得分 225.08\n",
      "损失函数： 0.0285033\n",
      "时间步 3106000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.380732e+01/ 轮得分 225.08\n",
      "损失函数： 0.0173535\n",
      "时间步 3107000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238728e+01/ 轮得分 225.69\n",
      "损失函数： 0.0221912\n",
      "时间步 3108000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423441e+01/ 轮得分 225.69\n",
      "损失函数： 0.0494339\n",
      "时间步 3109000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205327e+01/ 轮得分 225.92\n",
      "损失函数： 0.0298585\n",
      "时间步 3110000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240568e+01/ 轮得分 225.92\n",
      "损失函数： 0.0390656\n",
      "时间步 3111000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.352898e+01/ 轮得分 225.92\n",
      "损失函数： 0.0515588\n",
      "时间步 3112000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286040e+01/ 轮得分 225.92\n",
      "损失函数： 0.0167111\n",
      "时间步 3113000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189659e+01/ 轮得分 225.92\n",
      "损失函数： 0.0408315\n",
      "时间步 3114000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356509e+01/ 轮得分 225.92\n",
      "损失函数： 0.0486059\n",
      "时间步 3115000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.106517e+01/ 轮得分 226.40\n",
      "损失函数： 0.0492373\n",
      "时间步 3116000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337613e+01/ 轮得分 226.40\n",
      "损失函数： 0.0204191\n",
      "时间步 3117000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.136311e+01/ 轮得分 226.40\n",
      "损失函数： 0.0208256\n",
      "时间步 3118000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.483227e+01/ 轮得分 226.40\n",
      "损失函数： 0.0594857\n",
      "时间步 3119000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.221286e+01/ 轮得分 226.40\n",
      "损失函数： 0.0318661\n",
      "时间步 3120000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233462e+01/ 轮得分 226.40\n",
      "损失函数： 0.0267046\n",
      "时间步 3121000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299550e+01/ 轮得分 226.40\n",
      "损失函数： 0.0499661\n",
      "时间步 3122000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238265e+01/ 轮得分 226.99\n",
      "损失函数： 0.0346476\n",
      "时间步 3123000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319988e+01/ 轮得分 226.99\n",
      "损失函数： 0.0378889\n",
      "时间步 3124000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.305323e+01/ 轮得分 226.99\n",
      "损失函数： 0.018744\n",
      "时间步 3125000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.369593e+01/ 轮得分 226.99\n",
      "损失函数： 0.0391886\n",
      "时间步 3126000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.122248e+01/ 轮得分 227.39\n",
      "损失函数： 0.0189659\n",
      "时间步 3127000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.205030e+01/ 轮得分 227.33\n",
      "损失函数： 0.0579914\n",
      "时间步 3128000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.247941e+01/ 轮得分 227.47\n",
      "损失函数： 0.021334\n",
      "时间步 3129000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349221e+01/ 轮得分 227.51\n",
      "损失函数： 0.0425321\n",
      "时间步 3130000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.211397e+01/ 轮得分 227.51\n",
      "损失函数： 0.0148497\n",
      "时间步 3131000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.350610e+01/ 轮得分 227.51\n",
      "损失函数： 0.0232579\n",
      "时间步 3132000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184905e+01/ 轮得分 227.72\n",
      "损失函数： 0.0215272\n",
      "时间步 3133000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.258843e+01/ 轮得分 227.63\n",
      "损失函数： 0.0272805\n",
      "时间步 3134000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.153058e+01/ 轮得分 227.43\n",
      "损失函数： 0.0138785\n",
      "时间步 3135000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185751e+01/ 轮得分 227.43\n",
      "损失函数： 0.0674945\n",
      "时间步 3136000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.273981e+01/ 轮得分 227.55\n",
      "损失函数： 0.0247572\n",
      "时间步 3137000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282122e+01/ 轮得分 227.13\n",
      "损失函数： 0.0297272\n",
      "时间步 3138000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284556e+01/ 轮得分 226.94\n",
      "损失函数： 0.0175593\n",
      "时间步 3139000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.265497e+01/ 轮得分 226.94\n",
      "损失函数： 0.0587701\n",
      "时间步 3140000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186342e+01/ 轮得分 227.18\n",
      "损失函数： 0.0255943\n",
      "时间步 3141000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.266253e+01/ 轮得分 227.28\n",
      "损失函数： 0.0335135\n",
      "时间步 3142000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258065e+01/ 轮得分 227.28\n",
      "损失函数： 0.0258689\n",
      "时间步 3143000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180775e+01/ 轮得分 227.38\n",
      "损失函数： 0.0475236\n",
      "时间步 3144000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.474835e+01/ 轮得分 227.38\n",
      "损失函数： 0.0536158\n",
      "时间步 3145000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.402094e+01/ 轮得分 227.38\n",
      "损失函数： 0.0747068\n",
      "时间步 3146000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.408723e+01/ 轮得分 227.38\n",
      "损失函数： 0.0295048\n",
      "时间步 3147000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.480547e+01/ 轮得分 227.51\n",
      "损失函数： 0.0541254\n",
      "时间步 3148000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277515e+01/ 轮得分 227.51\n",
      "损失函数： 0.0496475\n",
      "时间步 3149000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.628276e+01/ 轮得分 227.51\n",
      "损失函数： 0.0504427\n",
      "时间步 3150000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242091e+01/ 轮得分 227.51\n",
      "损失函数： 0.0368555\n",
      "时间步 3151000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310591e+01/ 轮得分 227.51\n",
      "损失函数： 0.0391882\n",
      "时间步 3152000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205928e+01/ 轮得分 227.51\n",
      "损失函数： 0.0253155\n",
      "时间步 3153000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.370198e+01/ 轮得分 228.09\n",
      "损失函数： 0.0358552\n",
      "时间步 3154000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294053e+01/ 轮得分 228.09\n",
      "损失函数： 0.0520102\n",
      "时间步 3155000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245454e+01/ 轮得分 228.09\n",
      "损失函数： 0.0394244\n",
      "时间步 3156000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181711e+01/ 轮得分 228.52\n",
      "损失函数： 0.0564335\n",
      "时间步 3157000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407513e+01/ 轮得分 228.52\n",
      "损失函数： 0.0416833\n",
      "时间步 3158000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285857e+01/ 轮得分 228.52\n",
      "损失函数： 0.0483145\n",
      "时间步 3159000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239248e+01/ 轮得分 228.52\n",
      "损失函数： 0.0363034\n",
      "时间步 3160000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362984e+01/ 轮得分 228.61\n",
      "损失函数： 0.0406891\n",
      "时间步 3161000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297256e+01/ 轮得分 228.65\n",
      "损失函数： 0.0157612\n",
      "时间步 3162000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.068857e+01/ 轮得分 228.65\n",
      "损失函数： 0.034696\n",
      "时间步 3163000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290196e+01/ 轮得分 228.73\n",
      "损失函数： 0.0319474\n",
      "时间步 3164000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310555e+01/ 轮得分 228.60\n",
      "损失函数： 0.027872\n",
      "时间步 3165000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331886e+01/ 轮得分 228.60\n",
      "损失函数： 0.0290201\n",
      "时间步 3166000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.565632e+01/ 轮得分 228.60\n",
      "损失函数： 0.0306327\n",
      "时间步 3167000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352393e+01/ 轮得分 228.60\n",
      "损失函数： 0.0971935\n",
      "时间步 3168000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357945e+01/ 轮得分 229.00\n",
      "损失函数： 0.0394653\n",
      "时间步 3169000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 8.887914e+00/ 轮得分 229.00\n",
      "损失函数： 0.0146374\n",
      "时间步 3170000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351200e+01/ 轮得分 228.91\n",
      "损失函数： 0.0192217\n",
      "时间步 3171000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.587224e+01/ 轮得分 228.91\n",
      "损失函数： 0.033024\n",
      "时间步 3172000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.082785e+01/ 轮得分 228.91\n",
      "损失函数： 0.0293974\n",
      "时间步 3173000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.382778e+01/ 轮得分 228.96\n",
      "损失函数： 0.0746968\n",
      "时间步 3174000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328980e+01/ 轮得分 228.96\n",
      "损失函数： 0.0562183\n",
      "时间步 3175000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400886e+01/ 轮得分 228.96\n",
      "损失函数： 0.0569175\n",
      "时间步 3176000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259213e+01/ 轮得分 229.06\n",
      "损失函数： 0.0250521\n",
      "时间步 3177000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.441352e+01/ 轮得分 229.06\n",
      "损失函数： 0.0664529\n",
      "时间步 3178000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.468680e+01/ 轮得分 229.06\n",
      "损失函数： 0.0233138\n",
      "时间步 3179000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.286440e+01/ 轮得分 229.31\n",
      "损失函数： 0.0266427\n",
      "时间步 3180000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342584e+01/ 轮得分 229.31\n",
      "损失函数： 0.0744402\n",
      "时间步 3181000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.384420e+01/ 轮得分 229.31\n",
      "损失函数： 0.0411281\n",
      "时间步 3182000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.232607e+01/ 轮得分 229.61\n",
      "损失函数： 0.0584464\n",
      "时间步 3183000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.247419e+01/ 轮得分 229.61\n",
      "损失函数： 0.0456003\n",
      "时间步 3184000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.430830e+01/ 轮得分 229.83\n",
      "损失函数： 0.0414311\n",
      "时间步 3185000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237813e+01/ 轮得分 229.83\n",
      "损失函数： 0.0405199\n",
      "时间步 3186000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.250291e+01/ 轮得分 229.83\n",
      "损失函数： 0.0475734\n",
      "时间步 3187000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297829e+01/ 轮得分 230.04\n",
      "损失函数： 0.0244092\n",
      "时间步 3188000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 9.119980e+00/ 轮得分 230.04\n",
      "损失函数： 0.0301354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3189000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.142792e+01/ 轮得分 230.04\n",
      "损失函数： 0.0240095\n",
      "时间步 3190000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293141e+01/ 轮得分 230.04\n",
      "损失函数： 0.039357\n",
      "时间步 3191000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.376042e+01/ 轮得分 230.04\n",
      "损失函数： 0.0330297\n",
      "时间步 3192000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.416619e+01/ 轮得分 230.04\n",
      "损失函数： 0.0410941\n",
      "时间步 3193000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292873e+01/ 轮得分 230.04\n",
      "损失函数： 0.0363177\n",
      "时间步 3194000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.370655e+01/ 轮得分 230.04\n",
      "损失函数： 0.0228815\n",
      "时间步 3195000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 8.354009e+00/ 轮得分 230.04\n",
      "损失函数： 0.0449946\n",
      "时间步 3196000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264593e+01/ 轮得分 230.92\n",
      "损失函数： 0.0392645\n",
      "时间步 3197000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184900e+01/ 轮得分 230.91\n",
      "损失函数： 0.0197762\n",
      "时间步 3198000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.309282e+01/ 轮得分 230.91\n",
      "损失函数： 0.0298548\n",
      "时间步 3199000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.175492e+01/ 轮得分 230.91\n",
      "损失函数： 0.063657\n",
      "时间步 3200000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.110084e+01/ 轮得分 231.05\n",
      "损失函数： 0.0149081\n",
      "时间步 3201000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.167075e+01/ 轮得分 231.05\n",
      "损失函数： 0.0374093\n",
      "时间步 3202000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344527e+01/ 轮得分 231.05\n",
      "损失函数： 0.0609439\n",
      "时间步 3203000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338770e+01/ 轮得分 231.36\n",
      "损失函数： 0.017006\n",
      "时间步 3204000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294319e+01/ 轮得分 231.29\n",
      "损失函数： 0.023703\n",
      "时间步 3205000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.461371e+01/ 轮得分 231.29\n",
      "损失函数： 0.0456235\n",
      "时间步 3206000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.270545e+01/ 轮得分 231.48\n",
      "损失函数： 0.0251399\n",
      "时间步 3207000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312877e+01/ 轮得分 231.48\n",
      "损失函数： 0.0604864\n",
      "时间步 3208000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.389408e+01/ 轮得分 231.35\n",
      "损失函数： 0.0260571\n",
      "时间步 3209000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188696e+01/ 轮得分 231.35\n",
      "损失函数： 0.104947\n",
      "时间步 3210000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.297184e+01/ 轮得分 231.35\n",
      "损失函数： 0.0119181\n",
      "时间步 3211000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.430232e+01/ 轮得分 231.35\n",
      "损失函数： 0.044934\n",
      "时间步 3212000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256378e+01/ 轮得分 231.35\n",
      "损失函数： 0.035998\n",
      "时间步 3213000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.053420e+01/ 轮得分 231.35\n",
      "损失函数： 0.0478705\n",
      "时间步 3214000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228568e+01/ 轮得分 231.95\n",
      "损失函数： 0.0244741\n",
      "时间步 3215000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.481086e+01/ 轮得分 231.95\n",
      "损失函数： 0.0504914\n",
      "时间步 3216000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.203959e+01/ 轮得分 231.95\n",
      "损失函数： 0.0244676\n",
      "时间步 3217000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.556958e+01/ 轮得分 232.24\n",
      "损失函数： 0.0224299\n",
      "时间步 3218000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.556021e+01/ 轮得分 232.24\n",
      "损失函数： 0.0283109\n",
      "时间步 3219000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.384505e+01/ 轮得分 232.24\n",
      "损失函数： 0.0444476\n",
      "时间步 3220000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.436792e+01/ 轮得分 232.24\n",
      "损失函数： 0.047942\n",
      "时间步 3221000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.380882e+01/ 轮得分 232.24\n",
      "损失函数： 0.0310921\n",
      "时间步 3222000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.394842e+01/ 轮得分 232.24\n",
      "损失函数： 0.0312193\n",
      "时间步 3223000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.453941e+01/ 轮得分 232.90\n",
      "损失函数： 0.037551\n",
      "时间步 3224000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.488310e+01/ 轮得分 232.90\n",
      "损失函数： 0.0302634\n",
      "时间步 3225000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.455618e+01/ 轮得分 232.90\n",
      "损失函数： 0.00710925\n",
      "时间步 3226000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.398330e+01/ 轮得分 232.90\n",
      "损失函数： 0.0457025\n",
      "时间步 3227000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.281002e+01/ 轮得分 232.90\n",
      "损失函数： 0.0293929\n",
      "时间步 3228000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349251e+01/ 轮得分 233.44\n",
      "损失函数： 0.0376606\n",
      "时间步 3229000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291837e+01/ 轮得分 233.44\n",
      "损失函数： 0.0144021\n",
      "时间步 3230000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.529160e+01/ 轮得分 233.44\n",
      "损失函数： 0.053111\n",
      "时间步 3231000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193612e+01/ 轮得分 233.44\n",
      "损失函数： 0.0484784\n",
      "时间步 3232000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.285676e+01/ 轮得分 233.44\n",
      "损失函数： 0.0388828\n",
      "时间步 3233000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.294940e+01/ 轮得分 233.93\n",
      "损失函数： 0.0569686\n",
      "时间步 3234000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349744e+01/ 轮得分 233.93\n",
      "损失函数： 0.0253889\n",
      "时间步 3235000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.184280e+01/ 轮得分 234.12\n",
      "损失函数： 0.0590453\n",
      "时间步 3236000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348014e+01/ 轮得分 234.12\n",
      "损失函数： 0.0308075\n",
      "时间步 3237000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234437e+01/ 轮得分 234.34\n",
      "损失函数： 0.0167802\n",
      "时间步 3238000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 4.751175e+00/ 轮得分 234.34\n",
      "损失函数： 0.0188051\n",
      "时间步 3239000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.343625e+01/ 轮得分 234.41\n",
      "损失函数： 0.134519\n",
      "时间步 3240000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238759e+01/ 轮得分 234.53\n",
      "损失函数： 0.0225152\n",
      "时间步 3241000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391697e+01/ 轮得分 234.61\n",
      "损失函数： 0.0505468\n",
      "时间步 3242000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267197e+01/ 轮得分 234.61\n",
      "损失函数： 0.0794091\n",
      "时间步 3243000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.481669e+01/ 轮得分 234.61\n",
      "损失函数： 0.0240878\n",
      "时间步 3244000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.064317e+01/ 轮得分 234.61\n",
      "损失函数： 0.020857\n",
      "时间步 3245000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.176368e+01/ 轮得分 234.98\n",
      "损失函数： 0.0376859\n",
      "时间步 3246000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307582e+01/ 轮得分 234.98\n",
      "损失函数： 0.0410416\n",
      "时间步 3247000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181851e+01/ 轮得分 235.13\n",
      "损失函数： 0.0204306\n",
      "时间步 3248000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.246735e+01/ 轮得分 235.13\n",
      "损失函数： 0.0227082\n",
      "时间步 3249000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.226357e+01/ 轮得分 235.13\n",
      "损失函数： 0.0449698\n",
      "时间步 3250000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.505445e+01/ 轮得分 235.13\n",
      "损失函数： 0.0764306\n",
      "时间步 3251000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273564e+01/ 轮得分 235.13\n",
      "损失函数： 0.0145358\n",
      "时间步 3252000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.395608e+01/ 轮得分 235.13\n",
      "损失函数： 0.0205858\n",
      "时间步 3253000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206820e+01/ 轮得分 235.62\n",
      "损失函数： 0.0254192\n",
      "时间步 3254000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276871e+01/ 轮得分 235.62\n",
      "损失函数： 0.0190649\n",
      "时间步 3255000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.569455e+01/ 轮得分 235.62\n",
      "损失函数： 0.0440354\n",
      "时间步 3256000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359538e+01/ 轮得分 235.62\n",
      "损失函数： 0.0373445\n",
      "时间步 3257000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256660e+01/ 轮得分 235.62\n",
      "损失函数： 0.0451888\n",
      "时间步 3258000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324353e+01/ 轮得分 235.62\n",
      "损失函数： 0.0235675\n",
      "时间步 3259000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316275e+01/ 轮得分 235.62\n",
      "损失函数： 0.0258426\n",
      "时间步 3260000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.126164e+01/ 轮得分 235.62\n",
      "损失函数： 0.0339649\n",
      "时间步 3261000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.145955e+01/ 轮得分 236.49\n",
      "损失函数： 0.0254457\n",
      "时间步 3262000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.156770e+01/ 轮得分 236.49\n",
      "损失函数： 0.0145244\n",
      "时间步 3263000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339792e+01/ 轮得分 236.49\n",
      "损失函数： 0.0529744\n",
      "时间步 3264000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244136e+01/ 轮得分 236.49\n",
      "损失函数： 0.0304731\n",
      "时间步 3265000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.601859e+01/ 轮得分 237.06\n",
      "损失函数： 0.0850994\n",
      "时间步 3266000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.048658e+01/ 轮得分 237.06\n",
      "损失函数： 0.0120775\n",
      "时间步 3267000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220958e+01/ 轮得分 237.06\n",
      "损失函数： 0.0280887\n",
      "时间步 3268000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308578e+01/ 轮得分 237.06\n",
      "损失函数： 0.0233346\n",
      "时间步 3269000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237555e+01/ 轮得分 237.38\n",
      "损失函数： 0.0633219\n",
      "时间步 3270000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.144750e+01/ 轮得分 237.50\n",
      "损失函数： 0.05194\n",
      "时间步 3271000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.397919e+01/ 轮得分 237.50\n",
      "损失函数： 0.0312257\n",
      "时间步 3272000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.371745e+01/ 轮得分 237.50\n",
      "损失函数： 0.105626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3273000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.182900e+01/ 轮得分 237.50\n",
      "损失函数： 0.0146067\n",
      "时间步 3274000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294637e+01/ 轮得分 237.50\n",
      "损失函数： 0.0218306\n",
      "时间步 3275000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347237e+01/ 轮得分 237.79\n",
      "损失函数： 0.0340561\n",
      "时间步 3276000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.501201e+01/ 轮得分 237.79\n",
      "损失函数： 0.0384234\n",
      "时间步 3277000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.395769e+01/ 轮得分 237.79\n",
      "损失函数： 0.0344894\n",
      "时间步 3278000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.439853e+01/ 轮得分 237.79\n",
      "损失函数： 0.0313095\n",
      "时间步 3279000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291730e+01/ 轮得分 237.79\n",
      "损失函数： 0.0321357\n",
      "时间步 3280000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396614e+01/ 轮得分 238.26\n",
      "损失函数： 0.112022\n",
      "时间步 3281000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.408468e+01/ 轮得分 238.12\n",
      "损失函数： 0.0435926\n",
      "时间步 3282000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.451211e+01/ 轮得分 238.01\n",
      "损失函数： 0.0244592\n",
      "时间步 3283000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383067e+01/ 轮得分 238.01\n",
      "损失函数： 0.0211527\n",
      "时间步 3284000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202555e+01/ 轮得分 238.01\n",
      "损失函数： 0.0450672\n",
      "时间步 3285000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.214531e+01/ 轮得分 238.26\n",
      "损失函数： 0.033077\n",
      "时间步 3286000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233624e+01/ 轮得分 238.25\n",
      "损失函数： 0.0200557\n",
      "时间步 3287000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.281223e+01/ 轮得分 238.25\n",
      "损失函数： 0.0487421\n",
      "时间步 3288000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.334395e+01/ 轮得分 238.32\n",
      "损失函数： 0.0158789\n",
      "时间步 3289000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267286e+01/ 轮得分 238.32\n",
      "损失函数： 0.0107536\n",
      "时间步 3290000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.455958e+01/ 轮得分 238.39\n",
      "损失函数： 0.0503093\n",
      "时间步 3291000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319906e+01/ 轮得分 238.30\n",
      "损失函数： 0.0165664\n",
      "时间步 3292000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345398e+01/ 轮得分 238.30\n",
      "损失函数： 0.0101389\n",
      "时间步 3293000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318403e+01/ 轮得分 238.30\n",
      "损失函数： 0.0979169\n",
      "时间步 3294000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311526e+01/ 轮得分 238.66\n",
      "损失函数： 0.0317517\n",
      "时间步 3295000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.179595e+01/ 轮得分 238.60\n",
      "损失函数： 0.0377131\n",
      "时间步 3296000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.032032e+01/ 轮得分 238.60\n",
      "损失函数： 0.0901617\n",
      "时间步 3297000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303804e+01/ 轮得分 238.60\n",
      "损失函数： 0.0361394\n",
      "时间步 3298000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361469e+01/ 轮得分 238.60\n",
      "损失函数： 0.076175\n",
      "时间步 3299000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.392173e+01/ 轮得分 238.60\n",
      "损失函数： 0.0144059\n",
      "时间步 3300000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236146e+01/ 轮得分 238.60\n",
      "损失函数： 0.0412487\n",
      "时间步 3301000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.546563e+01/ 轮得分 238.60\n",
      "损失函数： 0.0426797\n",
      "时间步 3302000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338866e+01/ 轮得分 238.60\n",
      "损失函数： 0.0595173\n",
      "时间步 3303000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.403352e+01/ 轮得分 239.40\n",
      "损失函数： 0.0365547\n",
      "时间步 3304000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304429e+01/ 轮得分 239.40\n",
      "损失函数： 0.040335\n",
      "时间步 3305000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.402915e+01/ 轮得分 239.40\n",
      "损失函数： 0.0425038\n",
      "时间步 3306000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190360e+01/ 轮得分 239.40\n",
      "损失函数： 0.0233817\n",
      "时间步 3307000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 5.119957e+00/ 轮得分 239.40\n",
      "损失函数： 0.0757165\n",
      "时间步 3308000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337029e+01/ 轮得分 239.98\n",
      "损失函数： 0.0404172\n",
      "时间步 3309000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307785e+01/ 轮得分 239.98\n",
      "损失函数： 0.0183017\n",
      "时间步 3310000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375742e+01/ 轮得分 240.25\n",
      "损失函数： 0.0194183\n",
      "时间步 3311000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.281011e+01/ 轮得分 240.29\n",
      "损失函数： 0.0560258\n",
      "时间步 3312000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418171e+01/ 轮得分 240.29\n",
      "损失函数： 0.0388371\n",
      "时间步 3313000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.477327e+01/ 轮得分 240.29\n",
      "损失函数： 0.0173056\n",
      "时间步 3314000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329293e+01/ 轮得分 240.57\n",
      "损失函数： 0.0170115\n",
      "时间步 3315000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339398e+01/ 轮得分 240.66\n",
      "损失函数： 0.0621855\n",
      "时间步 3316000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311887e+01/ 轮得分 240.66\n",
      "损失函数： 0.00963516\n",
      "时间步 3317000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384035e+01/ 轮得分 240.22\n",
      "损失函数： 0.0960349\n",
      "时间步 3318000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412137e+01/ 轮得分 240.22\n",
      "损失函数： 0.0272122\n",
      "时间步 3319000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411411e+01/ 轮得分 240.22\n",
      "损失函数： 0.160062\n",
      "时间步 3320000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224709e+01/ 轮得分 240.22\n",
      "损失函数： 0.0336151\n",
      "时间步 3321000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298132e+01/ 轮得分 240.63\n",
      "损失函数： 0.0360289\n",
      "时间步 3322000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.729708e+01/ 轮得分 240.63\n",
      "损失函数： 0.035428\n",
      "时间步 3323000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185548e+01/ 轮得分 240.63\n",
      "损失函数： 0.0241497\n",
      "时间步 3324000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.543093e+01/ 轮得分 240.63\n",
      "损失函数： 0.0455393\n",
      "时间步 3325000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.425924e+01/ 轮得分 241.04\n",
      "损失函数： 0.0696342\n",
      "时间步 3326000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.280392e+01/ 轮得分 241.04\n",
      "损失函数： 0.0137115\n",
      "时间步 3327000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.552301e+01/ 轮得分 240.86\n",
      "损失函数： 0.0104582\n",
      "时间步 3328000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239507e+01/ 轮得分 240.86\n",
      "损失函数： 0.0254203\n",
      "时间步 3329000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.366695e+01/ 轮得分 240.64\n",
      "损失函数： 0.0545782\n",
      "时间步 3330000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388818e+01/ 轮得分 240.64\n",
      "损失函数： 0.0646596\n",
      "时间步 3331000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389846e+01/ 轮得分 240.64\n",
      "损失函数： 0.0235032\n",
      "时间步 3332000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319423e+01/ 轮得分 240.94\n",
      "损失函数： 0.0759837\n",
      "时间步 3333000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.449211e+01/ 轮得分 240.94\n",
      "损失函数： 0.0227606\n",
      "时间步 3334000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.526150e+01/ 轮得分 240.94\n",
      "损失函数： 0.0229095\n",
      "时间步 3335000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362189e+01/ 轮得分 240.94\n",
      "损失函数： 0.0252467\n",
      "时间步 3336000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165388e+01/ 轮得分 240.94\n",
      "损失函数： 0.046505\n",
      "时间步 3337000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.506683e+01/ 轮得分 240.94\n",
      "损失函数： 0.0492543\n",
      "时间步 3338000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 9.345853e+00/ 轮得分 240.94\n",
      "损失函数： 0.0254958\n",
      "时间步 3339000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.138871e+01/ 轮得分 240.94\n",
      "损失函数： 0.0301578\n",
      "时间步 3340000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389808e+01/ 轮得分 240.94\n",
      "损失函数： 0.0496765\n",
      "时间步 3341000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.372113e+01/ 轮得分 240.94\n",
      "损失函数： 0.0327343\n",
      "时间步 3342000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.419369e+01/ 轮得分 240.94\n",
      "损失函数： 0.043187\n",
      "时间步 3343000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.495629e+01/ 轮得分 240.94\n",
      "损失函数： 0.0222598\n",
      "时间步 3344000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.092560e+01/ 轮得分 240.94\n",
      "损失函数： 0.0174901\n",
      "时间步 3345000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332676e+01/ 轮得分 242.50\n",
      "损失函数： 0.077638\n",
      "时间步 3346000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345152e+01/ 轮得分 242.50\n",
      "损失函数： 0.0095427\n",
      "时间步 3347000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.146972e+01/ 轮得分 242.50\n",
      "损失函数： 0.042143\n",
      "时间步 3348000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.125139e+01/ 轮得分 242.50\n",
      "损失函数： 0.0155162\n",
      "时间步 3349000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315393e+01/ 轮得分 242.50\n",
      "损失函数： 0.0477595\n",
      "时间步 3350000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245763e+01/ 轮得分 242.50\n",
      "损失函数： 0.0320131\n",
      "时间步 3351000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.223207e+01/ 轮得分 242.50\n",
      "损失函数： 0.0324967\n",
      "时间步 3352000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252262e+01/ 轮得分 242.50\n",
      "损失函数： 0.0183221\n",
      "时间步 3353000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293898e+01/ 轮得分 243.35\n",
      "损失函数： 0.0565518\n",
      "时间步 3354000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.458455e+01/ 轮得分 243.35\n",
      "损失函数： 0.0253167\n",
      "时间步 3355000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.336772e+01/ 轮得分 243.35\n",
      "损失函数： 0.0404661\n",
      "时间步 3356000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301450e+01/ 轮得分 243.35\n",
      "损失函数： 0.0124262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3357000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298470e+01/ 轮得分 243.35\n",
      "损失函数： 0.0232353\n",
      "时间步 3358000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.156586e+01/ 轮得分 243.35\n",
      "损失函数： 0.0171194\n",
      "时间步 3359000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.369734e+01/ 轮得分 243.35\n",
      "损失函数： 0.0301704\n",
      "时间步 3360000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.148609e+01/ 轮得分 243.35\n",
      "损失函数： 0.0211496\n",
      "时间步 3361000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.169236e+01/ 轮得分 243.35\n",
      "损失函数： 0.0326011\n",
      "时间步 3362000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.438241e+01/ 轮得分 243.35\n",
      "损失函数： 0.0247569\n",
      "时间步 3363000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.338920e+01/ 轮得分 243.35\n",
      "损失函数： 0.0378882\n",
      "时间步 3364000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.508841e+01/ 轮得分 244.58\n",
      "损失函数： 0.0267192\n",
      "时间步 3365000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.140255e+01/ 轮得分 244.58\n",
      "损失函数： 0.0675119\n",
      "时间步 3366000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 8.928308e+00/ 轮得分 244.58\n",
      "损失函数： 0.0400878\n",
      "时间步 3367000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332196e+01/ 轮得分 244.58\n",
      "损失函数： 0.0171562\n",
      "时间步 3368000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186281e+01/ 轮得分 244.58\n",
      "损失函数： 0.0497056\n",
      "时间步 3369000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.359597e+01/ 轮得分 245.12\n",
      "损失函数： 0.0110584\n",
      "时间步 3370000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266332e+01/ 轮得分 245.12\n",
      "损失函数： 0.0234728\n",
      "时间步 3371000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159782e+01/ 轮得分 245.23\n",
      "损失函数： 0.0304623\n",
      "时间步 3372000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335323e+01/ 轮得分 245.14\n",
      "损失函数： 0.0118637\n",
      "时间步 3373000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.235975e+01/ 轮得分 245.13\n",
      "损失函数： 0.0339275\n",
      "时间步 3374000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220610e+01/ 轮得分 245.13\n",
      "损失函数： 0.0123724\n",
      "时间步 3375000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.073482e+01/ 轮得分 245.36\n",
      "损失函数： 0.0692532\n",
      "时间步 3376000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.188150e+01/ 轮得分 245.45\n",
      "损失函数： 0.0341059\n",
      "时间步 3377000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296423e+01/ 轮得分 245.37\n",
      "损失函数： 0.0324274\n",
      "时间步 3378000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.515937e+01/ 轮得分 245.47\n",
      "损失函数： 0.0658583\n",
      "时间步 3379000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265692e+01/ 轮得分 245.43\n",
      "损失函数： 0.0243596\n",
      "时间步 3380000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384851e+01/ 轮得分 245.12\n",
      "损失函数： 0.0241839\n",
      "时间步 3381000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367061e+01/ 轮得分 245.11\n",
      "损失函数： 0.10257\n",
      "时间步 3382000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.320060e+01/ 轮得分 245.11\n",
      "损失函数： 0.0374717\n",
      "时间步 3383000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.174164e+01/ 轮得分 245.11\n",
      "损失函数： 0.0252835\n",
      "时间步 3384000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.382203e+01/ 轮得分 245.39\n",
      "损失函数： 0.0371661\n",
      "时间步 3385000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312248e+01/ 轮得分 245.48\n",
      "损失函数： 0.0280878\n",
      "时间步 3386000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256577e+01/ 轮得分 245.46\n",
      "损失函数： 0.0451816\n",
      "时间步 3387000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366243e+01/ 轮得分 245.46\n",
      "损失函数： 0.0529107\n",
      "时间步 3388000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337694e+01/ 轮得分 245.59\n",
      "损失函数： 0.024293\n",
      "时间步 3389000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.496615e+01/ 轮得分 245.59\n",
      "损失函数： 0.0398772\n",
      "时间步 3390000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.286682e+01/ 轮得分 245.75\n",
      "损失函数： 0.0993399\n",
      "时间步 3391000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.543126e+01/ 轮得分 245.86\n",
      "损失函数： 0.0931308\n",
      "时间步 3392000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390757e+01/ 轮得分 245.86\n",
      "损失函数： 0.0195875\n",
      "时间步 3393000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266470e+01/ 轮得分 245.12\n",
      "损失函数： 0.038594\n",
      "时间步 3394000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330313e+01/ 轮得分 245.12\n",
      "损失函数： 0.0269017\n",
      "时间步 3395000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.417692e+01/ 轮得分 245.12\n",
      "损失函数： 0.103199\n",
      "时间步 3396000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.275420e+01/ 轮得分 245.12\n",
      "损失函数： 0.0186346\n",
      "时间步 3397000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197936e+01/ 轮得分 245.12\n",
      "损失函数： 0.062519\n",
      "时间步 3398000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327110e+01/ 轮得分 245.63\n",
      "损失函数： 0.0344892\n",
      "时间步 3399000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.501758e+01/ 轮得分 245.63\n",
      "损失函数： 0.0324722\n",
      "时间步 3400000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201359e+01/ 轮得分 245.63\n",
      "损失函数： 0.0273586\n",
      "时间步 3401000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.382735e+01/ 轮得分 245.98\n",
      "损失函数： 0.0116869\n",
      "时间步 3402000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.108678e+01/ 轮得分 245.98\n",
      "损失函数： 0.0228991\n",
      "时间步 3403000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.325943e+01/ 轮得分 245.98\n",
      "损失函数： 0.0349554\n",
      "时间步 3404000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384911e+01/ 轮得分 245.98\n",
      "损失函数： 0.029484\n",
      "时间步 3405000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 7.634943e+00/ 轮得分 245.98\n",
      "损失函数： 0.0333631\n",
      "时间步 3406000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.463648e+01/ 轮得分 245.98\n",
      "损失函数： 0.0658345\n",
      "时间步 3407000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.207739e+01/ 轮得分 246.64\n",
      "损失函数： 0.0323779\n",
      "时间步 3408000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.190786e+01/ 轮得分 246.64\n",
      "损失函数： 0.0323345\n",
      "时间步 3409000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.201353e+01/ 轮得分 246.64\n",
      "损失函数： 0.0998342\n",
      "时间步 3410000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.404559e+01/ 轮得分 246.64\n",
      "损失函数： 0.0369801\n",
      "时间步 3411000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.386476e+01/ 轮得分 246.64\n",
      "损失函数： 0.0301627\n",
      "时间步 3412000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267360e+01/ 轮得分 247.08\n",
      "损失函数： 0.0242522\n",
      "时间步 3413000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.395164e+01/ 轮得分 247.08\n",
      "损失函数： 0.0454334\n",
      "时间步 3414000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.292646e+01/ 轮得分 247.08\n",
      "损失函数： 0.0732583\n",
      "时间步 3415000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.272452e+01/ 轮得分 247.39\n",
      "损失函数： 0.048509\n",
      "时间步 3416000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.382620e+01/ 轮得分 247.39\n",
      "损失函数： 0.0202176\n",
      "时间步 3417000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274900e+01/ 轮得分 247.39\n",
      "损失函数： 0.0476974\n",
      "时间步 3418000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365254e+01/ 轮得分 247.39\n",
      "损失函数： 0.0247695\n",
      "时间步 3419000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.290016e+01/ 轮得分 247.39\n",
      "损失函数： 0.0269951\n",
      "时间步 3420000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.259658e+01/ 轮得分 247.87\n",
      "损失函数： 0.0175574\n",
      "时间步 3421000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.457950e+01/ 轮得分 247.74\n",
      "损失函数： 0.0140574\n",
      "时间步 3422000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322073e+01/ 轮得分 247.80\n",
      "损失函数： 0.031665\n",
      "时间步 3423000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325365e+01/ 轮得分 247.80\n",
      "损失函数： 0.0178895\n",
      "时间步 3424000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277788e+01/ 轮得分 247.80\n",
      "损失函数： 0.0128232\n",
      "时间步 3425000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268079e+01/ 轮得分 248.13\n",
      "损失函数： 0.0379426\n",
      "时间步 3426000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296114e+01/ 轮得分 248.13\n",
      "损失函数： 0.0228645\n",
      "时间步 3427000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231773e+01/ 轮得分 248.13\n",
      "损失函数： 0.0163783\n",
      "时间步 3428000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325892e+01/ 轮得分 248.45\n",
      "损失函数： 0.0942137\n",
      "时间步 3429000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407536e+01/ 轮得分 248.46\n",
      "损失函数： 0.0518926\n",
      "时间步 3430000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.293986e+01/ 轮得分 248.46\n",
      "损失函数： 0.0563997\n",
      "时间步 3431000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.472187e+01/ 轮得分 248.46\n",
      "损失函数： 0.0540357\n",
      "时间步 3432000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262936e+01/ 轮得分 248.46\n",
      "损失函数： 0.0301963\n",
      "时间步 3433000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.428057e+01/ 轮得分 248.46\n",
      "损失函数： 0.0136953\n",
      "时间步 3434000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301180e+01/ 轮得分 248.46\n",
      "损失函数： 0.0206089\n",
      "时间步 3435000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310904e+01/ 轮得分 248.46\n",
      "损失函数： 0.0494713\n",
      "时间步 3436000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250226e+01/ 轮得分 248.46\n",
      "损失函数： 0.00825272\n",
      "时间步 3437000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.435915e+01/ 轮得分 248.46\n",
      "损失函数： 0.024053\n",
      "时间步 3438000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117865e+01/ 轮得分 249.43\n",
      "损失函数： 0.0611642\n",
      "时间步 3439000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222916e+01/ 轮得分 249.43\n",
      "损失函数： 0.0299777\n",
      "时间步 3440000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177214e+01/ 轮得分 249.43\n",
      "损失函数： 0.0440027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3441000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278589e+01/ 轮得分 249.43\n",
      "损失函数： 0.0444164\n",
      "时间步 3442000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333630e+01/ 轮得分 249.43\n",
      "损失函数： 0.0579804\n",
      "时间步 3443000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237454e+01/ 轮得分 249.43\n",
      "损失函数： 0.01875\n",
      "时间步 3444000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414572e+01/ 轮得分 250.11\n",
      "损失函数： 0.0556186\n",
      "时间步 3445000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304257e+01/ 轮得分 250.21\n",
      "损失函数： 0.0246011\n",
      "时间步 3446000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.494855e+01/ 轮得分 250.21\n",
      "损失函数： 0.0413013\n",
      "时间步 3447000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418380e+01/ 轮得分 250.22\n",
      "损失函数： 0.0173359\n",
      "时间步 3448000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161543e+01/ 轮得分 250.34\n",
      "损失函数： 0.0253053\n",
      "时间步 3449000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310293e+01/ 轮得分 250.00\n",
      "损失函数： 0.0445507\n",
      "时间步 3450000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.503665e+01/ 轮得分 250.00\n",
      "损失函数： 0.03485\n",
      "时间步 3451000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248629e+01/ 轮得分 250.00\n",
      "损失函数： 0.0460813\n",
      "时间步 3452000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348717e+01/ 轮得分 250.10\n",
      "损失函数： 0.0341746\n",
      "时间步 3453000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319616e+01/ 轮得分 250.10\n",
      "损失函数： 0.0802302\n",
      "时间步 3454000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.378302e+01/ 轮得分 250.10\n",
      "损失函数： 0.0618391\n",
      "时间步 3455000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.368409e+01/ 轮得分 250.39\n",
      "损失函数： 0.0370931\n",
      "时间步 3456000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.443161e+01/ 轮得分 250.39\n",
      "损失函数： 0.019578\n",
      "时间步 3457000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.381044e+01/ 轮得分 250.62\n",
      "损失函数： 0.0187889\n",
      "时间步 3458000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.350487e+01/ 轮得分 250.62\n",
      "损失函数： 0.0410743\n",
      "时间步 3459000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307123e+01/ 轮得分 250.62\n",
      "损失函数： 0.0192468\n",
      "时间步 3460000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.762988e+01/ 轮得分 250.62\n",
      "损失函数： 0.0167215\n",
      "时间步 3461000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310359e+01/ 轮得分 250.65\n",
      "损失函数： 0.0271955\n",
      "时间步 3462000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.492103e+01/ 轮得分 250.66\n",
      "损失函数： 0.0392666\n",
      "时间步 3463000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286584e+01/ 轮得分 250.46\n",
      "损失函数： 0.0342858\n",
      "时间步 3464000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393048e+01/ 轮得分 250.46\n",
      "损失函数： 0.0300282\n",
      "时间步 3465000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306391e+01/ 轮得分 250.46\n",
      "损失函数： 0.0314622\n",
      "时间步 3466000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307400e+01/ 轮得分 250.75\n",
      "损失函数： 0.0192976\n",
      "时间步 3467000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262221e+01/ 轮得分 250.75\n",
      "损失函数： 0.0293975\n",
      "时间步 3468000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272308e+01/ 轮得分 250.75\n",
      "损失函数： 0.0437022\n",
      "时间步 3469000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.422063e+01/ 轮得分 250.75\n",
      "损失函数： 0.117059\n",
      "时间步 3470000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.452062e+01/ 轮得分 251.15\n",
      "损失函数： 0.0466788\n",
      "时间步 3471000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.420449e+01/ 轮得分 251.15\n",
      "损失函数： 0.0225917\n",
      "时间步 3472000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448729e+01/ 轮得分 251.15\n",
      "损失函数： 0.0271011\n",
      "时间步 3473000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268859e+01/ 轮得分 251.15\n",
      "损失函数： 0.0375097\n",
      "时间步 3474000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317457e+01/ 轮得分 251.15\n",
      "损失函数： 0.0288402\n",
      "时间步 3475000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414106e+01/ 轮得分 251.15\n",
      "损失函数： 0.0672957\n",
      "时间步 3476000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372251e+01/ 轮得分 251.85\n",
      "损失函数： 0.0731902\n",
      "时间步 3477000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.055664e+01/ 轮得分 251.71\n",
      "损失函数： 0.0393974\n",
      "时间步 3478000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.214156e+01/ 轮得分 251.70\n",
      "损失函数： 0.0173908\n",
      "时间步 3479000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.500686e+01/ 轮得分 251.70\n",
      "损失函数： 0.0569891\n",
      "时间步 3480000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294936e+01/ 轮得分 251.70\n",
      "损失函数： 0.0500522\n",
      "时间步 3481000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.177468e+01/ 轮得分 251.70\n",
      "损失函数： 0.0292011\n",
      "时间步 3482000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.153277e+01/ 轮得分 252.12\n",
      "损失函数： 0.0212815\n",
      "时间步 3483000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288218e+01/ 轮得分 252.12\n",
      "损失函数： 0.0505188\n",
      "时间步 3484000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284614e+01/ 轮得分 252.12\n",
      "损失函数： 0.0372332\n",
      "时间步 3485000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.004291e+01/ 轮得分 252.12\n",
      "损失函数： 0.0440265\n",
      "时间步 3486000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.444899e+01/ 轮得分 252.12\n",
      "损失函数： 0.0770418\n",
      "时间步 3487000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.421189e+01/ 轮得分 252.12\n",
      "损失函数： 0.0169999\n",
      "时间步 3488000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.365356e+01/ 轮得分 252.82\n",
      "损失函数： 0.0503683\n",
      "时间步 3489000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414405e+01/ 轮得分 252.82\n",
      "损失函数： 0.0340179\n",
      "时间步 3490000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238217e+01/ 轮得分 252.82\n",
      "损失函数： 0.0103114\n",
      "时间步 3491000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.461958e+01/ 轮得分 252.82\n",
      "损失函数： 0.0229325\n",
      "时间步 3492000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.331765e+01/ 轮得分 252.82\n",
      "损失函数： 0.0921068\n",
      "时间步 3493000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.461306e+01/ 轮得分 252.82\n",
      "损失函数： 0.0271653\n",
      "时间步 3494000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.213401e+01/ 轮得分 253.29\n",
      "损失函数： 0.0291824\n",
      "时间步 3495000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.442505e+01/ 轮得分 252.95\n",
      "损失函数： 0.0316534\n",
      "时间步 3496000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.432894e+01/ 轮得分 252.95\n",
      "损失函数： 0.0459075\n",
      "时间步 3497000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.517372e+01/ 轮得分 252.95\n",
      "损失函数： 0.04403\n",
      "时间步 3498000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.569647e+01/ 轮得分 252.95\n",
      "损失函数： 0.0222559\n",
      "时间步 3499000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.439740e+01/ 轮得分 253.34\n",
      "损失函数： 0.0156696\n",
      "时间步 3500000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.378382e+01/ 轮得分 253.34\n",
      "损失函数： 0.0330135\n",
      "时间步 3501000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.382990e+01/ 轮得分 253.34\n",
      "损失函数： 0.0246952\n",
      "时间步 3502000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411753e+01/ 轮得分 253.66\n",
      "损失函数： 0.0559189\n",
      "时间步 3503000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.313137e+01/ 轮得分 253.66\n",
      "损失函数： 0.0350111\n",
      "时间步 3504000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330389e+01/ 轮得分 253.66\n",
      "损失函数： 0.0403063\n",
      "时间步 3505000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340867e+01/ 轮得分 253.66\n",
      "损失函数： 0.045071\n",
      "时间步 3506000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 8.773987e+00/ 轮得分 253.66\n",
      "损失函数： 0.030662\n",
      "时间步 3507000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304475e+01/ 轮得分 254.16\n",
      "损失函数： 0.0276341\n",
      "时间步 3508000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.430900e+01/ 轮得分 254.16\n",
      "损失函数： 0.029318\n",
      "时间步 3509000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274274e+01/ 轮得分 254.16\n",
      "损失函数： 0.0901669\n",
      "时间步 3510000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295694e+01/ 轮得分 254.16\n",
      "损失函数： 0.0714386\n",
      "时间步 3511000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.445539e+01/ 轮得分 254.16\n",
      "损失函数： 0.0846185\n",
      "时间步 3512000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394695e+01/ 轮得分 254.16\n",
      "损失函数： 0.028477\n",
      "时间步 3513000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.379800e+01/ 轮得分 254.16\n",
      "损失函数： 0.0357979\n",
      "时间步 3514000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268683e+01/ 轮得分 254.14\n",
      "损失函数： 0.0263911\n",
      "时间步 3515000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302796e+01/ 轮得分 254.14\n",
      "损失函数： 0.0152568\n",
      "时间步 3516000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.357223e+01/ 轮得分 254.14\n",
      "损失函数： 0.0334381\n",
      "时间步 3517000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.501980e+01/ 轮得分 254.08\n",
      "损失函数： 0.033025\n",
      "时间步 3518000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447101e+01/ 轮得分 254.08\n",
      "损失函数： 0.0472144\n",
      "时间步 3519000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.285674e+01/ 轮得分 254.08\n",
      "损失函数： 0.0580867\n",
      "时间步 3520000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.193160e+01/ 轮得分 254.08\n",
      "损失函数： 0.0282922\n",
      "时间步 3521000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394367e+01/ 轮得分 254.25\n",
      "损失函数： 0.0706102\n",
      "时间步 3522000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.272697e+01/ 轮得分 254.25\n",
      "损失函数： 0.171658\n",
      "时间步 3523000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.173326e+01/ 轮得分 254.25\n",
      "损失函数： 0.0528157\n",
      "时间步 3524000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314532e+01/ 轮得分 254.25\n",
      "损失函数： 0.0242927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3525000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.171031e+01/ 轮得分 254.25\n",
      "损失函数： 0.108614\n",
      "时间步 3526000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 8.233405e+00/ 轮得分 254.25\n",
      "损失函数： 0.0545229\n",
      "时间步 3527000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346196e+01/ 轮得分 254.25\n",
      "损失函数： 0.043295\n",
      "时间步 3528000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.353740e+01/ 轮得分 254.73\n",
      "损失函数： 0.199023\n",
      "时间步 3529000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.543564e+01/ 轮得分 254.73\n",
      "损失函数： 0.0147343\n",
      "时间步 3530000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.471064e+01/ 轮得分 254.73\n",
      "损失函数： 0.02715\n",
      "时间步 3531000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.514621e+01/ 轮得分 254.73\n",
      "损失函数： 0.0159969\n",
      "时间步 3532000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.601029e+01/ 轮得分 254.73\n",
      "损失函数： 0.0365612\n",
      "时间步 3533000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377604e+01/ 轮得分 254.73\n",
      "损失函数： 0.0344127\n",
      "时间步 3534000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.467729e+01/ 轮得分 254.73\n",
      "损失函数： 0.0413394\n",
      "时间步 3535000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279805e+01/ 轮得分 254.73\n",
      "损失函数： 0.0172462\n",
      "时间步 3536000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.257120e+01/ 轮得分 255.67\n",
      "损失函数： 0.0339855\n",
      "时间步 3537000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.236868e+01/ 轮得分 255.67\n",
      "损失函数： 0.0600763\n",
      "时间步 3538000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.218115e+01/ 轮得分 255.67\n",
      "损失函数： 0.0224827\n",
      "时间步 3539000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.124500e+01/ 轮得分 255.67\n",
      "损失函数： 0.0346668\n",
      "时间步 3540000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.332416e+01/ 轮得分 255.71\n",
      "损失函数： 0.0298641\n",
      "时间步 3541000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329146e+01/ 轮得分 255.71\n",
      "损失函数： 0.0227533\n",
      "时间步 3542000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.592014e+01/ 轮得分 256.00\n",
      "损失函数： 0.0238433\n",
      "时间步 3543000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.148430e+01/ 轮得分 256.00\n",
      "损失函数： 0.0480221\n",
      "时间步 3544000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.406880e+01/ 轮得分 256.00\n",
      "损失函数： 0.0696981\n",
      "时间步 3545000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207000e+01/ 轮得分 255.87\n",
      "损失函数： 0.0314788\n",
      "时间步 3546000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.237642e+01/ 轮得分 255.82\n",
      "损失函数： 0.0402718\n",
      "时间步 3547000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.395686e+01/ 轮得分 255.82\n",
      "损失函数： 0.0188275\n",
      "时间步 3548000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326186e+01/ 轮得分 255.82\n",
      "损失函数： 0.0178551\n",
      "时间步 3549000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210295e+01/ 轮得分 255.82\n",
      "损失函数： 0.0684409\n",
      "时间步 3550000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391847e+01/ 轮得分 255.82\n",
      "损失函数： 0.0190107\n",
      "时间步 3551000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.221317e+01/ 轮得分 256.07\n",
      "损失函数： 0.0602619\n",
      "时间步 3552000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295552e+01/ 轮得分 256.20\n",
      "损失函数： 0.0226107\n",
      "时间步 3553000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212240e+01/ 轮得分 256.20\n",
      "损失函数： 0.055909\n",
      "时间步 3554000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231421e+01/ 轮得分 256.20\n",
      "损失函数： 0.0212189\n",
      "时间步 3555000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.401137e+01/ 轮得分 256.20\n",
      "损失函数： 2.89797\n",
      "时间步 3556000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312875e+01/ 轮得分 256.59\n",
      "损失函数： 0.0266032\n",
      "时间步 3557000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273249e+01/ 轮得分 256.59\n",
      "损失函数： 0.0188511\n",
      "时间步 3558000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191037e+01/ 轮得分 256.75\n",
      "损失函数： 0.0212591\n",
      "时间步 3559000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.395871e+01/ 轮得分 256.75\n",
      "损失函数： 0.0560712\n",
      "时间步 3560000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298461e+01/ 轮得分 256.75\n",
      "损失函数： 0.545702\n",
      "时间步 3561000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.307900e+01/ 轮得分 256.75\n",
      "损失函数： 0.0189849\n",
      "时间步 3562000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.172215e+01/ 轮得分 256.75\n",
      "损失函数： 0.0554146\n",
      "时间步 3563000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.245853e+01/ 轮得分 256.75\n",
      "损失函数： 0.0174904\n",
      "时间步 3564000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359326e+01/ 轮得分 256.75\n",
      "损失函数： 0.0500885\n",
      "时间步 3565000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305505e+01/ 轮得分 256.75\n",
      "损失函数： 2.01195\n",
      "时间步 3566000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.296616e+01/ 轮得分 256.75\n",
      "损失函数： 0.0205353\n",
      "时间步 3567000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.431747e+01/ 轮得分 257.69\n",
      "损失函数： 0.0225256\n",
      "时间步 3568000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270087e+01/ 轮得分 257.69\n",
      "损失函数： 0.0114703\n",
      "时间步 3569000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225571e+01/ 轮得分 257.69\n",
      "损失函数： 0.0178051\n",
      "时间步 3570000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262640e+01/ 轮得分 258.01\n",
      "损失函数： 0.0620338\n",
      "时间步 3571000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.215384e+01/ 轮得分 258.01\n",
      "损失函数： 0.0418283\n",
      "时间步 3572000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.560721e+01/ 轮得分 258.01\n",
      "损失函数： 0.0435088\n",
      "时间步 3573000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191061e+01/ 轮得分 258.01\n",
      "损失函数： 0.0190814\n",
      "时间步 3574000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.357093e+01/ 轮得分 258.01\n",
      "损失函数： 0.0258135\n",
      "时间步 3575000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248892e+01/ 轮得分 258.00\n",
      "损失函数： 0.0303874\n",
      "时间步 3576000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355516e+01/ 轮得分 258.00\n",
      "损失函数： 0.0138978\n",
      "时间步 3577000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.184872e+01/ 轮得分 258.00\n",
      "损失函数： 0.0419564\n",
      "时间步 3578000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326861e+01/ 轮得分 258.31\n",
      "损失函数： 0.0153013\n",
      "时间步 3579000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377384e+01/ 轮得分 258.31\n",
      "损失函数： 0.0367655\n",
      "时间步 3580000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394607e+01/ 轮得分 258.55\n",
      "损失函数： 0.0411414\n",
      "时间步 3581000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361257e+01/ 轮得分 258.43\n",
      "损失函数： 0.0358351\n",
      "时间步 3582000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320672e+01/ 轮得分 258.43\n",
      "损失函数： 0.0689192\n",
      "时间步 3583000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259258e+01/ 轮得分 258.43\n",
      "损失函数： 0.0579062\n",
      "时间步 3584000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.257697e+01/ 轮得分 258.43\n",
      "损失函数： 0.0341932\n",
      "时间步 3585000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360924e+01/ 轮得分 258.43\n",
      "损失函数： 0.0244368\n",
      "时间步 3586000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.122604e+01/ 轮得分 258.85\n",
      "损失函数： 0.0165336\n",
      "时间步 3587000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282951e+01/ 轮得分 258.85\n",
      "损失函数： 0.0394394\n",
      "时间步 3588000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.025328e+01/ 轮得分 258.85\n",
      "损失函数： 0.0655722\n",
      "时间步 3589000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362686e+01/ 轮得分 259.14\n",
      "损失函数： 0.0146675\n",
      "时间步 3590000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.332072e+01/ 轮得分 259.15\n",
      "损失函数： 0.0245723\n",
      "时间步 3591000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246835e+01/ 轮得分 259.15\n",
      "损失函数： 0.0306785\n",
      "时间步 3592000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345381e+01/ 轮得分 259.15\n",
      "损失函数： 0.024605\n",
      "时间步 3593000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321048e+01/ 轮得分 259.15\n",
      "损失函数： 0.0330288\n",
      "时间步 3594000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.476236e+01/ 轮得分 259.15\n",
      "损失函数： 0.0313879\n",
      "时间步 3595000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.440284e+01/ 轮得分 259.15\n",
      "损失函数： 0.0205953\n",
      "时间步 3596000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224900e+01/ 轮得分 259.82\n",
      "损失函数： 0.0475122\n",
      "时间步 3597000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.023587e+01/ 轮得分 259.82\n",
      "损失函数： 0.0140048\n",
      "时间步 3598000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.232534e+01/ 轮得分 259.82\n",
      "损失函数： 0.0136559\n",
      "时间步 3599000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239107e+01/ 轮得分 259.93\n",
      "损失函数： 0.0211103\n",
      "时间步 3600000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335815e+01/ 轮得分 259.93\n",
      "损失函数： 0.0651931\n",
      "时间步 3601000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.108278e+01/ 轮得分 260.05\n",
      "损失函数： 0.0305926\n",
      "时间步 3602000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.428087e+01/ 轮得分 260.09\n",
      "损失函数： 0.060393\n",
      "时间步 3603000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.350431e+01/ 轮得分 260.09\n",
      "损失函数： 0.0413776\n",
      "时间步 3604000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.278167e+01/ 轮得分 260.09\n",
      "损失函数： 0.0135867\n",
      "时间步 3605000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193335e+01/ 轮得分 260.09\n",
      "损失函数： 0.0179246\n",
      "时间步 3606000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376404e+01/ 轮得分 260.09\n",
      "损失函数： 0.0482031\n",
      "时间步 3607000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.217313e+01/ 轮得分 260.09\n",
      "损失函数： 0.11439\n",
      "时间步 3608000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.232858e+01/ 轮得分 260.83\n",
      "损失函数： 0.0247144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3609000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185351e+01/ 轮得分 260.42\n",
      "损失函数： 0.0200477\n",
      "时间步 3610000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237717e+01/ 轮得分 260.59\n",
      "损失函数： 0.031976\n",
      "时间步 3611000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.149375e+01/ 轮得分 260.59\n",
      "损失函数： 0.0379551\n",
      "时间步 3612000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282681e+01/ 轮得分 260.59\n",
      "损失函数： 0.00855649\n",
      "时间步 3613000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411160e+01/ 轮得分 260.59\n",
      "损失函数： 0.0683274\n",
      "时间步 3614000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234105e+01/ 轮得分 260.59\n",
      "损失函数： 0.0528867\n",
      "时间步 3615000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273044e+01/ 轮得分 260.59\n",
      "损失函数： 2.7628\n",
      "时间步 3616000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187577e+01/ 轮得分 261.25\n",
      "损失函数： 0.0375286\n",
      "时间步 3617000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117439e+01/ 轮得分 261.31\n",
      "损失函数： 0.0177063\n",
      "时间步 3618000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249642e+01/ 轮得分 261.31\n",
      "损失函数： 3.28329\n",
      "时间步 3619000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366906e+01/ 轮得分 261.41\n",
      "损失函数： 0.0634144\n",
      "时间步 3620000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.073477e+01/ 轮得分 261.31\n",
      "损失函数： 0.0320104\n",
      "时间步 3621000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280369e+01/ 轮得分 261.39\n",
      "损失函数： 0.0870311\n",
      "时间步 3622000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.347457e+01/ 轮得分 261.39\n",
      "损失函数： 0.0343692\n",
      "时间步 3623000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.084802e+01/ 轮得分 261.39\n",
      "损失函数： 0.0536649\n",
      "时间步 3624000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.424056e+01/ 轮得分 261.39\n",
      "损失函数： 0.0391828\n",
      "时间步 3625000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337888e+01/ 轮得分 261.39\n",
      "损失函数： 0.00733779\n",
      "时间步 3626000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.108865e+01/ 轮得分 261.62\n",
      "损失函数： 0.0436084\n",
      "时间步 3627000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.152668e+01/ 轮得分 261.66\n",
      "损失函数： 0.0662665\n",
      "时间步 3628000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249690e+01/ 轮得分 261.66\n",
      "损失函数： 0.0118527\n",
      "时间步 3629000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.336690e+01/ 轮得分 261.66\n",
      "损失函数： 0.0133989\n",
      "时间步 3630000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.420859e+01/ 轮得分 261.66\n",
      "损失函数： 0.0618559\n",
      "时间步 3631000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.530316e+00/ 轮得分 261.66\n",
      "损失函数： 0.0401664\n",
      "时间步 3632000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.111248e+01/ 轮得分 261.66\n",
      "损失函数： 0.0314511\n",
      "时间步 3633000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.084242e+01/ 轮得分 261.66\n",
      "损失函数： 0.029041\n",
      "时间步 3634000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.154694e+01/ 轮得分 261.66\n",
      "损失函数： 0.0302643\n",
      "时间步 3635000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.058966e+01/ 轮得分 261.66\n",
      "损失函数： 0.122246\n",
      "时间步 3636000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.120073e+01/ 轮得分 262.51\n",
      "损失函数： 0.0122859\n",
      "时间步 3637000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.830268e+00/ 轮得分 262.51\n",
      "损失函数： 0.032203\n",
      "时间步 3638000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.369135e+01/ 轮得分 262.47\n",
      "损失函数： 0.0339395\n",
      "时间步 3639000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205966e+01/ 轮得分 262.51\n",
      "损失函数： 0.0610604\n",
      "时间步 3640000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241944e+01/ 轮得分 262.51\n",
      "损失函数： 0.0302579\n",
      "时间步 3641000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279001e+01/ 轮得分 262.51\n",
      "损失函数： 0.031572\n",
      "时间步 3642000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.395519e+01/ 轮得分 262.51\n",
      "损失函数： 0.0228363\n",
      "时间步 3643000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.537697e+01/ 轮得分 262.69\n",
      "损失函数： 0.164751\n",
      "时间步 3644000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.151659e+01/ 轮得分 262.75\n",
      "损失函数： 0.0365642\n",
      "时间步 3645000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270337e+01/ 轮得分 262.57\n",
      "损失函数： 0.00869841\n",
      "时间步 3646000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.264210e+01/ 轮得分 262.57\n",
      "损失函数： 0.0209451\n",
      "时间步 3647000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.261508e+01/ 轮得分 262.45\n",
      "损失函数： 0.0425494\n",
      "时间步 3648000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357412e+01/ 轮得分 262.45\n",
      "损失函数： 0.0475344\n",
      "时间步 3649000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197174e+01/ 轮得分 262.45\n",
      "损失函数： 0.0503972\n",
      "时间步 3650000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.245085e+01/ 轮得分 262.69\n",
      "损失函数： 0.0138333\n",
      "时间步 3651000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.568608e+01/ 轮得分 262.69\n",
      "损失函数： 0.0206049\n",
      "时间步 3652000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.167643e+01/ 轮得分 262.69\n",
      "损失函数： 0.0144282\n",
      "时间步 3653000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.528542e+01/ 轮得分 262.69\n",
      "损失函数： 0.0469175\n",
      "时间步 3654000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.240683e+01/ 轮得分 262.69\n",
      "损失函数： 0.0265141\n",
      "时间步 3655000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340621e+01/ 轮得分 262.69\n",
      "损失函数： 0.0186768\n",
      "时间步 3656000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.387404e+01/ 轮得分 262.69\n",
      "损失函数： 0.0253286\n",
      "时间步 3657000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225068e+01/ 轮得分 263.46\n",
      "损失函数： 0.0211026\n",
      "时间步 3658000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274402e+01/ 轮得分 263.46\n",
      "损失函数： 0.0409583\n",
      "时间步 3659000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251349e+01/ 轮得分 263.46\n",
      "损失函数： 0.0722864\n",
      "时间步 3660000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.333291e+01/ 轮得分 263.46\n",
      "损失函数： 0.0165294\n",
      "时间步 3661000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273400e+01/ 轮得分 263.46\n",
      "损失函数： 0.0221579\n",
      "时间步 3662000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.148981e+01/ 轮得分 263.46\n",
      "损失函数： 0.0223596\n",
      "时间步 3663000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.011357e+01/ 轮得分 263.46\n",
      "损失函数： 0.0511063\n",
      "时间步 3664000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269677e+01/ 轮得分 263.46\n",
      "损失函数： 0.0145138\n",
      "时间步 3665000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324163e+01/ 轮得分 263.46\n",
      "损失函数： 0.0165357\n",
      "时间步 3666000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349557e+01/ 轮得分 264.19\n",
      "损失函数： 0.0255169\n",
      "时间步 3667000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.318993e+01/ 轮得分 264.19\n",
      "损失函数： 0.0203154\n",
      "时间步 3668000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.350035e+01/ 轮得分 264.19\n",
      "损失函数： 0.0805794\n",
      "时间步 3669000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222160e+01/ 轮得分 264.48\n",
      "损失函数： 0.0315716\n",
      "时间步 3670000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219204e+01/ 轮得分 264.55\n",
      "损失函数： 0.0299338\n",
      "时间步 3671000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.143492e+01/ 轮得分 264.43\n",
      "损失函数： 0.0372267\n",
      "时间步 3672000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.475418e+01/ 轮得分 264.43\n",
      "损失函数： 0.0148156\n",
      "时间步 3673000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272588e+01/ 轮得分 264.43\n",
      "损失函数： 0.0184489\n",
      "时间步 3674000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245117e+01/ 轮得分 264.58\n",
      "损失函数： 0.0373039\n",
      "时间步 3675000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186182e+01/ 轮得分 264.58\n",
      "损失函数： 0.0535925\n",
      "时间步 3676000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.104469e+01/ 轮得分 264.58\n",
      "损失函数： 0.0613499\n",
      "时间步 3677000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.398015e+01/ 轮得分 264.44\n",
      "损失函数： 0.0164014\n",
      "时间步 3678000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202350e+01/ 轮得分 264.44\n",
      "损失函数： 0.0474828\n",
      "时间步 3679000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.214203e+01/ 轮得分 264.24\n",
      "损失函数： 0.0242066\n",
      "时间步 3680000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.174554e+01/ 轮得分 264.25\n",
      "损失函数： 0.0686865\n",
      "时间步 3681000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220335e+01/ 轮得分 264.25\n",
      "损失函数： 0.0247592\n",
      "时间步 3682000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320124e+01/ 轮得分 264.25\n",
      "损失函数： 0.0510113\n",
      "时间步 3683000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.202890e+01/ 轮得分 264.54\n",
      "损失函数： 0.0217221\n",
      "时间步 3684000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228221e+01/ 轮得分 264.16\n",
      "损失函数： 0.0875098\n",
      "时间步 3685000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.313991e+01/ 轮得分 264.16\n",
      "损失函数： 0.0317844\n",
      "时间步 3686000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.183703e+01/ 轮得分 264.30\n",
      "损失函数： 0.0157856\n",
      "时间步 3687000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332581e+01/ 轮得分 264.30\n",
      "损失函数： 0.0383081\n",
      "时间步 3688000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282413e+01/ 轮得分 264.30\n",
      "损失函数： 0.0177281\n",
      "时间步 3689000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335693e+01/ 轮得分 264.30\n",
      "损失函数： 0.0574159\n",
      "时间步 3690000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411705e+01/ 轮得分 264.30\n",
      "损失函数： 0.0169243\n",
      "时间步 3691000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.200137e+01/ 轮得分 264.74\n",
      "损失函数： 0.0482539\n",
      "时间步 3692000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246175e+01/ 轮得分 264.73\n",
      "损失函数： 0.0382075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3693000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272998e+01/ 轮得分 264.73\n",
      "损失函数： 0.0194068\n",
      "时间步 3694000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.125089e+01/ 轮得分 264.73\n",
      "损失函数： 0.0328773\n",
      "时间步 3695000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308725e+01/ 轮得分 265.05\n",
      "损失函数： 0.0374879\n",
      "时间步 3696000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.050838e+01/ 轮得分 265.05\n",
      "损失函数： 0.074957\n",
      "时间步 3697000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.248231e+01/ 轮得分 265.32\n",
      "损失函数： 0.0442678\n",
      "时间步 3698000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.262912e+01/ 轮得分 265.32\n",
      "损失函数： 0.0689387\n",
      "时间步 3699000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.391011e+01/ 轮得分 265.42\n",
      "损失函数： 0.0532875\n",
      "时间步 3700000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.399296e+01/ 轮得分 265.08\n",
      "损失函数： 0.0759336\n",
      "时间步 3701000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222317e+01/ 轮得分 265.03\n",
      "损失函数： 0.027591\n",
      "时间步 3702000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.231164e+01/ 轮得分 265.03\n",
      "损失函数： 0.0331206\n",
      "时间步 3703000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331936e+01/ 轮得分 265.03\n",
      "损失函数： 0.0311354\n",
      "时间步 3704000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159789e+01/ 轮得分 265.03\n",
      "损失函数： 0.0336213\n",
      "时间步 3705000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308840e+01/ 轮得分 265.35\n",
      "损失函数： 0.0587509\n",
      "时间步 3706000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324994e+01/ 轮得分 265.35\n",
      "损失函数： 0.04195\n",
      "时间步 3707000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252740e+01/ 轮得分 265.35\n",
      "损失函数： 0.207704\n",
      "时间步 3708000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352353e+01/ 轮得分 265.35\n",
      "损失函数： 0.0929992\n",
      "时间步 3709000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407605e+01/ 轮得分 265.62\n",
      "损失函数： 0.0257302\n",
      "时间步 3710000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.404065e+01/ 轮得分 265.62\n",
      "损失函数： 0.0199697\n",
      "时间步 3711000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.024394e+01/ 轮得分 265.62\n",
      "损失函数： 0.0273435\n",
      "时间步 3712000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208570e+01/ 轮得分 265.69\n",
      "损失函数： 0.0370166\n",
      "时间步 3713000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.045725e+01/ 轮得分 265.69\n",
      "损失函数： 0.024532\n",
      "时间步 3714000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.225813e+01/ 轮得分 265.70\n",
      "损失函数： 0.0360876\n",
      "时间步 3715000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.420657e+01/ 轮得分 265.70\n",
      "损失函数： 0.0601932\n",
      "时间步 3716000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.619464e+01/ 轮得分 265.70\n",
      "损失函数： 0.0232344\n",
      "时间步 3717000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342533e+01/ 轮得分 265.70\n",
      "损失函数： 0.022322\n",
      "时间步 3718000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.443043e+01/ 轮得分 265.70\n",
      "损失函数： 0.0403532\n",
      "时间步 3719000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.106188e+01/ 轮得分 265.70\n",
      "损失函数： 0.0254844\n",
      "时间步 3720000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361472e+01/ 轮得分 265.70\n",
      "损失函数： 0.0373888\n",
      "时间步 3721000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269367e+01/ 轮得分 266.49\n",
      "损失函数： 0.0351957\n",
      "时间步 3722000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.204543e+01/ 轮得分 266.49\n",
      "损失函数： 0.0398838\n",
      "时间步 3723000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344871e+01/ 轮得分 266.49\n",
      "损失函数： 0.0246408\n",
      "时间步 3724000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.160570e+01/ 轮得分 266.89\n",
      "损失函数： 0.012335\n",
      "时间步 3725000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.123636e+01/ 轮得分 266.89\n",
      "损失函数： 0.0337086\n",
      "时间步 3726000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210996e+01/ 轮得分 266.89\n",
      "损失函数： 0.0211649\n",
      "时间步 3727000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278175e+01/ 轮得分 266.72\n",
      "损失函数： 0.0268662\n",
      "时间步 3728000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308733e+01/ 轮得分 266.72\n",
      "损失函数： 0.0202913\n",
      "时间步 3729000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349336e+01/ 轮得分 266.72\n",
      "损失函数： 0.028083\n",
      "时间步 3730000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.369065e+01/ 轮得分 266.72\n",
      "损失函数： 0.0272269\n",
      "时间步 3731000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.137543e+01/ 轮得分 266.83\n",
      "损失函数： 0.035407\n",
      "时间步 3732000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.410480e+01/ 轮得分 266.83\n",
      "损失函数： 0.0190325\n",
      "时间步 3733000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388592e+01/ 轮得分 266.86\n",
      "损失函数： 0.0202786\n",
      "时间步 3734000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.131847e+01/ 轮得分 266.92\n",
      "损失函数： 0.0332545\n",
      "时间步 3735000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210677e+01/ 轮得分 266.92\n",
      "损失函数： 0.0657015\n",
      "时间步 3736000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260162e+01/ 轮得分 266.92\n",
      "损失函数： 0.0683208\n",
      "时间步 3737000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.324955e+01/ 轮得分 267.20\n",
      "损失函数： 0.0302743\n",
      "时间步 3738000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.397143e+01/ 轮得分 267.25\n",
      "损失函数： 0.0344774\n",
      "时间步 3739000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241185e+01/ 轮得分 267.25\n",
      "损失函数： 0.0186821\n",
      "时间步 3740000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.478065e+01/ 轮得分 267.36\n",
      "损失函数： 0.0233948\n",
      "时间步 3741000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324030e+01/ 轮得分 267.36\n",
      "损失函数： 0.0487899\n",
      "时间步 3742000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.398926e+01/ 轮得分 267.36\n",
      "损失函数： 0.0659317\n",
      "时间步 3743000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396044e+01/ 轮得分 267.36\n",
      "损失函数： 0.0317248\n",
      "时间步 3744000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412108e+01/ 轮得分 267.78\n",
      "损失函数： 0.0387804\n",
      "时间步 3745000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.282996e+01/ 轮得分 267.03\n",
      "损失函数： 0.0542701\n",
      "时间步 3746000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288989e+01/ 轮得分 267.03\n",
      "损失函数： 0.049441\n",
      "时间步 3747000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197278e+01/ 轮得分 267.03\n",
      "损失函数： 0.0278819\n",
      "时间步 3748000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.266791e+01/ 轮得分 267.37\n",
      "损失函数： 0.0327922\n",
      "时间步 3749000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.255285e+01/ 轮得分 267.37\n",
      "损失函数： 0.0307266\n",
      "时间步 3750000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303542e+01/ 轮得分 267.37\n",
      "损失函数： 0.0179076\n",
      "时间步 3751000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241387e+01/ 轮得分 267.37\n",
      "损失函数： 0.025109\n",
      "时间步 3752000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.335297e+01/ 轮得分 267.37\n",
      "损失函数： 0.0122789\n",
      "时间步 3753000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321647e+01/ 轮得分 267.88\n",
      "损失函数： 0.0286009\n",
      "时间步 3754000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.429720e+01/ 轮得分 267.91\n",
      "损失函数： 0.0369594\n",
      "时间步 3755000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.320090e+01/ 轮得分 267.91\n",
      "损失函数： 0.0400032\n",
      "时间步 3756000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.458529e+01/ 轮得分 267.91\n",
      "损失函数： 0.0364863\n",
      "时间步 3757000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261596e+01/ 轮得分 267.91\n",
      "损失函数： 0.0231644\n",
      "时间步 3758000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221868e+01/ 轮得分 267.91\n",
      "损失函数： 0.0279133\n",
      "时间步 3759000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347898e+01/ 轮得分 268.55\n",
      "损失函数： 0.0183365\n",
      "时间步 3760000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224717e+01/ 轮得分 267.83\n",
      "损失函数： 0.0184407\n",
      "时间步 3761000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389396e+01/ 轮得分 267.83\n",
      "损失函数： 0.0177141\n",
      "时间步 3762000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.285139e+01/ 轮得分 267.83\n",
      "损失函数： 0.0974627\n",
      "时间步 3763000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.296510e+01/ 轮得分 267.83\n",
      "损失函数： 0.0297059\n",
      "时间步 3764000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.381759e+01/ 轮得分 267.83\n",
      "损失函数： 0.0273697\n",
      "时间步 3765000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.404594e+01/ 轮得分 267.83\n",
      "损失函数： 0.0192797\n",
      "时间步 3766000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.308087e+01/ 轮得分 268.52\n",
      "损失函数： 0.0217156\n",
      "时间步 3767000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.182545e+01/ 轮得分 268.52\n",
      "损失函数： 0.0201786\n",
      "时间步 3768000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193231e+01/ 轮得分 268.60\n",
      "损失函数： 0.0255392\n",
      "时间步 3769000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.413032e+01/ 轮得分 268.60\n",
      "损失函数： 0.0266393\n",
      "时间步 3770000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263416e+01/ 轮得分 268.77\n",
      "损失函数： 0.0488396\n",
      "时间步 3771000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286067e+01/ 轮得分 268.77\n",
      "损失函数： 0.0290762\n",
      "时间步 3772000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390659e+01/ 轮得分 268.77\n",
      "损失函数： 0.0555688\n",
      "时间步 3773000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349432e+01/ 轮得分 269.05\n",
      "损失函数： 0.0299973\n",
      "时间步 3774000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222289e+01/ 轮得分 269.05\n",
      "损失函数： 0.0226622\n",
      "时间步 3775000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.078698e+01/ 轮得分 269.24\n",
      "损失函数： 0.0227258\n",
      "时间步 3776000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.454132e+01/ 轮得分 269.24\n",
      "损失函数： 0.0164716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3777000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.300117e+01/ 轮得分 269.10\n",
      "损失函数： 0.0274121\n",
      "时间步 3778000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278072e+01/ 轮得分 269.10\n",
      "损失函数： 0.0509702\n",
      "时间步 3779000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.473615e+01/ 轮得分 269.10\n",
      "损失函数： 0.0155815\n",
      "时间步 3780000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255951e+01/ 轮得分 269.29\n",
      "损失函数： 0.0608591\n",
      "时间步 3781000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284982e+01/ 轮得分 269.39\n",
      "损失函数： 0.0255389\n",
      "时间步 3782000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213845e+01/ 轮得分 269.39\n",
      "损失函数： 0.0107736\n",
      "时间步 3783000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285016e+01/ 轮得分 269.41\n",
      "损失函数： 0.0129963\n",
      "时间步 3784000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 9.606457e+00/ 轮得分 269.41\n",
      "损失函数： 0.0670713\n",
      "时间步 3785000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334640e+01/ 轮得分 269.01\n",
      "损失函数： 0.0549626\n",
      "时间步 3786000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227852e+01/ 轮得分 268.99\n",
      "损失函数： 0.0184979\n",
      "时间步 3787000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.638927e+00/ 轮得分 268.99\n",
      "损失函数： 0.0213706\n",
      "时间步 3788000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242432e+01/ 轮得分 268.85\n",
      "损失函数： 0.0117712\n",
      "时间步 3789000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345056e+01/ 轮得分 268.85\n",
      "损失函数： 0.0146763\n",
      "时间步 3790000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 7.007408e+00/ 轮得分 268.85\n",
      "损失函数： 0.022924\n",
      "时间步 3791000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.417708e+01/ 轮得分 268.85\n",
      "损失函数： 0.0181213\n",
      "时间步 3792000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223911e+01/ 轮得分 268.85\n",
      "损失函数： 0.052056\n",
      "时间步 3793000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.369797e+01/ 轮得分 268.85\n",
      "损失函数： 0.0948566\n",
      "时间步 3794000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295638e+01/ 轮得分 268.85\n",
      "损失函数： 0.0180056\n",
      "时间步 3795000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229444e+01/ 轮得分 268.85\n",
      "损失函数： 0.0356039\n",
      "时间步 3796000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333881e+01/ 轮得分 268.85\n",
      "损失函数： 0.0388709\n",
      "时间步 3797000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212124e+01/ 轮得分 269.68\n",
      "损失函数： 0.0397627\n",
      "时间步 3798000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191842e+01/ 轮得分 269.68\n",
      "损失函数： 0.0940794\n",
      "时间步 3799000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.182973e+01/ 轮得分 269.68\n",
      "损失函数： 0.0591435\n",
      "时间步 3800000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243164e+01/ 轮得分 269.68\n",
      "损失函数： 0.0134836\n",
      "时间步 3801000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.044460e+01/ 轮得分 269.88\n",
      "损失函数： 0.0384648\n",
      "时间步 3802000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.143625e+01/ 轮得分 269.96\n",
      "损失函数： 0.0279989\n",
      "时间步 3803000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.174385e+01/ 轮得分 270.06\n",
      "损失函数： 0.0204498\n",
      "时间步 3804000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283166e+01/ 轮得分 270.06\n",
      "损失函数： 0.0949596\n",
      "时间步 3805000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290060e+01/ 轮得分 270.04\n",
      "损失函数： 0.0387698\n",
      "时间步 3806000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198915e+01/ 轮得分 270.04\n",
      "损失函数： 0.0142933\n",
      "时间步 3807000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.602756e+00/ 轮得分 270.04\n",
      "损失函数： 0.0109588\n",
      "时间步 3808000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.425659e+01/ 轮得分 270.04\n",
      "损失函数： 0.0376111\n",
      "时间步 3809000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180405e+01/ 轮得分 270.39\n",
      "损失函数： 0.036406\n",
      "时间步 3810000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215278e+01/ 轮得分 270.42\n",
      "损失函数： 0.0232891\n",
      "时间步 3811000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225273e+01/ 轮得分 270.26\n",
      "损失函数： 0.0243257\n",
      "时间步 3812000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.421032e+01/ 轮得分 270.26\n",
      "损失函数： 0.024691\n",
      "时间步 3813000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388299e+01/ 轮得分 270.04\n",
      "损失函数： 0.0335356\n",
      "时间步 3814000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.416854e+01/ 轮得分 269.85\n",
      "损失函数： 0.0817153\n",
      "时间步 3815000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.455170e+01/ 轮得分 269.85\n",
      "损失函数： 0.0545273\n",
      "时间步 3816000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.297064e+01/ 轮得分 269.66\n",
      "损失函数： 0.0369944\n",
      "时间步 3817000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296022e+01/ 轮得分 269.66\n",
      "损失函数： 0.036228\n",
      "时间步 3818000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328022e+01/ 轮得分 269.63\n",
      "损失函数： 0.0556659\n",
      "时间步 3819000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.047623e+01/ 轮得分 269.63\n",
      "损失函数： 0.0406414\n",
      "时间步 3820000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.335383e+01/ 轮得分 269.85\n",
      "损失函数： 0.0319576\n",
      "时间步 3821000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361555e+01/ 轮得分 269.85\n",
      "损失函数： 0.0289047\n",
      "时间步 3822000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351652e+01/ 轮得分 269.97\n",
      "损失函数： 0.105918\n",
      "时间步 3823000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206524e+01/ 轮得分 269.97\n",
      "损失函数： 0.0400278\n",
      "时间步 3824000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272891e+01/ 轮得分 269.97\n",
      "损失函数： 0.0237592\n",
      "时间步 3825000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.533073e+01/ 轮得分 269.97\n",
      "损失函数： 0.0349228\n",
      "时间步 3826000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269020e+01/ 轮得分 270.39\n",
      "损失函数： 0.0204884\n",
      "时间步 3827000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.160354e+01/ 轮得分 270.39\n",
      "损失函数： 0.0298899\n",
      "时间步 3828000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.107612e+01/ 轮得分 270.39\n",
      "损失函数： 0.022385\n",
      "时间步 3829000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310590e+01/ 轮得分 270.69\n",
      "损失函数： 0.058117\n",
      "时间步 3830000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267005e+01/ 轮得分 270.69\n",
      "损失函数： 0.0655243\n",
      "时间步 3831000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.051991e+01/ 轮得分 270.69\n",
      "损失函数： 0.018076\n",
      "时间步 3832000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.154436e+01/ 轮得分 270.94\n",
      "损失函数： 0.0301686\n",
      "时间步 3833000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.167429e+01/ 轮得分 270.94\n",
      "损失函数： 0.0394269\n",
      "时间步 3834000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243003e+01/ 轮得分 270.94\n",
      "损失函数： 0.0172919\n",
      "时间步 3835000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.206444e+01/ 轮得分 270.94\n",
      "损失函数： 0.0331124\n",
      "时间步 3836000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.542037e+01/ 轮得分 270.94\n",
      "损失函数： 0.0181363\n",
      "时间步 3837000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418899e+01/ 轮得分 270.94\n",
      "损失函数： 0.038557\n",
      "时间步 3838000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.489284e+01/ 轮得分 270.94\n",
      "损失函数： 0.0264937\n",
      "时间步 3839000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.336665e+01/ 轮得分 270.94\n",
      "损失函数： 0.0341303\n",
      "时间步 3840000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313346e+01/ 轮得分 270.94\n",
      "损失函数： 0.0544206\n",
      "时间步 3841000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 8.917341e+00/ 轮得分 270.94\n",
      "损失函数： 0.0304323\n",
      "时间步 3842000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.269798e+01/ 轮得分 271.93\n",
      "损失函数： 0.225864\n",
      "时间步 3843000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.263653e+01/ 轮得分 271.93\n",
      "损失函数： 0.0205836\n",
      "时间步 3844000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414846e+01/ 轮得分 271.93\n",
      "损失函数： 0.0559384\n",
      "时间步 3845000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.049865e+01/ 轮得分 272.27\n",
      "损失函数： 0.0282091\n",
      "时间步 3846000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263877e+01/ 轮得分 272.33\n",
      "损失函数： 0.0294334\n",
      "时间步 3847000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325679e+01/ 轮得分 272.46\n",
      "损失函数： 0.0491587\n",
      "时间步 3848000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181013e+01/ 轮得分 272.41\n",
      "损失函数： 0.0266406\n",
      "时间步 3849000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.367279e+01/ 轮得分 272.41\n",
      "损失函数： 0.0573109\n",
      "时间步 3850000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.424322e+01/ 轮得分 272.41\n",
      "损失函数： 0.0656302\n",
      "时间步 3851000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.268286e+01/ 轮得分 272.41\n",
      "损失函数： 0.0240477\n",
      "时间步 3852000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356781e+01/ 轮得分 272.41\n",
      "损失函数： 0.0493345\n",
      "时间步 3853000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225582e+01/ 轮得分 272.41\n",
      "损失函数： 0.0334089\n",
      "时间步 3854000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412007e+01/ 轮得分 272.41\n",
      "损失函数： 0.0341825\n",
      "时间步 3855000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407744e+01/ 轮得分 272.41\n",
      "损失函数： 0.0286307\n",
      "时间步 3856000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.228962e+01/ 轮得分 272.41\n",
      "损失函数： 0.0197894\n",
      "时间步 3857000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.224442e+01/ 轮得分 272.41\n",
      "损失函数： 0.0320028\n",
      "时间步 3858000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271793e+01/ 轮得分 272.41\n",
      "损失函数： 0.0172524\n",
      "时间步 3859000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376113e+01/ 轮得分 272.41\n",
      "损失函数： 0.0401619\n",
      "时间步 3860000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268328e+01/ 轮得分 272.41\n",
      "损失函数： 0.0381788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3861000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.530327e+01/ 轮得分 273.96\n",
      "损失函数： 0.0466158\n",
      "时间步 3862000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275515e+01/ 轮得分 273.96\n",
      "损失函数： 0.0506737\n",
      "时间步 3863000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346946e+01/ 轮得分 273.96\n",
      "损失函数： 0.0249442\n",
      "时间步 3864000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.572609e+01/ 轮得分 273.96\n",
      "损失函数： 0.0268825\n",
      "时间步 3865000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.617901e+01/ 轮得分 273.96\n",
      "损失函数： 0.049159\n",
      "时间步 3866000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165963e+01/ 轮得分 273.96\n",
      "损失函数： 0.0595005\n",
      "时间步 3867000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.249563e+01/ 轮得分 273.96\n",
      "损失函数： 0.0292097\n",
      "时间步 3868000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412007e+01/ 轮得分 273.96\n",
      "损失函数： 0.0164778\n",
      "时间步 3869000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.213271e+01/ 轮得分 273.96\n",
      "损失函数： 0.043221\n",
      "时间步 3870000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.178850e+01/ 轮得分 273.96\n",
      "损失函数： 0.0380023\n",
      "时间步 3871000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296840e+01/ 轮得分 273.96\n",
      "损失函数： 0.0220692\n",
      "时间步 3872000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.153980e+01/ 轮得分 273.96\n",
      "损失函数： 0.0230444\n",
      "时间步 3873000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340719e+01/ 轮得分 275.30\n",
      "损失函数： 0.025582\n",
      "时间步 3874000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227555e+01/ 轮得分 275.30\n",
      "损失函数： 0.0129451\n",
      "时间步 3875000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332185e+01/ 轮得分 274.99\n",
      "损失函数： 0.0169956\n",
      "时间步 3876000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.163420e+01/ 轮得分 274.99\n",
      "损失函数： 0.0280362\n",
      "时间步 3877000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330314e+01/ 轮得分 274.99\n",
      "损失函数： 0.0309637\n",
      "时间步 3878000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258395e+01/ 轮得分 274.99\n",
      "损失函数： 0.0683724\n",
      "时间步 3879000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.156429e+01/ 轮得分 275.38\n",
      "损失函数： 0.0236179\n",
      "时间步 3880000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339926e+01/ 轮得分 275.39\n",
      "损失函数： 0.025085\n",
      "时间步 3881000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325752e+01/ 轮得分 275.39\n",
      "损失函数： 0.0196804\n",
      "时间步 3882000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287217e+01/ 轮得分 275.40\n",
      "损失函数： 0.0340583\n",
      "时间步 3883000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.185735e+01/ 轮得分 275.21\n",
      "损失函数： 0.013888\n",
      "时间步 3884000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344139e+01/ 轮得分 275.21\n",
      "损失函数： 0.0322092\n",
      "时间步 3885000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320473e+01/ 轮得分 275.34\n",
      "损失函数： 0.0286744\n",
      "时间步 3886000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224262e+01/ 轮得分 275.46\n",
      "损失函数： 0.0190228\n",
      "时间步 3887000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.461707e+01/ 轮得分 275.46\n",
      "损失函数： 0.0271084\n",
      "时间步 3888000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.482204e+01/ 轮得分 275.46\n",
      "损失函数： 0.0205347\n",
      "时间步 3889000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324030e+01/ 轮得分 275.46\n",
      "损失函数： 0.0546123\n",
      "时间步 3890000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283832e+01/ 轮得分 275.46\n",
      "损失函数： 0.0301715\n",
      "时间步 3891000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245151e+01/ 轮得分 275.46\n",
      "损失函数： 0.0159786\n",
      "时间步 3892000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337287e+01/ 轮得分 275.74\n",
      "损失函数： 0.0202708\n",
      "时间步 3893000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188571e+01/ 轮得分 275.74\n",
      "损失函数： 0.051274\n",
      "时间步 3894000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204100e+01/ 轮得分 275.14\n",
      "损失函数： 0.0229584\n",
      "时间步 3895000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.213809e+01/ 轮得分 275.08\n",
      "损失函数： 0.0207037\n",
      "时间步 3896000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328207e+01/ 轮得分 275.08\n",
      "损失函数： 0.0291612\n",
      "时间步 3897000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222092e+01/ 轮得分 275.08\n",
      "损失函数： 0.00865916\n",
      "时间步 3898000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337198e+01/ 轮得分 275.08\n",
      "损失函数： 0.0330088\n",
      "时间步 3899000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344447e+01/ 轮得分 275.08\n",
      "损失函数： 0.0252177\n",
      "时间步 3900000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311595e+01/ 轮得分 275.64\n",
      "损失函数： 0.0677601\n",
      "时间步 3901000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.492044e+01/ 轮得分 275.64\n",
      "损失函数： 0.0456157\n",
      "时间步 3902000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.109619e+01/ 轮得分 275.64\n",
      "损失函数： 0.03336\n",
      "时间步 3903000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283112e+01/ 轮得分 275.87\n",
      "损失函数： 0.0279399\n",
      "时间步 3904000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.296544e+01/ 轮得分 275.87\n",
      "损失函数： 0.0400173\n",
      "时间步 3905000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.328129e+01/ 轮得分 275.87\n",
      "损失函数： 0.026414\n",
      "时间步 3906000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249664e+01/ 轮得分 275.87\n",
      "损失函数： 0.03575\n",
      "时间步 3907000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229066e+01/ 轮得分 276.23\n",
      "损失函数： 0.0156453\n",
      "时间步 3908000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365277e+01/ 轮得分 276.23\n",
      "损失函数： 0.0165934\n",
      "时间步 3909000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.151910e+01/ 轮得分 276.23\n",
      "损失函数： 0.724427\n",
      "时间步 3910000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 8.073898e+00/ 轮得分 276.51\n",
      "损失函数： 0.0219917\n",
      "时间步 3911000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.147962e+01/ 轮得分 276.55\n",
      "损失函数： 0.0365927\n",
      "时间步 3912000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.269702e+01/ 轮得分 276.32\n",
      "损失函数： 0.0355825\n",
      "时间步 3913000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.195428e+01/ 轮得分 276.32\n",
      "损失函数： 0.0577599\n",
      "时间步 3914000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193140e+01/ 轮得分 276.32\n",
      "损失函数： 0.0322843\n",
      "时间步 3915000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.100498e+00/ 轮得分 276.32\n",
      "损失函数： 0.0109985\n",
      "时间步 3916000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360310e+01/ 轮得分 276.82\n",
      "损失函数： 0.0106933\n",
      "时间步 3917000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.046026e+01/ 轮得分 276.82\n",
      "损失函数： 0.0178089\n",
      "时间步 3918000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354575e+01/ 轮得分 276.82\n",
      "损失函数： 0.0399892\n",
      "时间步 3919000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 8.675080e+00/ 轮得分 277.02\n",
      "损失函数： 0.0102966\n",
      "时间步 3920000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306535e+01/ 轮得分 277.12\n",
      "损失函数： 0.0224283\n",
      "时间步 3921000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.155860e+01/ 轮得分 277.12\n",
      "损失函数： 0.0327231\n",
      "时间步 3922000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.351070e+01/ 轮得分 277.12\n",
      "损失函数： 0.0253285\n",
      "时间步 3923000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.026260e+01/ 轮得分 277.39\n",
      "损失函数： 0.0396429\n",
      "时间步 3924000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258525e+01/ 轮得分 277.39\n",
      "损失函数： 0.0495723\n",
      "时间步 3925000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316849e+01/ 轮得分 277.39\n",
      "损失函数： 0.058392\n",
      "时间步 3926000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373521e+01/ 轮得分 277.39\n",
      "损失函数： 0.0507508\n",
      "时间步 3927000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.467796e+01/ 轮得分 277.39\n",
      "损失函数： 0.0231806\n",
      "时间步 3928000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.168956e+01/ 轮得分 277.85\n",
      "损失函数： 0.025118\n",
      "时间步 3929000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.518385e+01/ 轮得分 277.67\n",
      "损失函数： 0.0924687\n",
      "时间步 3930000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.421689e+01/ 轮得分 277.77\n",
      "损失函数： 0.0448085\n",
      "时间步 3931000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328971e+01/ 轮得分 277.76\n",
      "损失函数： 0.0223111\n",
      "时间步 3932000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351859e+01/ 轮得分 277.76\n",
      "损失函数： 0.0216492\n",
      "时间步 3933000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231233e+01/ 轮得分 277.76\n",
      "损失函数： 0.028671\n",
      "时间步 3934000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.565184e+01/ 轮得分 277.67\n",
      "损失函数： 0.0430161\n",
      "时间步 3935000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236204e+01/ 轮得分 277.67\n",
      "损失函数： 0.0996971\n",
      "时间步 3936000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279045e+01/ 轮得分 277.79\n",
      "损失函数： 0.0158425\n",
      "时间步 3937000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.398758e+01/ 轮得分 277.83\n",
      "损失函数： 0.0235192\n",
      "时间步 3938000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412674e+01/ 轮得分 277.93\n",
      "损失函数： 0.0411446\n",
      "时间步 3939000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287912e+01/ 轮得分 277.93\n",
      "损失函数： 0.0178431\n",
      "时间步 3940000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.328420e+01/ 轮得分 278.10\n",
      "损失函数： 0.0913536\n",
      "时间步 3941000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316580e+01/ 轮得分 278.10\n",
      "损失函数： 0.0753557\n",
      "时间步 3942000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.422365e+01/ 轮得分 278.10\n",
      "损失函数： 0.0216969\n",
      "时间步 3943000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265602e+01/ 轮得分 278.27\n",
      "损失函数： 0.0256241\n",
      "时间步 3944000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.060819e+01/ 轮得分 278.27\n",
      "损失函数： 0.030469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 3945000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319165e+01/ 轮得分 278.35\n",
      "损失函数： 0.1171\n",
      "时间步 3946000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.425136e+01/ 轮得分 278.35\n",
      "损失函数： 0.0300853\n",
      "时间步 3947000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347787e+01/ 轮得分 278.35\n",
      "损失函数： 0.0449627\n",
      "时间步 3948000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.454411e+01/ 轮得分 278.35\n",
      "损失函数： 0.0313463\n",
      "时间步 3949000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.368467e+01/ 轮得分 278.35\n",
      "损失函数： 0.0195609\n",
      "时间步 3950000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188846e+01/ 轮得分 278.35\n",
      "损失函数： 0.0197355\n",
      "时间步 3951000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 6.238728e-01/ 轮得分 278.35\n",
      "损失函数： 0.0326193\n",
      "时间步 3952000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207269e+01/ 轮得分 278.94\n",
      "损失函数： 0.0214806\n",
      "时间步 3953000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310544e+01/ 轮得分 278.82\n",
      "损失函数： 0.0350989\n",
      "时间步 3954000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295229e+01/ 轮得分 278.03\n",
      "损失函数： 0.021734\n",
      "时间步 3955000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347366e+01/ 轮得分 278.03\n",
      "损失函数： 0.0143382\n",
      "时间步 3956000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305212e+01/ 轮得分 278.22\n",
      "损失函数： 0.0633226\n",
      "时间步 3957000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249870e+01/ 轮得分 278.32\n",
      "损失函数： 0.0646227\n",
      "时间步 3958000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.496054e+01/ 轮得分 278.32\n",
      "损失函数： 0.0219925\n",
      "时间步 3959000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.044133e+01/ 轮得分 278.32\n",
      "损失函数： 0.0385856\n",
      "时间步 3960000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.429696e+01/ 轮得分 278.32\n",
      "损失函数： 0.0253637\n",
      "时间步 3961000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338061e+01/ 轮得分 278.32\n",
      "损失函数： 0.0492979\n",
      "时间步 3962000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.176118e+01/ 轮得分 278.32\n",
      "损失函数： 0.0292625\n",
      "时间步 3963000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.356452e+01/ 轮得分 278.32\n",
      "损失函数： 0.030601\n",
      "时间步 3964000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360090e+01/ 轮得分 278.32\n",
      "损失函数： 0.0353881\n",
      "时间步 3965000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252495e+01/ 轮得分 278.32\n",
      "损失函数： 0.022196\n",
      "时间步 3966000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.474951e+01/ 轮得分 278.32\n",
      "损失函数： 0.0199285\n",
      "时间步 3967000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334009e+01/ 轮得分 279.49\n",
      "损失函数： 0.0680534\n",
      "时间步 3968000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.190173e+01/ 轮得分 279.45\n",
      "损失函数： 0.0199812\n",
      "时间步 3969000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377827e+01/ 轮得分 279.45\n",
      "损失函数： 0.0226364\n",
      "时间步 3970000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.308172e+01/ 轮得分 279.49\n",
      "损失函数： 0.0279638\n",
      "时间步 3971000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.564250e+01/ 轮得分 279.49\n",
      "损失函数： 0.120193\n",
      "时间步 3972000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.522887e+01/ 轮得分 279.49\n",
      "损失函数： 0.014491\n",
      "时间步 3973000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.374295e+01/ 轮得分 279.75\n",
      "损失函数： 0.0257441\n",
      "时间步 3974000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.287851e+01/ 轮得分 279.68\n",
      "损失函数： 0.0506527\n",
      "时间步 3975000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234003e+01/ 轮得分 279.71\n",
      "损失函数： 0.139347\n",
      "时间步 3976000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.478407e+01/ 轮得分 279.28\n",
      "损失函数： 0.0345907\n",
      "时间步 3977000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411638e+01/ 轮得分 279.28\n",
      "损失函数： 0.0550576\n",
      "时间步 3978000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341945e+01/ 轮得分 279.00\n",
      "损失函数： 0.2078\n",
      "时间步 3979000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333025e+01/ 轮得分 279.00\n",
      "损失函数： 0.059867\n",
      "时间步 3980000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.217160e+01/ 轮得分 279.00\n",
      "损失函数： 0.0529161\n",
      "时间步 3981000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341415e+01/ 轮得分 279.29\n",
      "损失函数： 0.0514812\n",
      "时间步 3982000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.950478e+00/ 轮得分 279.25\n",
      "损失函数： 0.0210991\n",
      "时间步 3983000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.217191e+01/ 轮得分 278.55\n",
      "损失函数： 0.0274787\n",
      "时间步 3984000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251071e+01/ 轮得分 278.55\n",
      "损失函数： 0.0383346\n",
      "时间步 3985000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289392e+01/ 轮得分 278.55\n",
      "损失函数： 0.0510645\n",
      "时间步 3986000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281501e+01/ 轮得分 278.83\n",
      "损失函数： 0.0496355\n",
      "时间步 3987000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 9.911552e+00/ 轮得分 278.83\n",
      "损失函数： 0.084801\n",
      "时间步 3988000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.347858e+01/ 轮得分 279.12\n",
      "损失函数： 1.35986\n",
      "时间步 3989000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270699e+01/ 轮得分 279.12\n",
      "损失函数： 0.0372705\n",
      "时间步 3990000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.173664e+01/ 轮得分 279.12\n",
      "损失函数： 0.0380801\n",
      "时间步 3991000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.073319e+01/ 轮得分 279.12\n",
      "损失函数： 0.0239522\n",
      "时间步 3992000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393632e+01/ 轮得分 279.12\n",
      "损失函数： 0.0301961\n",
      "时间步 3993000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.420557e+01/ 轮得分 279.12\n",
      "损失函数： 0.0507306\n",
      "时间步 3994000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243539e+01/ 轮得分 279.12\n",
      "损失函数： 0.0162449\n",
      "时间步 3995000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357079e+01/ 轮得分 279.12\n",
      "损失函数： 0.0183215\n",
      "时间步 3996000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.408893e+01/ 轮得分 279.12\n",
      "损失函数： 0.0323854\n",
      "时间步 3997000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162469e+01/ 轮得分 279.12\n",
      "损失函数： 0.019984\n",
      "时间步 3998000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301299e+01/ 轮得分 279.12\n",
      "损失函数： 0.0613057\n",
      "时间步 3999000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262151e+01/ 轮得分 280.30\n",
      "损失函数： 0.0339293\n",
      "时间步 4000000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.599078e+01/ 轮得分 280.30\n",
      "损失函数： 0.0363073\n",
      "时间步 4001000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.621634e+01/ 轮得分 280.30\n",
      "损失函数： 0.0440383\n",
      "时间步 4002000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194320e+01/ 轮得分 280.30\n",
      "损失函数： 0.0334289\n",
      "时间步 4003000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185706e+01/ 轮得分 280.20\n",
      "损失函数： 0.0747616\n",
      "时间步 4004000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233999e+01/ 轮得分 280.39\n",
      "损失函数： 0.030668\n",
      "时间步 4005000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.176670e+01/ 轮得分 280.32\n",
      "损失函数： 0.054384\n",
      "时间步 4006000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322073e+01/ 轮得分 280.32\n",
      "损失函数： 0.0438802\n",
      "时间步 4007000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192306e+01/ 轮得分 280.32\n",
      "损失函数： 0.0252802\n",
      "时间步 4008000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.451781e+01/ 轮得分 280.32\n",
      "损失函数： 0.0343124\n",
      "时间步 4009000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.464415e+01/ 轮得分 280.54\n",
      "损失函数： 0.0401191\n",
      "时间步 4010000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.152193e+01/ 轮得分 280.52\n",
      "损失函数： 0.0278838\n",
      "时间步 4011000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193941e+01/ 轮得分 280.52\n",
      "损失函数： 0.0478074\n",
      "时间步 4012000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.514707e+01/ 轮得分 280.52\n",
      "损失函数： 0.0173449\n",
      "时间步 4013000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.446411e+01/ 轮得分 280.52\n",
      "损失函数： 0.059999\n",
      "时间步 4014000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255702e+01/ 轮得分 280.52\n",
      "损失函数： 0.0479226\n",
      "时间步 4015000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423088e+01/ 轮得分 280.52\n",
      "损失函数： 0.040819\n",
      "时间步 4016000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.174738e+01/ 轮得分 280.52\n",
      "损失函数： 0.0699956\n",
      "时间步 4017000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252056e+01/ 轮得分 281.38\n",
      "损失函数： 0.0258226\n",
      "时间步 4018000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.358230e+01/ 轮得分 281.38\n",
      "损失函数： 0.0156694\n",
      "时间步 4019000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318288e+01/ 轮得分 281.38\n",
      "损失函数： 0.0307787\n",
      "时间步 4020000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341992e+01/ 轮得分 281.38\n",
      "损失函数： 0.030348\n",
      "时间步 4021000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346889e+01/ 轮得分 281.38\n",
      "损失函数： 0.0137925\n",
      "时间步 4022000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240797e+01/ 轮得分 281.38\n",
      "损失函数： 0.029252\n",
      "时间步 4023000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.171548e+01/ 轮得分 281.38\n",
      "损失函数： 0.0333893\n",
      "时间步 4024000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185159e+01/ 轮得分 281.38\n",
      "损失函数： 0.0600966\n",
      "时间步 4025000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.221557e+01/ 轮得分 281.38\n",
      "损失函数： 0.0315814\n",
      "时间步 4026000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208710e+01/ 轮得分 281.38\n",
      "损失函数： 0.0573386\n",
      "时间步 4027000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271651e+01/ 轮得分 281.38\n",
      "损失函数： 0.0174811\n",
      "时间步 4028000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205973e+01/ 轮得分 282.58\n",
      "损失函数： 0.0192837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4029000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355006e+01/ 轮得分 282.53\n",
      "损失函数： 0.0466788\n",
      "时间步 4030000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294895e+01/ 轮得分 282.53\n",
      "损失函数： 0.0112348\n",
      "时间步 4031000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315333e+01/ 轮得分 282.53\n",
      "损失函数： 0.0404467\n",
      "时间步 4032000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.368642e+01/ 轮得分 282.53\n",
      "损失函数： 0.0189035\n",
      "时间步 4033000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346449e+01/ 轮得分 282.53\n",
      "损失函数： 0.0535472\n",
      "时间步 4034000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240874e+01/ 轮得分 282.80\n",
      "损失函数： 0.0139449\n",
      "时间步 4035000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296996e+01/ 轮得分 282.80\n",
      "损失函数： 0.0563908\n",
      "时间步 4036000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.279028e+01/ 轮得分 282.80\n",
      "损失函数： 0.014621\n",
      "时间步 4037000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 9.329541e+00/ 轮得分 282.80\n",
      "损失函数： 0.0232366\n",
      "时间步 4038000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.197609e+01/ 轮得分 283.07\n",
      "损失函数： 0.0433688\n",
      "时间步 4039000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.422414e+01/ 轮得分 283.07\n",
      "损失函数： 0.12262\n",
      "时间步 4040000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255804e+01/ 轮得分 283.07\n",
      "损失函数： 0.0319858\n",
      "时间步 4041000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.427493e+01/ 轮得分 283.07\n",
      "损失函数： 0.0138413\n",
      "时间步 4042000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258937e+01/ 轮得分 283.35\n",
      "损失函数： 0.0472416\n",
      "时间步 4043000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330240e+01/ 轮得分 283.35\n",
      "损失函数： 0.0665315\n",
      "时间步 4044000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.022249e+01/ 轮得分 283.35\n",
      "损失函数： 0.0419879\n",
      "时间步 4045000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301084e+01/ 轮得分 283.42\n",
      "损失函数： 0.0697656\n",
      "时间步 4046000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.339062e+01/ 轮得分 283.46\n",
      "损失函数： 0.0267558\n",
      "时间步 4047000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258241e+01/ 轮得分 283.46\n",
      "损失函数： 0.0384923\n",
      "时间步 4048000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.375650e+01/ 轮得分 283.46\n",
      "损失函数： 0.0361918\n",
      "时间步 4049000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.424934e+01/ 轮得分 283.46\n",
      "损失函数： 0.031595\n",
      "时间步 4050000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.286959e+01/ 轮得分 283.46\n",
      "损失函数： 0.0307859\n",
      "时间步 4051000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.158353e+01/ 轮得分 283.46\n",
      "损失函数： 0.0301143\n",
      "时间步 4052000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314698e+01/ 轮得分 283.84\n",
      "损失函数： 0.02792\n",
      "时间步 4053000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340235e+01/ 轮得分 283.89\n",
      "损失函数： 0.0118747\n",
      "时间步 4054000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226115e+01/ 轮得分 283.89\n",
      "损失函数： 0.0218109\n",
      "时间步 4055000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332700e+01/ 轮得分 284.05\n",
      "损失函数： 0.0787299\n",
      "时间步 4056000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177476e+01/ 轮得分 284.05\n",
      "损失函数： 0.0313354\n",
      "时间步 4057000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423895e+01/ 轮得分 284.05\n",
      "损失函数： 0.0253161\n",
      "时间步 4058000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316071e+01/ 轮得分 284.05\n",
      "损失函数： 0.0379396\n",
      "时间步 4059000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.126902e+01/ 轮得分 284.29\n",
      "损失函数： 0.0534517\n",
      "时间步 4060000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236949e+01/ 轮得分 284.29\n",
      "损失函数： 0.030595\n",
      "时间步 4061000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.134431e+01/ 轮得分 284.29\n",
      "损失函数： 0.0378162\n",
      "时间步 4062000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.293634e+01/ 轮得分 284.29\n",
      "损失函数： 0.0586029\n",
      "时间步 4063000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347134e+01/ 轮得分 284.29\n",
      "损失函数： 0.0720502\n",
      "时间步 4064000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 6.226359e+00/ 轮得分 284.67\n",
      "损失函数： 0.0279352\n",
      "时间步 4065000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233780e+01/ 轮得分 284.21\n",
      "损失函数： 0.0414782\n",
      "时间步 4066000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312474e+01/ 轮得分 284.21\n",
      "损失函数： 0.0231522\n",
      "时间步 4067000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.361176e+01/ 轮得分 284.21\n",
      "损失函数： 0.0241539\n",
      "时间步 4068000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.429854e+01/ 轮得分 284.21\n",
      "损失函数： 0.0201447\n",
      "时间步 4069000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.171921e+01/ 轮得分 284.21\n",
      "损失函数： 0.0464761\n",
      "时间步 4070000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.510234e+01/ 轮得分 284.21\n",
      "损失函数： 0.0134368\n",
      "时间步 4071000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.401155e+01/ 轮得分 284.21\n",
      "损失函数： 0.0210927\n",
      "时间步 4072000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.555105e+01/ 轮得分 284.21\n",
      "损失函数： 0.0352598\n",
      "时间步 4073000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.163317e+01/ 轮得分 284.21\n",
      "损失函数： 0.0217584\n",
      "时间步 4074000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287906e+01/ 轮得分 284.21\n",
      "损失函数： 0.0231554\n",
      "时间步 4075000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.147459e+01/ 轮得分 285.19\n",
      "损失函数： 0.0155673\n",
      "时间步 4076000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.219643e+01/ 轮得分 285.19\n",
      "损失函数： 0.0226714\n",
      "时间步 4077000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360256e+01/ 轮得分 285.19\n",
      "损失函数： 0.0568623\n",
      "时间步 4078000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245643e+01/ 轮得分 285.19\n",
      "损失函数： 0.0251118\n",
      "时间步 4079000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310567e+01/ 轮得分 285.19\n",
      "损失函数： 0.0477373\n",
      "时间步 4080000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.178255e+01/ 轮得分 285.85\n",
      "损失函数： 0.0595394\n",
      "时间步 4081000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.429807e+01/ 轮得分 285.68\n",
      "损失函数： 0.0780788\n",
      "时间步 4082000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308359e+01/ 轮得分 284.89\n",
      "损失函数： 0.0442408\n",
      "时间步 4083000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 8.374938e+00/ 轮得分 284.34\n",
      "损失函数： 0.0475686\n",
      "时间步 4084000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346845e+01/ 轮得分 284.14\n",
      "损失函数： 0.0375078\n",
      "时间步 4085000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448019e+01/ 轮得分 284.14\n",
      "损失函数： 0.0327632\n",
      "时间步 4086000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192332e+01/ 轮得分 284.14\n",
      "损失函数： 0.0279961\n",
      "时间步 4087000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.191880e+01/ 轮得分 284.14\n",
      "损失函数： 0.0845241\n",
      "时间步 4088000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.566373e+01/ 轮得分 284.43\n",
      "损失函数： 0.0184155\n",
      "时间步 4089000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208290e+01/ 轮得分 284.43\n",
      "损失函数： 0.0458001\n",
      "时间步 4090000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.326042e+01/ 轮得分 284.43\n",
      "损失函数： 0.0323753\n",
      "时间步 4091000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318182e+01/ 轮得分 284.43\n",
      "损失函数： 0.0407238\n",
      "时间步 4092000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.464732e+01/ 轮得分 284.43\n",
      "损失函数： 0.0102071\n",
      "时间步 4093000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.253189e+01/ 轮得分 284.43\n",
      "损失函数： 0.0155486\n",
      "时间步 4094000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.214833e+01/ 轮得分 284.43\n",
      "损失函数： 0.0166758\n",
      "时间步 4095000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239040e+01/ 轮得分 285.16\n",
      "损失函数： 0.0376053\n",
      "时间步 4096000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245468e+01/ 轮得分 285.16\n",
      "损失函数： 0.0238326\n",
      "时间步 4097000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.294814e+01/ 轮得分 285.16\n",
      "损失函数： 0.0382149\n",
      "时间步 4098000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294341e+01/ 轮得分 285.49\n",
      "损失函数： 0.0201143\n",
      "时间步 4099000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.166589e+01/ 轮得分 285.49\n",
      "损失函数： 0.0498602\n",
      "时间步 4100000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243049e+01/ 轮得分 285.49\n",
      "损失函数： 0.0104799\n",
      "时间步 4101000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.129107e+01/ 轮得分 285.85\n",
      "损失函数： 0.0250568\n",
      "时间步 4102000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.155178e+01/ 轮得分 285.51\n",
      "损失函数： 0.0373145\n",
      "时间步 4103000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.180339e+01/ 轮得分 285.51\n",
      "损失函数： 0.0299834\n",
      "时间步 4104000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330182e+01/ 轮得分 285.51\n",
      "损失函数： 0.038631\n",
      "时间步 4105000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.344707e+01/ 轮得分 285.90\n",
      "损失函数： 0.0243617\n",
      "时间步 4106000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241720e+01/ 轮得分 285.92\n",
      "损失函数： 0.0250132\n",
      "时间步 4107000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285005e+01/ 轮得分 285.98\n",
      "损失函数： 0.0279272\n",
      "时间步 4108000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244376e+01/ 轮得分 285.98\n",
      "损失函数： 0.0492612\n",
      "时间步 4109000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313152e+01/ 轮得分 286.20\n",
      "损失函数： 0.0271253\n",
      "时间步 4110000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.194695e+01/ 轮得分 286.20\n",
      "损失函数： 0.0574988\n",
      "时间步 4111000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396082e+01/ 轮得分 286.20\n",
      "损失函数： 0.0396322\n",
      "时间步 4112000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.419427e+01/ 轮得分 286.20\n",
      "损失函数： 0.0426047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4113000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.468103e+01/ 轮得分 286.20\n",
      "损失函数： 0.0622557\n",
      "时间步 4114000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.364160e+01/ 轮得分 286.70\n",
      "损失函数： 0.02055\n",
      "时间步 4115000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215470e+01/ 轮得分 286.29\n",
      "损失函数： 0.0326583\n",
      "时间步 4116000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.396285e+01/ 轮得分 286.29\n",
      "损失函数： 0.0369733\n",
      "时间步 4117000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.412091e+01/ 轮得分 286.29\n",
      "损失函数： 0.0526942\n",
      "时间步 4118000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267306e+01/ 轮得分 286.29\n",
      "损失函数： 0.0283863\n",
      "时间步 4119000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230148e+01/ 轮得分 286.72\n",
      "损失函数： 0.0346467\n",
      "时间步 4120000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161605e+01/ 轮得分 286.74\n",
      "损失函数： 0.0374404\n",
      "时间步 4121000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.269048e+01/ 轮得分 286.74\n",
      "损失函数： 0.0177848\n",
      "时间步 4122000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310720e+01/ 轮得分 286.74\n",
      "损失函数： 0.0248892\n",
      "时间步 4123000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196720e+01/ 轮得分 286.74\n",
      "损失函数： 0.0755184\n",
      "时间步 4124000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356123e+01/ 轮得分 286.74\n",
      "损失函数： 0.0385838\n",
      "时间步 4125000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.426076e+01/ 轮得分 286.96\n",
      "损失函数： 0.0133884\n",
      "时间步 4126000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170336e+01/ 轮得分 286.77\n",
      "损失函数： 0.0702105\n",
      "时间步 4127000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.207963e+01/ 轮得分 286.77\n",
      "损失函数： 0.0245837\n",
      "时间步 4128000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.370014e+01/ 轮得分 286.77\n",
      "损失函数： 0.00860548\n",
      "时间步 4129000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.109843e+01/ 轮得分 286.77\n",
      "损失函数： 0.0232371\n",
      "时间步 4130000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203449e+01/ 轮得分 286.70\n",
      "损失函数： 0.0399682\n",
      "时间步 4131000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311819e+01/ 轮得分 286.75\n",
      "损失函数： 0.0445306\n",
      "时间步 4132000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.320298e+01/ 轮得分 286.69\n",
      "损失函数： 0.0380957\n",
      "时间步 4133000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291207e+01/ 轮得分 286.46\n",
      "损失函数： 0.0185104\n",
      "时间步 4134000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285165e+01/ 轮得分 286.46\n",
      "损失函数： 0.0180419\n",
      "时间步 4135000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161517e+01/ 轮得分 286.46\n",
      "损失函数： 0.0516938\n",
      "时间步 4136000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423112e+01/ 轮得分 286.78\n",
      "损失函数： 0.047391\n",
      "时间步 4137000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.213313e+01/ 轮得分 286.80\n",
      "损失函数： 0.0468758\n",
      "时间步 4138000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.122306e+01/ 轮得分 286.80\n",
      "损失函数： 0.0245302\n",
      "时间步 4139000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285299e+01/ 轮得分 286.80\n",
      "损失函数： 0.08821\n",
      "时间步 4140000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.438501e+01/ 轮得分 286.31\n",
      "损失函数： 0.059776\n",
      "时间步 4141000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.519311e+01/ 轮得分 286.31\n",
      "损失函数： 0.0117775\n",
      "时间步 4142000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348284e+01/ 轮得分 286.55\n",
      "损失函数： 0.0881284\n",
      "时间步 4143000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347615e+01/ 轮得分 286.55\n",
      "损失函数： 0.0243204\n",
      "时间步 4144000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291882e+01/ 轮得分 286.55\n",
      "损失函数： 0.0134387\n",
      "时间步 4145000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.139319e+01/ 轮得分 286.55\n",
      "损失函数： 0.0416014\n",
      "时间步 4146000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161136e+01/ 轮得分 286.55\n",
      "损失函数： 0.0263969\n",
      "时间步 4147000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.605312e+01/ 轮得分 286.55\n",
      "损失函数： 0.0736635\n",
      "时间步 4148000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267364e+01/ 轮得分 287.17\n",
      "损失函数： 0.0140009\n",
      "时间步 4149000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186992e+01/ 轮得分 287.17\n",
      "损失函数： 0.070142\n",
      "时间步 4150000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.361267e+01/ 轮得分 286.81\n",
      "损失函数： 0.0495127\n",
      "时间步 4151000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298619e+01/ 轮得分 286.81\n",
      "损失函数： 0.0465383\n",
      "时间步 4152000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286906e+01/ 轮得分 286.81\n",
      "损失函数： 0.0153267\n",
      "时间步 4153000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207371e+01/ 轮得分 286.92\n",
      "损失函数： 0.0292589\n",
      "时间步 4154000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.446374e+01/ 轮得分 286.92\n",
      "损失函数： 0.0804639\n",
      "时间步 4155000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196685e+01/ 轮得分 286.92\n",
      "损失函数： 0.0308023\n",
      "时间步 4156000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.171228e+01/ 轮得分 286.92\n",
      "损失函数： 0.0498707\n",
      "时间步 4157000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.487590e+01/ 轮得分 286.92\n",
      "损失函数： 0.0813855\n",
      "时间步 4158000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.263231e+01/ 轮得分 286.92\n",
      "损失函数： 0.0286521\n",
      "时间步 4159000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304746e+01/ 轮得分 286.92\n",
      "损失函数： 0.0436918\n",
      "时间步 4160000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.610340e+01/ 轮得分 286.92\n",
      "损失函数： 0.0409871\n",
      "时间步 4161000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183966e+01/ 轮得分 286.92\n",
      "损失函数： 0.031164\n",
      "时间步 4162000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378876e+01/ 轮得分 286.92\n",
      "损失函数： 0.0638552\n",
      "时间步 4163000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234732e+01/ 轮得分 286.92\n",
      "损失函数： 0.0181398\n",
      "时间步 4164000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183685e+01/ 轮得分 288.20\n",
      "损失函数： 0.0153336\n",
      "时间步 4165000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364765e+01/ 轮得分 288.20\n",
      "损失函数： 0.0421968\n",
      "时间步 4166000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.328577e+01/ 轮得分 288.20\n",
      "损失函数： 0.0173138\n",
      "时间步 4167000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.372411e+01/ 轮得分 288.48\n",
      "损失函数： 0.0577926\n",
      "时间步 4168000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.202512e+01/ 轮得分 288.48\n",
      "损失函数： 0.0189462\n",
      "时间步 4169000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.210672e+01/ 轮得分 288.26\n",
      "损失函数： 0.0193972\n",
      "时间步 4170000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356399e+01/ 轮得分 288.26\n",
      "损失函数： 0.0461085\n",
      "时间步 4171000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.404669e+01/ 轮得分 288.26\n",
      "损失函数： 0.0257016\n",
      "时间步 4172000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225997e+01/ 轮得分 288.26\n",
      "损失函数： 0.0306224\n",
      "时间步 4173000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231421e+01/ 轮得分 288.26\n",
      "损失函数： 0.0458869\n",
      "时间步 4174000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326523e+01/ 轮得分 288.26\n",
      "损失函数： 0.0371325\n",
      "时间步 4175000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.237094e+01/ 轮得分 288.26\n",
      "损失函数： 0.0128419\n",
      "时间步 4176000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.479725e+01/ 轮得分 288.93\n",
      "损失函数： 0.133646\n",
      "时间步 4177000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313657e+01/ 轮得分 288.93\n",
      "损失函数： 0.0363348\n",
      "时间步 4178000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367942e+01/ 轮得分 288.93\n",
      "损失函数： 0.0221303\n",
      "时间步 4179000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322671e+01/ 轮得分 288.93\n",
      "损失函数： 0.0163951\n",
      "时间步 4180000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.238786e+01/ 轮得分 288.93\n",
      "损失函数： 0.0269822\n",
      "时间步 4181000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.360621e+01/ 轮得分 288.93\n",
      "损失函数： 0.0298632\n",
      "时间步 4182000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.380142e+01/ 轮得分 288.93\n",
      "损失函数： 0.0510506\n",
      "时间步 4183000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189719e+01/ 轮得分 289.66\n",
      "损失函数： 0.0317163\n",
      "时间步 4184000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234479e+01/ 轮得分 289.66\n",
      "损失函数： 0.013327\n",
      "时间步 4185000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268331e+01/ 轮得分 289.66\n",
      "损失函数： 0.0276889\n",
      "时间步 4186000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190246e+01/ 轮得分 289.66\n",
      "损失函数： 0.0391904\n",
      "时间步 4187000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393976e+01/ 轮得分 289.90\n",
      "损失函数： 0.0191565\n",
      "时间步 4188000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.178583e+01/ 轮得分 290.08\n",
      "损失函数： 0.0116871\n",
      "时间步 4189000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300829e+01/ 轮得分 290.08\n",
      "损失函数： 0.0357571\n",
      "时间步 4190000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352304e+01/ 轮得分 290.08\n",
      "损失函数： 0.0314771\n",
      "时间步 4191000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.414345e+01/ 轮得分 290.08\n",
      "损失函数： 0.0172879\n",
      "时间步 4192000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273126e+01/ 轮得分 290.08\n",
      "损失函数： 0.0113705\n",
      "时间步 4193000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.470567e+01/ 轮得分 290.08\n",
      "损失函数： 0.0297951\n",
      "时间步 4194000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.436738e+01/ 轮得分 290.08\n",
      "损失函数： 0.0398059\n",
      "时间步 4195000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306358e+01/ 轮得分 290.74\n",
      "损失函数： 0.0156794\n",
      "时间步 4196000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318749e+01/ 轮得分 290.74\n",
      "损失函数： 0.025385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4197000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300173e+01/ 轮得分 290.74\n",
      "损失函数： 0.016683\n",
      "时间步 4198000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.147673e+01/ 轮得分 290.92\n",
      "损失函数： 0.0180648\n",
      "时间步 4199000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.185711e+01/ 轮得分 290.92\n",
      "损失函数： 0.0225625\n",
      "时间步 4200000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334073e+01/ 轮得分 290.12\n",
      "损失函数： 0.0266715\n",
      "时间步 4201000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.340193e+01/ 轮得分 290.24\n",
      "损失函数： 0.0290114\n",
      "时间步 4202000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.454991e+01/ 轮得分 290.24\n",
      "损失函数： 0.0251142\n",
      "时间步 4203000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234928e+01/ 轮得分 290.24\n",
      "损失函数： 0.0276972\n",
      "时间步 4204000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.226909e+01/ 轮得分 289.94\n",
      "损失函数： 0.078866\n",
      "时间步 4205000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242604e+01/ 轮得分 289.54\n",
      "损失函数： 0.0409645\n",
      "时间步 4206000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.179806e+01/ 轮得分 289.22\n",
      "损失函数： 0.0163627\n",
      "时间步 4207000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 8.020752e+00/ 轮得分 289.26\n",
      "损失函数： 0.0895622\n",
      "时间步 4208000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279153e+01/ 轮得分 289.29\n",
      "损失函数： 0.0405004\n",
      "时间步 4209000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.133082e+01/ 轮得分 289.29\n",
      "损失函数： 0.0150045\n",
      "时间步 4210000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355256e+01/ 轮得分 289.29\n",
      "损失函数： 0.0176105\n",
      "时间步 4211000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.257891e+01/ 轮得分 289.29\n",
      "损失函数： 0.0880856\n",
      "时间步 4212000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.566078e+01/ 轮得分 289.50\n",
      "损失函数： 0.0581995\n",
      "时间步 4213000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327803e+01/ 轮得分 289.23\n",
      "损失函数： 0.0305319\n",
      "时间步 4214000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.490395e+01/ 轮得分 289.23\n",
      "损失函数： 0.0159427\n",
      "时间步 4215000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.480373e+01/ 轮得分 289.23\n",
      "损失函数： 0.038636\n",
      "时间步 4216000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.250452e+01/ 轮得分 289.53\n",
      "损失函数： 0.0540173\n",
      "时间步 4217000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298426e+01/ 轮得分 289.53\n",
      "损失函数： 0.0204921\n",
      "时间步 4218000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251841e+01/ 轮得分 289.53\n",
      "损失函数： 0.0906306\n",
      "时间步 4219000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314011e+01/ 轮得分 289.53\n",
      "损失函数： 0.03557\n",
      "时间步 4220000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222148e+01/ 轮得分 289.53\n",
      "损失函数： 0.0181727\n",
      "时间步 4221000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414491e+01/ 轮得分 290.01\n",
      "损失函数： 0.0464204\n",
      "时间步 4222000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.205054e+01/ 轮得分 290.01\n",
      "损失函数： 0.0285876\n",
      "时间步 4223000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.147952e+01/ 轮得分 290.08\n",
      "损失函数： 0.0676565\n",
      "时间步 4224000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282215e+01/ 轮得分 290.08\n",
      "损失函数： 0.092355\n",
      "时间步 4225000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.319303e+01/ 轮得分 290.21\n",
      "损失函数： 0.0365245\n",
      "时间步 4226000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.107324e+01/ 轮得分 290.21\n",
      "损失函数： 0.0627905\n",
      "时间步 4227000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268387e+01/ 轮得分 290.44\n",
      "损失函数： 0.040153\n",
      "时间步 4228000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.368639e+01/ 轮得分 290.44\n",
      "损失函数： 0.0287941\n",
      "时间步 4229000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.306456e+01/ 轮得分 290.44\n",
      "损失函数： 0.0406274\n",
      "时间步 4230000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.467412e+01/ 轮得分 290.44\n",
      "损失函数： 0.0514867\n",
      "时间步 4231000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432056e+01/ 轮得分 290.44\n",
      "损失函数： 0.368777\n",
      "时间步 4232000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.121841e+01/ 轮得分 291.05\n",
      "损失函数： 0.113221\n",
      "时间步 4233000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.466193e+01/ 轮得分 291.05\n",
      "损失函数： 0.0589473\n",
      "时间步 4234000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.359262e+01/ 轮得分 291.21\n",
      "损失函数： 0.0353206\n",
      "时间步 4235000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286374e+01/ 轮得分 291.32\n",
      "损失函数： 0.0599636\n",
      "时间步 4236000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.395517e+01/ 轮得分 291.32\n",
      "损失函数： 0.0131014\n",
      "时间步 4237000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.211979e+01/ 轮得分 291.32\n",
      "损失函数： 0.0115192\n",
      "时间步 4238000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305996e+01/ 轮得分 291.32\n",
      "损失函数： 0.0407002\n",
      "时间步 4239000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.245056e+01/ 轮得分 291.60\n",
      "损失函数： 0.0234865\n",
      "时间步 4240000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359268e+01/ 轮得分 291.60\n",
      "损失函数： 0.0226816\n",
      "时间步 4241000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.269370e+01/ 轮得分 291.60\n",
      "损失函数： 0.0624434\n",
      "时间步 4242000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.454942e+01/ 轮得分 291.60\n",
      "损失函数： 0.0383164\n",
      "时间步 4243000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.453300e+01/ 轮得分 291.60\n",
      "损失函数： 2.69556\n",
      "时间步 4244000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324005e+01/ 轮得分 291.60\n",
      "损失函数： 0.0176723\n",
      "时间步 4245000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.174158e+01/ 轮得分 291.92\n",
      "损失函数： 0.0495153\n",
      "时间步 4246000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346661e+01/ 轮得分 291.08\n",
      "损失函数： 0.0151963\n",
      "时间步 4247000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.553167e+01/ 轮得分 290.92\n",
      "损失函数： 0.0385909\n",
      "时间步 4248000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385916e+01/ 轮得分 290.92\n",
      "损失函数： 0.0250283\n",
      "时间步 4249000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.454356e+01/ 轮得分 290.84\n",
      "损失函数： 0.018947\n",
      "时间步 4250000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212472e+01/ 轮得分 290.84\n",
      "损失函数： 0.0831544\n",
      "时间步 4251000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286397e+01/ 轮得分 290.84\n",
      "损失函数： 0.0808696\n",
      "时间步 4252000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.515714e+01/ 轮得分 290.84\n",
      "损失函数： 0.1484\n",
      "时间步 4253000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384572e+01/ 轮得分 290.84\n",
      "损失函数： 0.0780746\n",
      "时间步 4254000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297807e+01/ 轮得分 290.84\n",
      "损失函数： 0.0324101\n",
      "时间步 4255000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.679042e+01/ 轮得分 290.84\n",
      "损失函数： 0.967965\n",
      "时间步 4256000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.195327e+01/ 轮得分 291.25\n",
      "损失函数： 0.0255727\n",
      "时间步 4257000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389014e+01/ 轮得分 291.25\n",
      "损失函数： 0.057597\n",
      "时间步 4258000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.246808e+01/ 轮得分 291.25\n",
      "损失函数： 0.116747\n",
      "时间步 4259000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 6.912870e+00/ 轮得分 291.25\n",
      "损失函数： 0.0395318\n",
      "时间步 4260000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.402146e+01/ 轮得分 291.25\n",
      "损失函数： 0.0330039\n",
      "时间步 4261000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215088e+01/ 轮得分 291.25\n",
      "损失函数： 0.144334\n",
      "时间步 4262000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.309114e+01/ 轮得分 291.25\n",
      "损失函数： 0.0141178\n",
      "时间步 4263000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282312e+01/ 轮得分 291.25\n",
      "损失函数： 0.0255381\n",
      "时间步 4264000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.353180e+01/ 轮得分 291.25\n",
      "损失函数： 0.0234421\n",
      "时间步 4265000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296553e+01/ 轮得分 292.13\n",
      "损失函数： 0.056238\n",
      "时间步 4266000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.182830e+01/ 轮得分 292.24\n",
      "损失函数： 0.0208739\n",
      "时间步 4267000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285338e+01/ 轮得分 292.24\n",
      "损失函数： 0.0387786\n",
      "时间步 4268000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.237439e+01/ 轮得分 292.20\n",
      "损失函数： 0.0417095\n",
      "时间步 4269000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.433350e+01/ 轮得分 292.20\n",
      "损失函数： 0.0415077\n",
      "时间步 4270000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.328814e+01/ 轮得分 292.20\n",
      "损失函数： 0.0644967\n",
      "时间步 4271000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372409e+01/ 轮得分 292.20\n",
      "损失函数： 0.0180382\n",
      "时间步 4272000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.240685e+01/ 轮得分 292.49\n",
      "损失函数： 0.0457611\n",
      "时间步 4273000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.612585e+01/ 轮得分 292.49\n",
      "损失函数： 0.0250967\n",
      "时间步 4274000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117117e+01/ 轮得分 292.49\n",
      "损失函数： 0.0448058\n",
      "时间步 4275000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.288865e+01/ 轮得分 292.49\n",
      "损失函数： 0.0317344\n",
      "时间步 4276000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293616e+01/ 轮得分 292.72\n",
      "损失函数： 0.0220783\n",
      "时间步 4277000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.510834e+01/ 轮得分 292.72\n",
      "损失函数： 0.0264323\n",
      "时间步 4278000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.368000e+01/ 轮得分 292.72\n",
      "损失函数： 0.04692\n",
      "时间步 4279000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.143832e+01/ 轮得分 292.72\n",
      "损失函数： 0.0223053\n",
      "时间步 4280000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407381e+01/ 轮得分 293.13\n",
      "损失函数： 0.0482488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4281000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.064036e+01/ 轮得分 292.46\n",
      "损失函数： 0.0451173\n",
      "时间步 4282000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.348034e+01/ 轮得分 292.46\n",
      "损失函数： 0.0260848\n",
      "时间步 4283000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.309861e+01/ 轮得分 292.46\n",
      "损失函数： 0.022305\n",
      "时间步 4284000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.471327e+01/ 轮得分 292.46\n",
      "损失函数： 0.137284\n",
      "时间步 4285000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.465993e+01/ 轮得分 292.46\n",
      "损失函数： 0.0587797\n",
      "时间步 4286000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.165653e+01/ 轮得分 292.46\n",
      "损失函数： 0.0311578\n",
      "时间步 4287000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447376e+01/ 轮得分 292.46\n",
      "损失函数： 0.0220753\n",
      "时间步 4288000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263413e+01/ 轮得分 292.46\n",
      "损失函数： 0.0523193\n",
      "时间步 4289000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228500e+01/ 轮得分 292.46\n",
      "损失函数： 0.00967337\n",
      "时间步 4290000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.343763e+01/ 轮得分 293.49\n",
      "损失函数： 0.0146801\n",
      "时间步 4291000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.399138e+01/ 轮得分 293.49\n",
      "损失函数： 0.0335649\n",
      "时间步 4292000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348341e+01/ 轮得分 293.78\n",
      "损失函数： 0.0808796\n",
      "时间步 4293000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400475e+01/ 轮得分 293.78\n",
      "损失函数： 0.0323013\n",
      "时间步 4294000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.401430e+01/ 轮得分 293.78\n",
      "损失函数： 0.0313847\n",
      "时间步 4295000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.211094e+01/ 轮得分 293.78\n",
      "损失函数： 0.0449227\n",
      "时间步 4296000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242502e+01/ 轮得分 293.78\n",
      "损失函数： 0.0578975\n",
      "时间步 4297000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311004e+01/ 轮得分 293.78\n",
      "损失函数： 0.0252657\n",
      "时间步 4298000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245822e+01/ 轮得分 294.43\n",
      "损失函数： 0.0238265\n",
      "时间步 4299000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170904e+01/ 轮得分 294.43\n",
      "损失函数： 0.0250951\n",
      "时间步 4300000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177503e+01/ 轮得分 294.43\n",
      "损失函数： 0.0274044\n",
      "时间步 4301000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.303375e+01/ 轮得分 294.43\n",
      "损失函数： 0.021934\n",
      "时间步 4302000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.261016e+01/ 轮得分 294.43\n",
      "损失函数： 0.0681708\n",
      "时间步 4303000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.323303e+01/ 轮得分 294.43\n",
      "损失函数： 0.0851009\n",
      "时间步 4304000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265246e+01/ 轮得分 294.43\n",
      "损失函数： 0.026004\n",
      "时间步 4305000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326486e+01/ 轮得分 294.43\n",
      "损失函数： 0.0266231\n",
      "时间步 4306000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289134e+01/ 轮得分 294.43\n",
      "损失函数： 0.0245878\n",
      "时间步 4307000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203426e+01/ 轮得分 295.30\n",
      "损失函数： 0.0190652\n",
      "时间步 4308000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.066015e+01/ 轮得分 295.34\n",
      "损失函数： 0.0777288\n",
      "时间步 4309000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.421746e+01/ 轮得分 295.34\n",
      "损失函数： 0.0135213\n",
      "时间步 4310000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.273120e+01/ 轮得分 295.34\n",
      "损失函数： 0.0384594\n",
      "时间步 4311000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.172319e+01/ 轮得分 295.34\n",
      "损失函数： 0.0327862\n",
      "时间步 4312000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.307921e+01/ 轮得分 295.34\n",
      "损失函数： 0.0287805\n",
      "时间步 4313000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260517e+01/ 轮得分 295.34\n",
      "损失函数： 0.046674\n",
      "时间步 4314000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.154670e+01/ 轮得分 296.04\n",
      "损失函数： 0.0164112\n",
      "时间步 4315000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213426e+01/ 轮得分 296.04\n",
      "损失函数： 0.0459197\n",
      "时间步 4316000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.323962e+01/ 轮得分 296.04\n",
      "损失函数： 0.0165332\n",
      "时间步 4317000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290664e+01/ 轮得分 296.35\n",
      "损失函数： 0.021425\n",
      "时间步 4318000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.236795e+01/ 轮得分 296.35\n",
      "损失函数： 0.0618575\n",
      "时间步 4319000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239755e+01/ 轮得分 296.46\n",
      "损失函数： 0.0336381\n",
      "时间步 4320000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.227528e+01/ 轮得分 296.38\n",
      "损失函数： 0.0190742\n",
      "时间步 4321000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.210294e+01/ 轮得分 296.38\n",
      "损失函数： 0.0424762\n",
      "时间步 4322000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373739e+01/ 轮得分 296.51\n",
      "损失函数： 0.0162238\n",
      "时间步 4323000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268565e+01/ 轮得分 296.51\n",
      "损失函数： 0.0251705\n",
      "时间步 4324000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340199e+01/ 轮得分 296.51\n",
      "损失函数： 0.0214154\n",
      "时间步 4325000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345040e+01/ 轮得分 296.51\n",
      "损失函数： 0.0194435\n",
      "时间步 4326000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.526010e+01/ 轮得分 296.51\n",
      "损失函数： 0.0266638\n",
      "时间步 4327000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291867e+01/ 轮得分 296.51\n",
      "损失函数： 0.0471884\n",
      "时间步 4328000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.308380e+01/ 轮得分 296.51\n",
      "损失函数： 0.017897\n",
      "时间步 4329000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.492419e+01/ 轮得分 297.12\n",
      "损失函数： 0.0353143\n",
      "时间步 4330000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291255e+01/ 轮得分 297.12\n",
      "损失函数： 0.0276443\n",
      "时间步 4331000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.150769e+01/ 轮得分 297.12\n",
      "损失函数： 0.0401241\n",
      "时间步 4332000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227178e+01/ 轮得分 297.39\n",
      "损失函数： 0.0277642\n",
      "时间步 4333000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.323972e+01/ 轮得分 297.39\n",
      "损失函数： 0.0311883\n",
      "时间步 4334000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.148621e+01/ 轮得分 297.25\n",
      "损失函数： 0.0183492\n",
      "时间步 4335000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.307279e+01/ 轮得分 297.25\n",
      "损失函数： 0.0343249\n",
      "时间步 4336000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260593e+01/ 轮得分 297.25\n",
      "损失函数： 0.0683989\n",
      "时间步 4337000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.251130e+01/ 轮得分 297.25\n",
      "损失函数： 0.0260773\n",
      "时间步 4338000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.118420e+01/ 轮得分 297.25\n",
      "损失函数： 0.0250248\n",
      "时间步 4339000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191301e+01/ 轮得分 297.25\n",
      "损失函数： 0.00834273\n",
      "时间步 4340000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201457e+01/ 轮得分 297.90\n",
      "损失函数： 0.0199381\n",
      "时间步 4341000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161714e+01/ 轮得分 297.90\n",
      "损失函数： 0.0385535\n",
      "时间步 4342000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299905e+01/ 轮得分 297.90\n",
      "损失函数： 0.0237362\n",
      "时间步 4343000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.712361e+01/ 轮得分 297.90\n",
      "损失函数： 0.0272449\n",
      "时间步 4344000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376100e+01/ 轮得分 297.90\n",
      "损失函数： 0.0171186\n",
      "时间步 4345000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.453208e+01/ 轮得分 297.90\n",
      "损失函数： 0.0207926\n",
      "时间步 4346000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.235016e+01/ 轮得分 297.90\n",
      "损失函数： 0.0756558\n",
      "时间步 4347000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216745e+01/ 轮得分 297.90\n",
      "损失函数： 0.054705\n",
      "时间步 4348000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269429e+01/ 轮得分 298.70\n",
      "损失函数： 0.0116845\n",
      "时间步 4349000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303804e+01/ 轮得分 298.70\n",
      "损失函数： 0.0523085\n",
      "时间步 4350000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198950e+01/ 轮得分 298.70\n",
      "损失函数： 0.0499457\n",
      "时间步 4351000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.402195e+01/ 轮得分 298.70\n",
      "损失函数： 0.0185701\n",
      "时间步 4352000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.382428e+01/ 轮得分 298.70\n",
      "损失函数： 0.0254383\n",
      "时间步 4353000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193182e+01/ 轮得分 298.70\n",
      "损失函数： 0.0342349\n",
      "时间步 4354000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219055e+01/ 轮得分 298.70\n",
      "损失函数： 0.0296185\n",
      "时间步 4355000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.309372e+01/ 轮得分 298.70\n",
      "损失函数： 0.0395203\n",
      "时间步 4356000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.485384e+01/ 轮得分 298.70\n",
      "损失函数： 0.0109202\n",
      "时间步 4357000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.619849e+01/ 轮得分 298.70\n",
      "损失函数： 0.0215495\n",
      "时间步 4358000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.404950e+01/ 轮得分 299.62\n",
      "损失函数： 0.0228935\n",
      "时间步 4359000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.122370e+01/ 轮得分 299.76\n",
      "损失函数： 0.0275793\n",
      "时间步 4360000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.456183e+01/ 轮得分 299.76\n",
      "损失函数： 0.0389371\n",
      "时间步 4361000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.299780e+01/ 轮得分 299.76\n",
      "损失函数： 0.0294857\n",
      "时间步 4362000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306220e+01/ 轮得分 299.76\n",
      "损失函数： 0.031606\n",
      "时间步 4363000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.333223e+01/ 轮得分 299.76\n",
      "损失函数： 0.021604\n",
      "时间步 4364000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361260e+01/ 轮得分 299.76\n",
      "损失函数： 0.0141486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4365000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305064e+01/ 轮得分 299.76\n",
      "损失函数： 0.0169107\n",
      "时间步 4366000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.163569e+01/ 轮得分 299.76\n",
      "损失函数： 0.0421052\n",
      "时间步 4367000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301025e+01/ 轮得分 299.76\n",
      "损失函数： 0.0550269\n",
      "时间步 4368000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400676e+01/ 轮得分 299.76\n",
      "损失函数： 0.0512546\n",
      "时间步 4369000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.319715e+01/ 轮得分 299.76\n",
      "损失函数： 0.00959213\n",
      "时间步 4370000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268535e+01/ 轮得分 300.65\n",
      "损失函数： 0.0279391\n",
      "时间步 4371000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256298e+01/ 轮得分 300.65\n",
      "损失函数： 0.0143042\n",
      "时间步 4372000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312710e+01/ 轮得分 300.65\n",
      "损失函数： 0.0393478\n",
      "时间步 4373000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411347e+01/ 轮得分 300.65\n",
      "损失函数： 0.0370058\n",
      "时间步 4374000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383183e+01/ 轮得分 300.65\n",
      "损失函数： 0.0380577\n",
      "时间步 4375000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302735e+01/ 轮得分 300.65\n",
      "损失函数： 0.0147368\n",
      "时间步 4376000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.425105e+01/ 轮得分 300.65\n",
      "损失函数： 0.0232474\n",
      "时间步 4377000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396829e+01/ 轮得分 300.65\n",
      "损失函数： 0.109779\n",
      "时间步 4378000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387042e+01/ 轮得分 300.65\n",
      "损失函数： 0.0765584\n",
      "时间步 4379000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.452036e+01/ 轮得分 300.65\n",
      "损失函数： 0.0307599\n",
      "时间步 4380000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.405426e+01/ 轮得分 300.65\n",
      "损失函数： 0.0540246\n",
      "时间步 4381000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257377e+01/ 轮得分 300.65\n",
      "损失函数： 0.0216775\n",
      "时间步 4382000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448839e+01/ 轮得分 300.65\n",
      "损失函数： 0.0367007\n",
      "时间步 4383000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.446554e+01/ 轮得分 300.65\n",
      "损失函数： 0.0515861\n",
      "时间步 4384000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.473702e+01/ 轮得分 300.65\n",
      "损失函数： 0.00788766\n",
      "时间步 4385000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.392294e+01/ 轮得分 300.65\n",
      "损失函数： 0.0384742\n",
      "时间步 4386000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.572810e+01/ 轮得分 300.65\n",
      "损失函数： 0.022167\n",
      "时间步 4387000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352916e+01/ 轮得分 302.74\n",
      "损失函数： 0.0308404\n",
      "时间步 4388000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288859e+01/ 轮得分 302.74\n",
      "损失函数： 0.0279017\n",
      "时间步 4389000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.353963e+01/ 轮得分 302.74\n",
      "损失函数： 0.0295665\n",
      "时间步 4390000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.254857e+01/ 轮得分 302.74\n",
      "损失函数： 0.0258485\n",
      "时间步 4391000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331080e+01/ 轮得分 302.74\n",
      "损失函数： 0.041672\n",
      "时间步 4392000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.254169e+01/ 轮得分 302.74\n",
      "损失函数： 0.0272275\n",
      "时间步 4393000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.144165e+01/ 轮得分 302.74\n",
      "损失函数： 0.0255029\n",
      "时间步 4394000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269895e+01/ 轮得分 302.74\n",
      "损失函数： 0.0172861\n",
      "时间步 4395000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.163233e+01/ 轮得分 303.28\n",
      "损失函数： 0.0173222\n",
      "时间步 4396000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.189237e+01/ 轮得分 303.28\n",
      "损失函数： 0.0408384\n",
      "时间步 4397000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284973e+01/ 轮得分 303.28\n",
      "损失函数： 0.0305639\n",
      "时间步 4398000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366113e+01/ 轮得分 303.28\n",
      "损失函数： 0.0142799\n",
      "时间步 4399000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201363e+01/ 轮得分 303.28\n",
      "损失函数： 0.010784\n",
      "时间步 4400000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255545e+01/ 轮得分 303.28\n",
      "损失函数： 0.0196964\n",
      "时间步 4401000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.448835e+01/ 轮得分 303.28\n",
      "损失函数： 0.0164468\n",
      "时间步 4402000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318620e+01/ 轮得分 303.28\n",
      "损失函数： 0.0206624\n",
      "时间步 4403000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.449659e+01/ 轮得分 303.28\n",
      "损失函数： 0.058213\n",
      "时间步 4404000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 9.488084e+00/ 轮得分 303.28\n",
      "损失函数： 0.0463829\n",
      "时间步 4405000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256759e+01/ 轮得分 303.89\n",
      "损失函数： 0.0240299\n",
      "时间步 4406000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.397894e+01/ 轮得分 303.89\n",
      "损失函数： 0.00794201\n",
      "时间步 4407000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194812e+01/ 轮得分 303.89\n",
      "损失函数： 0.0157418\n",
      "时间步 4408000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.109825e+01/ 轮得分 303.89\n",
      "损失函数： 0.0250729\n",
      "时间步 4409000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.137035e+01/ 轮得分 304.01\n",
      "损失函数： 0.0304872\n",
      "时间步 4410000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.217720e+01/ 轮得分 304.01\n",
      "损失函数： 0.0192681\n",
      "时间步 4411000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.436430e+01/ 轮得分 304.01\n",
      "损失函数： 0.0474425\n",
      "时间步 4412000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.345199e+01/ 轮得分 304.01\n",
      "损失函数： 0.0170037\n",
      "时间步 4413000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256395e+01/ 轮得分 304.01\n",
      "损失函数： 0.0144937\n",
      "时间步 4414000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.153064e+01/ 轮得分 304.48\n",
      "损失函数： 0.0310091\n",
      "时间步 4415000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325145e+01/ 轮得分 304.48\n",
      "损失函数： 0.0336498\n",
      "时间步 4416000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.404307e+01/ 轮得分 304.48\n",
      "损失函数： 0.0672957\n",
      "时间步 4417000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.376243e+01/ 轮得分 304.54\n",
      "损失函数： 0.0468471\n",
      "时间步 4418000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230032e+01/ 轮得分 304.54\n",
      "损失函数： 0.0244129\n",
      "时间步 4419000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.178525e+01/ 轮得分 304.54\n",
      "损失函数： 0.0233934\n",
      "时间步 4420000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.264656e+01/ 轮得分 304.54\n",
      "损失函数： 0.0172896\n",
      "时间步 4421000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.353500e+01/ 轮得分 304.54\n",
      "损失函数： 0.103971\n",
      "时间步 4422000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.416773e+01/ 轮得分 305.20\n",
      "损失函数： 0.0227975\n",
      "时间步 4423000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.399583e+01/ 轮得分 305.20\n",
      "损失函数： 0.0200013\n",
      "时间步 4424000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310367e+01/ 轮得分 305.20\n",
      "损失函数： 0.0156932\n",
      "时间步 4425000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.324883e+01/ 轮得分 305.20\n",
      "损失函数： 0.0306281\n",
      "时间步 4426000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356831e+01/ 轮得分 305.20\n",
      "损失函数： 0.0283206\n",
      "时间步 4427000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.129360e+01/ 轮得分 305.20\n",
      "损失函数： 0.0444658\n",
      "时间步 4428000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.510018e+01/ 轮得分 305.20\n",
      "损失函数： 0.0222144\n",
      "时间步 4429000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291985e+01/ 轮得分 305.20\n",
      "损失函数： 0.0132701\n",
      "时间步 4430000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193841e+01/ 轮得分 306.15\n",
      "损失函数： 0.0175119\n",
      "时间步 4431000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.215820e+01/ 轮得分 306.15\n",
      "损失函数： 0.00857738\n",
      "时间步 4432000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.406775e+01/ 轮得分 306.15\n",
      "损失函数： 0.0111905\n",
      "时间步 4433000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.471734e+01/ 轮得分 306.15\n",
      "损失函数： 0.0136634\n",
      "时间步 4434000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.273083e+01/ 轮得分 306.15\n",
      "损失函数： 0.116876\n",
      "时间步 4435000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.564650e+01/ 轮得分 306.15\n",
      "损失函数： 0.043037\n",
      "时间步 4436000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.153229e+01/ 轮得分 306.15\n",
      "损失函数： 0.0241961\n",
      "时间步 4437000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.277467e+01/ 轮得分 306.15\n",
      "损失函数： 0.0315767\n",
      "时间步 4438000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266960e+01/ 轮得分 306.15\n",
      "损失函数： 0.0450012\n",
      "时间步 4439000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.108236e+01/ 轮得分 306.15\n",
      "损失函数： 0.0250817\n",
      "时间步 4440000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170517e+01/ 轮得分 306.15\n",
      "损失函数： 0.0121707\n",
      "时间步 4441000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.137903e+01/ 轮得分 307.20\n",
      "损失函数： 0.0417923\n",
      "时间步 4442000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227911e+01/ 轮得分 307.20\n",
      "损失函数： 0.0272479\n",
      "时间步 4443000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231492e+01/ 轮得分 307.20\n",
      "损失函数： 0.0474648\n",
      "时间步 4444000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276274e+01/ 轮得分 307.20\n",
      "损失函数： 0.0148598\n",
      "时间步 4445000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255880e+01/ 轮得分 307.20\n",
      "损失函数： 0.0256964\n",
      "时间步 4446000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.409997e+01/ 轮得分 307.20\n",
      "损失函数： 0.0384099\n",
      "时间步 4447000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.256340e+01/ 轮得分 307.20\n",
      "损失函数： 0.00802631\n",
      "时间步 4448000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.167515e+01/ 轮得分 307.20\n",
      "损失函数： 0.00893995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4449000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.350673e+01/ 轮得分 307.20\n",
      "损失函数： 0.0598946\n",
      "时间步 4450000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280801e+01/ 轮得分 307.20\n",
      "损失函数： 0.0314067\n",
      "时间步 4451000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307901e+01/ 轮得分 307.20\n",
      "损失函数： 0.0300333\n",
      "时间步 4452000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.322646e+01/ 轮得分 307.20\n",
      "损失函数： 0.0302843\n",
      "时间步 4453000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.182307e+01/ 轮得分 308.63\n",
      "损失函数： 0.034495\n",
      "时间步 4454000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289324e+01/ 轮得分 308.63\n",
      "损失函数： 0.0298171\n",
      "时间步 4455000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301384e+01/ 轮得分 308.63\n",
      "损失函数： 0.0129895\n",
      "时间步 4456000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.482423e+01/ 轮得分 308.63\n",
      "损失函数： 0.00916065\n",
      "时间步 4457000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.130832e+01/ 轮得分 308.63\n",
      "损失函数： 0.0183947\n",
      "时间步 4458000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283792e+01/ 轮得分 308.63\n",
      "损失函数： 0.0293724\n",
      "时间步 4459000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349885e+01/ 轮得分 308.63\n",
      "损失函数： 0.0123794\n",
      "时间步 4460000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.272926e+01/ 轮得分 308.63\n",
      "损失函数： 0.045037\n",
      "时间步 4461000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.559160e+01/ 轮得分 308.63\n",
      "损失函数： 0.0207584\n",
      "时间步 4462000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201481e+01/ 轮得分 308.63\n",
      "损失函数： 0.0199649\n",
      "时间步 4463000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190930e+01/ 轮得分 308.63\n",
      "损失函数： 0.0225731\n",
      "时间步 4464000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.160997e+01/ 轮得分 308.63\n",
      "损失函数： 0.0263335\n",
      "时间步 4465000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.370256e+01/ 轮得分 308.63\n",
      "损失函数： 0.0181567\n",
      "时间步 4466000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.373532e+01/ 轮得分 309.97\n",
      "损失函数： 0.00634414\n",
      "时间步 4467000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.364882e+01/ 轮得分 309.97\n",
      "损失函数： 0.017237\n",
      "时间步 4468000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.173225e+01/ 轮得分 309.80\n",
      "损失函数： 0.0363638\n",
      "时间步 4469000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290136e+01/ 轮得分 309.80\n",
      "损失函数： 0.0375157\n",
      "时间步 4470000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225715e+01/ 轮得分 309.80\n",
      "损失函数： 0.0162781\n",
      "时间步 4471000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.404569e+01/ 轮得分 309.80\n",
      "损失函数： 0.0313855\n",
      "时间步 4472000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261561e+01/ 轮得分 309.80\n",
      "损失函数： 0.0131874\n",
      "时间步 4473000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.486558e+01/ 轮得分 310.28\n",
      "损失函数： 0.0443432\n",
      "时间步 4474000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240161e+01/ 轮得分 309.53\n",
      "损失函数： 0.0192764\n",
      "时间步 4475000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193837e+01/ 轮得分 309.53\n",
      "损失函数： 0.024695\n",
      "时间步 4476000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448931e+01/ 轮得分 309.53\n",
      "损失函数： 0.018596\n",
      "时间步 4477000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286274e+01/ 轮得分 309.53\n",
      "损失函数： 0.0349083\n",
      "时间步 4478000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341140e+01/ 轮得分 309.53\n",
      "损失函数： 0.0136417\n",
      "时间步 4479000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.715849e+01/ 轮得分 309.53\n",
      "损失函数： 0.0262512\n",
      "时间步 4480000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.122788e+01/ 轮得分 309.98\n",
      "损失函数： 0.0553364\n",
      "时间步 4481000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269956e+01/ 轮得分 309.98\n",
      "损失函数： 0.0588076\n",
      "时间步 4482000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183020e+01/ 轮得分 309.98\n",
      "损失函数： 0.0108245\n",
      "时间步 4483000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331208e+01/ 轮得分 309.98\n",
      "损失函数： 0.0270747\n",
      "时间步 4484000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287690e+01/ 轮得分 310.45\n",
      "损失函数： 0.0191472\n",
      "时间步 4485000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303604e+01/ 轮得分 310.45\n",
      "损失函数： 0.0291699\n",
      "时间步 4486000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.425956e+01/ 轮得分 310.46\n",
      "损失函数： 0.0279162\n",
      "时间步 4487000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322362e+01/ 轮得分 310.46\n",
      "损失函数： 0.0301307\n",
      "时间步 4488000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329726e+01/ 轮得分 310.46\n",
      "损失函数： 0.03789\n",
      "时间步 4489000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447992e+01/ 轮得分 310.46\n",
      "损失函数： 0.0570978\n",
      "时间步 4490000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.188249e+01/ 轮得分 310.46\n",
      "损失函数： 0.0197169\n",
      "时间步 4491000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.111842e+01/ 轮得分 310.46\n",
      "损失函数： 0.0166937\n",
      "时间步 4492000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309297e+01/ 轮得分 310.46\n",
      "损失函数： 0.0431037\n",
      "时间步 4493000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222555e+01/ 轮得分 310.46\n",
      "损失函数： 0.0355068\n",
      "时间步 4494000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.519789e+01/ 轮得分 310.46\n",
      "损失函数： 0.0206373\n",
      "时间步 4495000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192818e+01/ 轮得分 311.51\n",
      "损失函数： 0.0155174\n",
      "时间步 4496000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.372791e+01/ 轮得分 311.51\n",
      "损失函数： 0.0700904\n",
      "时间步 4497000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249046e+01/ 轮得分 311.51\n",
      "损失函数： 1.20741\n",
      "时间步 4498000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.316633e+01/ 轮得分 311.51\n",
      "损失函数： 0.0494823\n",
      "时间步 4499000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.353618e+01/ 轮得分 311.85\n",
      "损失函数： 0.0891369\n",
      "时间步 4500000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.136051e+01/ 轮得分 311.85\n",
      "损失函数： 0.0637374\n",
      "时间步 4501000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237588e+01/ 轮得分 311.85\n",
      "损失函数： 0.0176442\n",
      "时间步 4502000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285828e+01/ 轮得分 311.85\n",
      "损失函数： 0.0406808\n",
      "时间步 4503000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.532706e+01/ 轮得分 311.85\n",
      "损失函数： 0.0210248\n",
      "时间步 4504000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396994e+01/ 轮得分 312.27\n",
      "损失函数： 0.0291561\n",
      "时间步 4505000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238173e+01/ 轮得分 312.27\n",
      "损失函数： 0.015991\n",
      "时间步 4506000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188512e+01/ 轮得分 312.27\n",
      "损失函数： 0.0109099\n",
      "时间步 4507000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.428221e+01/ 轮得分 312.27\n",
      "损失函数： 0.0196464\n",
      "时间步 4508000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230106e+01/ 轮得分 312.27\n",
      "损失函数： 0.0241099\n",
      "时间步 4509000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349331e+01/ 轮得分 312.27\n",
      "损失函数： 0.0498822\n",
      "时间步 4510000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.559148e+01/ 轮得分 312.27\n",
      "损失函数： 2.24666\n",
      "时间步 4511000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280621e+01/ 轮得分 312.27\n",
      "损失函数： 0.0386212\n",
      "时间步 4512000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329171e+01/ 轮得分 312.27\n",
      "损失函数： 0.0325312\n",
      "时间步 4513000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.196906e+01/ 轮得分 313.02\n",
      "损失函数： 0.0276665\n",
      "时间步 4514000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.232866e+01/ 轮得分 313.05\n",
      "损失函数： 0.0473743\n",
      "时间步 4515000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.274241e+01/ 轮得分 313.05\n",
      "损失函数： 0.101757\n",
      "时间步 4516000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330452e+01/ 轮得分 313.05\n",
      "损失函数： 0.0155613\n",
      "时间步 4517000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333251e+01/ 轮得分 313.05\n",
      "损失函数： 0.0215492\n",
      "时间步 4518000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.285518e+01/ 轮得分 313.05\n",
      "损失函数： 0.0187418\n",
      "时间步 4519000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277912e+01/ 轮得分 313.05\n",
      "损失函数： 0.0221532\n",
      "时间步 4520000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307495e+01/ 轮得分 313.05\n",
      "损失函数： 0.01998\n",
      "时间步 4521000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299285e+01/ 轮得分 313.83\n",
      "损失函数： 0.0386032\n",
      "时间步 4522000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308252e+01/ 轮得分 313.79\n",
      "损失函数： 0.0179751\n",
      "时间步 4523000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244659e+01/ 轮得分 313.79\n",
      "损失函数： 0.0205914\n",
      "时间步 4524000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159852e+01/ 轮得分 313.79\n",
      "损失函数： 0.0217804\n",
      "时间步 4525000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.093128e+01/ 轮得分 313.79\n",
      "损失函数： 0.0710407\n",
      "时间步 4526000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.188617e+01/ 轮得分 313.97\n",
      "损失函数： 0.0255529\n",
      "时间步 4527000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193341e+01/ 轮得分 313.88\n",
      "损失函数： 0.0363158\n",
      "时间步 4528000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.550200e+01/ 轮得分 313.88\n",
      "损失函数： 0.0139199\n",
      "时间步 4529000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202491e+01/ 轮得分 313.88\n",
      "损失函数： 0.061785\n",
      "时间步 4530000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323877e+01/ 轮得分 313.88\n",
      "损失函数： 0.0277364\n",
      "时间步 4531000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323464e+01/ 轮得分 313.88\n",
      "损失函数： 0.0484635\n",
      "时间步 4532000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286003e+01/ 轮得分 313.88\n",
      "损失函数： 0.0419339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4533000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.270037e+01/ 轮得分 313.88\n",
      "损失函数： 0.01541\n",
      "时间步 4534000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.211179e+01/ 轮得分 313.88\n",
      "损失函数： 0.024809\n",
      "时间步 4535000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.651384e+01/ 轮得分 313.88\n",
      "损失函数： 0.0169019\n",
      "时间步 4536000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337590e+01/ 轮得分 313.88\n",
      "损失函数： 0.0205427\n",
      "时间步 4537000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252278e+01/ 轮得分 313.88\n",
      "损失函数： 0.0176746\n",
      "时间步 4538000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351184e+01/ 轮得分 313.88\n",
      "损失函数： 0.0270733\n",
      "时间步 4539000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259223e+01/ 轮得分 313.88\n",
      "损失函数： 0.0387879\n",
      "时间步 4540000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262353e+01/ 轮得分 315.42\n",
      "损失函数： 0.0248357\n",
      "时间步 4541000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.330718e+01/ 轮得分 315.42\n",
      "损失函数： 0.0195834\n",
      "时间步 4542000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 9.503638e+00/ 轮得分 315.42\n",
      "损失函数： 0.017265\n",
      "时间步 4543000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.114621e+01/ 轮得分 315.42\n",
      "损失函数： 0.0278169\n",
      "时间步 4544000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387037e+01/ 轮得分 315.42\n",
      "损失函数： 0.0263433\n",
      "时间步 4545000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269420e+01/ 轮得分 315.67\n",
      "损失函数： 0.0488017\n",
      "时间步 4546000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.459296e+01/ 轮得分 315.67\n",
      "损失函数： 0.02425\n",
      "时间步 4547000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296980e+01/ 轮得分 315.67\n",
      "损失函数： 0.0235546\n",
      "时间步 4548000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274740e+01/ 轮得分 315.67\n",
      "损失函数： 0.0257091\n",
      "时间步 4549000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.308621e+01/ 轮得分 316.19\n",
      "损失函数： 0.0466189\n",
      "时间步 4550000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.208093e+01/ 轮得分 316.19\n",
      "损失函数： 0.0291048\n",
      "时间步 4551000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.453121e+01/ 轮得分 315.89\n",
      "损失函数： 0.0444659\n",
      "时间步 4552000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.313846e+01/ 轮得分 315.76\n",
      "损失函数： 0.0233295\n",
      "时间步 4553000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226004e+01/ 轮得分 315.76\n",
      "损失函数： 0.00833261\n",
      "时间步 4554000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.378836e+01/ 轮得分 315.88\n",
      "损失函数： 0.0161098\n",
      "时间步 4555000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.203720e+01/ 轮得分 315.88\n",
      "损失函数： 0.0228494\n",
      "时间步 4556000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415613e+01/ 轮得分 315.88\n",
      "损失函数： 0.630204\n",
      "时间步 4557000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285357e+01/ 轮得分 315.88\n",
      "损失函数： 0.0209873\n",
      "时间步 4558000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229225e+01/ 轮得分 315.88\n",
      "损失函数： 0.0821526\n",
      "时间步 4559000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.180112e+01/ 轮得分 315.88\n",
      "损失函数： 0.0307437\n",
      "时间步 4560000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316030e+01/ 轮得分 315.88\n",
      "损失函数： 0.0704413\n",
      "时间步 4561000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.418247e+01/ 轮得分 315.88\n",
      "损失函数： 0.0296314\n",
      "时间步 4562000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292604e+01/ 轮得分 315.88\n",
      "损失函数： 0.0712087\n",
      "时间步 4563000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293408e+01/ 轮得分 316.59\n",
      "损失函数： 0.0155685\n",
      "时间步 4564000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432316e+01/ 轮得分 316.59\n",
      "损失函数： 0.118041\n",
      "时间步 4565000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300346e+01/ 轮得分 316.79\n",
      "损失函数： 0.0187355\n",
      "时间步 4566000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299796e+01/ 轮得分 316.80\n",
      "损失函数： 0.0419108\n",
      "时间步 4567000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412175e+01/ 轮得分 316.80\n",
      "损失函数： 0.00933577\n",
      "时间步 4568000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.271683e+01/ 轮得分 316.80\n",
      "损失函数： 0.0177085\n",
      "时间步 4569000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.381563e+01/ 轮得分 316.80\n",
      "损失函数： 0.0219382\n",
      "时间步 4570000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 4.161528e+00/ 轮得分 316.80\n",
      "损失函数： 0.0152289\n",
      "时间步 4571000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.342569e+01/ 轮得分 317.21\n",
      "损失函数： 0.0168674\n",
      "时间步 4572000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.160874e+01/ 轮得分 317.21\n",
      "损失函数： 0.0471457\n",
      "时间步 4573000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296557e+01/ 轮得分 317.21\n",
      "损失函数： 0.0144672\n",
      "时间步 4574000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162774e+01/ 轮得分 317.50\n",
      "损失函数： 0.0303994\n",
      "时间步 4575000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335331e+01/ 轮得分 317.50\n",
      "损失函数： 0.0225326\n",
      "时间步 4576000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.124920e+01/ 轮得分 317.50\n",
      "损失函数： 0.00952019\n",
      "时间步 4577000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272823e+01/ 轮得分 317.68\n",
      "损失函数： 0.0151905\n",
      "时间步 4578000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373197e+01/ 轮得分 317.80\n",
      "损失函数： 0.0239397\n",
      "时间步 4579000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219549e+01/ 轮得分 317.80\n",
      "损失函数： 0.0179715\n",
      "时间步 4580000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.232962e+01/ 轮得分 317.71\n",
      "损失函数： 0.0593475\n",
      "时间步 4581000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.454449e+01/ 轮得分 317.71\n",
      "损失函数： 0.0704671\n",
      "时间步 4582000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321496e+01/ 轮得分 317.61\n",
      "损失函数： 0.0374986\n",
      "时间步 4583000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418799e+01/ 轮得分 317.61\n",
      "损失函数： 0.0502264\n",
      "时间步 4584000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.148668e+01/ 轮得分 317.40\n",
      "损失函数： 0.066367\n",
      "时间步 4585000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418364e+01/ 轮得分 317.43\n",
      "损失函数： 0.0158263\n",
      "时间步 4586000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334532e+01/ 轮得分 317.43\n",
      "损失函数： 0.0188179\n",
      "时间步 4587000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269412e+01/ 轮得分 317.49\n",
      "损失函数： 0.0362631\n",
      "时间步 4588000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.244552e+01/ 轮得分 317.49\n",
      "损失函数： 0.0416429\n",
      "时间步 4589000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245494e+01/ 轮得分 317.62\n",
      "损失函数： 0.098168\n",
      "时间步 4590000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231586e+01/ 轮得分 317.62\n",
      "损失函数： 0.0303968\n",
      "时间步 4591000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363503e+01/ 轮得分 317.62\n",
      "损失函数： 0.0321855\n",
      "时间步 4592000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.175344e+01/ 轮得分 317.62\n",
      "损失函数： 0.031732\n",
      "时间步 4593000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335467e+01/ 轮得分 317.62\n",
      "损失函数： 0.0131146\n",
      "时间步 4594000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.475128e+01/ 轮得分 317.62\n",
      "损失函数： 0.0308055\n",
      "时间步 4595000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.399262e+01/ 轮得分 317.62\n",
      "损失函数： 0.0144337\n",
      "时间步 4596000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354380e+01/ 轮得分 318.22\n",
      "损失函数： 0.0246061\n",
      "时间步 4597000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.077425e+01/ 轮得分 318.31\n",
      "损失函数： 0.0132043\n",
      "时间步 4598000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.653189e+01/ 轮得分 318.31\n",
      "损失函数： 1.56092\n",
      "时间步 4599000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275898e+01/ 轮得分 318.31\n",
      "损失函数： 0.0141689\n",
      "时间步 4600000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290490e+01/ 轮得分 318.31\n",
      "损失函数： 0.0178703\n",
      "时间步 4601000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197503e+01/ 轮得分 318.31\n",
      "损失函数： 0.0237715\n",
      "时间步 4602000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.190724e+01/ 轮得分 318.31\n",
      "损失函数： 0.0120393\n",
      "时间步 4603000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322587e+01/ 轮得分 318.31\n",
      "损失函数： 0.0335125\n",
      "时间步 4604000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.127466e+01/ 轮得分 318.31\n",
      "损失函数： 0.0363232\n",
      "时间步 4605000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 4.651503e+00/ 轮得分 318.31\n",
      "损失函数： 0.0680205\n",
      "时间步 4606000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.431913e+01/ 轮得分 319.38\n",
      "损失函数： 0.0207464\n",
      "时间步 4607000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.353470e+01/ 轮得分 319.38\n",
      "损失函数： 0.0203984\n",
      "时间步 4608000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.371594e+01/ 轮得分 319.38\n",
      "损失函数： 0.0155793\n",
      "时间步 4609000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411756e+01/ 轮得分 319.38\n",
      "损失函数： 0.0582993\n",
      "时间步 4610000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.206381e+01/ 轮得分 319.38\n",
      "损失函数： 0.0527149\n",
      "时间步 4611000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275555e+01/ 轮得分 319.69\n",
      "损失函数： 0.00964027\n",
      "时间步 4612000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.642469e+01/ 轮得分 319.69\n",
      "损失函数： 0.0539109\n",
      "时间步 4613000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321697e+01/ 轮得分 318.93\n",
      "损失函数： 0.0428552\n",
      "时间步 4614000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286534e+01/ 轮得分 318.93\n",
      "损失函数： 0.0255873\n",
      "时间步 4615000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360873e+01/ 轮得分 318.93\n",
      "损失函数： 0.033483\n",
      "时间步 4616000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315330e+01/ 轮得分 318.30\n",
      "损失函数： 0.00953448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4617000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.414634e+01/ 轮得分 318.30\n",
      "损失函数： 0.0269897\n",
      "时间步 4618000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337745e+01/ 轮得分 318.30\n",
      "损失函数： 0.0492956\n",
      "时间步 4619000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.363954e+01/ 轮得分 318.30\n",
      "损失函数： 0.0155867\n",
      "时间步 4620000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.281186e+01/ 轮得分 318.62\n",
      "损失函数： 0.0266954\n",
      "时间步 4621000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.474735e+01/ 轮得分 318.62\n",
      "损失函数： 0.0216668\n",
      "时间步 4622000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314369e+01/ 轮得分 318.54\n",
      "损失函数： 0.0127923\n",
      "时间步 4623000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.164409e+01/ 轮得分 318.38\n",
      "损失函数： 0.0409575\n",
      "时间步 4624000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283970e+01/ 轮得分 318.38\n",
      "损失函数： 0.0216815\n",
      "时间步 4625000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363356e+01/ 轮得分 318.38\n",
      "损失函数： 0.0281119\n",
      "时间步 4626000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.282091e+01/ 轮得分 318.52\n",
      "损失函数： 0.0257158\n",
      "时间步 4627000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264455e+01/ 轮得分 318.52\n",
      "损失函数： 0.0466489\n",
      "时间步 4628000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.306051e+01/ 轮得分 318.63\n",
      "损失函数： 0.0215243\n",
      "时间步 4629000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.358696e+01/ 轮得分 318.63\n",
      "损失函数： 0.0530389\n",
      "时间步 4630000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.516463e+01/ 轮得分 318.63\n",
      "损失函数： 0.0919744\n",
      "时间步 4631000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.480565e+01/ 轮得分 318.63\n",
      "损失函数： 0.0204007\n",
      "时间步 4632000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203157e+01/ 轮得分 318.72\n",
      "损失函数： 0.056824\n",
      "时间步 4633000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193217e+01/ 轮得分 318.72\n",
      "损失函数： 0.016278\n",
      "时间步 4634000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.631602e+01/ 轮得分 318.72\n",
      "损失函数： 0.025984\n",
      "时间步 4635000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298194e+01/ 轮得分 318.72\n",
      "损失函数： 0.0224671\n",
      "时间步 4636000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.480324e+01/ 轮得分 318.72\n",
      "损失函数： 0.0603285\n",
      "时间步 4637000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.279538e+01/ 轮得分 318.72\n",
      "损失函数： 0.030218\n",
      "时间步 4638000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391867e+01/ 轮得分 318.72\n",
      "损失函数： 0.026776\n",
      "时间步 4639000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.627639e+01/ 轮得分 318.72\n",
      "损失函数： 0.0433327\n",
      "时间步 4640000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.166131e+01/ 轮得分 318.72\n",
      "损失函数： 0.0196343\n",
      "时间步 4641000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.417962e+01/ 轮得分 318.72\n",
      "损失函数： 0.0350321\n",
      "时间步 4642000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292040e+01/ 轮得分 318.72\n",
      "损失函数： 0.0328\n",
      "时间步 4643000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.475202e+01/ 轮得分 318.72\n",
      "损失函数： 0.0375408\n",
      "时间步 4644000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.724341e+01/ 轮得分 320.03\n",
      "损失函数： 0.0382834\n",
      "时间步 4645000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.503273e+01/ 轮得分 320.03\n",
      "损失函数： 0.015832\n",
      "时间步 4646000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.333139e+01/ 轮得分 320.03\n",
      "损失函数： 0.0614174\n",
      "时间步 4647000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.465084e+01/ 轮得分 320.03\n",
      "损失函数： 0.0266175\n",
      "时间步 4648000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.339332e+01/ 轮得分 320.03\n",
      "损失函数： 0.0334336\n",
      "时间步 4649000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.247134e+01/ 轮得分 320.03\n",
      "损失函数： 0.0211747\n",
      "时间步 4650000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.464839e+01/ 轮得分 320.03\n",
      "损失函数： 0.0148507\n",
      "时间步 4651000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415253e+01/ 轮得分 320.03\n",
      "损失函数： 0.0265194\n",
      "时间步 4652000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389416e+01/ 轮得分 320.03\n",
      "损失函数： 0.0361846\n",
      "时间步 4653000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.404120e+01/ 轮得分 320.03\n",
      "损失函数： 0.036298\n",
      "时间步 4654000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313571e+01/ 轮得分 320.03\n",
      "损失函数： 0.0394079\n",
      "时间步 4655000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242225e+01/ 轮得分 320.03\n",
      "损失函数： 0.0146477\n",
      "时间步 4656000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.457025e+01/ 轮得分 321.16\n",
      "损失函数： 0.0201581\n",
      "时间步 4657000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432615e+01/ 轮得分 321.26\n",
      "损失函数： 0.0325337\n",
      "时间步 4658000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302336e+01/ 轮得分 321.26\n",
      "损失函数： 0.0388059\n",
      "时间步 4659000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357959e+01/ 轮得分 321.19\n",
      "损失函数： 0.0183995\n",
      "时间步 4660000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.470205e+01/ 轮得分 321.19\n",
      "损失函数： 0.0202032\n",
      "时间步 4661000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.382906e+01/ 轮得分 321.19\n",
      "损失函数： 0.0200821\n",
      "时间步 4662000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318824e+01/ 轮得分 321.33\n",
      "损失函数： 0.0474814\n",
      "时间步 4663000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296716e+01/ 轮得分 321.33\n",
      "损失函数： 0.0279138\n",
      "时间步 4664000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255076e+01/ 轮得分 321.11\n",
      "损失函数： 0.0463499\n",
      "时间步 4665000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.199445e+01/ 轮得分 321.11\n",
      "损失函数： 0.0140878\n",
      "时间步 4666000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.380292e+01/ 轮得分 321.11\n",
      "损失函数： 0.0237386\n",
      "时间步 4667000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.182132e+01/ 轮得分 321.11\n",
      "损失函数： 0.0149792\n",
      "时间步 4668000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.051025e+01/ 轮得分 321.11\n",
      "损失函数： 0.0231203\n",
      "时间步 4669000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.224516e+01/ 轮得分 321.55\n",
      "损失函数： 0.0281241\n",
      "时间步 4670000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.352133e+01/ 轮得分 321.55\n",
      "损失函数： 0.0196921\n",
      "时间步 4671000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334511e+01/ 轮得分 321.55\n",
      "损失函数： 0.0120151\n",
      "时间步 4672000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.442937e+01/ 轮得分 321.55\n",
      "损失函数： 0.0148305\n",
      "时间步 4673000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244905e+01/ 轮得分 321.55\n",
      "损失函数： 0.0221716\n",
      "时间步 4674000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.482522e+01/ 轮得分 321.55\n",
      "损失函数： 0.0114049\n",
      "时间步 4675000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.461285e+01/ 轮得分 321.55\n",
      "损失函数： 0.0142011\n",
      "时间步 4676000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.395908e+01/ 轮得分 322.15\n",
      "损失函数： 0.0384442\n",
      "时间步 4677000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.484791e+01/ 轮得分 322.15\n",
      "损失函数： 0.0492097\n",
      "时间步 4678000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189053e+01/ 轮得分 322.15\n",
      "损失函数： 0.0233564\n",
      "时间步 4679000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343806e+01/ 轮得分 322.15\n",
      "损失函数： 0.0652619\n",
      "时间步 4680000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320594e+01/ 轮得分 322.15\n",
      "损失函数： 0.0244274\n",
      "时间步 4681000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220197e+01/ 轮得分 322.15\n",
      "损失函数： 0.0332606\n",
      "时间步 4682000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372329e+01/ 轮得分 322.15\n",
      "损失函数： 0.0491243\n",
      "时间步 4683000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.146661e+01/ 轮得分 322.83\n",
      "损失函数： 0.0284431\n",
      "时间步 4684000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292984e+01/ 轮得分 322.94\n",
      "损失函数： 0.0328668\n",
      "时间步 4685000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212233e+01/ 轮得分 322.94\n",
      "损失函数： 0.0482221\n",
      "时间步 4686000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355626e+01/ 轮得分 322.61\n",
      "损失函数： 0.0210273\n",
      "时间步 4687000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.449150e+01/ 轮得分 322.68\n",
      "损失函数： 0.0772017\n",
      "时间步 4688000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263166e+01/ 轮得分 322.68\n",
      "损失函数： 0.0442532\n",
      "时间步 4689000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344313e+01/ 轮得分 322.60\n",
      "损失函数： 0.0341499\n",
      "时间步 4690000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257357e+01/ 轮得分 322.60\n",
      "损失函数： 0.0784208\n",
      "时间步 4691000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333775e+01/ 轮得分 322.60\n",
      "损失函数： 0.00803822\n",
      "时间步 4692000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337343e+01/ 轮得分 322.60\n",
      "损失函数： 0.0426117\n",
      "时间步 4693000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.186439e+01/ 轮得分 322.75\n",
      "损失函数： 0.0200498\n",
      "时间步 4694000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208741e+01/ 轮得分 322.75\n",
      "损失函数： 0.0271691\n",
      "时间步 4695000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180686e+01/ 轮得分 322.75\n",
      "损失函数： 0.0280672\n",
      "时间步 4696000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.432678e+01/ 轮得分 322.75\n",
      "损失函数： 0.0128532\n",
      "时间步 4697000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295699e+01/ 轮得分 322.75\n",
      "损失函数： 0.0350452\n",
      "时间步 4698000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.402274e+01/ 轮得分 322.75\n",
      "损失函数： 0.0257043\n",
      "时间步 4699000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193747e+01/ 轮得分 323.09\n",
      "损失函数： 0.0244315\n",
      "时间步 4700000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.588392e+01/ 轮得分 323.09\n",
      "损失函数： 0.0399458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4701000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.374631e+01/ 轮得分 323.09\n",
      "损失函数： 0.0469724\n",
      "时间步 4702000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.608113e+01/ 轮得分 323.09\n",
      "损失函数： 0.0588471\n",
      "时间步 4703000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.257205e+01/ 轮得分 323.52\n",
      "损失函数： 0.0275022\n",
      "时间步 4704000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.549216e+01/ 轮得分 323.52\n",
      "损失函数： 0.0454519\n",
      "时间步 4705000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.337376e+01/ 轮得分 323.63\n",
      "损失函数： 0.0216229\n",
      "时间步 4706000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.501929e+01/ 轮得分 323.63\n",
      "损失函数： 0.0126487\n",
      "时间步 4707000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.234678e+01/ 轮得分 323.71\n",
      "损失函数： 0.0324803\n",
      "时间步 4708000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323515e+01/ 轮得分 323.72\n",
      "损失函数： 0.0244364\n",
      "时间步 4709000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.348878e+01/ 轮得分 323.72\n",
      "损失函数： 0.0687593\n",
      "时间步 4710000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259343e+01/ 轮得分 323.72\n",
      "损失函数： 0.0397552\n",
      "时间步 4711000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.229118e+01/ 轮得分 323.72\n",
      "损失函数： 0.0472614\n",
      "时间步 4712000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189788e+01/ 轮得分 323.97\n",
      "损失函数： 0.0237282\n",
      "时间步 4713000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333328e+01/ 轮得分 323.97\n",
      "损失函数： 0.0196329\n",
      "时间步 4714000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.434798e+01/ 轮得分 323.97\n",
      "损失函数： 0.0206309\n",
      "时间步 4715000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 4.944023e+00/ 轮得分 324.27\n",
      "损失函数： 0.0271988\n",
      "时间步 4716000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291355e+01/ 轮得分 324.27\n",
      "损失函数： 0.0636948\n",
      "时间步 4717000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.250315e+01/ 轮得分 324.27\n",
      "损失函数： 0.0740744\n",
      "时间步 4718000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.421287e+01/ 轮得分 324.27\n",
      "损失函数： 0.0192255\n",
      "时间步 4719000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298890e+01/ 轮得分 324.27\n",
      "损失函数： 0.080593\n",
      "时间步 4720000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.348078e+01/ 轮得分 324.27\n",
      "损失函数： 0.0383443\n",
      "时间步 4721000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287580e+01/ 轮得分 324.94\n",
      "损失函数： 0.0319038\n",
      "时间步 4722000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248234e+01/ 轮得分 324.94\n",
      "损失函数： 0.0581256\n",
      "时间步 4723000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281632e+01/ 轮得分 324.94\n",
      "损失函数： 0.0321553\n",
      "时间步 4724000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.219736e+01/ 轮得分 324.94\n",
      "损失函数： 0.0308402\n",
      "时间步 4725000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202760e+01/ 轮得分 324.79\n",
      "损失函数： 0.0124568\n",
      "时间步 4726000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197678e+01/ 轮得分 324.79\n",
      "损失函数： 0.0189692\n",
      "时间步 4727000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251565e+01/ 轮得分 324.79\n",
      "损失函数： 0.100051\n",
      "时间步 4728000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206211e+01/ 轮得分 324.79\n",
      "损失函数： 0.0194911\n",
      "时间步 4729000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.308947e+01/ 轮得分 324.79\n",
      "损失函数： 0.0341592\n",
      "时间步 4730000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288532e+01/ 轮得分 324.79\n",
      "损失函数： 0.0240997\n",
      "时间步 4731000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.278777e+01/ 轮得分 325.23\n",
      "损失函数： 0.0114749\n",
      "时间步 4732000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360239e+01/ 轮得分 325.23\n",
      "损失函数： 0.0136666\n",
      "时间步 4733000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.408673e+01/ 轮得分 325.23\n",
      "损失函数： 0.0710969\n",
      "时间步 4734000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.439914e+01/ 轮得分 325.23\n",
      "损失函数： 0.0475367\n",
      "时间步 4735000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.380119e+01/ 轮得分 325.65\n",
      "损失函数： 0.0194458\n",
      "时间步 4736000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.508353e+01/ 轮得分 325.65\n",
      "损失函数： 0.0660771\n",
      "时间步 4737000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.240730e+01/ 轮得分 325.84\n",
      "损失函数： 0.0272745\n",
      "时间步 4738000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.401282e+01/ 轮得分 325.84\n",
      "损失函数： 0.0159236\n",
      "时间步 4739000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.692714e+01/ 轮得分 325.84\n",
      "损失函数： 0.0594729\n",
      "时间步 4740000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.509450e+01/ 轮得分 325.84\n",
      "损失函数： 0.0494466\n",
      "时间步 4741000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341811e+01/ 轮得分 325.84\n",
      "损失函数： 0.0164396\n",
      "时间步 4742000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.321014e+01/ 轮得分 325.84\n",
      "损失函数： 0.028\n",
      "时间步 4743000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338227e+01/ 轮得分 326.13\n",
      "损失函数： 0.01389\n",
      "时间步 4744000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.818548e+01/ 轮得分 326.13\n",
      "损失函数： 0.0323526\n",
      "时间步 4745000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.415448e+01/ 轮得分 326.36\n",
      "损失函数： 0.0334938\n",
      "时间步 4746000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339249e+01/ 轮得分 326.40\n",
      "损失函数： 0.0273036\n",
      "时间步 4747000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229200e+01/ 轮得分 326.40\n",
      "损失函数： 0.0249824\n",
      "时间步 4748000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.205546e+01/ 轮得分 326.40\n",
      "损失函数： 0.0201493\n",
      "时间步 4749000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267326e+01/ 轮得分 326.40\n",
      "损失函数： 0.0232551\n",
      "时间步 4750000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318558e+01/ 轮得分 326.40\n",
      "损失函数： 0.0739777\n",
      "时间步 4751000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227053e+01/ 轮得分 327.00\n",
      "损失函数： 0.0247149\n",
      "时间步 4752000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184254e+01/ 轮得分 327.00\n",
      "损失函数： 0.0379404\n",
      "时间步 4753000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.200100e+01/ 轮得分 327.00\n",
      "损失函数： 0.0305677\n",
      "时间步 4754000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362454e+01/ 轮得分 327.31\n",
      "损失函数： 0.0533742\n",
      "时间步 4755000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262940e+01/ 轮得分 327.29\n",
      "损失函数： 0.0195935\n",
      "时间步 4756000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338119e+01/ 轮得分 327.04\n",
      "损失函数： 0.0186527\n",
      "时间步 4757000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390687e+01/ 轮得分 327.04\n",
      "损失函数： 0.0950838\n",
      "时间步 4758000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219802e+01/ 轮得分 327.04\n",
      "损失函数： 0.0438255\n",
      "时间步 4759000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.400005e+01/ 轮得分 327.04\n",
      "损失函数： 0.0395059\n",
      "时间步 4760000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.460420e+01/ 轮得分 327.04\n",
      "损失函数： 0.0154875\n",
      "时间步 4761000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.226527e+01/ 轮得分 327.04\n",
      "损失函数： 0.0350004\n",
      "时间步 4762000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.459541e+01/ 轮得分 327.59\n",
      "损失函数： 0.0118147\n",
      "时间步 4763000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271821e+01/ 轮得分 327.59\n",
      "损失函数： 0.0416799\n",
      "时间步 4764000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.141914e+01/ 轮得分 327.59\n",
      "损失函数： 0.0247601\n",
      "时间步 4765000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315598e+01/ 轮得分 327.59\n",
      "损失函数： 0.0262271\n",
      "时间步 4766000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.272668e+01/ 轮得分 327.59\n",
      "损失函数： 0.0164178\n",
      "时间步 4767000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324238e+01/ 轮得分 327.59\n",
      "损失函数： 0.0605972\n",
      "时间步 4768000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.487198e+01/ 轮得分 328.21\n",
      "损失函数： 0.0315156\n",
      "时间步 4769000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.538278e+01/ 轮得分 328.21\n",
      "损失函数： 3.88671\n",
      "时间步 4770000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.416724e+01/ 轮得分 328.21\n",
      "损失函数： 0.0679653\n",
      "时间步 4771000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.488865e+01/ 轮得分 328.21\n",
      "损失函数： 0.0534799\n",
      "时间步 4772000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.324292e+01/ 轮得分 328.21\n",
      "损失函数： 0.0283826\n",
      "时间步 4773000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.434906e+01/ 轮得分 328.21\n",
      "损失函数： 0.0145813\n",
      "时间步 4774000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.392108e+01/ 轮得分 328.21\n",
      "损失函数： 0.0194477\n",
      "时间步 4775000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327411e+01/ 轮得分 328.21\n",
      "损失函数： 0.0139509\n",
      "时间步 4776000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.353706e+01/ 轮得分 328.21\n",
      "损失函数： 0.0397939\n",
      "时间步 4777000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334585e+01/ 轮得分 328.21\n",
      "损失函数： 0.0280419\n",
      "时间步 4778000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.236359e+01/ 轮得分 329.36\n",
      "损失函数： 0.0846055\n",
      "时间步 4779000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.368105e+01/ 轮得分 329.36\n",
      "损失函数： 0.0290911\n",
      "时间步 4780000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390980e+01/ 轮得分 329.36\n",
      "损失函数： 0.023359\n",
      "时间步 4781000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230953e+01/ 轮得分 329.65\n",
      "损失函数： 0.0369365\n",
      "时间步 4782000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.174645e+01/ 轮得分 329.64\n",
      "损失函数： 0.0198757\n",
      "时间步 4783000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.335862e+01/ 轮得分 329.64\n",
      "损失函数： 0.0160182\n",
      "时间步 4784000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193620e+01/ 轮得分 329.64\n",
      "损失函数： 0.0075666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4785000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.163340e+01/ 轮得分 329.39\n",
      "损失函数： 0.03439\n",
      "时间步 4786000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407107e+01/ 轮得分 329.39\n",
      "损失函数： 0.0475272\n",
      "时间步 4787000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266695e+01/ 轮得分 329.39\n",
      "损失函数： 0.0690158\n",
      "时间步 4788000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.526648e+01/ 轮得分 329.39\n",
      "损失函数： 0.0495517\n",
      "时间步 4789000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297580e+01/ 轮得分 329.39\n",
      "损失函数： 0.015608\n",
      "时间步 4790000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.252502e+01/ 轮得分 329.39\n",
      "损失函数： 0.024414\n",
      "时间步 4791000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.253581e+01/ 轮得分 329.39\n",
      "损失函数： 0.0612077\n",
      "时间步 4792000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248190e+01/ 轮得分 329.39\n",
      "损失函数： 0.0154526\n",
      "时间步 4793000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.380135e+01/ 轮得分 329.39\n",
      "损失函数： 0.0364399\n",
      "时间步 4794000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297106e+01/ 轮得分 329.39\n",
      "损失函数： 0.037076\n",
      "时间步 4795000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258769e+01/ 轮得分 329.39\n",
      "损失函数： 0.0387148\n",
      "时间步 4796000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330942e+01/ 轮得分 329.39\n",
      "损失函数： 0.0338829\n",
      "时间步 4797000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.458582e+01/ 轮得分 330.54\n",
      "损失函数： 0.0139663\n",
      "时间步 4798000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.271851e+01/ 轮得分 330.54\n",
      "损失函数： 0.055696\n",
      "时间步 4799000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.420621e+01/ 轮得分 330.65\n",
      "损失函数： 0.035837\n",
      "时间步 4800000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.482739e+01/ 轮得分 330.51\n",
      "损失函数： 0.0250148\n",
      "时间步 4801000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360003e+01/ 轮得分 330.51\n",
      "损失函数： 0.01416\n",
      "时间步 4802000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412218e+01/ 轮得分 330.72\n",
      "损失函数： 0.0247872\n",
      "时间步 4803000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.440477e+01/ 轮得分 330.72\n",
      "损失函数： 0.0499784\n",
      "时间步 4804000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.177964e+01/ 轮得分 330.72\n",
      "损失函数： 0.0439061\n",
      "时间步 4805000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.333207e+01/ 轮得分 330.72\n",
      "损失函数： 0.0404767\n",
      "时间步 4806000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.169066e+01/ 轮得分 330.72\n",
      "损失函数： 0.0364974\n",
      "时间步 4807000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.360611e+01/ 轮得分 330.72\n",
      "损失函数： 0.0692455\n",
      "时间步 4808000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332140e+01/ 轮得分 330.72\n",
      "损失函数： 0.0195139\n",
      "时间步 4809000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.296214e+01/ 轮得分 331.47\n",
      "损失函数： 0.0640762\n",
      "时间步 4810000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.189938e+01/ 轮得分 331.47\n",
      "损失函数： 0.0148506\n",
      "时间步 4811000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.160702e+01/ 轮得分 331.54\n",
      "损失函数： 0.0207321\n",
      "时间步 4812000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.379151e+01/ 轮得分 331.54\n",
      "损失函数： 0.0356532\n",
      "时间步 4813000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383834e+01/ 轮得分 331.54\n",
      "损失函数： 0.0161558\n",
      "时间步 4814000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310934e+01/ 轮得分 331.54\n",
      "损失函数： 0.0139492\n",
      "时间步 4815000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276345e+01/ 轮得分 331.54\n",
      "损失函数： 0.0200678\n",
      "时间步 4816000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170881e+01/ 轮得分 331.69\n",
      "损失函数： 0.0129369\n",
      "时间步 4817000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197493e+01/ 轮得分 331.35\n",
      "损失函数： 0.0203369\n",
      "时间步 4818000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.404602e+01/ 轮得分 331.08\n",
      "损失函数： 0.0303159\n",
      "时间步 4819000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230024e+01/ 轮得分 331.18\n",
      "损失函数： 0.054824\n",
      "时间步 4820000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294465e+01/ 轮得分 331.24\n",
      "损失函数： 0.0177408\n",
      "时间步 4821000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.209850e+01/ 轮得分 331.22\n",
      "损失函数： 0.0191374\n",
      "时间步 4822000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237845e+01/ 轮得分 331.01\n",
      "损失函数： 0.00921194\n",
      "时间步 4823000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.500121e+01/ 轮得分 330.95\n",
      "损失函数： 0.0257108\n",
      "时间步 4824000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.159807e+01/ 轮得分 330.95\n",
      "损失函数： 0.0261944\n",
      "时间步 4825000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.091612e+01/ 轮得分 330.95\n",
      "损失函数： 0.0232211\n",
      "时间步 4826000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188962e+01/ 轮得分 331.20\n",
      "损失函数： 0.0286099\n",
      "时间步 4827000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.437742e+01/ 轮得分 331.20\n",
      "损失函数： 0.0611017\n",
      "时间步 4828000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.379718e+01/ 轮得分 331.20\n",
      "损失函数： 0.0330216\n",
      "时间步 4829000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263794e+01/ 轮得分 331.05\n",
      "损失函数： 0.0291838\n",
      "时间步 4830000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367265e+01/ 轮得分 331.05\n",
      "损失函数： 0.0299625\n",
      "时间步 4831000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238822e+01/ 轮得分 331.05\n",
      "损失函数： 0.0530779\n",
      "时间步 4832000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.210028e+01/ 轮得分 331.19\n",
      "损失函数： 0.0572017\n",
      "时间步 4833000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241542e+01/ 轮得分 331.06\n",
      "损失函数： 0.147614\n",
      "时间步 4834000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311770e+01/ 轮得分 331.06\n",
      "损失函数： 0.0148279\n",
      "时间步 4835000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.402266e+01/ 轮得分 331.06\n",
      "损失函数： 0.0577958\n",
      "时间步 4836000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.353348e+01/ 轮得分 331.27\n",
      "损失函数： 0.0136637\n",
      "时间步 4837000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193393e+01/ 轮得分 331.27\n",
      "损失函数： 0.0205047\n",
      "时间步 4838000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.145583e+01/ 轮得分 331.28\n",
      "损失函数： 0.0379399\n",
      "时间步 4839000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.183600e+01/ 轮得分 331.28\n",
      "损失函数： 0.0193168\n",
      "时间步 4840000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.457785e+01/ 轮得分 331.28\n",
      "损失函数： 0.0239453\n",
      "时间步 4841000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.320995e+01/ 轮得分 331.45\n",
      "损失函数： 0.0330289\n",
      "时间步 4842000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259099e+01/ 轮得分 331.45\n",
      "损失函数： 0.0454171\n",
      "时间步 4843000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.512382e+01/ 轮得分 331.45\n",
      "损失函数： 0.0641005\n",
      "时间步 4844000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411333e+01/ 轮得分 331.12\n",
      "损失函数： 0.0489441\n",
      "时间步 4845000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.213546e+01/ 轮得分 331.12\n",
      "损失函数： 0.0212996\n",
      "时间步 4846000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308272e+01/ 轮得分 331.12\n",
      "损失函数： 0.0308563\n",
      "时间步 4847000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.487245e+01/ 轮得分 331.12\n",
      "损失函数： 0.0392167\n",
      "时间步 4848000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.533718e+01/ 轮得分 331.12\n",
      "损失函数： 0.0184486\n",
      "时间步 4849000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.359011e+01/ 轮得分 331.47\n",
      "损失函数： 0.0198471\n",
      "时间步 4850000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.064675e+01/ 轮得分 331.47\n",
      "损失函数： 0.0378509\n",
      "时间步 4851000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220636e+01/ 轮得分 331.47\n",
      "损失函数： 0.0343543\n",
      "时间步 4852000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.379858e+01/ 轮得分 331.47\n",
      "损失函数： 0.0456734\n",
      "时间步 4853000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278697e+01/ 轮得分 331.47\n",
      "损失函数： 0.0695907\n",
      "时间步 4854000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274637e+01/ 轮得分 331.39\n",
      "损失函数： 0.0137203\n",
      "时间步 4855000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309151e+01/ 轮得分 330.76\n",
      "损失函数： 0.0508079\n",
      "时间步 4856000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.493861e+01/ 轮得分 330.76\n",
      "损失函数： 0.0716374\n",
      "时间步 4857000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324038e+01/ 轮得分 330.76\n",
      "损失函数： 0.029316\n",
      "时间步 4858000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.192523e+01/ 轮得分 330.76\n",
      "损失函数： 0.0123351\n",
      "时间步 4859000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.515827e+01/ 轮得分 330.76\n",
      "损失函数： 0.0414284\n",
      "时间步 4860000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.483072e+01/ 轮得分 330.76\n",
      "损失函数： 0.0196731\n",
      "时间步 4861000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242775e+01/ 轮得分 330.76\n",
      "损失函数： 0.0256871\n",
      "时间步 4862000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.376102e+01/ 轮得分 330.76\n",
      "损失函数： 0.033226\n",
      "时间步 4863000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327917e+01/ 轮得分 330.76\n",
      "损失函数： 0.0673448\n",
      "时间步 4864000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389466e+01/ 轮得分 330.76\n",
      "损失函数： 0.0329649\n",
      "时间步 4865000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219178e+01/ 轮得分 330.76\n",
      "损失函数： 0.0394616\n",
      "时间步 4866000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.333795e+01/ 轮得分 330.76\n",
      "损失函数： 0.00841316\n",
      "时间步 4867000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255133e+01/ 轮得分 330.76\n",
      "损失函数： 0.029796\n",
      "时间步 4868000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.483351e+01/ 轮得分 330.76\n",
      "损失函数： 0.0646924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4869000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279700e+01/ 轮得分 330.76\n",
      "损失函数： 0.0456324\n",
      "时间步 4870000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.139501e+01/ 轮得分 332.39\n",
      "损失函数： 0.00587988\n",
      "时间步 4871000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.370465e+01/ 轮得分 332.39\n",
      "损失函数： 0.0356267\n",
      "时间步 4872000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335615e+01/ 轮得分 332.39\n",
      "损失函数： 0.0215035\n",
      "时间步 4873000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231355e+01/ 轮得分 332.39\n",
      "损失函数： 0.034732\n",
      "时间步 4874000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393000e+01/ 轮得分 332.53\n",
      "损失函数： 0.0516107\n",
      "时间步 4875000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269547e+01/ 轮得分 332.53\n",
      "损失函数： 0.0135076\n",
      "时间步 4876000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.485862e+01/ 轮得分 332.53\n",
      "损失函数： 0.0169336\n",
      "时间步 4877000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.236907e+01/ 轮得分 332.66\n",
      "损失函数： 0.0182243\n",
      "时间步 4878000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224584e+01/ 轮得分 332.66\n",
      "损失函数： 0.0326596\n",
      "时间步 4879000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.244029e+01/ 轮得分 332.66\n",
      "损失函数： 0.0197382\n",
      "时间步 4880000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.055233e+01/ 轮得分 332.66\n",
      "损失函数： 0.0127416\n",
      "时间步 4881000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313184e+01/ 轮得分 332.66\n",
      "损失函数： 0.0459903\n",
      "时间步 4882000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303655e+01/ 轮得分 332.66\n",
      "损失函数： 0.0224201\n",
      "时间步 4883000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.285885e+01/ 轮得分 332.66\n",
      "损失函数： 0.0343751\n",
      "时间步 4884000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.453302e+01/ 轮得分 332.66\n",
      "损失函数： 0.0482996\n",
      "时间步 4885000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.378988e+01/ 轮得分 332.66\n",
      "损失函数： 0.0160887\n",
      "时间步 4886000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229101e+01/ 轮得分 332.66\n",
      "损失函数： 0.0209171\n",
      "时间步 4887000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.392692e+01/ 轮得分 332.66\n",
      "损失函数： 0.0137395\n",
      "时间步 4888000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.286233e+01/ 轮得分 332.66\n",
      "损失函数： 0.029911\n",
      "时间步 4889000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.456829e+01/ 轮得分 332.66\n",
      "损失函数： 0.0176596\n",
      "时间步 4890000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187971e+01/ 轮得分 332.66\n",
      "损失函数： 0.0148012\n",
      "时间步 4891000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.248956e+01/ 轮得分 332.66\n",
      "损失函数： 0.0330105\n",
      "时间步 4892000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.145901e+01/ 轮得分 332.66\n",
      "损失函数： 0.0426371\n",
      "时间步 4893000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281944e+01/ 轮得分 334.41\n",
      "损失函数： 0.0427331\n",
      "时间步 4894000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.512361e+01/ 轮得分 334.41\n",
      "损失函数： 0.0477391\n",
      "时间步 4895000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.270924e+01/ 轮得分 334.41\n",
      "损失函数： 0.0376293\n",
      "时间步 4896000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365882e+01/ 轮得分 334.41\n",
      "损失函数： 0.0291744\n",
      "时间步 4897000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327273e+01/ 轮得分 334.41\n",
      "损失函数： 0.0251599\n",
      "时间步 4898000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.119733e+01/ 轮得分 334.41\n",
      "损失函数： 0.0255105\n",
      "时间步 4899000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.486793e+01/ 轮得分 334.41\n",
      "损失函数： 0.0145732\n",
      "时间步 4900000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.425350e+01/ 轮得分 334.41\n",
      "损失函数： 0.0132934\n",
      "时间步 4901000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348123e+01/ 轮得分 334.41\n",
      "损失函数： 0.0199897\n",
      "时间步 4902000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330884e+01/ 轮得分 334.41\n",
      "损失函数： 0.0107993\n",
      "时间步 4903000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249515e+01/ 轮得分 334.41\n",
      "损失函数： 0.0358448\n",
      "时间步 4904000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.205565e+01/ 轮得分 335.50\n",
      "损失函数： 0.0173164\n",
      "时间步 4905000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.325323e+01/ 轮得分 335.50\n",
      "损失函数： 0.0329753\n",
      "时间步 4906000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432994e+01/ 轮得分 335.50\n",
      "损失函数： 0.0623666\n",
      "时间步 4907000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244261e+01/ 轮得分 334.86\n",
      "损失函数： 0.0422519\n",
      "时间步 4908000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250726e+01/ 轮得分 334.86\n",
      "损失函数： 0.0122469\n",
      "时间步 4909000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299939e+01/ 轮得分 334.86\n",
      "损失函数： 0.0272102\n",
      "时间步 4910000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206539e+01/ 轮得分 335.13\n",
      "损失函数： 0.039492\n",
      "时间步 4911000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299484e+01/ 轮得分 335.13\n",
      "损失函数： 0.0564458\n",
      "时间步 4912000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.515389e+01/ 轮得分 335.13\n",
      "损失函数： 0.0145942\n",
      "时间步 4913000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351782e+01/ 轮得分 335.13\n",
      "损失函数： 0.0191818\n",
      "时间步 4914000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418761e+01/ 轮得分 335.13\n",
      "损失函数： 0.0115193\n",
      "时间步 4915000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.340489e+01/ 轮得分 335.13\n",
      "损失函数： 0.0123147\n",
      "时间步 4916000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307715e+01/ 轮得分 335.13\n",
      "损失函数： 0.0271978\n",
      "时间步 4917000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.441052e+01/ 轮得分 335.13\n",
      "损失函数： 0.0469511\n",
      "时间步 4918000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330851e+01/ 轮得分 335.13\n",
      "损失函数： 0.013166\n",
      "时间步 4919000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301709e+01/ 轮得分 335.13\n",
      "损失函数： 0.00814783\n",
      "时间步 4920000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317514e+01/ 轮得分 335.62\n",
      "损失函数： 0.0353016\n",
      "时间步 4921000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.246423e+01/ 轮得分 335.62\n",
      "损失函数： 0.0156623\n",
      "时间步 4922000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.452401e+01/ 轮得分 335.19\n",
      "损失函数： 0.0489358\n",
      "时间步 4923000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.203788e+01/ 轮得分 335.19\n",
      "损失函数： 0.0785737\n",
      "时间步 4924000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391660e+01/ 轮得分 335.32\n",
      "损失函数： 0.0171152\n",
      "时间步 4925000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298041e+01/ 轮得分 335.42\n",
      "损失函数： 0.010077\n",
      "时间步 4926000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271172e+01/ 轮得分 335.42\n",
      "损失函数： 0.0133236\n",
      "时间步 4927000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194792e+01/ 轮得分 335.61\n",
      "损失函数： 2.54349\n",
      "时间步 4928000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.313376e+01/ 轮得分 335.61\n",
      "损失函数： 0.0371372\n",
      "时间步 4929000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270983e+01/ 轮得分 335.61\n",
      "损失函数： 0.0127202\n",
      "时间步 4930000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185083e+01/ 轮得分 335.61\n",
      "损失函数： 0.0436184\n",
      "时间步 4931000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206517e+01/ 轮得分 335.61\n",
      "损失函数： 0.0141711\n",
      "时间步 4932000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185298e+01/ 轮得分 335.61\n",
      "损失函数： 0.0174624\n",
      "时间步 4933000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208508e+01/ 轮得分 335.21\n",
      "损失函数： 0.042808\n",
      "时间步 4934000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.162213e+01/ 轮得分 334.44\n",
      "损失函数： 0.0164934\n",
      "时间步 4935000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.243350e+01/ 轮得分 334.44\n",
      "损失函数： 0.0106399\n",
      "时间步 4936000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333037e+01/ 轮得分 334.44\n",
      "损失函数： 0.0409461\n",
      "时间步 4937000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314726e+01/ 轮得分 334.44\n",
      "损失函数： 0.0130709\n",
      "时间步 4938000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411491e+01/ 轮得分 334.59\n",
      "损失函数： 0.018835\n",
      "时间步 4939000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.137672e+01/ 轮得分 334.69\n",
      "损失函数： 0.0370805\n",
      "时间步 4940000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.418520e+01/ 轮得分 334.36\n",
      "损失函数： 0.0666033\n",
      "时间步 4941000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185355e+01/ 轮得分 334.34\n",
      "损失函数： 0.0583473\n",
      "时间步 4942000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.154174e+01/ 轮得分 334.34\n",
      "损失函数： 0.0908583\n",
      "时间步 4943000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.439103e+01/ 轮得分 334.34\n",
      "损失函数： 0.0293625\n",
      "时间步 4944000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384217e+01/ 轮得分 334.34\n",
      "损失函数： 0.0230364\n",
      "时间步 4945000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226759e+01/ 轮得分 334.34\n",
      "损失函数： 0.0117004\n",
      "时间步 4946000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.245372e+01/ 轮得分 334.34\n",
      "损失函数： 0.0549769\n",
      "时间步 4947000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.248650e+01/ 轮得分 334.34\n",
      "损失函数： 0.0416571\n",
      "时间步 4948000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255468e+01/ 轮得分 335.06\n",
      "损失函数： 0.0214514\n",
      "时间步 4949000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.457326e+01/ 轮得分 335.06\n",
      "损失函数： 0.0448698\n",
      "时间步 4950000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394525e+01/ 轮得分 335.06\n",
      "损失函数： 0.02626\n",
      "时间步 4951000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361328e+01/ 轮得分 335.06\n",
      "损失函数： 0.0314634\n",
      "时间步 4952000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.518535e+01/ 轮得分 335.06\n",
      "损失函数： 0.0285868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 4953000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330128e+01/ 轮得分 335.06\n",
      "损失函数： 0.0383429\n",
      "时间步 4954000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.381513e+01/ 轮得分 335.06\n",
      "损失函数： 0.0319329\n",
      "时间步 4955000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 9.821373e+00/ 轮得分 335.06\n",
      "损失函数： 0.0219874\n",
      "时间步 4956000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.218742e+01/ 轮得分 335.75\n",
      "损失函数： 0.0185785\n",
      "时间步 4957000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237533e+01/ 轮得分 335.75\n",
      "损失函数： 0.0184116\n",
      "时间步 4958000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332293e+01/ 轮得分 335.75\n",
      "损失函数： 0.0138842\n",
      "时间步 4959000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.255374e+01/ 轮得分 335.75\n",
      "损失函数： 0.0488586\n",
      "时间步 4960000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400833e+01/ 轮得分 336.13\n",
      "损失函数： 0.0144022\n",
      "时间步 4961000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248477e+01/ 轮得分 336.03\n",
      "损失函数： 0.0469182\n",
      "时间步 4962000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236375e+01/ 轮得分 336.03\n",
      "损失函数： 0.0870276\n",
      "时间步 4963000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315469e+01/ 轮得分 336.27\n",
      "损失函数： 0.0133347\n",
      "时间步 4964000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407332e+01/ 轮得分 335.96\n",
      "损失函数： 0.0266944\n",
      "时间步 4965000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334666e+01/ 轮得分 335.96\n",
      "损失函数： 0.0177552\n",
      "时间步 4966000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.241182e+01/ 轮得分 335.96\n",
      "损失函数： 0.0145588\n",
      "时间步 4967000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269584e+01/ 轮得分 335.96\n",
      "损失函数： 0.0267476\n",
      "时间步 4968000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317164e+01/ 轮得分 336.28\n",
      "损失函数： 0.0197861\n",
      "时间步 4969000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188955e+01/ 轮得分 336.28\n",
      "损失函数： 0.0194792\n",
      "时间步 4970000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.405307e+01/ 轮得分 336.28\n",
      "损失函数： 0.048759\n",
      "时间步 4971000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234124e+01/ 轮得分 336.28\n",
      "损失函数： 0.0146534\n",
      "时间步 4972000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319900e+01/ 轮得分 336.28\n",
      "损失函数： 0.036213\n",
      "时间步 4973000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206293e+01/ 轮得分 336.28\n",
      "损失函数： 0.0189\n",
      "时间步 4974000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315990e+01/ 轮得分 336.28\n",
      "损失函数： 0.0291917\n",
      "时间步 4975000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.614728e+01/ 轮得分 336.28\n",
      "损失函数： 0.0704982\n",
      "时间步 4976000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228810e+01/ 轮得分 337.00\n",
      "损失函数： 0.0717885\n",
      "时间步 4977000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186927e+01/ 轮得分 337.00\n",
      "损失函数： 0.0272636\n",
      "时间步 4978000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.378628e+01/ 轮得分 337.00\n",
      "损失函数： 0.0213927\n",
      "时间步 4979000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.499607e+01/ 轮得分 337.00\n",
      "损失函数： 0.0105977\n",
      "时间步 4980000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229006e+01/ 轮得分 337.00\n",
      "损失函数： 0.0127843\n",
      "时间步 4981000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236830e+01/ 轮得分 337.00\n",
      "损失函数： 0.0229629\n",
      "时间步 4982000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363603e+01/ 轮得分 337.00\n",
      "损失函数： 0.0825286\n",
      "时间步 4983000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.445222e+01/ 轮得分 337.00\n",
      "损失函数： 0.0598098\n",
      "时间步 4984000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.209466e+01/ 轮得分 337.91\n",
      "损失函数： 0.0899895\n",
      "时间步 4985000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.427660e+01/ 轮得分 337.91\n",
      "损失函数： 0.0223456\n",
      "时间步 4986000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.155556e+01/ 轮得分 337.91\n",
      "损失函数： 0.0109168\n",
      "时间步 4987000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339128e+01/ 轮得分 337.91\n",
      "损失函数： 0.0335096\n",
      "时间步 4988000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192362e+01/ 轮得分 337.91\n",
      "损失函数： 0.035773\n",
      "时间步 4989000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.216711e+01/ 轮得分 337.91\n",
      "损失函数： 0.0164056\n",
      "时间步 4990000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.600467e+01/ 轮得分 338.50\n",
      "损失函数： 0.0156008\n",
      "时间步 4991000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226803e+01/ 轮得分 338.50\n",
      "损失函数： 0.0206343\n",
      "时间步 4992000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.402279e+01/ 轮得分 338.50\n",
      "损失函数： 0.0105255\n",
      "时间步 4993000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.444577e+01/ 轮得分 338.50\n",
      "损失函数： 0.0423239\n",
      "时间步 4994000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205066e+01/ 轮得分 338.50\n",
      "损失函数： 0.0179969\n",
      "时间步 4995000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.302270e+01/ 轮得分 338.50\n",
      "损失函数： 0.0125089\n",
      "时间步 4996000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.252189e+01/ 轮得分 338.50\n",
      "损失函数： 0.043311\n",
      "时间步 4997000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.129093e+01/ 轮得分 338.50\n",
      "损失函数： 0.0342511\n",
      "时间步 4998000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301872e+01/ 轮得分 338.50\n",
      "损失函数： 0.00914895\n",
      "时间步 4999000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252946e+01/ 轮得分 338.50\n",
      "损失函数： 0.0212462\n",
      "时间步 5000000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196845e+01/ 轮得分 339.58\n",
      "损失函数： 0.0685166\n",
      "时间步 5001000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.475756e+01/ 轮得分 339.58\n",
      "损失函数： 0.0141392\n",
      "时间步 5002000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299747e+01/ 轮得分 339.58\n",
      "损失函数： 0.0397008\n",
      "时间步 5003000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306061e+01/ 轮得分 339.58\n",
      "损失函数： 0.0401236\n",
      "时间步 5004000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207421e+01/ 轮得分 339.84\n",
      "损失函数： 0.0177383\n",
      "时间步 5005000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290201e+01/ 轮得分 339.84\n",
      "损失函数： 0.0394191\n",
      "时间步 5006000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.353028e+01/ 轮得分 339.84\n",
      "损失函数： 0.0217298\n",
      "时间步 5007000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191593e+01/ 轮得分 339.84\n",
      "损失函数： 0.0123911\n",
      "时间步 5008000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188054e+01/ 轮得分 339.84\n",
      "损失函数： 0.0250886\n",
      "时间步 5009000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319845e+01/ 轮得分 339.84\n",
      "损失函数： 0.00761997\n",
      "时间步 5010000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277950e+01/ 轮得分 339.84\n",
      "损失函数： 0.031567\n",
      "时间步 5011000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348460e+01/ 轮得分 339.84\n",
      "损失函数： 0.0372831\n",
      "时间步 5012000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248041e+01/ 轮得分 339.84\n",
      "损失函数： 0.0170875\n",
      "时间步 5013000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331083e+01/ 轮得分 339.84\n",
      "损失函数： 0.0192708\n",
      "时间步 5014000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.294773e+01/ 轮得分 340.70\n",
      "损失函数： 0.030154\n",
      "时间步 5015000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.139854e+01/ 轮得分 340.55\n",
      "损失函数： 0.0400407\n",
      "时间步 5016000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.480158e+01/ 轮得分 340.55\n",
      "损失函数： 0.00558088\n",
      "时间步 5017000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187781e+01/ 轮得分 340.70\n",
      "损失函数： 0.0185013\n",
      "时间步 5018000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207768e+01/ 轮得分 340.64\n",
      "损失函数： 0.0267037\n",
      "时间步 5019000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375373e+01/ 轮得分 340.64\n",
      "损失函数： 0.0212145\n",
      "时间步 5020000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414496e+01/ 轮得分 340.48\n",
      "损失函数： 0.00879635\n",
      "时间步 5021000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.182678e+01/ 轮得分 340.48\n",
      "损失函数： 0.0158161\n",
      "时间步 5022000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.146102e+01/ 轮得分 340.48\n",
      "损失函数： 0.0113087\n",
      "时间步 5023000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393024e+01/ 轮得分 340.75\n",
      "损失函数： 0.0216833\n",
      "时间步 5024000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.271998e+01/ 轮得分 340.75\n",
      "损失函数： 0.0509636\n",
      "时间步 5025000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284807e+01/ 轮得分 340.75\n",
      "损失函数： 0.0444539\n",
      "时间步 5026000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.371833e+01/ 轮得分 340.67\n",
      "损失函数： 0.0363722\n",
      "时间步 5027000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.523898e+01/ 轮得分 340.67\n",
      "损失函数： 0.0478471\n",
      "时间步 5028000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330891e+01/ 轮得分 340.67\n",
      "损失函数： 0.0108653\n",
      "时间步 5029000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235677e+01/ 轮得分 340.67\n",
      "损失函数： 0.0133269\n",
      "时间步 5030000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354331e+01/ 轮得分 340.67\n",
      "损失函数： 0.0694396\n",
      "时间步 5031000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.250285e+01/ 轮得分 340.67\n",
      "损失函数： 0.0211911\n",
      "时间步 5032000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264604e+01/ 轮得分 340.67\n",
      "损失函数： 0.0119954\n",
      "时间步 5033000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345827e+01/ 轮得分 340.67\n",
      "损失函数： 0.0478612\n",
      "时间步 5034000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347706e+01/ 轮得分 340.67\n",
      "损失函数： 0.0200983\n",
      "时间步 5035000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294334e+01/ 轮得分 340.67\n",
      "损失函数： 3.80962\n",
      "时间步 5036000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.440505e+01/ 轮得分 340.67\n",
      "损失函数： 0.035326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5037000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323946e+01/ 轮得分 340.67\n",
      "损失函数： 0.0224989\n",
      "时间步 5038000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.553415e+01/ 轮得分 340.67\n",
      "损失函数： 0.0306507\n",
      "时间步 5039000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251908e+01/ 轮得分 340.67\n",
      "损失函数： 0.0658338\n",
      "时间步 5040000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328978e+01/ 轮得分 340.67\n",
      "损失函数： 0.0257294\n",
      "时间步 5041000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.322890e+01/ 轮得分 342.46\n",
      "损失函数： 0.0577295\n",
      "时间步 5042000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.166512e+01/ 轮得分 342.46\n",
      "损失函数： 0.0151908\n",
      "时间步 5043000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.451289e+01/ 轮得分 342.46\n",
      "损失函数： 0.0182109\n",
      "时间步 5044000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345310e+01/ 轮得分 342.46\n",
      "损失函数： 0.0394081\n",
      "时间步 5045000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248464e+01/ 轮得分 342.83\n",
      "损失函数： 0.0296789\n",
      "时间步 5046000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.401098e+01/ 轮得分 342.83\n",
      "损失函数： 0.0292702\n",
      "时间步 5047000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.470217e+01/ 轮得分 342.83\n",
      "损失函数： 0.0201867\n",
      "时间步 5048000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272942e+01/ 轮得分 342.83\n",
      "损失函数： 0.0315075\n",
      "时间步 5049000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.348597e+01/ 轮得分 342.83\n",
      "损失函数： 0.0202767\n",
      "时间步 5050000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275875e+01/ 轮得分 342.83\n",
      "损失函数： 0.0284667\n",
      "时间步 5051000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.500709e+01/ 轮得分 342.83\n",
      "损失函数： 0.0425191\n",
      "时间步 5052000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.594605e+01/ 轮得分 343.30\n",
      "损失函数： 0.0351585\n",
      "时间步 5053000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291574e+01/ 轮得分 343.30\n",
      "损失函数： 0.0128165\n",
      "时间步 5054000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341254e+01/ 轮得分 343.27\n",
      "损失函数： 0.0270125\n",
      "时间步 5055000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.491747e+01/ 轮得分 343.27\n",
      "损失函数： 0.0765174\n",
      "时间步 5056000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373253e+01/ 轮得分 343.27\n",
      "损失函数： 0.0667585\n",
      "时间步 5057000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276837e+01/ 轮得分 342.15\n",
      "损失函数： 0.0491911\n",
      "时间步 5058000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.346835e+01/ 轮得分 342.15\n",
      "损失函数： 0.0263622\n",
      "时间步 5059000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.022997e+01/ 轮得分 342.22\n",
      "损失函数： 0.0151155\n",
      "时间步 5060000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.051967e+01/ 轮得分 342.14\n",
      "损失函数： 0.015307\n",
      "时间步 5061000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.502870e+01/ 轮得分 342.14\n",
      "损失函数： 0.0225209\n",
      "时间步 5062000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231854e+01/ 轮得分 342.43\n",
      "损失函数： 0.0363045\n",
      "时间步 5063000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324997e+01/ 轮得分 342.17\n",
      "损失函数： 0.0261373\n",
      "时间步 5064000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.189693e+01/ 轮得分 342.17\n",
      "损失函数： 0.0103972\n",
      "时间步 5065000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.371139e+01/ 轮得分 342.17\n",
      "损失函数： 0.0181113\n",
      "时间步 5066000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.213000e+01/ 轮得分 342.17\n",
      "损失函数： 0.0215698\n",
      "时间步 5067000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355997e+01/ 轮得分 342.17\n",
      "损失函数： 0.0772201\n",
      "时间步 5068000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225062e+01/ 轮得分 342.17\n",
      "损失函数： 0.0416953\n",
      "时间步 5069000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 3.848689e+00/ 轮得分 342.17\n",
      "损失函数： 0.012511\n",
      "时间步 5070000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.439908e+01/ 轮得分 342.61\n",
      "损失函数： 0.0446315\n",
      "时间步 5071000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257095e+01/ 轮得分 342.46\n",
      "损失函数： 0.0271221\n",
      "时间步 5072000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215542e+01/ 轮得分 342.19\n",
      "损失函数： 0.0274722\n",
      "时间步 5073000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.119949e+01/ 轮得分 342.14\n",
      "损失函数： 0.0688618\n",
      "时间步 5074000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269054e+01/ 轮得分 342.14\n",
      "损失函数： 0.030483\n",
      "时间步 5075000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338099e+01/ 轮得分 342.14\n",
      "损失函数： 0.0143594\n",
      "时间步 5076000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263243e+01/ 轮得分 342.14\n",
      "损失函数： 0.0191375\n",
      "时间步 5077000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.350017e+01/ 轮得分 342.14\n",
      "损失函数： 0.0494457\n",
      "时间步 5078000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.450327e+01/ 轮得分 342.14\n",
      "损失函数： 0.0208354\n",
      "时间步 5079000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294099e+01/ 轮得分 342.14\n",
      "损失函数： 0.018865\n",
      "时间步 5080000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.394168e+01/ 轮得分 342.14\n",
      "损失函数： 0.0211406\n",
      "时间步 5081000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224376e+01/ 轮得分 342.14\n",
      "损失函数： 0.0236293\n",
      "时间步 5082000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.051371e+01/ 轮得分 342.14\n",
      "损失函数： 0.0308179\n",
      "时间步 5083000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377247e+01/ 轮得分 343.00\n",
      "损失函数： 0.0509804\n",
      "时间步 5084000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208562e+01/ 轮得分 343.00\n",
      "损失函数： 0.0413621\n",
      "时间步 5085000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.176578e+01/ 轮得分 343.00\n",
      "损失函数： 0.0527469\n",
      "时间步 5086000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.067055e+01/ 轮得分 343.00\n",
      "损失函数： 0.0325367\n",
      "时间步 5087000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177625e+01/ 轮得分 343.00\n",
      "损失函数： 0.0404365\n",
      "时间步 5088000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170476e+01/ 轮得分 343.03\n",
      "损失函数： 0.0136415\n",
      "时间步 5089000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.429743e+01/ 轮得分 343.03\n",
      "损失函数： 0.110319\n",
      "时间步 5090000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.237910e+01/ 轮得分 343.01\n",
      "损失函数： 0.0192803\n",
      "时间步 5091000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345895e+01/ 轮得分 343.01\n",
      "损失函数： 0.0108394\n",
      "时间步 5092000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.400111e+01/ 轮得分 342.40\n",
      "损失函数： 0.0338932\n",
      "时间步 5093000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.274828e+01/ 轮得分 342.40\n",
      "损失函数： 0.0201752\n",
      "时间步 5094000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284252e+01/ 轮得分 342.40\n",
      "损失函数： 0.0361499\n",
      "时间步 5095000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233960e+01/ 轮得分 342.68\n",
      "损失函数： 0.0147232\n",
      "时间步 5096000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412559e+01/ 轮得分 342.68\n",
      "损失函数： 0.0312809\n",
      "时间步 5097000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.490409e+01/ 轮得分 342.68\n",
      "损失函数： 0.0264727\n",
      "时间步 5098000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.143695e+01/ 轮得分 342.68\n",
      "损失函数： 0.0978638\n",
      "时间步 5099000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.421385e+01/ 轮得分 342.68\n",
      "损失函数： 0.0351295\n",
      "时间步 5100000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.116829e+01/ 轮得分 343.31\n",
      "损失函数： 0.0230375\n",
      "时间步 5101000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.194102e+01/ 轮得分 343.31\n",
      "损失函数： 0.102046\n",
      "时间步 5102000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396928e+01/ 轮得分 343.31\n",
      "损失函数： 0.0175426\n",
      "时间步 5103000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345062e+01/ 轮得分 343.31\n",
      "损失函数： 0.129088\n",
      "时间步 5104000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208704e+01/ 轮得分 343.31\n",
      "损失函数： 0.0452465\n",
      "时间步 5105000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.254939e+01/ 轮得分 343.31\n",
      "损失函数： 0.0427087\n",
      "时间步 5106000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.336772e+01/ 轮得分 343.31\n",
      "损失函数： 0.0236122\n",
      "时间步 5107000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349339e+01/ 轮得分 343.83\n",
      "损失函数： 0.0384336\n",
      "时间步 5108000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276075e+01/ 轮得分 343.83\n",
      "损失函数： 0.0198151\n",
      "时间步 5109000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274923e+01/ 轮得分 343.83\n",
      "损失函数： 0.0118942\n",
      "时间步 5110000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.137897e+01/ 轮得分 343.98\n",
      "损失函数： 0.0416049\n",
      "时间步 5111000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.364241e+01/ 轮得分 343.98\n",
      "损失函数： 0.0227716\n",
      "时间步 5112000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.386130e+01/ 轮得分 344.11\n",
      "损失函数： 0.0466476\n",
      "时间步 5113000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162735e+01/ 轮得分 344.11\n",
      "损失函数： 0.0250785\n",
      "时间步 5114000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225745e+01/ 轮得分 344.39\n",
      "损失函数： 0.0231757\n",
      "时间步 5115000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307385e+01/ 轮得分 344.39\n",
      "损失函数： 0.0304498\n",
      "时间步 5116000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.337357e+01/ 轮得分 344.37\n",
      "损失函数： 0.0198492\n",
      "时间步 5117000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.200200e+01/ 轮得分 344.37\n",
      "损失函数： 0.0120882\n",
      "时间步 5118000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.178224e+01/ 轮得分 344.49\n",
      "损失函数： 0.0628229\n",
      "时间步 5119000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274514e+01/ 轮得分 344.49\n",
      "损失函数： 0.0241905\n",
      "时间步 5120000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305434e+01/ 轮得分 344.49\n",
      "损失函数： 0.0514394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5121000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192885e+01/ 轮得分 344.40\n",
      "损失函数： 0.0579927\n",
      "时间步 5122000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184774e+01/ 轮得分 344.40\n",
      "损失函数： 0.0483882\n",
      "时间步 5123000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227348e+01/ 轮得分 344.09\n",
      "损失函数： 0.0267014\n",
      "时间步 5124000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.536771e+01/ 轮得分 344.09\n",
      "损失函数： 0.0460092\n",
      "时间步 5125000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245285e+01/ 轮得分 344.09\n",
      "损失函数： 0.0584694\n",
      "时间步 5126000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255154e+01/ 轮得分 344.09\n",
      "损失函数： 0.0411327\n",
      "时间步 5127000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223961e+01/ 轮得分 344.32\n",
      "损失函数： 0.0409454\n",
      "时间步 5128000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391720e+01/ 轮得分 344.32\n",
      "损失函数： 0.0891471\n",
      "时间步 5129000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.236501e+01/ 轮得分 344.32\n",
      "损失函数： 0.072482\n",
      "时间步 5130000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260491e+01/ 轮得分 344.32\n",
      "损失函数： 0.0453399\n",
      "时间步 5131000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.516926e+01/ 轮得分 344.32\n",
      "损失函数： 0.0505146\n",
      "时间步 5132000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.333072e+01/ 轮得分 344.32\n",
      "损失函数： 0.0148194\n",
      "时间步 5133000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159382e+01/ 轮得分 344.32\n",
      "损失函数： 0.0235977\n",
      "时间步 5134000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.218482e+01/ 轮得分 345.02\n",
      "损失函数： 0.0302975\n",
      "时间步 5135000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.163869e+01/ 轮得分 345.02\n",
      "损失函数： 0.0207056\n",
      "时间步 5136000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197144e+01/ 轮得分 345.26\n",
      "损失函数： 0.0884856\n",
      "时间步 5137000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.138519e+01/ 轮得分 345.15\n",
      "损失函数： 0.0289565\n",
      "时间步 5138000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.332393e+01/ 轮得分 345.15\n",
      "损失函数： 0.0165047\n",
      "时间步 5139000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241205e+01/ 轮得分 345.15\n",
      "损失函数： 0.0360907\n",
      "时间步 5140000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.565260e+01/ 轮得分 345.21\n",
      "损失函数： 0.0347448\n",
      "时间步 5141000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271427e+01/ 轮得分 345.29\n",
      "损失函数： 0.016218\n",
      "时间步 5142000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316217e+01/ 轮得分 345.29\n",
      "损失函数： 0.0266427\n",
      "时间步 5143000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339038e+01/ 轮得分 345.29\n",
      "损失函数： 0.0642337\n",
      "时间步 5144000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.328557e+01/ 轮得分 345.15\n",
      "损失函数： 0.0286803\n",
      "时间步 5145000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.314380e+01/ 轮得分 345.15\n",
      "损失函数： 0.0284904\n",
      "时间步 5146000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.416313e+01/ 轮得分 345.05\n",
      "损失函数： 0.04217\n",
      "时间步 5147000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.281227e+00/ 轮得分 345.05\n",
      "损失函数： 0.0112781\n",
      "时间步 5148000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.429425e+01/ 轮得分 345.05\n",
      "损失函数： 0.0254927\n",
      "时间步 5149000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.213244e+01/ 轮得分 345.05\n",
      "损失函数： 0.279765\n",
      "时间步 5150000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.362337e+01/ 轮得分 345.12\n",
      "损失函数： 0.0323527\n",
      "时间步 5151000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.151422e+01/ 轮得分 345.11\n",
      "损失函数： 0.0482108\n",
      "时间步 5152000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448989e+01/ 轮得分 345.11\n",
      "损失函数： 0.0270631\n",
      "时间步 5153000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.194688e+01/ 轮得分 345.11\n",
      "损失函数： 0.0678659\n",
      "时间步 5154000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.392437e+01/ 轮得分 345.42\n",
      "损失函数： 0.0197357\n",
      "时间步 5155000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263614e+01/ 轮得分 344.60\n",
      "损失函数： 0.0543233\n",
      "时间步 5156000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315628e+01/ 轮得分 344.60\n",
      "损失函数： 0.0260606\n",
      "时间步 5157000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414892e+01/ 轮得分 344.60\n",
      "损失函数： 0.0165863\n",
      "时间步 5158000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201506e+01/ 轮得分 344.37\n",
      "损失函数： 0.0234335\n",
      "时间步 5159000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249127e+01/ 轮得分 344.37\n",
      "损失函数： 0.0114376\n",
      "时间步 5160000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.636016e+01/ 轮得分 344.37\n",
      "损失函数： 0.0198578\n",
      "时间步 5161000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.253662e+01/ 轮得分 344.37\n",
      "损失函数： 0.0279628\n",
      "时间步 5162000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273067e+01/ 轮得分 344.37\n",
      "损失函数： 0.0377645\n",
      "时间步 5163000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.263113e+01/ 轮得分 344.80\n",
      "损失函数： 0.0132563\n",
      "时间步 5164000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.442951e+01/ 轮得分 344.80\n",
      "损失函数： 0.0147102\n",
      "时间步 5165000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194728e+01/ 轮得分 345.08\n",
      "损失函数： 0.0385686\n",
      "时间步 5166000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355365e+01/ 轮得分 345.08\n",
      "损失函数： 0.0112417\n",
      "时间步 5167000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 8.258299e+00/ 轮得分 345.08\n",
      "损失函数： 0.0498155\n",
      "时间步 5168000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327571e+01/ 轮得分 345.12\n",
      "损失函数： 0.0262498\n",
      "时间步 5169000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.401092e+01/ 轮得分 344.94\n",
      "损失函数： 0.0258825\n",
      "时间步 5170000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281628e+01/ 轮得分 344.94\n",
      "损失函数： 0.0345804\n",
      "时间步 5171000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.557268e+01/ 轮得分 344.85\n",
      "损失函数： 0.0118676\n",
      "时间步 5172000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255180e+01/ 轮得分 344.85\n",
      "损失函数： 0.0228955\n",
      "时间步 5173000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.426320e+01/ 轮得分 344.85\n",
      "损失函数： 0.0323156\n",
      "时间步 5174000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396682e+01/ 轮得分 344.85\n",
      "损失函数： 0.0306174\n",
      "时间步 5175000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229425e+01/ 轮得分 344.53\n",
      "损失函数： 0.0264008\n",
      "时间步 5176000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.390626e+01/ 轮得分 344.53\n",
      "损失函数： 0.0491493\n",
      "时间步 5177000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296815e+01/ 轮得分 344.53\n",
      "损失函数： 0.0348885\n",
      "时间步 5178000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.247119e+01/ 轮得分 344.53\n",
      "损失函数： 0.0282971\n",
      "时间步 5179000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.439876e+01/ 轮得分 344.53\n",
      "损失函数： 0.0404522\n",
      "时间步 5180000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318329e+01/ 轮得分 344.53\n",
      "损失函数： 0.0147355\n",
      "时间步 5181000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346927e+01/ 轮得分 344.53\n",
      "损失函数： 0.104032\n",
      "时间步 5182000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287140e+01/ 轮得分 344.53\n",
      "损失函数： 0.0313153\n",
      "时间步 5183000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.626468e+01/ 轮得分 344.53\n",
      "损失函数： 0.0226323\n",
      "时间步 5184000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.258064e+01/ 轮得分 344.53\n",
      "损失函数： 0.0232435\n",
      "时间步 5185000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447536e+01/ 轮得分 344.53\n",
      "损失函数： 0.0296683\n",
      "时间步 5186000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.158103e+01/ 轮得分 345.53\n",
      "损失函数： 0.0423355\n",
      "时间步 5187000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293644e+01/ 轮得分 345.53\n",
      "损失函数： 0.0488356\n",
      "时间步 5188000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.297251e+01/ 轮得分 345.53\n",
      "损失函数： 0.0118412\n",
      "时间步 5189000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.549050e+01/ 轮得分 345.53\n",
      "损失函数： 0.0275464\n",
      "时间步 5190000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315871e+01/ 轮得分 345.53\n",
      "损失函数： 0.0307856\n",
      "时间步 5191000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.429724e+01/ 轮得分 346.10\n",
      "损失函数： 0.0507957\n",
      "时间步 5192000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305622e+01/ 轮得分 345.62\n",
      "损失函数： 0.0351025\n",
      "时间步 5193000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327638e+01/ 轮得分 345.56\n",
      "损失函数： 0.0131884\n",
      "时间步 5194000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.399024e+01/ 轮得分 345.56\n",
      "损失函数： 0.0287417\n",
      "时间步 5195000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334343e+01/ 轮得分 345.56\n",
      "损失函数： 0.0292721\n",
      "时间步 5196000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.502639e+01/ 轮得分 345.56\n",
      "损失函数： 0.0456535\n",
      "时间步 5197000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322128e+01/ 轮得分 345.56\n",
      "损失函数： 0.0311806\n",
      "时间步 5198000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.404965e+01/ 轮得分 345.56\n",
      "损失函数： 0.0537702\n",
      "时间步 5199000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.512960e+01/ 轮得分 346.21\n",
      "损失函数： 0.0231622\n",
      "时间步 5200000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.232469e+01/ 轮得分 346.21\n",
      "损失函数： 0.0348992\n",
      "时间步 5201000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.441347e+01/ 轮得分 345.75\n",
      "损失函数： 0.0216793\n",
      "时间步 5202000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.428767e+01/ 轮得分 345.75\n",
      "损失函数： 0.0256935\n",
      "时间步 5203000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.123525e+01/ 轮得分 345.75\n",
      "损失函数： 0.039727\n",
      "时间步 5204000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293269e+01/ 轮得分 345.46\n",
      "损失函数： 0.0286373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5205000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304186e+01/ 轮得分 345.46\n",
      "损失函数： 0.0342787\n",
      "时间步 5206000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.265711e+01/ 轮得分 345.46\n",
      "损失函数： 0.029019\n",
      "时间步 5207000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.240276e+01/ 轮得分 345.68\n",
      "损失函数： 0.0301988\n",
      "时间步 5208000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.345929e+01/ 轮得分 345.68\n",
      "损失函数： 0.0166416\n",
      "时间步 5209000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.495890e+01/ 轮得分 345.68\n",
      "损失函数： 0.0199553\n",
      "时间步 5210000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.283179e+01/ 轮得分 345.95\n",
      "损失函数： 0.0226354\n",
      "时间步 5211000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.372244e+01/ 轮得分 346.01\n",
      "损失函数： 0.0395511\n",
      "时间步 5212000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259791e+01/ 轮得分 346.01\n",
      "损失函数： 0.0269395\n",
      "时间步 5213000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390401e+01/ 轮得分 345.96\n",
      "损失函数： 0.0258627\n",
      "时间步 5214000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188879e+01/ 轮得分 345.56\n",
      "损失函数： 0.0259053\n",
      "时间步 5215000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284183e+01/ 轮得分 345.56\n",
      "损失函数： 0.0378282\n",
      "时间步 5216000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.428354e+01/ 轮得分 345.56\n",
      "损失函数： 0.017767\n",
      "时间步 5217000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.240092e+01/ 轮得分 345.40\n",
      "损失函数： 0.219499\n",
      "时间步 5218000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.006307e+01/ 轮得分 345.40\n",
      "损失函数： 0.0296167\n",
      "时间步 5219000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.422371e+01/ 轮得分 345.40\n",
      "损失函数： 0.138895\n",
      "时间步 5220000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233441e+01/ 轮得分 345.40\n",
      "损失函数： 0.0171121\n",
      "时间步 5221000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.455649e+01/ 轮得分 345.40\n",
      "损失函数： 0.0245733\n",
      "时间步 5222000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229743e+01/ 轮得分 345.40\n",
      "损失函数： 0.0402834\n",
      "时间步 5223000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.420923e+01/ 轮得分 345.40\n",
      "损失函数： 0.025406\n",
      "时间步 5224000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432855e+01/ 轮得分 345.40\n",
      "损失函数： 0.0315107\n",
      "时间步 5225000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.158663e+01/ 轮得分 345.40\n",
      "损失函数： 0.0112384\n",
      "时间步 5226000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332211e+01/ 轮得分 345.40\n",
      "损失函数： 0.116356\n",
      "时间步 5227000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.507933e+01/ 轮得分 346.29\n",
      "损失函数： 0.0174235\n",
      "时间步 5228000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.516488e+01/ 轮得分 346.38\n",
      "损失函数： 0.0134207\n",
      "时间步 5229000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.295397e+01/ 轮得分 346.38\n",
      "损失函数： 0.0166359\n",
      "时间步 5230000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250481e+01/ 轮得分 346.38\n",
      "损失函数： 0.0371553\n",
      "时间步 5231000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.158926e+01/ 轮得分 346.38\n",
      "损失函数： 0.0806741\n",
      "时间步 5232000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290287e+01/ 轮得分 346.38\n",
      "损失函数： 0.0140752\n",
      "时间步 5233000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.195551e+01/ 轮得分 346.38\n",
      "损失函数： 0.0190839\n",
      "时间步 5234000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411848e+01/ 轮得分 346.62\n",
      "损失函数： 0.0121416\n",
      "时间步 5235000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308604e+01/ 轮得分 346.62\n",
      "损失函数： 0.0418007\n",
      "时间步 5236000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.535875e+01/ 轮得分 346.62\n",
      "损失函数： 0.0151117\n",
      "时间步 5237000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.424870e+01/ 轮得分 346.62\n",
      "损失函数： 0.188358\n",
      "时间步 5238000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254018e+01/ 轮得分 346.62\n",
      "损失函数： 0.0324331\n",
      "时间步 5239000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286586e+01/ 轮得分 346.62\n",
      "损失函数： 0.0310708\n",
      "时间步 5240000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296598e+01/ 轮得分 346.62\n",
      "损失函数： 0.0250983\n",
      "时间步 5241000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.449971e+01/ 轮得分 346.62\n",
      "损失函数： 0.028931\n",
      "时间步 5242000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.479886e+01/ 轮得分 346.62\n",
      "损失函数： 0.0169048\n",
      "时间步 5243000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312177e+01/ 轮得分 346.62\n",
      "损失函数： 0.0277783\n",
      "时间步 5244000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.422142e+01/ 轮得分 346.62\n",
      "损失函数： 0.0192238\n",
      "时间步 5245000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.395374e+01/ 轮得分 347.64\n",
      "损失函数： 0.0125027\n",
      "时间步 5246000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.165894e+01/ 轮得分 347.64\n",
      "损失函数： 0.0195715\n",
      "时间步 5247000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187366e+01/ 轮得分 347.64\n",
      "损失函数： 0.0721586\n",
      "时间步 5248000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276387e+01/ 轮得分 347.84\n",
      "损失函数： 0.0263237\n",
      "时间步 5249000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354383e+01/ 轮得分 347.77\n",
      "损失函数： 0.0235487\n",
      "时间步 5250000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204393e+01/ 轮得分 347.77\n",
      "损失函数： 0.0191527\n",
      "时间步 5251000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271621e+01/ 轮得分 347.77\n",
      "损失函数： 0.0148523\n",
      "时间步 5252000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.385552e+01/ 轮得分 347.77\n",
      "损失函数： 0.0397101\n",
      "时间步 5253000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.274397e+01/ 轮得分 347.77\n",
      "损失函数： 0.0228535\n",
      "时间步 5254000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.453025e+01/ 轮得分 348.46\n",
      "损失函数： 0.00881835\n",
      "时间步 5255000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363444e+01/ 轮得分 348.37\n",
      "损失函数： 0.0552349\n",
      "时间步 5256000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360075e+01/ 轮得分 348.37\n",
      "损失函数： 0.0149472\n",
      "时间步 5257000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.375214e+01/ 轮得分 348.37\n",
      "损失函数： 0.0653293\n",
      "时间步 5258000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.641048e+01/ 轮得分 348.54\n",
      "损失函数： 0.0192197\n",
      "时间步 5259000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.052950e+01/ 轮得分 348.41\n",
      "损失函数： 0.0206478\n",
      "时间步 5260000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400959e+01/ 轮得分 348.18\n",
      "损失函数： 0.032437\n",
      "时间步 5261000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329792e+01/ 轮得分 348.15\n",
      "损失函数： 0.0336059\n",
      "时间步 5262000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317912e+01/ 轮得分 348.17\n",
      "损失函数： 0.0291203\n",
      "时间步 5263000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.466437e+01/ 轮得分 348.17\n",
      "损失函数： 0.0167059\n",
      "时间步 5264000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298710e+01/ 轮得分 348.17\n",
      "损失函数： 0.0194751\n",
      "时间步 5265000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311609e+01/ 轮得分 348.52\n",
      "损失函数： 0.0373843\n",
      "时间步 5266000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.524558e+01/ 轮得分 348.52\n",
      "损失函数： 0.0132504\n",
      "时间步 5267000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299001e+01/ 轮得分 348.52\n",
      "损失函数： 0.051061\n",
      "时间步 5268000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291043e+01/ 轮得分 348.52\n",
      "损失函数： 0.0435254\n",
      "时间步 5269000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.223800e+01/ 轮得分 348.66\n",
      "损失函数： 0.0149474\n",
      "时间步 5270000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240875e+01/ 轮得分 348.66\n",
      "损失函数： 0.0240655\n",
      "时间步 5271000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291564e+01/ 轮得分 348.66\n",
      "损失函数： 0.0340301\n",
      "时间步 5272000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239847e+01/ 轮得分 348.66\n",
      "损失函数： 0.021757\n",
      "时间步 5273000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.182008e+01/ 轮得分 348.66\n",
      "损失函数： 0.0228599\n",
      "时间步 5274000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275708e+01/ 轮得分 348.66\n",
      "损失函数： 0.0213379\n",
      "时间步 5275000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242549e+01/ 轮得分 348.66\n",
      "损失函数： 0.0695628\n",
      "时间步 5276000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.422725e+01/ 轮得分 349.13\n",
      "损失函数： 0.0184074\n",
      "时间步 5277000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.241113e+01/ 轮得分 349.13\n",
      "损失函数： 0.0193417\n",
      "时间步 5278000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.684313e+00/ 轮得分 349.13\n",
      "损失函数： 0.0221964\n",
      "时间步 5279000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227212e+01/ 轮得分 349.13\n",
      "损失函数： 0.0221063\n",
      "时间步 5280000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231833e+01/ 轮得分 349.56\n",
      "损失函数： 0.0123085\n",
      "时间步 5281000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.434970e+01/ 轮得分 349.56\n",
      "损失函数： 0.054617\n",
      "时间步 5282000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.168611e+01/ 轮得分 348.89\n",
      "损失函数： 0.0183759\n",
      "时间步 5283000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213565e+01/ 轮得分 348.89\n",
      "损失函数： 0.0171329\n",
      "时间步 5284000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.442350e+01/ 轮得分 348.89\n",
      "损失函数： 0.0444467\n",
      "时间步 5285000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202518e+01/ 轮得分 348.89\n",
      "损失函数： 0.0530189\n",
      "时间步 5286000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.451991e+01/ 轮得分 348.89\n",
      "损失函数： 0.0304907\n",
      "时间步 5287000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307730e+01/ 轮得分 348.89\n",
      "损失函数： 0.00958789\n",
      "时间步 5288000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271151e+01/ 轮得分 348.48\n",
      "损失函数： 0.0622178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5289000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267790e+01/ 轮得分 348.49\n",
      "损失函数： 0.0416387\n",
      "时间步 5290000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 7.451513e+00/ 轮得分 348.49\n",
      "损失函数： 0.0239182\n",
      "时间步 5291000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244429e+01/ 轮得分 348.65\n",
      "损失函数： 0.0616052\n",
      "时间步 5292000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.168239e+01/ 轮得分 348.65\n",
      "损失函数： 0.0187039\n",
      "时间步 5293000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.967215e+00/ 轮得分 348.69\n",
      "损失函数： 0.0354322\n",
      "时间步 5294000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349299e+01/ 轮得分 348.69\n",
      "损失函数： 0.0116629\n",
      "时间步 5295000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.316834e+01/ 轮得分 348.69\n",
      "损失函数： 0.0467902\n",
      "时间步 5296000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177358e+01/ 轮得分 348.69\n",
      "损失函数： 0.0433678\n",
      "时间步 5297000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250108e+01/ 轮得分 348.69\n",
      "损失函数： 0.0175036\n",
      "时间步 5298000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362359e+01/ 轮得分 348.69\n",
      "损失函数： 0.0255384\n",
      "时间步 5299000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264592e+01/ 轮得分 348.69\n",
      "损失函数： 0.0282779\n",
      "时间步 5300000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.211875e+01/ 轮得分 348.69\n",
      "损失函数： 0.0475515\n",
      "时间步 5301000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.135455e+01/ 轮得分 349.29\n",
      "损失函数： 0.0375022\n",
      "时间步 5302000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333197e+01/ 轮得分 349.29\n",
      "损失函数： 0.0131616\n",
      "时间步 5303000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229102e+01/ 轮得分 349.29\n",
      "损失函数： 0.031336\n",
      "时间步 5304000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224713e+01/ 轮得分 349.29\n",
      "损失函数： 0.0479649\n",
      "时间步 5305000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412229e+01/ 轮得分 349.29\n",
      "损失函数： 0.0179384\n",
      "时间步 5306000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.275851e+01/ 轮得分 349.29\n",
      "损失函数： 0.0339693\n",
      "时间步 5307000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348701e+01/ 轮得分 349.29\n",
      "损失函数： 0.0112634\n",
      "时间步 5308000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.487679e+01/ 轮得分 349.29\n",
      "损失函数： 0.0181064\n",
      "时间步 5309000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177526e+01/ 轮得分 349.79\n",
      "损失函数： 0.0235428\n",
      "时间步 5310000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.426406e+01/ 轮得分 349.60\n",
      "损失函数： 0.0387252\n",
      "时间步 5311000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.317195e+01/ 轮得分 349.60\n",
      "损失函数： 0.044942\n",
      "时间步 5312000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212245e+01/ 轮得分 349.29\n",
      "损失函数： 0.0611012\n",
      "时间步 5313000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.358305e+01/ 轮得分 349.29\n",
      "损失函数： 0.0196621\n",
      "时间步 5314000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372918e+01/ 轮得分 349.29\n",
      "损失函数： 0.0195897\n",
      "时间步 5315000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.255498e+01/ 轮得分 349.29\n",
      "损失函数： 0.0265579\n",
      "时间步 5316000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.531527e+01/ 轮得分 349.29\n",
      "损失函数： 0.0738633\n",
      "时间步 5317000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270677e+01/ 轮得分 349.29\n",
      "损失函数： 0.337801\n",
      "时间步 5318000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324029e+01/ 轮得分 349.29\n",
      "损失函数： 0.0286497\n",
      "时间步 5319000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.316368e+01/ 轮得分 349.29\n",
      "损失函数： 0.024731\n",
      "时间步 5320000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423978e+01/ 轮得分 349.29\n",
      "损失函数： 0.0622407\n",
      "时间步 5321000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.397131e+01/ 轮得分 349.29\n",
      "损失函数： 0.0125566\n",
      "时间步 5322000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372578e+01/ 轮得分 349.29\n",
      "损失函数： 0.0248885\n",
      "时间步 5323000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225417e+01/ 轮得分 349.29\n",
      "损失函数： 0.0151458\n",
      "时间步 5324000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.139046e+01/ 轮得分 349.29\n",
      "损失函数： 0.0182306\n",
      "时间步 5325000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.519238e+01/ 轮得分 349.29\n",
      "损失函数： 0.0412982\n",
      "时间步 5326000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206477e+01/ 轮得分 349.29\n",
      "损失函数： 0.0454141\n",
      "时间步 5327000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.365502e+01/ 轮得分 349.29\n",
      "损失函数： 0.0979976\n",
      "时间步 5328000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339717e+01/ 轮得分 349.29\n",
      "损失函数： 0.0198433\n",
      "时间步 5329000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.046181e+01/ 轮得分 351.32\n",
      "损失函数： 0.0340454\n",
      "时间步 5330000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262496e+01/ 轮得分 351.32\n",
      "损失函数： 0.0290298\n",
      "时间步 5331000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.382664e+01/ 轮得分 351.32\n",
      "损失函数： 0.029668\n",
      "时间步 5332000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269151e+01/ 轮得分 351.32\n",
      "损失函数： 0.0556456\n",
      "时间步 5333000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299786e+01/ 轮得分 351.32\n",
      "损失函数： 0.0726352\n",
      "时间步 5334000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.483304e+01/ 轮得分 351.32\n",
      "损失函数： 0.0246695\n",
      "时间步 5335000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328253e+01/ 轮得分 351.32\n",
      "损失函数： 0.0267462\n",
      "时间步 5336000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229303e+01/ 轮得分 351.99\n",
      "损失函数： 0.0794159\n",
      "时间步 5337000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.347287e+01/ 轮得分 351.99\n",
      "损失函数： 0.0633017\n",
      "时间步 5338000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.470282e+01/ 轮得分 352.01\n",
      "损失函数： 0.017219\n",
      "时间步 5339000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293207e+01/ 轮得分 352.17\n",
      "损失函数： 0.0325762\n",
      "时间步 5340000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204930e+01/ 轮得分 352.20\n",
      "损失函数： 0.0438373\n",
      "时间步 5341000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.427032e+01/ 轮得分 352.24\n",
      "损失函数： 0.0256384\n",
      "时间步 5342000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238387e+01/ 轮得分 352.24\n",
      "损失函数： 0.0327953\n",
      "时间步 5343000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.570091e+01/ 轮得分 352.24\n",
      "损失函数： 0.0575595\n",
      "时间步 5344000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.583220e+01/ 轮得分 352.24\n",
      "损失函数： 0.0315652\n",
      "时间步 5345000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393322e+01/ 轮得分 352.24\n",
      "损失函数： 0.0564687\n",
      "时间步 5346000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273259e+01/ 轮得分 352.24\n",
      "损失函数： 0.0421061\n",
      "时间步 5347000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.740937e+01/ 轮得分 352.24\n",
      "损失函数： 0.0115719\n",
      "时间步 5348000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.438764e+01/ 轮得分 352.24\n",
      "损失函数： 0.0219682\n",
      "时间步 5349000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.314838e+01/ 轮得分 352.24\n",
      "损失函数： 0.0188268\n",
      "时间步 5350000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364893e+01/ 轮得分 352.24\n",
      "损失函数： 0.0580455\n",
      "时间步 5351000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.374632e+01/ 轮得分 352.24\n",
      "损失函数： 0.0220278\n",
      "时间步 5352000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275064e+01/ 轮得分 352.24\n",
      "损失函数： 0.0222507\n",
      "时间步 5353000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.613329e+01/ 轮得分 352.24\n",
      "损失函数： 0.0188442\n",
      "时间步 5354000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306813e+01/ 轮得分 352.24\n",
      "损失函数： 0.00980487\n",
      "时间步 5355000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313377e+01/ 轮得分 352.24\n",
      "损失函数： 0.0244875\n",
      "时间步 5356000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.397734e+01/ 轮得分 352.24\n",
      "损失函数： 0.0225748\n",
      "时间步 5357000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317148e+01/ 轮得分 352.24\n",
      "损失函数： 0.0213169\n",
      "时间步 5358000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.168357e+01/ 轮得分 352.24\n",
      "损失函数： 0.0213556\n",
      "时间步 5359000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373488e+01/ 轮得分 352.24\n",
      "损失函数： 0.0200177\n",
      "时间步 5360000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.081446e+01/ 轮得分 352.24\n",
      "损失函数： 0.0672859\n",
      "时间步 5361000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267968e+01/ 轮得分 354.60\n",
      "损失函数： 0.0434828\n",
      "时间步 5362000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184191e+01/ 轮得分 354.39\n",
      "损失函数： 0.0398208\n",
      "时间步 5363000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.479109e+01/ 轮得分 354.39\n",
      "损失函数： 0.0164986\n",
      "时间步 5364000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331368e+01/ 轮得分 354.39\n",
      "损失函数： 0.00960737\n",
      "时间步 5365000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328174e+01/ 轮得分 354.39\n",
      "损失函数： 0.0166644\n",
      "时间步 5366000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.564631e+01/ 轮得分 354.39\n",
      "损失函数： 0.0370866\n",
      "时间步 5367000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.155458e+01/ 轮得分 354.39\n",
      "损失函数： 0.0342567\n",
      "时间步 5368000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.996866e+00/ 轮得分 354.39\n",
      "损失函数： 0.0383438\n",
      "时间步 5369000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.138151e+01/ 轮得分 354.39\n",
      "损失函数： 0.00830035\n",
      "时间步 5370000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.158366e+01/ 轮得分 354.39\n",
      "损失函数： 0.0294141\n",
      "时间步 5371000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.179090e+01/ 轮得分 354.39\n",
      "损失函数： 0.0245622\n",
      "时间步 5372000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.143638e+01/ 轮得分 354.39\n",
      "损失函数： 0.0246975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5373000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276750e+01/ 轮得分 354.39\n",
      "损失函数： 0.0449543\n",
      "时间步 5374000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256302e+01/ 轮得分 354.39\n",
      "损失函数： 0.0134682\n",
      "时间步 5375000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.367049e+01/ 轮得分 355.74\n",
      "损失函数： 0.0112915\n",
      "时间步 5376000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.179886e+01/ 轮得分 355.81\n",
      "损失函数： 0.186404\n",
      "时间步 5377000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.209896e+01/ 轮得分 355.81\n",
      "损失函数： 0.0336495\n",
      "时间步 5378000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.372142e+01/ 轮得分 355.81\n",
      "损失函数： 0.00546013\n",
      "时间步 5379000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270570e+01/ 轮得分 355.81\n",
      "损失函数： 0.0451045\n",
      "时间步 5380000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.382575e+01/ 轮得分 355.81\n",
      "损失函数： 0.035618\n",
      "时间步 5381000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383233e+01/ 轮得分 355.81\n",
      "损失函数： 0.0441621\n",
      "时间步 5382000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238572e+01/ 轮得分 356.44\n",
      "损失函数： 0.0260447\n",
      "时间步 5383000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.330613e+01/ 轮得分 356.44\n",
      "损失函数： 0.0240993\n",
      "时间步 5384000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273785e+01/ 轮得分 356.44\n",
      "损失函数： 0.0150704\n",
      "时间步 5385000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365371e+01/ 轮得分 356.44\n",
      "损失函数： 0.0232145\n",
      "时间步 5386000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310102e+01/ 轮得分 356.44\n",
      "损失函数： 0.0302077\n",
      "时间步 5387000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.344654e+01/ 轮得分 356.44\n",
      "损失函数： 0.019865\n",
      "时间步 5388000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.378277e+01/ 轮得分 356.44\n",
      "损失函数： 0.0152811\n",
      "时间步 5389000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.449155e+01/ 轮得分 357.24\n",
      "损失函数： 0.0413455\n",
      "时间步 5390000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.370483e+01/ 轮得分 357.24\n",
      "损失函数： 0.022539\n",
      "时间步 5391000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.123098e+01/ 轮得分 357.51\n",
      "损失函数： 0.052363\n",
      "时间步 5392000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.441810e+01/ 轮得分 357.48\n",
      "损失函数： 0.0265285\n",
      "时间步 5393000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224795e+01/ 轮得分 357.48\n",
      "损失函数： 0.0277536\n",
      "时间步 5394000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258794e+01/ 轮得分 357.48\n",
      "损失函数： 0.0148672\n",
      "时间步 5395000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286109e+01/ 轮得分 357.48\n",
      "损失函数： 0.0136966\n",
      "时间步 5396000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294907e+01/ 轮得分 357.48\n",
      "损失函数： 0.0300617\n",
      "时间步 5397000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.251978e+01/ 轮得分 358.01\n",
      "损失函数： 0.0181204\n",
      "时间步 5398000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183088e+01/ 轮得分 358.01\n",
      "损失函数： 0.034401\n",
      "时间步 5399000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.111686e+01/ 轮得分 358.01\n",
      "损失函数： 0.0157792\n",
      "时间步 5400000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.289491e+01/ 轮得分 358.30\n",
      "损失函数： 0.0366128\n",
      "时间步 5401000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258906e+01/ 轮得分 358.30\n",
      "损失函数： 0.0262091\n",
      "时间步 5402000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208405e+01/ 轮得分 358.30\n",
      "损失函数： 0.0689091\n",
      "时间步 5403000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.195184e+01/ 轮得分 358.26\n",
      "损失函数： 0.0188097\n",
      "时间步 5404000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323320e+01/ 轮得分 358.26\n",
      "损失函数： 0.0410557\n",
      "时间步 5405000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212425e+01/ 轮得分 358.36\n",
      "损失函数： 0.0523796\n",
      "时间步 5406000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196403e+01/ 轮得分 358.36\n",
      "损失函数： 0.0336202\n",
      "时间步 5407000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291598e+01/ 轮得分 358.36\n",
      "损失函数： 0.0211083\n",
      "时间步 5408000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.150104e+01/ 轮得分 358.36\n",
      "损失函数： 0.0549638\n",
      "时间步 5409000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315402e+01/ 轮得分 358.36\n",
      "损失函数： 0.0239284\n",
      "时间步 5410000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256264e+01/ 轮得分 358.36\n",
      "损失函数： 0.0489434\n",
      "时间步 5411000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.312551e+01/ 轮得分 358.36\n",
      "损失函数： 0.0322433\n",
      "时间步 5412000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352993e+01/ 轮得分 358.36\n",
      "损失函数： 0.0371595\n",
      "时间步 5413000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.454487e+01/ 轮得分 358.36\n",
      "损失函数： 0.0234127\n",
      "时间步 5414000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.487422e+01/ 轮得分 358.36\n",
      "损失函数： 0.0610766\n",
      "时间步 5415000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384956e+01/ 轮得分 358.60\n",
      "损失函数： 0.0345544\n",
      "时间步 5416000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226378e+01/ 轮得分 358.40\n",
      "损失函数： 0.0249882\n",
      "时间步 5417000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337889e+01/ 轮得分 358.41\n",
      "损失函数： 0.0120285\n",
      "时间步 5418000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.119625e+01/ 轮得分 357.97\n",
      "损失函数： 0.0372471\n",
      "时间步 5419000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.180673e+01/ 轮得分 357.67\n",
      "损失函数： 0.0218566\n",
      "时间步 5420000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272010e+01/ 轮得分 357.67\n",
      "损失函数： 0.0607478\n",
      "时间步 5421000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365535e+01/ 轮得分 357.67\n",
      "损失函数： 0.65484\n",
      "时间步 5422000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.097863e+01/ 轮得分 357.67\n",
      "损失函数： 0.126333\n",
      "时间步 5423000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.339227e+01/ 轮得分 357.67\n",
      "损失函数： 0.0257431\n",
      "时间步 5424000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.294481e+01/ 轮得分 357.67\n",
      "损失函数： 0.0535478\n",
      "时间步 5425000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.258909e+01/ 轮得分 357.67\n",
      "损失函数： 0.0150297\n",
      "时间步 5426000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202973e+01/ 轮得分 357.67\n",
      "损失函数： 0.0360588\n",
      "时间步 5427000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306693e+01/ 轮得分 357.67\n",
      "损失函数： 0.014008\n",
      "时间步 5428000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.488994e+01/ 轮得分 357.67\n",
      "损失函数： 0.0439876\n",
      "时间步 5429000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277754e+01/ 轮得分 357.67\n",
      "损失函数： 0.022846\n",
      "时间步 5430000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.322755e+01/ 轮得分 357.67\n",
      "损失函数： 0.0591421\n",
      "时间步 5431000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260652e+01/ 轮得分 357.67\n",
      "损失函数： 0.0280765\n",
      "时间步 5432000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244756e+01/ 轮得分 357.67\n",
      "损失函数： 0.0551258\n",
      "时间步 5433000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.358328e+01/ 轮得分 357.67\n",
      "损失函数： 0.0409942\n",
      "时间步 5434000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.114696e+01/ 轮得分 357.67\n",
      "损失函数： 0.0187191\n",
      "时间步 5435000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329117e+01/ 轮得分 357.67\n",
      "损失函数： 0.0405166\n",
      "时间步 5436000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356403e+01/ 轮得分 357.67\n",
      "损失函数： 0.00878428\n",
      "时间步 5437000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337770e+01/ 轮得分 357.67\n",
      "损失函数： 0.0245537\n",
      "时间步 5438000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351261e+01/ 轮得分 357.67\n",
      "损失函数： 1.42522\n",
      "时间步 5439000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.367182e+01/ 轮得分 357.67\n",
      "损失函数： 0.026736\n",
      "时间步 5440000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285664e+01/ 轮得分 357.67\n",
      "损失函数： 0.0270157\n",
      "时间步 5441000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.168160e+01/ 轮得分 357.67\n",
      "损失函数： 0.0327954\n",
      "时间步 5442000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357730e+01/ 轮得分 359.80\n",
      "损失函数： 0.0352152\n",
      "时间步 5443000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407037e+01/ 轮得分 359.80\n",
      "损失函数： 2.70976\n",
      "时间步 5444000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.485825e+01/ 轮得分 359.93\n",
      "损失函数： 0.0197377\n",
      "时间步 5445000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.456929e+01/ 轮得分 359.93\n",
      "损失函数： 0.00813728\n",
      "时间步 5446000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.217942e+01/ 轮得分 359.60\n",
      "损失函数： 0.0228232\n",
      "时间步 5447000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234876e+01/ 轮得分 359.60\n",
      "损失函数： 0.0145297\n",
      "时间步 5448000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.627297e+01/ 轮得分 359.60\n",
      "损失函数： 0.0155557\n",
      "时间步 5449000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394700e+01/ 轮得分 359.60\n",
      "损失函数： 0.0124473\n",
      "时间步 5450000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.406059e+01/ 轮得分 359.60\n",
      "损失函数： 0.0401834\n",
      "时间步 5451000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271558e+01/ 轮得分 360.18\n",
      "损失函数： 0.0277119\n",
      "时间步 5452000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322047e+01/ 轮得分 360.18\n",
      "损失函数： 0.0151868\n",
      "时间步 5453000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361397e+01/ 轮得分 360.18\n",
      "损失函数： 0.0346728\n",
      "时间步 5454000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216823e+01/ 轮得分 360.18\n",
      "损失函数： 0.0384527\n",
      "时间步 5455000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.134170e+01/ 轮得分 360.18\n",
      "损失函数： 0.0198959\n",
      "时间步 5456000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.432607e+01/ 轮得分 360.18\n",
      "损失函数： 0.0136511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5457000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339548e+01/ 轮得分 360.71\n",
      "损失函数： 0.037929\n",
      "时间步 5458000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.302190e+01/ 轮得分 360.71\n",
      "损失函数： 0.0169683\n",
      "时间步 5459000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.417580e+01/ 轮得分 360.71\n",
      "损失函数： 0.00576853\n",
      "时间步 5460000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.292068e+01/ 轮得分 360.71\n",
      "损失函数： 0.0412363\n",
      "时间步 5461000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269279e+01/ 轮得分 360.71\n",
      "损失函数： 0.027473\n",
      "时间步 5462000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230320e+01/ 轮得分 360.92\n",
      "损失函数： 0.0224809\n",
      "时间步 5463000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294529e+01/ 轮得分 360.92\n",
      "损失函数： 0.0128382\n",
      "时间步 5464000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229004e+01/ 轮得分 361.17\n",
      "损失函数： 0.00813152\n",
      "时间步 5465000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.369855e+01/ 轮得分 361.17\n",
      "损失函数： 0.0380131\n",
      "时间步 5466000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.398982e+01/ 轮得分 361.17\n",
      "损失函数： 0.0172072\n",
      "时间步 5467000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.155211e+01/ 轮得分 361.29\n",
      "损失函数： 0.0234753\n",
      "时间步 5468000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.214460e+01/ 轮得分 361.29\n",
      "损失函数： 0.0238886\n",
      "时间步 5469000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313279e+01/ 轮得分 361.29\n",
      "损失函数： 0.0630908\n",
      "时间步 5470000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394695e+01/ 轮得分 361.29\n",
      "损失函数： 0.0357444\n",
      "时间步 5471000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.574426e+01/ 轮得分 361.29\n",
      "损失函数： 0.0105431\n",
      "时间步 5472000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248350e+01/ 轮得分 361.46\n",
      "损失函数： 0.0393817\n",
      "时间步 5473000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249040e+01/ 轮得分 361.46\n",
      "损失函数： 0.0170206\n",
      "时间步 5474000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203056e+01/ 轮得分 361.46\n",
      "损失函数： 0.0518816\n",
      "时间步 5475000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184099e+01/ 轮得分 361.46\n",
      "损失函数： 0.0195936\n",
      "时间步 5476000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228817e+01/ 轮得分 361.46\n",
      "损失函数： 0.0253296\n",
      "时间步 5477000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.183968e+01/ 轮得分 361.92\n",
      "损失函数： 0.0482782\n",
      "时间步 5478000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385119e+01/ 轮得分 361.92\n",
      "损失函数： 0.0321161\n",
      "时间步 5479000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.410066e+01/ 轮得分 361.92\n",
      "损失函数： 0.0330565\n",
      "时间步 5480000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376356e+01/ 轮得分 361.92\n",
      "损失函数： 0.0220258\n",
      "时间步 5481000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.209384e+01/ 轮得分 361.92\n",
      "损失函数： 0.0245434\n",
      "时间步 5482000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.502207e+01/ 轮得分 361.92\n",
      "损失函数： 0.0254262\n",
      "时间步 5483000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391059e+01/ 轮得分 361.92\n",
      "损失函数： 0.0507906\n",
      "时间步 5484000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290377e+01/ 轮得分 361.92\n",
      "损失函数： 0.0272855\n",
      "时间步 5485000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276300e+01/ 轮得分 361.92\n",
      "损失函数： 0.0248328\n",
      "时间步 5486000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216048e+01/ 轮得分 361.92\n",
      "损失函数： 0.0231848\n",
      "时间步 5487000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400914e+01/ 轮得分 361.92\n",
      "损失函数： 0.0219715\n",
      "时间步 5488000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.436077e+01/ 轮得分 361.92\n",
      "损失函数： 0.0180732\n",
      "时间步 5489000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304914e+01/ 轮得分 361.92\n",
      "损失函数： 0.0379754\n",
      "时间步 5490000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364549e+01/ 轮得分 361.92\n",
      "损失函数： 0.0239165\n",
      "时间步 5491000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.552378e+01/ 轮得分 363.23\n",
      "损失函数： 0.0405744\n",
      "时间步 5492000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.218646e+01/ 轮得分 363.06\n",
      "损失函数： 0.015498\n",
      "时间步 5493000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.234780e+01/ 轮得分 363.06\n",
      "损失函数： 0.101271\n",
      "时间步 5494000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.213444e+01/ 轮得分 363.06\n",
      "损失函数： 0.0176301\n",
      "时间步 5495000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354749e+01/ 轮得分 363.06\n",
      "损失函数： 0.0430248\n",
      "时间步 5496000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.599096e+01/ 轮得分 363.06\n",
      "损失函数： 0.0127679\n",
      "时间步 5497000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224556e+01/ 轮得分 363.06\n",
      "损失函数： 0.0276252\n",
      "时间步 5498000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.350797e+01/ 轮得分 363.06\n",
      "损失函数： 0.0311435\n",
      "时间步 5499000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284255e+01/ 轮得分 363.06\n",
      "损失函数： 0.0894825\n",
      "时间步 5500000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.386698e+01/ 轮得分 363.06\n",
      "损失函数： 0.0518591\n",
      "时间步 5501000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210564e+01/ 轮得分 363.06\n",
      "损失函数： 0.0370861\n",
      "时间步 5502000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337579e+01/ 轮得分 363.06\n",
      "损失函数： 0.0260604\n",
      "时间步 5503000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249865e+01/ 轮得分 363.06\n",
      "损失函数： 0.0399122\n",
      "时间步 5504000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.164609e+01/ 轮得分 364.23\n",
      "损失函数： 0.0354555\n",
      "时间步 5505000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275394e+01/ 轮得分 364.28\n",
      "损失函数： 0.0372645\n",
      "时间步 5506000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321118e+01/ 轮得分 364.28\n",
      "损失函数： 0.0192343\n",
      "时间步 5507000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.279432e+01/ 轮得分 363.87\n",
      "损失函数： 0.0124189\n",
      "时间步 5508000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290138e+01/ 轮得分 363.87\n",
      "损失函数： 0.0220442\n",
      "时间步 5509000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393391e+01/ 轮得分 363.75\n",
      "损失函数： 0.0374703\n",
      "时间步 5510000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284546e+01/ 轮得分 363.75\n",
      "损失函数： 0.0377222\n",
      "时间步 5511000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237166e+01/ 轮得分 363.75\n",
      "损失函数： 0.0550412\n",
      "时间步 5512000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.127516e+01/ 轮得分 363.61\n",
      "损失函数： 0.0423465\n",
      "时间步 5513000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254205e+01/ 轮得分 363.61\n",
      "损失函数： 0.0346824\n",
      "时间步 5514000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283607e+01/ 轮得分 363.61\n",
      "损失函数： 0.0698664\n",
      "时间步 5515000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237748e+01/ 轮得分 363.61\n",
      "损失函数： 0.0192695\n",
      "时间步 5516000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268705e+01/ 轮得分 363.61\n",
      "损失函数： 0.0144549\n",
      "时间步 5517000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299174e+01/ 轮得分 363.61\n",
      "损失函数： 0.0291418\n",
      "时间步 5518000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388166e+01/ 轮得分 363.95\n",
      "损失函数： 0.0316493\n",
      "时间步 5519000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229080e+01/ 轮得分 363.95\n",
      "损失函数： 0.0368927\n",
      "时间步 5520000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373815e+01/ 轮得分 363.95\n",
      "损失函数： 0.0312174\n",
      "时间步 5521000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348679e+01/ 轮得分 363.95\n",
      "损失函数： 0.0234736\n",
      "时间步 5522000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.097888e+01/ 轮得分 363.95\n",
      "损失函数： 0.10147\n",
      "时间步 5523000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286051e+01/ 轮得分 363.95\n",
      "损失函数： 0.0337852\n",
      "时间步 5524000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.182341e+01/ 轮得分 363.95\n",
      "损失函数： 0.0135489\n",
      "时间步 5525000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186547e+01/ 轮得分 363.95\n",
      "损失函数： 0.037625\n",
      "时间步 5526000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.115526e+01/ 轮得分 363.95\n",
      "损失函数： 0.0255602\n",
      "时间步 5527000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258702e+01/ 轮得分 364.63\n",
      "损失函数： 0.0167148\n",
      "时间步 5528000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266755e+01/ 轮得分 364.49\n",
      "损失函数： 0.0181214\n",
      "时间步 5529000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.135823e+01/ 轮得分 364.32\n",
      "损失函数： 0.0344884\n",
      "时间步 5530000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.194332e+01/ 轮得分 364.32\n",
      "损失函数： 0.0159326\n",
      "时间步 5531000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210082e+01/ 轮得分 364.32\n",
      "损失函数： 0.042901\n",
      "时间步 5532000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.356060e+01/ 轮得分 364.48\n",
      "损失函数： 0.0325435\n",
      "时间步 5533000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.238155e+01/ 轮得分 364.48\n",
      "损失函数： 0.0429745\n",
      "时间步 5534000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.296335e+01/ 轮得分 363.94\n",
      "损失函数： 0.0218268\n",
      "时间步 5535000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213564e+01/ 轮得分 363.94\n",
      "损失函数： 0.0131556\n",
      "时间步 5536000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320317e+01/ 轮得分 363.94\n",
      "损失函数： 0.0297157\n",
      "时间步 5537000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.485394e+01/ 轮得分 363.94\n",
      "损失函数： 0.0067635\n",
      "时间步 5538000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258097e+01/ 轮得分 364.10\n",
      "损失函数： 0.0371639\n",
      "时间步 5539000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277735e+01/ 轮得分 364.10\n",
      "损失函数： 0.0154425\n",
      "时间步 5540000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309577e+01/ 轮得分 364.32\n",
      "损失函数： 0.171029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5541000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.468643e+01/ 轮得分 364.32\n",
      "损失函数： 0.0191395\n",
      "时间步 5542000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255340e+01/ 轮得分 364.32\n",
      "损失函数： 0.0352255\n",
      "时间步 5543000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.469163e+01/ 轮得分 364.32\n",
      "损失函数： 0.0428172\n",
      "时间步 5544000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362814e+01/ 轮得分 364.73\n",
      "损失函数： 0.0410164\n",
      "时间步 5545000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 9.047643e+00/ 轮得分 364.56\n",
      "损失函数： 0.02685\n",
      "时间步 5546000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299792e+01/ 轮得分 364.33\n",
      "损失函数： 0.0160175\n",
      "时间步 5547000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.533872e+01/ 轮得分 364.33\n",
      "损失函数： 0.0404786\n",
      "时间步 5548000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.366126e+01/ 轮得分 364.31\n",
      "损失函数： 0.0943804\n",
      "时间步 5549000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.146777e+01/ 轮得分 364.31\n",
      "损失函数： 0.0410404\n",
      "时间步 5550000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.477543e+01/ 轮得分 364.31\n",
      "损失函数： 0.0214899\n",
      "时间步 5551000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.455890e+01/ 轮得分 364.31\n",
      "损失函数： 0.0659906\n",
      "时间步 5552000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.131170e+01/ 轮得分 364.31\n",
      "损失函数： 0.0914777\n",
      "时间步 5553000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331732e+01/ 轮得分 364.31\n",
      "损失函数： 0.0428324\n",
      "时间步 5554000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198218e+01/ 轮得分 364.36\n",
      "损失函数： 0.0940464\n",
      "时间步 5555000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.560436e+01/ 轮得分 364.36\n",
      "损失函数： 0.0722715\n",
      "时间步 5556000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.172233e+01/ 轮得分 364.18\n",
      "损失函数： 0.0195388\n",
      "时间步 5557000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361451e+01/ 轮得分 364.18\n",
      "损失函数： 0.0353488\n",
      "时间步 5558000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372883e+01/ 轮得分 364.33\n",
      "损失函数： 0.0604842\n",
      "时间步 5559000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345315e+01/ 轮得分 364.50\n",
      "损失函数： 0.163057\n",
      "时间步 5560000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.476603e+01/ 轮得分 364.50\n",
      "损失函数： 0.163808\n",
      "时间步 5561000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.353261e+01/ 轮得分 364.33\n",
      "损失函数： 0.0143863\n",
      "时间步 5562000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.586128e+00/ 轮得分 363.46\n",
      "损失函数： 0.0426346\n",
      "时间步 5563000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343446e+01/ 轮得分 363.29\n",
      "损失函数： 0.0590705\n",
      "时间步 5564000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.070360e+01/ 轮得分 363.15\n",
      "损失函数： 0.0427399\n",
      "时间步 5565000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345552e+01/ 轮得分 363.15\n",
      "损失函数： 0.0993309\n",
      "时间步 5566000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352295e+01/ 轮得分 363.15\n",
      "损失函数： 0.0197712\n",
      "时间步 5567000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203298e+01/ 轮得分 363.15\n",
      "损失函数： 0.0469485\n",
      "时间步 5568000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.312810e+01/ 轮得分 363.15\n",
      "损失函数： 0.07828\n",
      "时间步 5569000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.551625e+01/ 轮得分 363.15\n",
      "损失函数： 0.0245544\n",
      "时间步 5570000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.080600e+00/ 轮得分 363.15\n",
      "损失函数： 0.0149552\n",
      "时间步 5571000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342134e+01/ 轮得分 363.15\n",
      "损失函数： 0.0225404\n",
      "时间步 5572000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362538e+01/ 轮得分 363.15\n",
      "损失函数： 0.0734619\n",
      "时间步 5573000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.676560e+01/ 轮得分 363.64\n",
      "损失函数： 0.0801347\n",
      "时间步 5574000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.169621e+01/ 轮得分 363.64\n",
      "损失函数： 0.0318864\n",
      "时间步 5575000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432934e+01/ 轮得分 363.64\n",
      "损失函数： 0.0547489\n",
      "时间步 5576000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.620226e+01/ 轮得分 363.64\n",
      "损失函数： 0.0121565\n",
      "时间步 5577000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.466273e+01/ 轮得分 363.64\n",
      "损失函数： 0.0424046\n",
      "时间步 5578000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316534e+01/ 轮得分 364.10\n",
      "损失函数： 0.0372828\n",
      "时间步 5579000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.188380e+01/ 轮得分 364.10\n",
      "损失函数： 0.0202326\n",
      "时间步 5580000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269489e+01/ 轮得分 364.10\n",
      "损失函数： 0.0461772\n",
      "时间步 5581000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.308840e+01/ 轮得分 364.10\n",
      "损失函数： 0.0217521\n",
      "时间步 5582000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.134213e+01/ 轮得分 364.10\n",
      "损失函数： 0.0186506\n",
      "时间步 5583000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292821e+01/ 轮得分 364.10\n",
      "损失函数： 0.0236806\n",
      "时间步 5584000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.478251e+01/ 轮得分 364.42\n",
      "损失函数： 0.0297162\n",
      "时间步 5585000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.333046e+01/ 轮得分 364.42\n",
      "损失函数： 0.0498166\n",
      "时间步 5586000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.321342e+01/ 轮得分 364.42\n",
      "损失函数： 0.0330569\n",
      "时间步 5587000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.269933e+01/ 轮得分 364.53\n",
      "损失函数： 0.0522063\n",
      "时间步 5588000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.199251e+01/ 轮得分 364.53\n",
      "损失函数： 0.119159\n",
      "时间步 5589000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.227604e+01/ 轮得分 364.53\n",
      "损失函数： 0.0355447\n",
      "时间步 5590000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.331049e+01/ 轮得分 364.70\n",
      "损失函数： 0.0246824\n",
      "时间步 5591000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279690e+01/ 轮得分 364.70\n",
      "损失函数： 0.0391792\n",
      "时间步 5592000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.200573e+01/ 轮得分 364.13\n",
      "损失函数： 0.0200838\n",
      "时间步 5593000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.371286e+01/ 轮得分 364.13\n",
      "损失函数： 0.0627169\n",
      "时间步 5594000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267493e+01/ 轮得分 364.13\n",
      "损失函数： 0.101872\n",
      "时间步 5595000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323724e+01/ 轮得分 364.13\n",
      "损失函数： 0.0336351\n",
      "时间步 5596000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261960e+01/ 轮得分 364.13\n",
      "损失函数： 0.0160597\n",
      "时间步 5597000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285111e+01/ 轮得分 364.35\n",
      "损失函数： 0.0444371\n",
      "时间步 5598000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448361e+01/ 轮得分 364.35\n",
      "损失函数： 0.0216332\n",
      "时间步 5599000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.445054e+01/ 轮得分 364.35\n",
      "损失函数： 0.0446933\n",
      "时间步 5600000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314868e+01/ 轮得分 364.35\n",
      "损失函数： 0.0249903\n",
      "时间步 5601000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319065e+01/ 轮得分 364.35\n",
      "损失函数： 0.0138995\n",
      "时间步 5602000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.218827e+01/ 轮得分 364.35\n",
      "损失函数： 0.0252433\n",
      "时间步 5603000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.113143e+01/ 轮得分 364.35\n",
      "损失函数： 0.020644\n",
      "时间步 5604000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243180e+01/ 轮得分 364.35\n",
      "损失函数： 0.0166042\n",
      "时间步 5605000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.209021e+01/ 轮得分 364.35\n",
      "损失函数： 0.0165534\n",
      "时间步 5606000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334324e+01/ 轮得分 364.35\n",
      "损失函数： 0.0413892\n",
      "时间步 5607000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.409891e+01/ 轮得分 364.35\n",
      "损失函数： 0.0222079\n",
      "时间步 5608000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335034e+01/ 轮得分 364.35\n",
      "损失函数： 0.02564\n",
      "时间步 5609000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221324e+01/ 轮得分 364.35\n",
      "损失函数： 0.0894534\n",
      "时间步 5610000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.370860e+01/ 轮得分 364.35\n",
      "损失函数： 0.0532233\n",
      "时间步 5611000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329871e+01/ 轮得分 364.35\n",
      "损失函数： 0.0333597\n",
      "时间步 5612000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.302971e+01/ 轮得分 364.35\n",
      "损失函数： 0.0560468\n",
      "时间步 5613000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231486e+01/ 轮得分 364.35\n",
      "损失函数： 0.0620268\n",
      "时间步 5614000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 2.1/ Q_MAX 1.476014e+01/ 轮得分 364.35\n",
      "损失函数： 0.0187094\n",
      "时间步 5615000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.374411e+01/ 轮得分 364.35\n",
      "损失函数： 0.0151303\n",
      "时间步 5616000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262844e+01/ 轮得分 364.35\n",
      "损失函数： 0.100125\n",
      "时间步 5617000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268653e+01/ 轮得分 364.35\n",
      "损失函数： 0.0226505\n",
      "时间步 5618000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415366e+01/ 轮得分 366.73\n",
      "损失函数： 0.01873\n",
      "时间步 5619000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.375296e+01/ 轮得分 366.73\n",
      "损失函数： 0.0397487\n",
      "时间步 5620000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407348e+01/ 轮得分 366.73\n",
      "损失函数： 0.0273807\n",
      "时间步 5621000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314628e+01/ 轮得分 366.73\n",
      "损失函数： 0.0507228\n",
      "时间步 5622000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231006e+01/ 轮得分 366.73\n",
      "损失函数： 0.0384443\n",
      "时间步 5623000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.146043e+01/ 轮得分 366.73\n",
      "损失函数： 0.0300164\n",
      "时间步 5624000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.110975e+01/ 轮得分 366.73\n",
      "损失函数： 0.0199598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5625000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190504e+01/ 轮得分 366.73\n",
      "损失函数： 0.0277941\n",
      "时间步 5626000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400082e+01/ 轮得分 366.73\n",
      "损失函数： 0.0140123\n",
      "时间步 5627000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278152e+01/ 轮得分 366.73\n",
      "损失函数： 0.0622577\n",
      "时间步 5628000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.166522e+01/ 轮得分 366.73\n",
      "损失函数： 0.0298229\n",
      "时间步 5629000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206270e+01/ 轮得分 368.08\n",
      "损失函数： 0.0396288\n",
      "时间步 5630000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.147395e+01/ 轮得分 368.16\n",
      "损失函数： 0.0190482\n",
      "时间步 5631000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362224e+01/ 轮得分 368.16\n",
      "损失函数： 0.0309382\n",
      "时间步 5632000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372772e+01/ 轮得分 368.16\n",
      "损失函数： 0.037473\n",
      "时间步 5633000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330102e+01/ 轮得分 368.16\n",
      "损失函数： 0.0647833\n",
      "时间步 5634000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.112658e+01/ 轮得分 368.16\n",
      "损失函数： 0.0330511\n",
      "时间步 5635000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189199e+01/ 轮得分 368.16\n",
      "损失函数： 0.0145115\n",
      "时间步 5636000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.654648e+01/ 轮得分 368.16\n",
      "损失函数： 0.0335187\n",
      "时间步 5637000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.456484e+01/ 轮得分 368.16\n",
      "损失函数： 0.0170017\n",
      "时间步 5638000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234960e+01/ 轮得分 368.16\n",
      "损失函数： 0.0311171\n",
      "时间步 5639000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.524298e+01/ 轮得分 368.16\n",
      "损失函数： 0.0279649\n",
      "时间步 5640000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331108e+01/ 轮得分 368.16\n",
      "损失函数： 0.0131765\n",
      "时间步 5641000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.460564e+01/ 轮得分 368.16\n",
      "损失函数： 0.0259263\n",
      "时间步 5642000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.200386e+01/ 轮得分 369.47\n",
      "损失函数： 0.0297841\n",
      "时间步 5643000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.600450e+01/ 轮得分 369.47\n",
      "损失函数： 0.0201986\n",
      "时间步 5644000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303542e+01/ 轮得分 369.47\n",
      "损失函数： 0.0087436\n",
      "时间步 5645000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.422402e+01/ 轮得分 369.47\n",
      "损失函数： 0.0307344\n",
      "时间步 5646000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.293307e+01/ 轮得分 369.47\n",
      "损失函数： 0.0678768\n",
      "时间步 5647000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263297e+01/ 轮得分 369.47\n",
      "损失函数： 0.046597\n",
      "时间步 5648000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.218985e+01/ 轮得分 369.47\n",
      "损失函数： 0.0272039\n",
      "时间步 5649000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183625e+01/ 轮得分 369.47\n",
      "损失函数： 0.057544\n",
      "时间步 5650000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165333e+01/ 轮得分 369.47\n",
      "损失函数： 0.0333822\n",
      "时间步 5651000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390372e+01/ 轮得分 370.45\n",
      "损失函数： 0.0518436\n",
      "时间步 5652000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.556422e+01/ 轮得分 370.45\n",
      "损失函数： 0.0418506\n",
      "时间步 5653000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.442626e+01/ 轮得分 370.45\n",
      "损失函数： 0.0165326\n",
      "时间步 5654000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262568e+01/ 轮得分 370.45\n",
      "损失函数： 0.0263195\n",
      "时间步 5655000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324306e+01/ 轮得分 370.45\n",
      "损失函数： 0.00766624\n",
      "时间步 5656000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.506440e+01/ 轮得分 370.45\n",
      "损失函数： 0.0317002\n",
      "时间步 5657000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.427479e+01/ 轮得分 370.47\n",
      "损失函数： 0.0142604\n",
      "时间步 5658000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.195148e+01/ 轮得分 370.47\n",
      "损失函数： 0.0120948\n",
      "时间步 5659000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203867e+01/ 轮得分 370.47\n",
      "损失函数： 0.0133316\n",
      "时间步 5660000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281153e+01/ 轮得分 370.47\n",
      "损失函数： 0.0298479\n",
      "时间步 5661000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271720e+01/ 轮得分 370.47\n",
      "损失函数： 0.0252749\n",
      "时间步 5662000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.316371e+01/ 轮得分 370.47\n",
      "损失函数： 0.0262621\n",
      "时间步 5663000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.135370e+01/ 轮得分 370.47\n",
      "损失函数： 0.0225107\n",
      "时间步 5664000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.538637e+01/ 轮得分 370.47\n",
      "损失函数： 0.0291866\n",
      "时间步 5665000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.336522e+01/ 轮得分 370.47\n",
      "损失函数： 0.0320508\n",
      "时间步 5666000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.470590e+01/ 轮得分 371.49\n",
      "损失函数： 0.0180476\n",
      "时间步 5667000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423316e+01/ 轮得分 371.49\n",
      "损失函数： 0.0288489\n",
      "时间步 5668000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226535e+01/ 轮得分 371.49\n",
      "损失函数： 0.0292234\n",
      "时间步 5669000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.422926e+01/ 轮得分 371.49\n",
      "损失函数： 0.0165031\n",
      "时间步 5670000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305340e+01/ 轮得分 371.83\n",
      "损失函数： 0.0175609\n",
      "时间步 5671000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320202e+01/ 轮得分 371.93\n",
      "损失函数： 0.0471544\n",
      "时间步 5672000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262734e+01/ 轮得分 371.93\n",
      "损失函数： 0.00885175\n",
      "时间步 5673000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.237324e+01/ 轮得分 371.93\n",
      "损失函数： 1.45829\n",
      "时间步 5674000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354136e+01/ 轮得分 371.93\n",
      "损失函数： 0.0488402\n",
      "时间步 5675000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260835e+01/ 轮得分 371.93\n",
      "损失函数： 0.0259864\n",
      "时间步 5676000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.424650e+01/ 轮得分 372.23\n",
      "损失函数： 0.0156554\n",
      "时间步 5677000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.501861e+01/ 轮得分 372.23\n",
      "损失函数： 0.0161035\n",
      "时间步 5678000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343833e+01/ 轮得分 372.23\n",
      "损失函数： 0.0277835\n",
      "时间步 5679000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.269114e+01/ 轮得分 372.23\n",
      "损失函数： 0.0494864\n",
      "时间步 5680000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389847e+01/ 轮得分 372.23\n",
      "损失函数： 0.00549233\n",
      "时间步 5681000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.150749e+01/ 轮得分 372.86\n",
      "损失函数： 0.0474266\n",
      "时间步 5682000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187515e+01/ 轮得分 372.86\n",
      "损失函数： 0.0138852\n",
      "时间步 5683000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305176e+01/ 轮得分 372.86\n",
      "损失函数： 0.0178834\n",
      "时间步 5684000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.217927e+01/ 轮得分 372.86\n",
      "损失函数： 0.0107578\n",
      "时间步 5685000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.178101e+01/ 轮得分 373.31\n",
      "损失函数： 0.02249\n",
      "时间步 5686000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.443719e+01/ 轮得分 373.31\n",
      "损失函数： 0.0233674\n",
      "时间步 5687000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303713e+01/ 轮得分 373.43\n",
      "损失函数： 0.0078738\n",
      "时间步 5688000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.496519e+01/ 轮得分 373.43\n",
      "损失函数： 0.0340799\n",
      "时间步 5689000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301974e+01/ 轮得分 373.43\n",
      "损失函数： 0.0526022\n",
      "时间步 5690000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.353240e+01/ 轮得分 373.43\n",
      "损失函数： 0.0477261\n",
      "时间步 5691000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.211316e+01/ 轮得分 373.43\n",
      "损失函数： 0.0324244\n",
      "时间步 5692000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.303155e+01/ 轮得分 373.68\n",
      "损失函数： 0.0289418\n",
      "时间步 5693000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234604e+01/ 轮得分 373.68\n",
      "损失函数： 0.0198284\n",
      "时间步 5694000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356993e+01/ 轮得分 373.68\n",
      "损失函数： 0.0188385\n",
      "时间步 5695000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.448816e+01/ 轮得分 373.68\n",
      "损失函数： 0.0132911\n",
      "时间步 5696000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229961e+01/ 轮得分 373.68\n",
      "损失函数： 0.0395638\n",
      "时间步 5697000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234004e+01/ 轮得分 373.68\n",
      "损失函数： 0.0263641\n",
      "时间步 5698000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184387e+01/ 轮得分 373.76\n",
      "损失函数： 0.0235115\n",
      "时间步 5699000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.142971e+01/ 轮得分 373.41\n",
      "损失函数： 0.020542\n",
      "时间步 5700000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271789e+01/ 轮得分 373.41\n",
      "损失函数： 0.017202\n",
      "时间步 5701000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210995e+01/ 轮得分 373.41\n",
      "损失函数： 0.0418017\n",
      "时间步 5702000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254433e+01/ 轮得分 373.41\n",
      "损失函数： 0.0419276\n",
      "时间步 5703000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391828e+01/ 轮得分 373.41\n",
      "损失函数： 0.0327423\n",
      "时间步 5704000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307860e+01/ 轮得分 373.41\n",
      "损失函数： 0.0421136\n",
      "时间步 5705000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.436165e+01/ 轮得分 373.41\n",
      "损失函数： 0.0195136\n",
      "时间步 5706000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.215328e+01/ 轮得分 373.41\n",
      "损失函数： 0.03135\n",
      "时间步 5707000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.443105e+01/ 轮得分 373.41\n",
      "损失函数： 0.014807\n",
      "时间步 5708000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.153588e+01/ 轮得分 374.23\n",
      "损失函数： 0.0247028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5709000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230631e+01/ 轮得分 374.23\n",
      "损失函数： 0.0125921\n",
      "时间步 5710000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.163043e+01/ 轮得分 374.23\n",
      "损失函数： 0.0854245\n",
      "时间步 5711000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.178031e+01/ 轮得分 374.23\n",
      "损失函数： 0.0884534\n",
      "时间步 5712000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.125666e+01/ 轮得分 374.23\n",
      "损失函数： 0.0226491\n",
      "时间步 5713000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.370391e+01/ 轮得分 374.23\n",
      "损失函数： 0.0874127\n",
      "时间步 5714000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191413e+01/ 轮得分 374.42\n",
      "损失函数： 0.0343239\n",
      "时间步 5715000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.669595e+01/ 轮得分 374.42\n",
      "损失函数： 0.0275076\n",
      "时间步 5716000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339982e+01/ 轮得分 374.33\n",
      "损失函数： 0.0211653\n",
      "时间步 5717000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.424325e+01/ 轮得分 374.33\n",
      "损失函数： 0.0388057\n",
      "时间步 5718000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306645e+01/ 轮得分 374.57\n",
      "损失函数： 0.0325747\n",
      "时间步 5719000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.263799e+01/ 轮得分 374.57\n",
      "损失函数： 0.0345689\n",
      "时间步 5720000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.356069e+01/ 轮得分 374.57\n",
      "损失函数： 0.0459736\n",
      "时间步 5721000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 7.251850e+00/ 轮得分 374.57\n",
      "损失函数： 0.0171662\n",
      "时间步 5722000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.419733e+01/ 轮得分 374.63\n",
      "损失函数： 0.0314551\n",
      "时间步 5723000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281902e+01/ 轮得分 374.63\n",
      "损失函数： 0.0832361\n",
      "时间步 5724000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243564e+01/ 轮得分 374.63\n",
      "损失函数： 0.0124904\n",
      "时间步 5725000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.369396e+01/ 轮得分 374.63\n",
      "损失函数： 0.0287675\n",
      "时间步 5726000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432730e+01/ 轮得分 374.63\n",
      "损失函数： 0.0538701\n",
      "时间步 5727000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349919e+01/ 轮得分 374.63\n",
      "损失函数： 0.0326557\n",
      "时间步 5728000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.431540e+01/ 轮得分 374.63\n",
      "损失函数： 0.0291457\n",
      "时间步 5729000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215022e+01/ 轮得分 374.73\n",
      "损失函数： 0.0171862\n",
      "时间步 5730000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.470340e+01/ 轮得分 374.73\n",
      "损失函数： 0.03739\n",
      "时间步 5731000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.462624e+01/ 轮得分 374.73\n",
      "损失函数： 0.0209219\n",
      "时间步 5732000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.150946e+01/ 轮得分 374.48\n",
      "损失函数： 0.0257767\n",
      "时间步 5733000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203016e+01/ 轮得分 374.48\n",
      "损失函数： 0.0383651\n",
      "时间步 5734000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274315e+01/ 轮得分 374.48\n",
      "损失函数： 0.051879\n",
      "时间步 5735000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.211455e+01/ 轮得分 374.12\n",
      "损失函数： 0.0489316\n",
      "时间步 5736000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193995e+01/ 轮得分 374.12\n",
      "损失函数： 0.0354293\n",
      "时间步 5737000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.174135e+01/ 轮得分 374.12\n",
      "损失函数： 0.0443517\n",
      "时间步 5738000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.159472e+01/ 轮得分 374.08\n",
      "损失函数： 0.0195564\n",
      "时间步 5739000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391467e+01/ 轮得分 374.08\n",
      "损失函数： 0.026718\n",
      "时间步 5740000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.380317e+01/ 轮得分 374.08\n",
      "损失函数： 0.0176784\n",
      "时间步 5741000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.166547e+01/ 轮得分 374.08\n",
      "损失函数： 0.0441384\n",
      "时间步 5742000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.358943e+01/ 轮得分 374.08\n",
      "损失函数： 0.0266544\n",
      "时间步 5743000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377658e+01/ 轮得分 374.08\n",
      "损失函数： 0.027441\n",
      "时间步 5744000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.349359e+01/ 轮得分 374.08\n",
      "损失函数： 0.0727413\n",
      "时间步 5745000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.277833e+01/ 轮得分 374.08\n",
      "损失函数： 0.0511338\n",
      "时间步 5746000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.191494e+01/ 轮得分 374.95\n",
      "损失函数： 0.0138701\n",
      "时间步 5747000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191721e+01/ 轮得分 374.87\n",
      "损失函数： 0.0573108\n",
      "时间步 5748000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.504455e+01/ 轮得分 374.87\n",
      "损失函数： 0.0261127\n",
      "时间步 5749000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.153975e+01/ 轮得分 374.87\n",
      "损失函数： 0.0350168\n",
      "时间步 5750000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185980e+01/ 轮得分 374.87\n",
      "损失函数： 0.0605026\n",
      "时间步 5751000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.035934e+01/ 轮得分 374.87\n",
      "损失函数： 0.0354748\n",
      "时间步 5752000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281788e+01/ 轮得分 374.87\n",
      "损失函数： 0.0362316\n",
      "时间步 5753000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.253674e+01/ 轮得分 374.87\n",
      "损失函数： 0.0240631\n",
      "时间步 5754000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.265620e+01/ 轮得分 374.87\n",
      "损失函数： 0.0211291\n",
      "时间步 5755000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.070337e+01/ 轮得分 374.87\n",
      "损失函数： 0.0213375\n",
      "时间步 5756000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.265329e+01/ 轮得分 374.87\n",
      "损失函数： 0.0242593\n",
      "时间步 5757000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390017e+01/ 轮得分 375.71\n",
      "损失函数： 0.0313548\n",
      "时间步 5758000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306510e+01/ 轮得分 375.71\n",
      "损失函数： 0.0530721\n",
      "时间步 5759000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339616e+01/ 轮得分 375.71\n",
      "损失函数： 0.0227196\n",
      "时间步 5760000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.175213e+01/ 轮得分 375.71\n",
      "损失函数： 0.040294\n",
      "时间步 5761000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224034e+01/ 轮得分 375.78\n",
      "损失函数： 0.0323838\n",
      "时间步 5762000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.228287e+01/ 轮得分 376.00\n",
      "损失函数： 0.0337862\n",
      "时间步 5763000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.336656e+01/ 轮得分 376.00\n",
      "损失函数： 0.024293\n",
      "时间步 5764000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.402546e+01/ 轮得分 376.00\n",
      "损失函数： 0.0326792\n",
      "时间步 5765000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.390396e+01/ 轮得分 375.85\n",
      "损失函数： 0.0406373\n",
      "时间步 5766000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.504836e+01/ 轮得分 375.85\n",
      "损失函数： 0.0117077\n",
      "时间步 5767000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.428016e+01/ 轮得分 375.85\n",
      "损失函数： 0.0146271\n",
      "时间步 5768000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184184e+01/ 轮得分 375.85\n",
      "损失函数： 0.053946\n",
      "时间步 5769000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.522769e+01/ 轮得分 375.85\n",
      "损失函数： 0.0161254\n",
      "时间步 5770000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.431995e+01/ 轮得分 375.85\n",
      "损失函数： 0.0116562\n",
      "时间步 5771000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215256e+01/ 轮得分 375.93\n",
      "损失函数： 0.100698\n",
      "时间步 5772000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366670e+01/ 轮得分 375.80\n",
      "损失函数： 0.0246526\n",
      "时间步 5773000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277252e+01/ 轮得分 375.80\n",
      "损失函数： 0.0574368\n",
      "时间步 5774000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.468931e+01/ 轮得分 375.80\n",
      "损失函数： 0.0218958\n",
      "时间步 5775000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297939e+01/ 轮得分 375.80\n",
      "损失函数： 0.0415652\n",
      "时间步 5776000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.144562e+01/ 轮得分 375.80\n",
      "损失函数： 0.0269037\n",
      "时间步 5777000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.153370e+01/ 轮得分 375.80\n",
      "损失函数： 0.0259716\n",
      "时间步 5778000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394132e+01/ 轮得分 375.80\n",
      "损失函数： 0.0255621\n",
      "时间步 5779000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362971e+01/ 轮得分 375.80\n",
      "损失函数： 0.032383\n",
      "时间步 5780000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.130738e+01/ 轮得分 375.80\n",
      "损失函数： 0.0423194\n",
      "时间步 5781000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303832e+01/ 轮得分 375.80\n",
      "损失函数： 0.0288172\n",
      "时间步 5782000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320824e+01/ 轮得分 376.60\n",
      "损失函数： 0.0236366\n",
      "时间步 5783000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447430e+01/ 轮得分 376.60\n",
      "损失函数： 0.0154074\n",
      "时间步 5784000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.405085e+01/ 轮得分 376.60\n",
      "损失函数： 0.014563\n",
      "时间步 5785000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.374058e+01/ 轮得分 376.60\n",
      "损失函数： 0.0248682\n",
      "时间步 5786000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311982e+01/ 轮得分 376.60\n",
      "损失函数： 0.0390903\n",
      "时间步 5787000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 8.459224e+00/ 轮得分 376.60\n",
      "损失函数： 0.0183846\n",
      "时间步 5788000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316075e+01/ 轮得分 377.32\n",
      "损失函数： 0.0755458\n",
      "时间步 5789000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.404522e+01/ 轮得分 377.32\n",
      "损失函数： 0.0129017\n",
      "时间步 5790000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276953e+01/ 轮得分 377.32\n",
      "损失函数： 0.0104278\n",
      "时间步 5791000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.437261e+01/ 轮得分 377.32\n",
      "损失函数： 0.0317717\n",
      "时间步 5792000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319026e+01/ 轮得分 377.32\n",
      "损失函数： 0.0299793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5793000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384051e+01/ 轮得分 377.32\n",
      "损失函数： 0.0495029\n",
      "时间步 5794000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.167529e+01/ 轮得分 377.32\n",
      "损失函数： 0.013927\n",
      "时间步 5795000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359736e+01/ 轮得分 377.32\n",
      "损失函数： 0.0416987\n",
      "时间步 5796000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.061641e+01/ 轮得分 377.32\n",
      "损失函数： 0.0217985\n",
      "时间步 5797000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.344051e+01/ 轮得分 378.38\n",
      "损失函数： 0.0186048\n",
      "时间步 5798000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329420e+01/ 轮得分 378.38\n",
      "损失函数： 0.0504974\n",
      "时间步 5799000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227552e+01/ 轮得分 378.13\n",
      "损失函数： 0.0384096\n",
      "时间步 5800000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363701e+01/ 轮得分 378.13\n",
      "损失函数： 0.0170358\n",
      "时间步 5801000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.336053e+01/ 轮得分 378.13\n",
      "损失函数： 0.0393653\n",
      "时间步 5802000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.271096e+01/ 轮得分 378.31\n",
      "损失函数： 0.0278709\n",
      "时间步 5803000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.345327e+01/ 轮得分 378.31\n",
      "损失函数： 0.0303363\n",
      "时间步 5804000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.406137e+01/ 轮得分 378.31\n",
      "损失函数： 0.0132123\n",
      "时间步 5805000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.211854e+01/ 轮得分 378.31\n",
      "损失函数： 0.0473943\n",
      "时间步 5806000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305745e+01/ 轮得分 378.31\n",
      "损失函数： 0.0525391\n",
      "时间步 5807000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.382614e+01/ 轮得分 378.63\n",
      "损失函数： 0.022248\n",
      "时间步 5808000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282465e+01/ 轮得分 378.63\n",
      "损失函数： 0.0406992\n",
      "时间步 5809000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310969e+01/ 轮得分 378.63\n",
      "损失函数： 0.0610652\n",
      "时间步 5810000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.256216e+01/ 轮得分 378.63\n",
      "损失函数： 0.0351839\n",
      "时间步 5811000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.229296e+01/ 轮得分 378.63\n",
      "损失函数： 0.0342364\n",
      "时间步 5812000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257009e+01/ 轮得分 378.63\n",
      "损失函数： 0.0207314\n",
      "时间步 5813000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.257775e+01/ 轮得分 378.63\n",
      "损失函数： 0.0208225\n",
      "时间步 5814000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.165310e+01/ 轮得分 378.63\n",
      "损失函数： 0.025038\n",
      "时间步 5815000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.370380e+01/ 轮得分 378.63\n",
      "损失函数： 0.0414792\n",
      "时间步 5816000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.144849e+01/ 轮得分 379.60\n",
      "损失函数： 0.0345235\n",
      "时间步 5817000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204871e+01/ 轮得分 379.60\n",
      "损失函数： 0.0426486\n",
      "时间步 5818000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285093e+01/ 轮得分 379.60\n",
      "损失函数： 0.0187852\n",
      "时间步 5819000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.608317e+01/ 轮得分 379.60\n",
      "损失函数： 0.0492431\n",
      "时间步 5820000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221412e+01/ 轮得分 379.59\n",
      "损失函数： 0.0311426\n",
      "时间步 5821000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290604e+01/ 轮得分 379.59\n",
      "损失函数： 0.0626628\n",
      "时间步 5822000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.339190e+01/ 轮得分 379.59\n",
      "损失函数： 0.0272789\n",
      "时间步 5823000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324775e+01/ 轮得分 379.64\n",
      "损失函数： 0.0515496\n",
      "时间步 5824000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.419430e+01/ 轮得分 379.64\n",
      "损失函数： 0.0193561\n",
      "时间步 5825000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339366e+01/ 轮得分 379.64\n",
      "损失函数： 0.0240113\n",
      "时间步 5826000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.392608e+01/ 轮得分 380.03\n",
      "损失函数： 0.0193578\n",
      "时间步 5827000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.638129e+01/ 轮得分 380.03\n",
      "损失函数： 0.0202304\n",
      "时间步 5828000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.028889e+01/ 轮得分 380.03\n",
      "损失函数： 0.0393127\n",
      "时间步 5829000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.429241e+01/ 轮得分 380.33\n",
      "损失函数： 0.0498889\n",
      "时间步 5830000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204386e+01/ 轮得分 379.87\n",
      "损失函数： 0.0721361\n",
      "时间步 5831000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229421e+01/ 轮得分 379.32\n",
      "损失函数： 0.0548385\n",
      "时间步 5832000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226492e+01/ 轮得分 379.32\n",
      "损失函数： 0.0228768\n",
      "时间步 5833000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187650e+01/ 轮得分 379.32\n",
      "损失函数： 0.0187059\n",
      "时间步 5834000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411010e+01/ 轮得分 378.92\n",
      "损失函数： 0.0444116\n",
      "时间步 5835000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.352450e+01/ 轮得分 378.92\n",
      "损失函数： 0.0137267\n",
      "时间步 5836000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313996e+01/ 轮得分 378.92\n",
      "损失函数： 0.0356478\n",
      "时间步 5837000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.446098e+01/ 轮得分 378.92\n",
      "损失函数： 0.0469772\n",
      "时间步 5838000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298693e+01/ 轮得分 378.92\n",
      "损失函数： 0.0205164\n",
      "时间步 5839000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244508e+01/ 轮得分 378.92\n",
      "损失函数： 0.0569473\n",
      "时间步 5840000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305409e+01/ 轮得分 379.65\n",
      "损失函数： 0.0182538\n",
      "时间步 5841000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205516e+01/ 轮得分 379.65\n",
      "损失函数： 0.0510888\n",
      "时间步 5842000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.200966e+01/ 轮得分 379.65\n",
      "损失函数： 0.0245384\n",
      "时间步 5843000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246927e+01/ 轮得分 379.85\n",
      "损失函数： 0.0537693\n",
      "时间步 5844000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.485360e+01/ 轮得分 379.85\n",
      "损失函数： 0.0168128\n",
      "时间步 5845000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231983e+01/ 轮得分 379.85\n",
      "损失函数： 0.0185726\n",
      "时间步 5846000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.315495e+01/ 轮得分 379.85\n",
      "损失函数： 0.0244868\n",
      "时间步 5847000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.370960e+01/ 轮得分 380.29\n",
      "损失函数： 0.0186321\n",
      "时间步 5848000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.171814e+01/ 轮得分 380.29\n",
      "损失函数： 0.492716\n",
      "时间步 5849000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.314104e+01/ 轮得分 380.29\n",
      "损失函数： 0.0127749\n",
      "时间步 5850000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311600e+01/ 轮得分 380.29\n",
      "损失函数： 0.0393638\n",
      "时间步 5851000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.408122e+01/ 轮得分 380.03\n",
      "损失函数： 0.0604185\n",
      "时间步 5852000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345214e+01/ 轮得分 380.03\n",
      "损失函数： 0.0185051\n",
      "时间步 5853000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292233e+01/ 轮得分 380.03\n",
      "损失函数： 0.0409559\n",
      "时间步 5854000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340743e+01/ 轮得分 380.03\n",
      "损失函数： 0.0336017\n",
      "时间步 5855000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.470516e+01/ 轮得分 380.03\n",
      "损失函数： 0.0296334\n",
      "时间步 5856000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.252369e+01/ 轮得分 380.03\n",
      "损失函数： 0.0670926\n",
      "时间步 5857000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216285e+01/ 轮得分 380.03\n",
      "损失函数： 0.017118\n",
      "时间步 5858000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.418373e+01/ 轮得分 380.03\n",
      "损失函数： 0.0497118\n",
      "时间步 5859000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.493736e+01/ 轮得分 380.27\n",
      "损失函数： 0.0128343\n",
      "时间步 5860000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274762e+01/ 轮得分 380.27\n",
      "损失函数： 0.0230124\n",
      "时间步 5861000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.199791e+01/ 轮得分 380.27\n",
      "损失函数： 0.00905804\n",
      "时间步 5862000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306425e+01/ 轮得分 380.27\n",
      "损失函数： 0.0197697\n",
      "时间步 5863000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277405e+01/ 轮得分 380.27\n",
      "损失函数： 0.0345391\n",
      "时间步 5864000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.137038e+01/ 轮得分 380.27\n",
      "损失函数： 0.0120711\n",
      "时间步 5865000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352380e+01/ 轮得分 380.27\n",
      "损失函数： 0.0133696\n",
      "时间步 5866000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.139449e+01/ 轮得分 380.90\n",
      "损失函数： 0.0199316\n",
      "时间步 5867000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263894e+01/ 轮得分 380.90\n",
      "损失函数： 0.0183313\n",
      "时间步 5868000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308800e+01/ 轮得分 380.90\n",
      "损失函数： 0.00944991\n",
      "时间步 5869000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254569e+01/ 轮得分 380.90\n",
      "损失函数： 0.0307287\n",
      "时间步 5870000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180384e+01/ 轮得分 381.34\n",
      "损失函数： 0.0465348\n",
      "时间步 5871000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412861e+01/ 轮得分 381.34\n",
      "损失函数： 0.0319799\n",
      "时间步 5872000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.434465e+01/ 轮得分 381.34\n",
      "损失函数： 0.0440322\n",
      "时间步 5873000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235608e+01/ 轮得分 381.34\n",
      "损失函数： 0.0408705\n",
      "时间步 5874000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296024e+01/ 轮得分 381.34\n",
      "损失函数： 0.00844847\n",
      "时间步 5875000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.465275e+01/ 轮得分 381.21\n",
      "损失函数： 0.0496234\n",
      "时间步 5876000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339647e+01/ 轮得分 381.21\n",
      "损失函数： 0.0221552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5877000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287118e+01/ 轮得分 381.21\n",
      "损失函数： 0.00676231\n",
      "时间步 5878000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.429887e+01/ 轮得分 381.21\n",
      "损失函数： 0.0187991\n",
      "时间步 5879000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234180e+01/ 轮得分 381.48\n",
      "损失函数： 0.0168328\n",
      "时间步 5880000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.449990e+01/ 轮得分 381.48\n",
      "损失函数： 0.0359277\n",
      "时间步 5881000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284008e+01/ 轮得分 381.48\n",
      "损失函数： 0.0182331\n",
      "时间步 5882000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400607e+01/ 轮得分 381.48\n",
      "损失函数： 0.0225635\n",
      "时间步 5883000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.237267e+01/ 轮得分 381.48\n",
      "损失函数： 0.0159565\n",
      "时间步 5884000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.386709e+01/ 轮得分 381.48\n",
      "损失函数： 0.0304479\n",
      "时间步 5885000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.583941e+01/ 轮得分 382.02\n",
      "损失函数： 0.0122237\n",
      "时间步 5886000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239313e+01/ 轮得分 382.15\n",
      "损失函数： 0.0295185\n",
      "时间步 5887000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418951e+01/ 轮得分 382.15\n",
      "损失函数： 0.0365249\n",
      "时间步 5888000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.565454e+01/ 轮得分 382.15\n",
      "损失函数： 0.0755079\n",
      "时间步 5889000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.142767e+01/ 轮得分 382.15\n",
      "损失函数： 0.0204408\n",
      "时间步 5890000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223296e+01/ 轮得分 382.15\n",
      "损失函数： 0.0301541\n",
      "时间步 5891000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.536591e+01/ 轮得分 382.15\n",
      "损失函数： 0.0377472\n",
      "时间步 5892000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249602e+01/ 轮得分 382.15\n",
      "损失函数： 0.0579138\n",
      "时间步 5893000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.063961e+01/ 轮得分 382.15\n",
      "损失函数： 0.0203451\n",
      "时间步 5894000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.367953e+01/ 轮得分 382.38\n",
      "损失函数： 0.0488418\n",
      "时间步 5895000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276541e+01/ 轮得分 382.38\n",
      "损失函数： 0.0377012\n",
      "时间步 5896000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378864e+01/ 轮得分 382.38\n",
      "损失函数： 0.00929531\n",
      "时间步 5897000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372633e+01/ 轮得分 382.38\n",
      "损失函数： 0.0487685\n",
      "时间步 5898000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193108e+01/ 轮得分 382.79\n",
      "损失函数： 0.0386853\n",
      "时间步 5899000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.435386e+01/ 轮得分 382.79\n",
      "损失函数： 0.0447421\n",
      "时间步 5900000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332961e+01/ 轮得分 382.79\n",
      "损失函数： 0.0360784\n",
      "时间步 5901000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.334753e+01/ 轮得分 382.79\n",
      "损失函数： 0.0220336\n",
      "时间步 5902000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.269359e+01/ 轮得分 382.79\n",
      "损失函数： 0.0154975\n",
      "时间步 5903000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 7.657166e+00/ 轮得分 383.07\n",
      "损失函数： 0.0284318\n",
      "时间步 5904000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230241e+01/ 轮得分 382.22\n",
      "损失函数： 0.0476073\n",
      "时间步 5905000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316102e+01/ 轮得分 382.22\n",
      "损失函数： 0.0170866\n",
      "时间步 5906000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.350465e+01/ 轮得分 381.74\n",
      "损失函数： 0.317816\n",
      "时间步 5907000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.290762e+01/ 轮得分 381.74\n",
      "损失函数： 0.0467157\n",
      "时间步 5908000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117748e+01/ 轮得分 381.74\n",
      "损失函数： 0.0114712\n",
      "时间步 5909000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.479590e+01/ 轮得分 381.74\n",
      "损失函数： 0.0138132\n",
      "时间步 5910000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.107159e+01/ 轮得分 381.93\n",
      "损失函数： 0.0143618\n",
      "时间步 5911000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.179103e+01/ 轮得分 381.73\n",
      "损失函数： 0.057811\n",
      "时间步 5912000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313681e+01/ 轮得分 381.73\n",
      "损失函数： 0.0158892\n",
      "时间步 5913000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.128624e+01/ 轮得分 381.98\n",
      "损失函数： 0.0379552\n",
      "时间步 5914000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.155298e+01/ 轮得分 381.98\n",
      "损失函数： 0.0251056\n",
      "时间步 5915000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188229e+01/ 轮得分 381.98\n",
      "损失函数： 0.0277937\n",
      "时间步 5916000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254038e+01/ 轮得分 381.98\n",
      "损失函数： 0.0190927\n",
      "时间步 5917000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385190e+01/ 轮得分 381.98\n",
      "损失函数： 0.0579501\n",
      "时间步 5918000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322447e+01/ 轮得分 382.07\n",
      "损失函数： 0.0361045\n",
      "时间步 5919000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.292519e+01/ 轮得分 382.04\n",
      "损失函数： 0.0375288\n",
      "时间步 5920000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.438174e+01/ 轮得分 382.04\n",
      "损失函数： 0.0398105\n",
      "时间步 5921000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378962e+01/ 轮得分 382.04\n",
      "损失函数： 0.0606762\n",
      "时间步 5922000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.270300e+01/ 轮得分 382.04\n",
      "损失函数： 0.0345781\n",
      "时间步 5923000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276672e+01/ 轮得分 382.04\n",
      "损失函数： 0.0427023\n",
      "时间步 5924000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.506796e+01/ 轮得分 382.58\n",
      "损失函数： 0.0472611\n",
      "时间步 5925000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376244e+01/ 轮得分 382.58\n",
      "损失函数： 0.0208085\n",
      "时间步 5926000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.203240e+01/ 轮得分 382.58\n",
      "损失函数： 0.0771998\n",
      "时间步 5927000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 7.919161e+00/ 轮得分 382.58\n",
      "损失函数： 0.0400827\n",
      "时间步 5928000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213008e+01/ 轮得分 382.49\n",
      "损失函数： 0.151055\n",
      "时间步 5929000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318439e+01/ 轮得分 382.49\n",
      "损失函数： 0.0432567\n",
      "时间步 5930000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271160e+01/ 轮得分 382.49\n",
      "损失函数： 0.0348193\n",
      "时间步 5931000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196253e+01/ 轮得分 382.49\n",
      "损失函数： 0.0101145\n",
      "时间步 5932000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236433e+01/ 轮得分 382.49\n",
      "损失函数： 0.0448738\n",
      "时间步 5933000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309831e+01/ 轮得分 382.49\n",
      "损失函数： 0.0456005\n",
      "时间步 5934000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255350e+01/ 轮得分 382.49\n",
      "损失函数： 0.0276255\n",
      "时间步 5935000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.290793e+01/ 轮得分 383.08\n",
      "损失函数： 0.0697369\n",
      "时间步 5936000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.528467e+01/ 轮得分 383.08\n",
      "损失函数： 0.0811427\n",
      "时间步 5937000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.314676e+01/ 轮得分 383.08\n",
      "损失函数： 0.0167419\n",
      "时间步 5938000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378569e+01/ 轮得分 383.19\n",
      "损失函数： 0.0204659\n",
      "时间步 5939000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314708e+01/ 轮得分 383.19\n",
      "损失函数： 0.0143884\n",
      "时间步 5940000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233353e+01/ 轮得分 383.19\n",
      "损失函数： 0.0246427\n",
      "时间步 5941000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.475553e+01/ 轮得分 383.19\n",
      "损失函数： 0.0218944\n",
      "时间步 5942000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.448396e+01/ 轮得分 382.47\n",
      "损失函数： 0.0647331\n",
      "时间步 5943000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286542e+01/ 轮得分 382.47\n",
      "损失函数： 0.0145747\n",
      "时间步 5944000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177546e+01/ 轮得分 382.47\n",
      "损失函数： 0.0399747\n",
      "时间步 5945000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.386288e+01/ 轮得分 382.47\n",
      "损失函数： 0.0329327\n",
      "时间步 5946000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.427748e+01/ 轮得分 382.47\n",
      "损失函数： 0.0357364\n",
      "时间步 5947000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.364833e+01/ 轮得分 382.70\n",
      "损失函数： 0.0100658\n",
      "时间步 5948000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367110e+01/ 轮得分 382.70\n",
      "损失函数： 0.0184568\n",
      "时间步 5949000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352541e+01/ 轮得分 382.70\n",
      "损失函数： 0.0466061\n",
      "时间步 5950000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.583452e+01/ 轮得分 382.70\n",
      "损失函数： 0.0232126\n",
      "时间步 5951000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344124e+01/ 轮得分 382.70\n",
      "损失函数： 0.0320753\n",
      "时间步 5952000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387815e+01/ 轮得分 382.70\n",
      "损失函数： 0.0673162\n",
      "时间步 5953000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220630e+01/ 轮得分 383.28\n",
      "损失函数： 0.04333\n",
      "时间步 5954000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346225e+01/ 轮得分 383.28\n",
      "损失函数： 0.0219426\n",
      "时间步 5955000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304370e+01/ 轮得分 383.28\n",
      "损失函数： 0.0571026\n",
      "时间步 5956000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344999e+01/ 轮得分 383.28\n",
      "损失函数： 0.0458245\n",
      "时间步 5957000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268630e+01/ 轮得分 383.29\n",
      "损失函数： 0.112033\n",
      "时间步 5958000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.353849e+01/ 轮得分 383.29\n",
      "损失函数： 0.0339709\n",
      "时间步 5959000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.340173e+01/ 轮得分 383.29\n",
      "损失函数： 0.0495748\n",
      "时间步 5960000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423651e+01/ 轮得分 383.29\n",
      "损失函数： 0.0195984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 5961000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.319415e+01/ 轮得分 383.29\n",
      "损失函数： 0.0211423\n",
      "时间步 5962000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.337920e+01/ 轮得分 383.29\n",
      "损失函数： 0.108867\n",
      "时间步 5963000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348102e+01/ 轮得分 383.29\n",
      "损失函数： 0.056017\n",
      "时间步 5964000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.152549e+01/ 轮得分 383.42\n",
      "损失函数： 0.0121501\n",
      "时间步 5965000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.242872e+01/ 轮得分 383.42\n",
      "损失函数： 0.110686\n",
      "时间步 5966000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332137e+01/ 轮得分 383.42\n",
      "损失函数： 0.0524547\n",
      "时间步 5967000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265582e+01/ 轮得分 383.42\n",
      "损失函数： 0.0291402\n",
      "时间步 5968000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.168820e+01/ 轮得分 383.42\n",
      "损失函数： 0.0501212\n",
      "时间步 5969000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251540e+01/ 轮得分 383.42\n",
      "损失函数： 0.0305129\n",
      "时间步 5970000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.428918e+01/ 轮得分 383.42\n",
      "损失函数： 0.0495918\n",
      "时间步 5971000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.140518e+01/ 轮得分 383.42\n",
      "损失函数： 0.0166485\n",
      "时间步 5972000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.504185e+01/ 轮得分 383.42\n",
      "损失函数： 0.0434858\n",
      "时间步 5973000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.382137e+01/ 轮得分 383.42\n",
      "损失函数： 0.0278439\n",
      "时间步 5974000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.553181e+01/ 轮得分 383.42\n",
      "损失函数： 0.018577\n",
      "时间步 5975000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357024e+01/ 轮得分 383.42\n",
      "损失函数： 0.0138595\n",
      "时间步 5976000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.426914e+01/ 轮得分 383.42\n",
      "损失函数： 0.0102185\n",
      "时间步 5977000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.413466e+01/ 轮得分 384.47\n",
      "损失函数： 0.0301554\n",
      "时间步 5978000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.028438e+01/ 轮得分 384.47\n",
      "损失函数： 0.0226262\n",
      "时间步 5979000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.110024e+01/ 轮得分 384.47\n",
      "损失函数： 0.0189028\n",
      "时间步 5980000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.441852e+01/ 轮得分 384.47\n",
      "损失函数： 0.0243823\n",
      "时间步 5981000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239516e+01/ 轮得分 384.83\n",
      "损失函数： 0.0215052\n",
      "时间步 5982000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161208e+01/ 轮得分 384.83\n",
      "损失函数： 0.0278785\n",
      "时间步 5983000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303371e+01/ 轮得分 384.64\n",
      "损失函数： 0.0211319\n",
      "时间步 5984000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313774e+01/ 轮得分 384.64\n",
      "损失函数： 0.0381336\n",
      "时间步 5985000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.285909e+01/ 轮得分 384.89\n",
      "损失函数： 0.0204569\n",
      "时间步 5986000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265300e+01/ 轮得分 384.89\n",
      "损失函数： 0.0576432\n",
      "时间步 5987000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309648e+01/ 轮得分 384.89\n",
      "损失函数： 0.0248381\n",
      "时间步 5988000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335876e+01/ 轮得分 384.89\n",
      "损失函数： 0.0165776\n",
      "时间步 5989000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290096e+01/ 轮得分 384.89\n",
      "损失函数： 0.0514389\n",
      "时间步 5990000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.307526e+01/ 轮得分 385.11\n",
      "损失函数： 0.00565698\n",
      "时间步 5991000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314346e+01/ 轮得分 385.11\n",
      "损失函数： 0.00773414\n",
      "时间步 5992000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.187865e+01/ 轮得分 385.11\n",
      "损失函数： 0.0143629\n",
      "时间步 5993000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339362e+01/ 轮得分 385.20\n",
      "损失函数： 0.0166942\n",
      "时间步 5994000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.239920e+01/ 轮得分 384.91\n",
      "损失函数： 0.0099224\n",
      "时间步 5995000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.395696e+01/ 轮得分 384.96\n",
      "损失函数： 0.0186812\n",
      "时间步 5996000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.463451e+01/ 轮得分 384.96\n",
      "损失函数： 0.0506384\n",
      "时间步 5997000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221891e+01/ 轮得分 384.96\n",
      "损失函数： 0.120435\n",
      "时间步 5998000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230120e+01/ 轮得分 384.96\n",
      "损失函数： 0.0368449\n",
      "时间步 5999000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.211797e+01/ 轮得分 384.46\n",
      "损失函数： 0.0326344\n",
      "时间步 6000000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162489e+01/ 轮得分 384.46\n",
      "损失函数： 0.0383865\n",
      "时间步 6001000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330862e+01/ 轮得分 384.46\n",
      "损失函数： 0.0442572\n",
      "时间步 6002000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.464171e+01/ 轮得分 384.46\n",
      "损失函数： 0.0187079\n",
      "时间步 6003000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.434838e+01/ 轮得分 384.46\n",
      "损失函数： 0.0589587\n",
      "时间步 6004000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367186e+01/ 轮得分 384.86\n",
      "损失函数： 0.0371774\n",
      "时间步 6005000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333138e+01/ 轮得分 384.86\n",
      "损失函数： 0.0264788\n",
      "时间步 6006000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.442093e+01/ 轮得分 384.86\n",
      "损失函数： 0.0185712\n",
      "时间步 6007000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.133042e+01/ 轮得分 384.17\n",
      "损失函数： 0.0192417\n",
      "时间步 6008000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233507e+01/ 轮得分 384.17\n",
      "损失函数： 0.0329547\n",
      "时间步 6009000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.460887e+01/ 轮得分 384.17\n",
      "损失函数： 0.00988021\n",
      "时间步 6010000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384747e+01/ 轮得分 384.17\n",
      "损失函数： 0.0131566\n",
      "时间步 6011000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.350250e+01/ 轮得分 384.17\n",
      "损失函数： 0.0283702\n",
      "时间步 6012000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347472e+01/ 轮得分 384.17\n",
      "损失函数： 0.0120415\n",
      "时间步 6013000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.516909e+01/ 轮得分 384.17\n",
      "损失函数： 0.0405769\n",
      "时间步 6014000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.081395e+01/ 轮得分 384.17\n",
      "损失函数： 0.0143705\n",
      "时间步 6015000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285637e+01/ 轮得分 384.17\n",
      "损失函数： 0.0224733\n",
      "时间步 6016000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.305219e+01/ 轮得分 384.17\n",
      "损失函数： 0.0456259\n",
      "时间步 6017000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244551e+01/ 轮得分 384.17\n",
      "损失函数： 0.0385841\n",
      "时间步 6018000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196825e+01/ 轮得分 384.95\n",
      "损失函数： 0.0382744\n",
      "时间步 6019000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206415e+01/ 轮得分 384.95\n",
      "损失函数： 0.0213545\n",
      "时间步 6020000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221612e+01/ 轮得分 384.95\n",
      "损失函数： 0.0184499\n",
      "时间步 6021000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.120920e+01/ 轮得分 384.95\n",
      "损失函数： 0.0249532\n",
      "时间步 6022000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.124614e+01/ 轮得分 384.95\n",
      "损失函数： 0.0414396\n",
      "时间步 6023000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.129808e+01/ 轮得分 384.95\n",
      "损失函数： 0.0513258\n",
      "时间步 6024000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.080536e+01/ 轮得分 385.36\n",
      "损失函数： 0.0332973\n",
      "时间步 6025000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235145e+01/ 轮得分 385.36\n",
      "损失函数： 0.089575\n",
      "时间步 6026000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375498e+01/ 轮得分 385.36\n",
      "损失函数： 0.0132079\n",
      "时间步 6027000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.124885e+01/ 轮得分 385.36\n",
      "损失函数： 0.0203786\n",
      "时间步 6028000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202500e+01/ 轮得分 385.36\n",
      "损失函数： 0.020459\n",
      "时间步 6029000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184466e+01/ 轮得分 385.36\n",
      "损失函数： 0.0736683\n",
      "时间步 6030000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337581e+01/ 轮得分 385.36\n",
      "损失函数： 0.0198061\n",
      "时间步 6031000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.221934e+01/ 轮得分 385.99\n",
      "损失函数： 0.0256243\n",
      "时间步 6032000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.292590e+01/ 轮得分 385.99\n",
      "损失函数： 0.0122323\n",
      "时间步 6033000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319972e+01/ 轮得分 385.99\n",
      "损失函数： 0.0823798\n",
      "时间步 6034000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223237e+01/ 轮得分 385.99\n",
      "损失函数： 0.0423996\n",
      "时间步 6035000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326980e+01/ 轮得分 385.99\n",
      "损失函数： 0.031297\n",
      "时间步 6036000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202426e+01/ 轮得分 386.43\n",
      "损失函数： 0.0155865\n",
      "时间步 6037000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.279684e+01/ 轮得分 386.43\n",
      "损失函数： 0.0981415\n",
      "时间步 6038000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252366e+01/ 轮得分 386.44\n",
      "损失函数： 0.0236951\n",
      "时间步 6039000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.233686e+01/ 轮得分 386.44\n",
      "损失函数： 0.0369404\n",
      "时间步 6040000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373872e+01/ 轮得分 386.55\n",
      "损失函数： 0.0275073\n",
      "时间步 6041000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.565472e+01/ 轮得分 386.55\n",
      "损失函数： 0.0141347\n",
      "时间步 6042000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.382314e+01/ 轮得分 386.55\n",
      "损失函数： 0.0175482\n",
      "时间步 6043000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250406e+01/ 轮得分 386.55\n",
      "损失函数： 0.0138693\n",
      "时间步 6044000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231382e+01/ 轮得分 386.55\n",
      "损失函数： 0.0442825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6045000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.129479e+01/ 轮得分 386.55\n",
      "损失函数： 0.0142625\n",
      "时间步 6046000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.438821e+01/ 轮得分 386.55\n",
      "损失函数： 0.0509121\n",
      "时间步 6047000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318203e+01/ 轮得分 386.55\n",
      "损失函数： 0.0343498\n",
      "时间步 6048000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245583e+01/ 轮得分 386.08\n",
      "损失函数： 0.0508199\n",
      "时间步 6049000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170039e+01/ 轮得分 386.12\n",
      "损失函数： 0.0355641\n",
      "时间步 6050000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263799e+01/ 轮得分 386.12\n",
      "损失函数： 0.0416708\n",
      "时间步 6051000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.247398e+01/ 轮得分 386.12\n",
      "损失函数： 0.00785279\n",
      "时间步 6052000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352883e+01/ 轮得分 386.12\n",
      "损失函数： 0.0329716\n",
      "时间步 6053000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349755e+01/ 轮得分 386.38\n",
      "损失函数： 4.01687\n",
      "时间步 6054000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308447e+01/ 轮得分 386.38\n",
      "损失函数： 0.0500593\n",
      "时间步 6055000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226580e+01/ 轮得分 386.50\n",
      "损失函数： 0.0300104\n",
      "时间步 6056000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356100e+01/ 轮得分 386.50\n",
      "损失函数： 0.0314996\n",
      "时间步 6057000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.120492e+01/ 轮得分 386.50\n",
      "损失函数： 0.0213009\n",
      "时间步 6058000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.251621e+01/ 轮得分 386.54\n",
      "损失函数： 0.0215256\n",
      "时间步 6059000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330188e+01/ 轮得分 386.37\n",
      "损失函数： 0.00807052\n",
      "时间步 6060000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.173788e+01/ 轮得分 386.37\n",
      "损失函数： 0.0138568\n",
      "时间步 6061000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407320e+01/ 轮得分 386.37\n",
      "损失函数： 0.0286047\n",
      "时间步 6062000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246414e+01/ 轮得分 386.37\n",
      "损失函数： 0.0670958\n",
      "时间步 6063000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239454e+01/ 轮得分 386.70\n",
      "损失函数： 0.0348348\n",
      "时间步 6064000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309384e+01/ 轮得分 386.70\n",
      "损失函数： 0.0161298\n",
      "时间步 6065000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.232868e+01/ 轮得分 386.70\n",
      "损失函数： 0.012501\n",
      "时间步 6066000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.493086e+01/ 轮得分 386.82\n",
      "损失函数： 0.0244622\n",
      "时间步 6067000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291174e+01/ 轮得分 386.82\n",
      "损失函数： 0.0643647\n",
      "时间步 6068000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313229e+01/ 轮得分 386.82\n",
      "损失函数： 0.0254927\n",
      "时间步 6069000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248918e+01/ 轮得分 386.82\n",
      "损失函数： 0.0233476\n",
      "时间步 6070000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.476572e+01/ 轮得分 386.82\n",
      "损失函数： 0.0500322\n",
      "时间步 6071000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.172955e+01/ 轮得分 387.22\n",
      "损失函数： 0.0163878\n",
      "时间步 6072000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220471e+01/ 轮得分 386.89\n",
      "损失函数： 0.0273999\n",
      "时间步 6073000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312112e+01/ 轮得分 386.89\n",
      "损失函数： 0.0280044\n",
      "时间步 6074000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.386428e+01/ 轮得分 386.89\n",
      "损失函数： 0.0247859\n",
      "时间步 6075000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327780e+01/ 轮得分 386.89\n",
      "损失函数： 0.0176562\n",
      "时间步 6076000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316602e+01/ 轮得分 386.89\n",
      "损失函数： 0.0252107\n",
      "时间步 6077000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.122531e+01/ 轮得分 386.89\n",
      "损失函数： 0.0300527\n",
      "时间步 6078000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256525e+01/ 轮得分 386.89\n",
      "损失函数： 0.025943\n",
      "时间步 6079000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.138270e+01/ 轮得分 386.89\n",
      "损失函数： 0.0378521\n",
      "时间步 6080000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.168743e+01/ 轮得分 386.89\n",
      "损失函数： 0.0312475\n",
      "时间步 6081000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.420167e+01/ 轮得分 386.89\n",
      "损失函数： 0.013466\n",
      "时间步 6082000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246010e+01/ 轮得分 386.89\n",
      "损失函数： 0.0177895\n",
      "时间步 6083000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301169e+01/ 轮得分 386.89\n",
      "损失函数： 0.00895965\n",
      "时间步 6084000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.479590e+01/ 轮得分 386.89\n",
      "损失函数： 0.0218735\n",
      "时间步 6085000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411608e+01/ 轮得分 386.89\n",
      "损失函数： 0.061507\n",
      "时间步 6086000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234365e+01/ 轮得分 388.14\n",
      "损失函数： 0.0485168\n",
      "时间步 6087000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231932e+01/ 轮得分 388.26\n",
      "损失函数： 0.0262889\n",
      "时间步 6088000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340006e+01/ 轮得分 388.26\n",
      "损失函数： 0.0608525\n",
      "时间步 6089000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.382470e+01/ 轮得分 388.26\n",
      "损失函数： 0.0532128\n",
      "时间步 6090000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375946e+01/ 轮得分 388.26\n",
      "损失函数： 0.0529238\n",
      "时间步 6091000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.095876e+01/ 轮得分 388.26\n",
      "损失函数： 0.00441685\n",
      "时间步 6092000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323837e+01/ 轮得分 388.60\n",
      "损失函数： 0.0209377\n",
      "时间步 6093000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361709e+01/ 轮得分 388.60\n",
      "损失函数： 0.0371241\n",
      "时间步 6094000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279314e+01/ 轮得分 388.60\n",
      "损失函数： 0.0410447\n",
      "时间步 6095000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.397133e+01/ 轮得分 388.60\n",
      "损失函数： 0.0332515\n",
      "时间步 6096000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170559e+01/ 轮得分 388.90\n",
      "损失函数： 0.0594507\n",
      "时间步 6097000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.460517e+01/ 轮得分 388.90\n",
      "损失函数： 0.14188\n",
      "时间步 6098000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.110964e+01/ 轮得分 388.90\n",
      "损失函数： 0.0347953\n",
      "时间步 6099000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334136e+01/ 轮得分 389.19\n",
      "损失函数： 0.0320735\n",
      "时间步 6100000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.495417e+01/ 轮得分 389.19\n",
      "损失函数： 0.0135593\n",
      "时间步 6101000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314599e+01/ 轮得分 389.27\n",
      "损失函数： 0.0185708\n",
      "时间步 6102000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342697e+01/ 轮得分 389.27\n",
      "损失函数： 0.0584164\n",
      "时间步 6103000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183120e+01/ 轮得分 389.39\n",
      "损失函数： 0.0166567\n",
      "时间步 6104000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197090e+01/ 轮得分 389.39\n",
      "损失函数： 0.0307674\n",
      "时间步 6105000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314951e+01/ 轮得分 389.39\n",
      "损失函数： 0.0304359\n",
      "时间步 6106000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.119096e+01/ 轮得分 389.48\n",
      "损失函数： 0.0117735\n",
      "时间步 6107000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.139673e+01/ 轮得分 388.79\n",
      "损失函数： 0.0129491\n",
      "时间步 6108000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.521081e+01/ 轮得分 388.79\n",
      "损失函数： 0.0304626\n",
      "时间步 6109000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314288e+01/ 轮得分 388.79\n",
      "损失函数： 0.0337528\n",
      "时间步 6110000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312595e+01/ 轮得分 388.79\n",
      "损失函数： 0.124944\n",
      "时间步 6111000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.409717e+01/ 轮得分 388.79\n",
      "损失函数： 0.0914004\n",
      "时间步 6112000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.147137e+01/ 轮得分 388.79\n",
      "损失函数： 0.0722553\n",
      "时间步 6113000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367910e+01/ 轮得分 388.79\n",
      "损失函数： 0.0470907\n",
      "时间步 6114000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340475e+01/ 轮得分 388.79\n",
      "损失函数： 0.0302824\n",
      "时间步 6115000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.231064e+01/ 轮得分 388.79\n",
      "损失函数： 0.0292145\n",
      "时间步 6116000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193311e+01/ 轮得分 389.18\n",
      "损失函数： 0.0365729\n",
      "时间步 6117000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.281308e+01/ 轮得分 387.98\n",
      "损失函数： 0.031363\n",
      "时间步 6118000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.410804e+01/ 轮得分 387.71\n",
      "损失函数： 0.0137234\n",
      "时间步 6119000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.514257e+01/ 轮得分 387.90\n",
      "损失函数： 0.0273493\n",
      "时间步 6120000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.274856e+01/ 轮得分 387.90\n",
      "损失函数： 0.0150728\n",
      "时间步 6121000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328577e+01/ 轮得分 387.90\n",
      "损失函数： 0.0437087\n",
      "时间步 6122000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.381483e+01/ 轮得分 387.90\n",
      "损失函数： 0.0247699\n",
      "时间步 6123000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388342e+01/ 轮得分 388.32\n",
      "损失函数： 0.0201386\n",
      "时间步 6124000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.232315e+01/ 轮得分 388.30\n",
      "损失函数： 0.0254022\n",
      "时间步 6125000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363195e+01/ 轮得分 388.35\n",
      "损失函数： 0.0390291\n",
      "时间步 6126000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.416563e+01/ 轮得分 388.35\n",
      "损失函数： 0.09935\n",
      "时间步 6127000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299192e+01/ 轮得分 388.35\n",
      "损失函数： 0.0486502\n",
      "时间步 6128000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.641355e+01/ 轮得分 388.51\n",
      "损失函数： 0.0522451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6129000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.167922e+01/ 轮得分 388.58\n",
      "损失函数： 0.0377768\n",
      "时间步 6130000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300273e+01/ 轮得分 388.35\n",
      "损失函数： 0.0328692\n",
      "时间步 6131000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.421788e+01/ 轮得分 388.35\n",
      "损失函数： 0.0146645\n",
      "时间步 6132000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349752e+01/ 轮得分 388.44\n",
      "损失函数： 0.0745235\n",
      "时间步 6133000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284880e+01/ 轮得分 388.44\n",
      "损失函数： 0.0477665\n",
      "时间步 6134000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.227837e+01/ 轮得分 388.44\n",
      "损失函数： 0.0290397\n",
      "时间步 6135000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365339e+01/ 轮得分 388.44\n",
      "损失函数： 0.0322043\n",
      "时间步 6136000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 8.177440e+00/ 轮得分 388.44\n",
      "损失函数： 0.0300269\n",
      "时间步 6137000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243900e+01/ 轮得分 388.91\n",
      "损失函数： 0.0731057\n",
      "时间步 6138000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360424e+01/ 轮得分 388.91\n",
      "损失函数： 0.0319662\n",
      "时间步 6139000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244804e+01/ 轮得分 388.91\n",
      "损失函数： 0.0292557\n",
      "时间步 6140000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359095e+01/ 轮得分 389.24\n",
      "损失函数： 0.0372626\n",
      "时间步 6141000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.549225e+01/ 轮得分 389.24\n",
      "损失函数： 0.0520384\n",
      "时间步 6142000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273487e+01/ 轮得分 389.24\n",
      "损失函数： 0.0117263\n",
      "时间步 6143000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323746e+01/ 轮得分 389.24\n",
      "损失函数： 0.0158069\n",
      "时间步 6144000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.505283e+01/ 轮得分 389.24\n",
      "损失函数： 0.0500851\n",
      "时间步 6145000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177069e+01/ 轮得分 389.24\n",
      "损失函数： 0.0272489\n",
      "时间步 6146000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268989e+01/ 轮得分 389.80\n",
      "损失函数： 0.0548421\n",
      "时间步 6147000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.164713e+01/ 轮得分 389.80\n",
      "损失函数： 0.0208501\n",
      "时间步 6148000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412245e+01/ 轮得分 389.80\n",
      "损失函数： 0.0168063\n",
      "时间步 6149000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194448e+01/ 轮得分 389.80\n",
      "损失函数： 0.0518525\n",
      "时间步 6150000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233809e+01/ 轮得分 389.80\n",
      "损失函数： 0.0557863\n",
      "时间步 6151000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.218015e+01/ 轮得分 389.80\n",
      "损失函数： 0.0145262\n",
      "时间步 6152000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244241e+01/ 轮得分 389.80\n",
      "损失函数： 0.0200076\n",
      "时间步 6153000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.431321e+01/ 轮得分 389.80\n",
      "损失函数： 0.0278107\n",
      "时间步 6154000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.166950e+01/ 轮得分 390.26\n",
      "损失函数： 0.0152346\n",
      "时间步 6155000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222846e+01/ 轮得分 390.26\n",
      "损失函数： 0.0570556\n",
      "时间步 6156000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.426268e+01/ 轮得分 390.26\n",
      "损失函数： 0.02571\n",
      "时间步 6157000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250076e+01/ 轮得分 390.33\n",
      "损失函数： 0.0550114\n",
      "时间步 6158000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.495569e+01/ 轮得分 390.33\n",
      "损失函数： 0.0432095\n",
      "时间步 6159000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.445804e+01/ 轮得分 390.33\n",
      "损失函数： 0.0168352\n",
      "时间步 6160000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.510946e+01/ 轮得分 390.49\n",
      "损失函数： 0.0711147\n",
      "时间步 6161000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411981e+01/ 轮得分 390.50\n",
      "损失函数： 0.0227375\n",
      "时间步 6162000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376319e+01/ 轮得分 390.50\n",
      "损失函数： 0.0248182\n",
      "时间步 6163000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.129506e+01/ 轮得分 390.50\n",
      "损失函数： 0.0109955\n",
      "时间步 6164000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362517e+01/ 轮得分 390.61\n",
      "损失函数： 0.0145144\n",
      "时间步 6165000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.144941e+01/ 轮得分 390.61\n",
      "损失函数： 0.0183209\n",
      "时间步 6166000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.190588e+01/ 轮得分 390.61\n",
      "损失函数： 0.033394\n",
      "时间步 6167000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.265765e+01/ 轮得分 390.61\n",
      "损失函数： 0.0262248\n",
      "时间步 6168000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359217e+01/ 轮得分 390.61\n",
      "损失函数： 0.117483\n",
      "时间步 6169000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342037e+01/ 轮得分 391.13\n",
      "损失函数： 0.0172127\n",
      "时间步 6170000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306893e+01/ 轮得分 391.13\n",
      "损失函数： 0.0657541\n",
      "时间步 6171000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297967e+01/ 轮得分 391.13\n",
      "损失函数： 0.017588\n",
      "时间步 6172000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310917e+01/ 轮得分 391.43\n",
      "损失函数： 0.0254463\n",
      "时间步 6173000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165662e+01/ 轮得分 391.43\n",
      "损失函数： 0.020424\n",
      "时间步 6174000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.490665e+01/ 轮得分 391.43\n",
      "损失函数： 0.0177224\n",
      "时间步 6175000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.706922e+01/ 轮得分 391.69\n",
      "损失函数： 0.0346738\n",
      "时间步 6176000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261197e+01/ 轮得分 391.40\n",
      "损失函数： 0.0186767\n",
      "时间步 6177000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.462066e+01/ 轮得分 391.40\n",
      "损失函数： 0.0647915\n",
      "时间步 6178000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.406765e+01/ 轮得分 391.40\n",
      "损失函数： 0.0193734\n",
      "时间步 6179000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.436478e+01/ 轮得分 391.40\n",
      "损失函数： 0.0446745\n",
      "时间步 6180000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289697e+01/ 轮得分 391.40\n",
      "损失函数： 0.013735\n",
      "时间步 6181000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271733e+01/ 轮得分 391.40\n",
      "损失函数： 0.0175207\n",
      "时间步 6182000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.434178e+01/ 轮得分 391.40\n",
      "损失函数： 0.0371144\n",
      "时间步 6183000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283358e+01/ 轮得分 391.40\n",
      "损失函数： 0.0272025\n",
      "时间步 6184000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258868e+01/ 轮得分 391.40\n",
      "损失函数： 0.0124262\n",
      "时间步 6185000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216516e+01/ 轮得分 391.40\n",
      "损失函数： 0.0270349\n",
      "时间步 6186000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384347e+01/ 轮得分 391.40\n",
      "损失函数： 0.0127896\n",
      "时间步 6187000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385645e+01/ 轮得分 391.40\n",
      "损失函数： 0.0986687\n",
      "时间步 6188000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286628e+01/ 轮得分 391.40\n",
      "损失函数： 0.0142668\n",
      "时间步 6189000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318613e+01/ 轮得分 391.40\n",
      "损失函数： 0.0252838\n",
      "时间步 6190000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268323e+01/ 轮得分 391.40\n",
      "损失函数： 0.00946576\n",
      "时间步 6191000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407101e+01/ 轮得分 391.40\n",
      "损失函数： 0.0105236\n",
      "时间步 6192000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.034220e+01/ 轮得分 391.40\n",
      "损失函数： 0.0559675\n",
      "时间步 6193000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239612e+01/ 轮得分 391.40\n",
      "损失函数： 0.0217206\n",
      "时间步 6194000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.421363e+01/ 轮得分 391.40\n",
      "损失函数： 0.0347026\n",
      "时间步 6195000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325231e+01/ 轮得分 393.20\n",
      "损失函数： 0.0453595\n",
      "时间步 6196000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230669e+01/ 轮得分 393.33\n",
      "损失函数： 0.032994\n",
      "时间步 6197000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.123851e+01/ 轮得分 393.33\n",
      "损失函数： 0.0130154\n",
      "时间步 6198000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266975e+01/ 轮得分 393.33\n",
      "损失函数： 0.0210973\n",
      "时间步 6199000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415471e+01/ 轮得分 393.33\n",
      "损失函数： 0.0210851\n",
      "时间步 6200000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.370741e+01/ 轮得分 393.40\n",
      "损失函数： 0.0306194\n",
      "时间步 6201000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.381410e+01/ 轮得分 393.40\n",
      "损失函数： 0.0269915\n",
      "时间步 6202000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.451319e+01/ 轮得分 393.40\n",
      "损失函数： 0.085935\n",
      "时间步 6203000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.228955e+01/ 轮得分 393.40\n",
      "损失函数： 0.0388546\n",
      "时间步 6204000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204342e+01/ 轮得分 393.40\n",
      "损失函数： 0.0492512\n",
      "时间步 6205000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.131859e+01/ 轮得分 393.40\n",
      "损失函数： 0.0150096\n",
      "时间步 6206000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.203958e+01/ 轮得分 393.40\n",
      "损失函数： 0.0173146\n",
      "时间步 6207000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.358045e+01/ 轮得分 393.40\n",
      "损失函数： 0.059178\n",
      "时间步 6208000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.479903e+01/ 轮得分 393.40\n",
      "损失函数： 0.0124739\n",
      "时间步 6209000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287307e+01/ 轮得分 393.40\n",
      "损失函数： 0.0151705\n",
      "时间步 6210000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372523e+01/ 轮得分 393.40\n",
      "损失函数： 0.0243787\n",
      "时间步 6211000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263477e+01/ 轮得分 393.40\n",
      "损失函数： 0.0516684\n",
      "时间步 6212000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.116661e+01/ 轮得分 393.40\n",
      "损失函数： 0.0169191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6213000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345037e+01/ 轮得分 394.95\n",
      "损失函数： 0.0133671\n",
      "时间步 6214000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339071e+01/ 轮得分 395.03\n",
      "损失函数： 0.0225974\n",
      "时间步 6215000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.488053e+01/ 轮得分 395.03\n",
      "损失函数： 0.0204509\n",
      "时间步 6216000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.329191e+01/ 轮得分 395.17\n",
      "损失函数： 0.0359136\n",
      "时间步 6217000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.376723e+01/ 轮得分 395.17\n",
      "损失函数： 0.0118343\n",
      "时间步 6218000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318590e+01/ 轮得分 395.17\n",
      "损失函数： 0.0245605\n",
      "时间步 6219000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407759e+01/ 轮得分 394.72\n",
      "损失函数： 0.0431394\n",
      "时间步 6220000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319916e+01/ 轮得分 394.72\n",
      "损失函数： 0.0709725\n",
      "时间步 6221000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364695e+01/ 轮得分 394.48\n",
      "损失函数： 0.0343114\n",
      "时间步 6222000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237271e+01/ 轮得分 394.48\n",
      "损失函数： 0.0168777\n",
      "时间步 6223000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240476e+01/ 轮得分 394.36\n",
      "损失函数： 0.0704129\n",
      "时间步 6224000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389300e+01/ 轮得分 394.42\n",
      "损失函数： 0.031626\n",
      "时间步 6225000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.410852e+01/ 轮得分 394.42\n",
      "损失函数： 0.02264\n",
      "时间步 6226000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331832e+01/ 轮得分 394.42\n",
      "损失函数： 0.0169449\n",
      "时间步 6227000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.255729e+01/ 轮得分 394.42\n",
      "损失函数： 0.0274502\n",
      "时间步 6228000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.196184e+01/ 轮得分 394.42\n",
      "损失函数： 0.0169043\n",
      "时间步 6229000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.523148e+01/ 轮得分 394.73\n",
      "损失函数： 0.0738311\n",
      "时间步 6230000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361140e+01/ 轮得分 394.73\n",
      "损失函数： 0.0265536\n",
      "时间步 6231000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263419e+01/ 轮得分 394.84\n",
      "损失函数： 0.0406932\n",
      "时间步 6232000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242121e+01/ 轮得分 394.84\n",
      "损失函数： 0.0346449\n",
      "时间步 6233000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271019e+01/ 轮得分 394.84\n",
      "损失函数： 0.0161497\n",
      "时间步 6234000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319994e+01/ 轮得分 394.84\n",
      "损失函数： 0.0264681\n",
      "时间步 6235000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377184e+01/ 轮得分 394.84\n",
      "损失函数： 0.0185451\n",
      "时间步 6236000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.284159e+01/ 轮得分 394.84\n",
      "损失函数： 0.0260633\n",
      "时间步 6237000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299691e+01/ 轮得分 395.45\n",
      "损失函数： 0.136801\n",
      "时间步 6238000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183439e+01/ 轮得分 395.06\n",
      "损失函数： 0.0312145\n",
      "时间步 6239000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197879e+01/ 轮得分 395.06\n",
      "损失函数： 0.0466499\n",
      "时间步 6240000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254220e+01/ 轮得分 395.06\n",
      "损失函数： 0.0248466\n",
      "时间步 6241000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.128865e+00/ 轮得分 395.06\n",
      "损失函数： 0.0212664\n",
      "时间步 6242000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213604e+01/ 轮得分 395.24\n",
      "损失函数： 0.0206207\n",
      "时间步 6243000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.224117e+01/ 轮得分 395.24\n",
      "损失函数： 0.0605144\n",
      "时间步 6244000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.119782e+01/ 轮得分 395.24\n",
      "损失函数： 0.061219\n",
      "时间步 6245000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348633e+01/ 轮得分 395.24\n",
      "损失函数： 0.0257364\n",
      "时间步 6246000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.176011e+01/ 轮得分 395.24\n",
      "损失函数： 0.049618\n",
      "时间步 6247000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226412e+01/ 轮得分 395.24\n",
      "损失函数： 0.0214008\n",
      "时间步 6248000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197012e+01/ 轮得分 396.02\n",
      "损失函数： 1.45478\n",
      "时间步 6249000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.435339e+01/ 轮得分 396.02\n",
      "损失函数： 0.0260147\n",
      "时间步 6250000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.200466e+01/ 轮得分 396.02\n",
      "损失函数： 0.039324\n",
      "时间步 6251000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222460e+01/ 轮得分 396.02\n",
      "损失函数： 0.0268955\n",
      "时间步 6252000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249720e+01/ 轮得分 396.27\n",
      "损失函数： 0.0253771\n",
      "时间步 6253000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341253e+01/ 轮得分 395.45\n",
      "损失函数： 0.00735975\n",
      "时间步 6254000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.542817e+01/ 轮得分 395.45\n",
      "损失函数： 0.0173052\n",
      "时间步 6255000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206713e+01/ 轮得分 395.45\n",
      "损失函数： 0.0477573\n",
      "时间步 6256000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.374887e+01/ 轮得分 395.45\n",
      "损失函数： 0.0292819\n",
      "时间步 6257000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341470e+01/ 轮得分 395.45\n",
      "损失函数： 0.0180592\n",
      "时间步 6258000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.078963e+01/ 轮得分 395.45\n",
      "损失函数： 0.0279274\n",
      "时间步 6259000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.294418e+01/ 轮得分 395.45\n",
      "损失函数： 0.0531275\n",
      "时间步 6260000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.441498e+01/ 轮得分 395.45\n",
      "损失函数： 0.0354753\n",
      "时间步 6261000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.204851e+01/ 轮得分 396.28\n",
      "损失函数： 0.00997453\n",
      "时间步 6262000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327613e+01/ 轮得分 396.28\n",
      "损失函数： 0.0261792\n",
      "时间步 6263000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.431172e+01/ 轮得分 396.28\n",
      "损失函数： 0.0190704\n",
      "时间步 6264000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.223696e+01/ 轮得分 396.28\n",
      "损失函数： 0.0319727\n",
      "时间步 6265000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264162e+01/ 轮得分 396.28\n",
      "损失函数： 0.0287294\n",
      "时间步 6266000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432401e+01/ 轮得分 396.28\n",
      "损失函数： 0.0289661\n",
      "时间步 6267000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259395e+01/ 轮得分 396.28\n",
      "损失函数： 0.0144111\n",
      "时间步 6268000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.102785e+01/ 轮得分 396.28\n",
      "损失函数： 0.0205249\n",
      "时间步 6269000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301520e+01/ 轮得分 396.98\n",
      "损失函数： 0.0681952\n",
      "时间步 6270000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255381e+01/ 轮得分 396.98\n",
      "损失函数： 0.0341562\n",
      "时间步 6271000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345279e+01/ 轮得分 396.98\n",
      "损失函数： 0.0443112\n",
      "时间步 6272000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.363812e+01/ 轮得分 396.91\n",
      "损失函数： 0.0538087\n",
      "时间步 6273000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377688e+01/ 轮得分 396.81\n",
      "损失函数： 0.0231459\n",
      "时间步 6274000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 8.525433e+00/ 轮得分 396.81\n",
      "损失函数： 0.00825483\n",
      "时间步 6275000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.143911e+01/ 轮得分 396.39\n",
      "损失函数： 0.0412337\n",
      "时间步 6276000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234380e+01/ 轮得分 395.68\n",
      "损失函数： 0.0134933\n",
      "时间步 6277000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339259e+01/ 轮得分 394.81\n",
      "损失函数： 0.0949763\n",
      "时间步 6278000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.281957e+01/ 轮得分 394.81\n",
      "损失函数： 0.0337598\n",
      "时间步 6279000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239757e+01/ 轮得分 394.61\n",
      "损失函数： 0.0330247\n",
      "时间步 6280000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314655e+01/ 轮得分 394.61\n",
      "损失函数： 0.0368173\n",
      "时间步 6281000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.402859e+01/ 轮得分 394.51\n",
      "损失函数： 0.0379637\n",
      "时间步 6282000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.200006e+01/ 轮得分 394.51\n",
      "损失函数： 0.0811062\n",
      "时间步 6283000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191652e+01/ 轮得分 394.18\n",
      "损失函数： 0.0207674\n",
      "时间步 6284000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191648e+01/ 轮得分 394.18\n",
      "损失函数： 0.0287507\n",
      "时间步 6285000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.381107e+01/ 轮得分 394.18\n",
      "损失函数： 0.0283554\n",
      "时间步 6286000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 6.322273e+00/ 轮得分 394.18\n",
      "损失函数： 0.0539037\n",
      "时间步 6287000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.406541e+01/ 轮得分 394.18\n",
      "损失函数： 0.0124616\n",
      "时间步 6288000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258119e+01/ 轮得分 394.18\n",
      "损失函数： 0.0211897\n",
      "时间步 6289000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.053839e+01/ 轮得分 394.18\n",
      "损失函数： 0.0299215\n",
      "时间步 6290000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249567e+01/ 轮得分 394.79\n",
      "损失函数： 0.0444892\n",
      "时间步 6291000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.085359e+01/ 轮得分 394.79\n",
      "损失函数： 0.0238089\n",
      "时间步 6292000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.142279e+01/ 轮得分 394.79\n",
      "损失函数： 0.0147421\n",
      "时间步 6293000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.481026e+01/ 轮得分 394.79\n",
      "损失函数： 0.0434834\n",
      "时间步 6294000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432484e+01/ 轮得分 394.79\n",
      "损失函数： 0.0270161\n",
      "时间步 6295000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.441953e+01/ 轮得分 394.79\n",
      "损失函数： 0.0306651\n",
      "时间步 6296000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.178485e+00/ 轮得分 394.79\n",
      "损失函数： 0.0456555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6297000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252681e+01/ 轮得分 394.79\n",
      "损失函数： 0.0220578\n",
      "时间步 6298000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.121390e+01/ 轮得分 394.79\n",
      "损失函数： 0.0257816\n",
      "时间步 6299000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.397595e+01/ 轮得分 395.09\n",
      "损失函数： 0.0300891\n",
      "时间步 6300000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215122e+01/ 轮得分 395.17\n",
      "损失函数： 0.0273599\n",
      "时间步 6301000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271196e+01/ 轮得分 395.17\n",
      "损失函数： 0.0229109\n",
      "时间步 6302000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338636e+01/ 轮得分 395.02\n",
      "损失函数： 0.0556305\n",
      "时间步 6303000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.499655e+01/ 轮得分 395.02\n",
      "损失函数： 0.0763583\n",
      "时间步 6304000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340409e+01/ 轮得分 394.91\n",
      "损失函数： 0.0225628\n",
      "时间步 6305000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355662e+01/ 轮得分 394.91\n",
      "损失函数： 0.0446872\n",
      "时间步 6306000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.495093e+01/ 轮得分 394.91\n",
      "损失函数： 0.046761\n",
      "时间步 6307000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288377e+01/ 轮得分 394.91\n",
      "损失函数： 0.0314667\n",
      "时间步 6308000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165372e+01/ 轮得分 394.91\n",
      "损失函数： 0.0129018\n",
      "时间步 6309000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251596e+01/ 轮得分 394.91\n",
      "损失函数： 0.0457985\n",
      "时间步 6310000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262946e+01/ 轮得分 394.91\n",
      "损失函数： 0.0201061\n",
      "时间步 6311000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.581824e+01/ 轮得分 394.91\n",
      "损失函数： 0.0365962\n",
      "时间步 6312000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326055e+01/ 轮得分 394.91\n",
      "损失函数： 0.0190338\n",
      "时间步 6313000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303137e+01/ 轮得分 394.91\n",
      "损失函数： 0.0155882\n",
      "时间步 6314000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184807e+01/ 轮得分 394.91\n",
      "损失函数： 0.0056868\n",
      "时间步 6315000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220342e+01/ 轮得分 394.91\n",
      "损失函数： 0.0394622\n",
      "时间步 6316000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275545e+01/ 轮得分 394.91\n",
      "损失函数： 0.00982202\n",
      "时间步 6317000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198756e+01/ 轮得分 394.91\n",
      "损失函数： 0.0741502\n",
      "时间步 6318000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.116602e+01/ 轮得分 394.91\n",
      "损失函数： 0.0163938\n",
      "时间步 6319000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325218e+01/ 轮得分 396.64\n",
      "损失函数： 0.0265602\n",
      "时间步 6320000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275139e+01/ 轮得分 396.64\n",
      "损失函数： 0.0322097\n",
      "时间步 6321000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295325e+01/ 轮得分 396.64\n",
      "损失函数： 0.0161657\n",
      "时间步 6322000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299117e+01/ 轮得分 396.64\n",
      "损失函数： 0.0198367\n",
      "时间步 6323000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.204968e+01/ 轮得分 396.64\n",
      "损失函数： 0.0194906\n",
      "时间步 6324000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170421e+01/ 轮得分 397.09\n",
      "损失函数： 0.0335631\n",
      "时间步 6325000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.125540e+01/ 轮得分 397.09\n",
      "损失函数： 0.0157303\n",
      "时间步 6326000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.047027e+01/ 轮得分 397.09\n",
      "损失函数： 0.0376885\n",
      "时间步 6327000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.413185e+01/ 轮得分 397.09\n",
      "损失函数： 0.0384682\n",
      "时间步 6328000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.176471e+01/ 轮得分 397.09\n",
      "损失函数： 0.036566\n",
      "时间步 6329000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234757e+01/ 轮得分 397.09\n",
      "损失函数： 0.0146096\n",
      "时间步 6330000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.146200e+01/ 轮得分 397.62\n",
      "损失函数： 0.0173786\n",
      "时间步 6331000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.175348e+01/ 轮得分 397.62\n",
      "损失函数： 0.0262736\n",
      "时间步 6332000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.148178e+01/ 轮得分 396.52\n",
      "损失函数： 0.0285923\n",
      "时间步 6333000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310904e+01/ 轮得分 396.52\n",
      "损失函数： 0.0186128\n",
      "时间步 6334000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.371142e+01/ 轮得分 396.52\n",
      "损失函数： 0.0153452\n",
      "时间步 6335000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289165e+01/ 轮得分 396.52\n",
      "损失函数： 0.0541577\n",
      "时间步 6336000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243290e+01/ 轮得分 396.52\n",
      "损失函数： 0.0709174\n",
      "时间步 6337000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.064988e+01/ 轮得分 396.52\n",
      "损失函数： 0.0158004\n",
      "时间步 6338000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356639e+01/ 轮得分 396.52\n",
      "损失函数： 0.0242709\n",
      "时间步 6339000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198310e+01/ 轮得分 396.52\n",
      "损失函数： 0.0310438\n",
      "时间步 6340000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234134e+01/ 轮得分 396.52\n",
      "损失函数： 0.0235053\n",
      "时间步 6341000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.285926e+01/ 轮得分 396.52\n",
      "损失函数： 0.0129602\n",
      "时间步 6342000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418231e+01/ 轮得分 396.52\n",
      "损失函数： 0.0318135\n",
      "时间步 6343000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270782e+01/ 轮得分 396.52\n",
      "损失函数： 0.0126286\n",
      "时间步 6344000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.151099e+01/ 轮得分 397.17\n",
      "损失函数： 0.0148858\n",
      "时间步 6345000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360202e+01/ 轮得分 397.03\n",
      "损失函数： 0.0235517\n",
      "时间步 6346000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341679e+01/ 轮得分 397.03\n",
      "损失函数： 0.0123425\n",
      "时间步 6347000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265122e+01/ 轮得分 397.03\n",
      "损失函数： 0.0217163\n",
      "时间步 6348000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.399017e+01/ 轮得分 396.82\n",
      "损失函数： 0.0116554\n",
      "时间步 6349000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286333e+01/ 轮得分 396.82\n",
      "损失函数： 0.0370074\n",
      "时间步 6350000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296685e+01/ 轮得分 396.82\n",
      "损失函数： 0.0188813\n",
      "时间步 6351000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.512043e+01/ 轮得分 396.82\n",
      "损失函数： 0.0560635\n",
      "时间步 6352000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.452497e+01/ 轮得分 396.82\n",
      "损失函数： 0.0549557\n",
      "时间步 6353000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.477092e+01/ 轮得分 396.48\n",
      "损失函数： 0.0644448\n",
      "时间步 6354000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294198e+01/ 轮得分 396.48\n",
      "损失函数： 0.0424319\n",
      "时间步 6355000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388458e+01/ 轮得分 396.48\n",
      "损失函数： 0.0136573\n",
      "时间步 6356000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.156030e+01/ 轮得分 396.48\n",
      "损失函数： 0.0510447\n",
      "时间步 6357000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223259e+01/ 轮得分 396.48\n",
      "损失函数： 0.54274\n",
      "时间步 6358000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330171e+01/ 轮得分 396.48\n",
      "损失函数： 0.0447741\n",
      "时间步 6359000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197226e+01/ 轮得分 396.48\n",
      "损失函数： 0.034193\n",
      "时间步 6360000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.402620e+01/ 轮得分 396.48\n",
      "损失函数： 0.101423\n",
      "时间步 6361000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.409386e+01/ 轮得分 396.48\n",
      "损失函数： 0.0198376\n",
      "时间步 6362000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317025e+01/ 轮得分 396.48\n",
      "损失函数： 0.0236076\n",
      "时间步 6363000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306886e+01/ 轮得分 396.48\n",
      "损失函数： 0.0174595\n",
      "时间步 6364000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284649e+01/ 轮得分 396.48\n",
      "损失函数： 0.0200247\n",
      "时间步 6365000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298220e+01/ 轮得分 396.48\n",
      "损失函数： 0.0356826\n",
      "时间步 6366000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.281964e+01/ 轮得分 396.48\n",
      "损失函数： 0.0418578\n",
      "时间步 6367000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.126834e+01/ 轮得分 397.66\n",
      "损失函数： 0.0138854\n",
      "时间步 6368000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.395883e+01/ 轮得分 397.66\n",
      "损失函数： 0.0503163\n",
      "时间步 6369000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249661e+01/ 轮得分 397.86\n",
      "损失函数： 0.00874032\n",
      "时间步 6370000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341650e+01/ 轮得分 397.86\n",
      "损失函数： 0.0641634\n",
      "时间步 6371000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333359e+01/ 轮得分 397.86\n",
      "损失函数： 0.0249654\n",
      "时间步 6372000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306075e+01/ 轮得分 397.86\n",
      "损失函数： 0.00796735\n",
      "时间步 6373000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227122e+01/ 轮得分 397.86\n",
      "损失函数： 0.0242494\n",
      "时间步 6374000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.392155e+01/ 轮得分 397.86\n",
      "损失函数： 0.00770981\n",
      "时间步 6375000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.157251e+01/ 轮得分 397.86\n",
      "损失函数： 0.0171658\n",
      "时间步 6376000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205722e+01/ 轮得分 398.56\n",
      "损失函数： 0.0223483\n",
      "时间步 6377000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.253953e+01/ 轮得分 398.56\n",
      "损失函数： 0.0543775\n",
      "时间步 6378000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 7.135262e+00/ 轮得分 398.72\n",
      "损失函数： 0.073123\n",
      "时间步 6379000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.080411e+01/ 轮得分 398.37\n",
      "损失函数： 0.0275099\n",
      "时间步 6380000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.068766e+01/ 轮得分 398.37\n",
      "损失函数： 0.0866268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6381000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.135791e+01/ 轮得分 398.37\n",
      "损失函数： 0.017548\n",
      "时间步 6382000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289191e+01/ 轮得分 398.62\n",
      "损失函数： 0.0306017\n",
      "时间步 6383000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251535e+01/ 轮得分 398.62\n",
      "损失函数： 0.0239642\n",
      "时间步 6384000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.120440e+01/ 轮得分 398.62\n",
      "损失函数： 0.0381241\n",
      "时间步 6385000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.406710e+01/ 轮得分 398.62\n",
      "损失函数： 0.0236172\n",
      "时间步 6386000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197958e+01/ 轮得分 399.20\n",
      "损失函数： 0.0479797\n",
      "时间步 6387000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387586e+01/ 轮得分 399.20\n",
      "损失函数： 0.0285082\n",
      "时间步 6388000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305506e+01/ 轮得分 399.39\n",
      "损失函数： 0.0253116\n",
      "时间步 6389000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.399413e+01/ 轮得分 399.16\n",
      "损失函数： 0.0434375\n",
      "时间步 6390000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.243669e+01/ 轮得分 399.16\n",
      "损失函数： 0.0268048\n",
      "时间步 6391000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.336617e+01/ 轮得分 399.33\n",
      "损失函数： 0.0373096\n",
      "时间步 6392000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.420877e+01/ 轮得分 399.33\n",
      "损失函数： 0.0242766\n",
      "时间步 6393000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.120440e+01/ 轮得分 399.41\n",
      "损失函数： 0.0132937\n",
      "时间步 6394000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361084e+01/ 轮得分 399.41\n",
      "损失函数： 0.0521911\n",
      "时间步 6395000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271095e+01/ 轮得分 399.41\n",
      "损失函数： 0.0124098\n",
      "时间步 6396000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.502453e+01/ 轮得分 399.41\n",
      "损失函数： 0.0199518\n",
      "时间步 6397000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196441e+01/ 轮得分 399.70\n",
      "损失函数： 0.0213911\n",
      "时间步 6398000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338122e+01/ 轮得分 399.70\n",
      "损失函数： 0.00729411\n",
      "时间步 6399000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320491e+01/ 轮得分 399.70\n",
      "损失函数： 0.0116076\n",
      "时间步 6400000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205570e+01/ 轮得分 399.70\n",
      "损失函数： 0.0132647\n",
      "时间步 6401000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213670e+01/ 轮得分 399.70\n",
      "损失函数： 0.0573741\n",
      "时间步 6402000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.105311e+01/ 轮得分 399.70\n",
      "损失函数： 0.0165067\n",
      "时间步 6403000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342677e+01/ 轮得分 400.24\n",
      "损失函数： 0.0243265\n",
      "时间步 6404000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.439124e+01/ 轮得分 400.24\n",
      "损失函数： 0.0372628\n",
      "时间步 6405000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.144844e+01/ 轮得分 400.24\n",
      "损失函数： 0.0141139\n",
      "时间步 6406000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372412e+01/ 轮得分 400.24\n",
      "损失函数： 0.0366375\n",
      "时间步 6407000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.136139e+01/ 轮得分 400.58\n",
      "损失函数： 0.0623366\n",
      "时间步 6408000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364345e+01/ 轮得分 400.58\n",
      "损失函数： 0.0190052\n",
      "时间步 6409000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248384e+01/ 轮得分 400.58\n",
      "损失函数： 0.0197658\n",
      "时间步 6410000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.214078e+01/ 轮得分 400.58\n",
      "损失函数： 0.0284818\n",
      "时间步 6411000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 5.490107e+00/ 轮得分 400.58\n",
      "损失函数： 0.00977958\n",
      "时间步 6412000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339755e+01/ 轮得分 400.73\n",
      "损失函数： 0.0279732\n",
      "时间步 6413000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302281e+01/ 轮得分 400.73\n",
      "损失函数： 0.0397992\n",
      "时间步 6414000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245399e+01/ 轮得分 400.73\n",
      "损失函数： 0.0111944\n",
      "时间步 6415000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.336496e+01/ 轮得分 400.73\n",
      "损失函数： 0.0322097\n",
      "时间步 6416000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244692e+01/ 轮得分 400.73\n",
      "损失函数： 0.0137464\n",
      "时间步 6417000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321769e+01/ 轮得分 400.66\n",
      "损失函数： 0.0310552\n",
      "时间步 6418000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.498214e+01/ 轮得分 400.66\n",
      "损失函数： 0.0197573\n",
      "时间步 6419000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.132924e+01/ 轮得分 400.66\n",
      "损失函数： 0.0116902\n",
      "时间步 6420000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269771e+01/ 轮得分 400.21\n",
      "损失函数： 0.0326062\n",
      "时间步 6421000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215922e+01/ 轮得分 400.21\n",
      "损失函数： 0.056429\n",
      "时间步 6422000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.135897e+01/ 轮得分 400.28\n",
      "损失函数： 0.0193836\n",
      "时间步 6423000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.511657e+01/ 轮得分 400.28\n",
      "损失函数： 0.0255583\n",
      "时间步 6424000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193416e+01/ 轮得分 400.28\n",
      "损失函数： 0.0247991\n",
      "时间步 6425000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259288e+01/ 轮得分 400.28\n",
      "损失函数： 0.0214735\n",
      "时间步 6426000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308084e+01/ 轮得分 400.61\n",
      "损失函数： 0.0282524\n",
      "时间步 6427000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.071657e+01/ 轮得分 400.61\n",
      "损失函数： 0.0408736\n",
      "时间步 6428000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.138196e+01/ 轮得分 400.66\n",
      "损失函数： 0.0397252\n",
      "时间步 6429000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319394e+01/ 轮得分 400.66\n",
      "损失函数： 0.0257911\n",
      "时间步 6430000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.468423e+01/ 轮得分 400.66\n",
      "损失函数： 0.0591082\n",
      "时间步 6431000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393213e+01/ 轮得分 400.60\n",
      "损失函数： 0.043429\n",
      "时间步 6432000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.382617e+01/ 轮得分 400.60\n",
      "损失函数： 0.0257096\n",
      "时间步 6433000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.433196e+01/ 轮得分 400.60\n",
      "损失函数： 0.0283265\n",
      "时间步 6434000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.240759e+01/ 轮得分 400.60\n",
      "损失函数： 0.0420517\n",
      "时间步 6435000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.453105e+01/ 轮得分 400.60\n",
      "损失函数： 0.0809661\n",
      "时间步 6436000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347486e+01/ 轮得分 400.60\n",
      "损失函数： 0.0282117\n",
      "时间步 6437000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212201e+01/ 轮得分 400.60\n",
      "损失函数： 0.0418844\n",
      "时间步 6438000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.143633e+01/ 轮得分 401.22\n",
      "损失函数： 0.0342898\n",
      "时间步 6439000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385663e+01/ 轮得分 401.22\n",
      "损失函数： 0.0324526\n",
      "时间步 6440000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.301458e+01/ 轮得分 401.22\n",
      "损失函数： 0.0404314\n",
      "时间步 6441000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415603e+01/ 轮得分 401.22\n",
      "损失函数： 0.0543419\n",
      "时间步 6442000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238948e+01/ 轮得分 401.22\n",
      "损失函数： 0.0383021\n",
      "时间步 6443000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.148784e+01/ 轮得分 401.50\n",
      "损失函数： 0.0293054\n",
      "时间步 6444000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.197004e+01/ 轮得分 401.50\n",
      "损失函数： 0.0173963\n",
      "时间步 6445000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.127102e+01/ 轮得分 401.50\n",
      "损失函数： 0.0401823\n",
      "时间步 6446000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280458e+01/ 轮得分 401.50\n",
      "损失函数： 0.0274323\n",
      "时间步 6447000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.158387e+01/ 轮得分 401.50\n",
      "损失函数： 0.0899628\n",
      "时间步 6448000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341361e+01/ 轮得分 401.50\n",
      "损失函数： 0.0563434\n",
      "时间步 6449000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.570139e+01/ 轮得分 401.50\n",
      "损失函数： 0.0426036\n",
      "时间步 6450000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254786e+01/ 轮得分 402.11\n",
      "损失函数： 0.0207557\n",
      "时间步 6451000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447643e+01/ 轮得分 402.11\n",
      "损失函数： 0.0185708\n",
      "时间步 6452000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224761e+01/ 轮得分 402.11\n",
      "损失函数： 0.0296913\n",
      "时间步 6453000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.154649e+01/ 轮得分 402.11\n",
      "损失函数： 0.112835\n",
      "时间步 6454000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186573e+01/ 轮得分 402.11\n",
      "损失函数： 0.0229566\n",
      "时间步 6455000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376341e+01/ 轮得分 402.11\n",
      "损失函数： 0.0347372\n",
      "时间步 6456000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220877e+01/ 轮得分 402.11\n",
      "损失函数： 0.0229737\n",
      "时间步 6457000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.435166e+01/ 轮得分 402.11\n",
      "损失函数： 0.0315963\n",
      "时间步 6458000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332762e+01/ 轮得分 402.11\n",
      "损失函数： 0.0285171\n",
      "时间步 6459000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.503363e+01/ 轮得分 403.02\n",
      "损失函数： 0.0316901\n",
      "时间步 6460000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233237e+01/ 轮得分 403.02\n",
      "损失函数： 0.0499583\n",
      "时间步 6461000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.576118e+01/ 轮得分 403.02\n",
      "损失函数： 0.0439968\n",
      "时间步 6462000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376186e+01/ 轮得分 403.08\n",
      "损失函数： 0.0443464\n",
      "时间步 6463000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250585e+01/ 轮得分 402.85\n",
      "损失函数： 0.0306341\n",
      "时间步 6464000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254488e+01/ 轮得分 402.85\n",
      "损失函数： 0.0360869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6465000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.050878e+01/ 轮得分 402.85\n",
      "损失函数： 0.0677557\n",
      "时间步 6466000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.435119e+01/ 轮得分 402.85\n",
      "损失函数： 0.0800644\n",
      "时间步 6467000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183118e+01/ 轮得分 402.85\n",
      "损失函数： 0.254723\n",
      "时间步 6468000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225852e+01/ 轮得分 403.23\n",
      "损失函数： 0.0226227\n",
      "时间步 6469000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.498169e+01/ 轮得分 403.23\n",
      "损失函数： 0.0167122\n",
      "时间步 6470000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.380686e+01/ 轮得分 403.06\n",
      "损失函数： 0.0187766\n",
      "时间步 6471000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.517508e+01/ 轮得分 403.06\n",
      "损失函数： 0.0197767\n",
      "时间步 6472000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320228e+01/ 轮得分 403.06\n",
      "损失函数： 0.175463\n",
      "时间步 6473000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.199834e+01/ 轮得分 403.06\n",
      "损失函数： 0.0300524\n",
      "时间步 6474000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.416315e+01/ 轮得分 403.06\n",
      "损失函数： 0.0975248\n",
      "时间步 6475000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117248e+01/ 轮得分 402.60\n",
      "损失函数： 0.0190611\n",
      "时间步 6476000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377847e+01/ 轮得分 402.54\n",
      "损失函数： 0.0384535\n",
      "时间步 6477000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183750e+01/ 轮得分 402.54\n",
      "损失函数： 0.0177236\n",
      "时间步 6478000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328373e+01/ 轮得分 402.54\n",
      "损失函数： 0.0473757\n",
      "时间步 6479000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261272e+01/ 轮得分 402.54\n",
      "损失函数： 0.0305159\n",
      "时间步 6480000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.376876e+01/ 轮得分 402.54\n",
      "损失函数： 0.0511088\n",
      "时间步 6481000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237313e+01/ 轮得分 402.86\n",
      "损失函数： 0.0125297\n",
      "时间步 6482000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329271e+01/ 轮得分 402.63\n",
      "损失函数： 0.00997884\n",
      "时间步 6483000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268138e+01/ 轮得分 402.63\n",
      "损失函数： 0.026011\n",
      "时间步 6484000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.095237e+01/ 轮得分 402.63\n",
      "损失函数： 0.0291913\n",
      "时间步 6485000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251862e+01/ 轮得分 402.63\n",
      "损失函数： 0.0240127\n",
      "时间步 6486000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.156097e+01/ 轮得分 402.63\n",
      "损失函数： 0.0334093\n",
      "时间步 6487000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.168329e+01/ 轮得分 402.63\n",
      "损失函数： 0.0835084\n",
      "时间步 6488000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295700e+01/ 轮得分 402.63\n",
      "损失函数： 0.0153221\n",
      "时间步 6489000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187869e+01/ 轮得分 403.26\n",
      "损失函数： 0.0221718\n",
      "时间步 6490000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.169776e+01/ 轮得分 403.26\n",
      "损失函数： 1.00505\n",
      "时间步 6491000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.128705e+01/ 轮得分 403.26\n",
      "损失函数： 0.0333882\n",
      "时间步 6492000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357857e+01/ 轮得分 403.26\n",
      "损失函数： 0.0490829\n",
      "时间步 6493000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.363994e+01/ 轮得分 403.26\n",
      "损失函数： 0.0361708\n",
      "时间步 6494000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310692e+01/ 轮得分 403.26\n",
      "损失函数： 0.0445158\n",
      "时间步 6495000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412716e+01/ 轮得分 403.26\n",
      "损失函数： 0.0338462\n",
      "时间步 6496000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185567e+01/ 轮得分 403.26\n",
      "损失函数： 0.00706181\n",
      "时间步 6497000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.135497e+01/ 轮得分 404.07\n",
      "损失函数： 0.0990647\n",
      "时间步 6498000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377474e+01/ 轮得分 404.10\n",
      "损失函数： 0.0564338\n",
      "时间步 6499000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364543e+01/ 轮得分 404.10\n",
      "损失函数： 0.0859278\n",
      "时间步 6500000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.141913e+01/ 轮得分 404.10\n",
      "损失函数： 0.0352153\n",
      "时间步 6501000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.096936e+01/ 轮得分 404.10\n",
      "损失函数： 0.0190666\n",
      "时间步 6502000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300598e+01/ 轮得分 404.10\n",
      "损失函数： 0.0338714\n",
      "时间步 6503000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.406485e+01/ 轮得分 404.10\n",
      "损失函数： 0.0150368\n",
      "时间步 6504000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194030e+01/ 轮得分 404.10\n",
      "损失函数： 0.0114425\n",
      "时间步 6505000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345588e+01/ 轮得分 404.10\n",
      "损失函数： 0.0244367\n",
      "时间步 6506000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227017e+01/ 轮得分 404.21\n",
      "损失函数： 0.0256481\n",
      "时间步 6507000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310440e+01/ 轮得分 403.98\n",
      "损失函数： 0.0202824\n",
      "时间步 6508000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292633e+01/ 轮得分 403.98\n",
      "损失函数： 0.020044\n",
      "时间步 6509000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261034e+01/ 轮得分 403.98\n",
      "损失函数： 0.0261131\n",
      "时间步 6510000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.341041e+01/ 轮得分 403.98\n",
      "损失函数： 0.0216774\n",
      "时间步 6511000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363201e+01/ 轮得分 403.98\n",
      "损失函数： 0.0217101\n",
      "时间步 6512000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.225141e+01/ 轮得分 403.98\n",
      "损失函数： 0.0474497\n",
      "时间步 6513000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251258e+01/ 轮得分 403.98\n",
      "损失函数： 0.037627\n",
      "时间步 6514000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.386038e+01/ 轮得分 403.98\n",
      "损失函数： 0.0117604\n",
      "时间步 6515000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.460004e+01/ 轮得分 403.60\n",
      "损失函数： 0.0155836\n",
      "时间步 6516000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228301e+01/ 轮得分 403.60\n",
      "损失函数： 0.0139623\n",
      "时间步 6517000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180958e+01/ 轮得分 403.22\n",
      "损失函数： 0.0251095\n",
      "时间步 6518000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277944e+01/ 轮得分 403.22\n",
      "损失函数： 0.0230744\n",
      "时间步 6519000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.449248e+01/ 轮得分 403.22\n",
      "损失函数： 0.0203049\n",
      "时间步 6520000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.280123e+01/ 轮得分 403.22\n",
      "损失函数： 0.029984\n",
      "时间步 6521000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.168124e+01/ 轮得分 403.22\n",
      "损失函数： 0.0501949\n",
      "时间步 6522000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252445e+01/ 轮得分 403.22\n",
      "损失函数： 0.415932\n",
      "时间步 6523000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.531499e+01/ 轮得分 403.63\n",
      "损失函数： 0.0286626\n",
      "时间步 6524000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216842e+01/ 轮得分 403.63\n",
      "损失函数： 0.0309703\n",
      "时间步 6525000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246818e+01/ 轮得分 403.63\n",
      "损失函数： 0.0309952\n",
      "时间步 6526000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295122e+01/ 轮得分 403.63\n",
      "损失函数： 0.0170441\n",
      "时间步 6527000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343794e+01/ 轮得分 403.63\n",
      "损失函数： 0.0338143\n",
      "时间步 6528000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.430966e+01/ 轮得分 403.63\n",
      "损失函数： 0.0138687\n",
      "时间步 6529000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293477e+01/ 轮得分 403.63\n",
      "损失函数： 0.0207756\n",
      "时间步 6530000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335713e+01/ 轮得分 403.63\n",
      "损失函数： 0.0244904\n",
      "时间步 6531000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306809e+01/ 轮得分 403.63\n",
      "损失函数： 0.0352226\n",
      "时间步 6532000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229522e+01/ 轮得分 403.63\n",
      "损失函数： 0.0290583\n",
      "时间步 6533000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.361436e+01/ 轮得分 404.37\n",
      "损失函数： 0.0159058\n",
      "时间步 6534000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 9.761317e+00/ 轮得分 404.37\n",
      "损失函数： 0.0197587\n",
      "时间步 6535000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.155390e+01/ 轮得分 404.37\n",
      "损失函数： 0.0457143\n",
      "时间步 6536000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323908e+01/ 轮得分 404.37\n",
      "损失函数： 0.0489643\n",
      "时间步 6537000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341399e+01/ 轮得分 404.74\n",
      "损失函数： 0.0615668\n",
      "时间步 6538000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375749e+01/ 轮得分 404.74\n",
      "损失函数： 0.0203708\n",
      "时间步 6539000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.302862e+01/ 轮得分 404.74\n",
      "损失函数： 0.0876041\n",
      "时间步 6540000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.140524e+01/ 轮得分 404.67\n",
      "损失函数： 0.0252638\n",
      "时间步 6541000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246147e+01/ 轮得分 404.67\n",
      "损失函数： 0.0179797\n",
      "时间步 6542000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299427e+01/ 轮得分 404.67\n",
      "损失函数： 0.0187229\n",
      "时间步 6543000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414896e+01/ 轮得分 404.67\n",
      "损失函数： 0.0374065\n",
      "时间步 6544000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.437065e+01/ 轮得分 404.67\n",
      "损失函数： 0.0441226\n",
      "时间步 6545000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448261e+01/ 轮得分 404.67\n",
      "损失函数： 0.0737566\n",
      "时间步 6546000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.397121e+01/ 轮得分 404.67\n",
      "损失函数： 0.0470772\n",
      "时间步 6547000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.241105e+01/ 轮得分 405.42\n",
      "损失函数： 0.0359589\n",
      "时间步 6548000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365762e+01/ 轮得分 405.42\n",
      "损失函数： 0.0369412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6549000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.054410e+01/ 轮得分 404.67\n",
      "损失函数： 0.0757802\n",
      "时间步 6550000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.597506e+01/ 轮得分 403.79\n",
      "损失函数： 0.0524952\n",
      "时间步 6551000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.152033e+01/ 轮得分 403.79\n",
      "损失函数： 0.0397997\n",
      "时间步 6552000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180040e+01/ 轮得分 403.79\n",
      "损失函数： 0.0353245\n",
      "时间步 6553000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.182242e+01/ 轮得分 403.79\n",
      "损失函数： 0.041242\n",
      "时间步 6554000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225910e+01/ 轮得分 403.76\n",
      "损失函数： 0.0631915\n",
      "时间步 6555000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.462718e+01/ 轮得分 403.76\n",
      "损失函数： 0.0277768\n",
      "时间步 6556000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194849e+01/ 轮得分 403.57\n",
      "损失函数： 0.0202795\n",
      "时间步 6557000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258514e+01/ 轮得分 403.57\n",
      "损失函数： 0.0591929\n",
      "时间步 6558000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412200e+01/ 轮得分 403.57\n",
      "损失函数： 0.009143\n",
      "时间步 6559000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.040504e+01/ 轮得分 403.70\n",
      "损失函数： 0.0271811\n",
      "时间步 6560000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267074e+01/ 轮得分 403.70\n",
      "损失函数： 0.0450314\n",
      "时间步 6561000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.175772e+01/ 轮得分 403.44\n",
      "损失函数： 0.0072515\n",
      "时间步 6562000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.450846e+01/ 轮得分 403.44\n",
      "损失函数： 0.0479842\n",
      "时间步 6563000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.346876e+01/ 轮得分 403.44\n",
      "损失函数： 0.0278795\n",
      "时间步 6564000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186752e+01/ 轮得分 403.13\n",
      "损失函数： 0.0233286\n",
      "时间步 6565000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315435e+01/ 轮得分 403.13\n",
      "损失函数： 0.0174851\n",
      "时间步 6566000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.157916e+01/ 轮得分 403.13\n",
      "损失函数： 0.00688486\n",
      "时间步 6567000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269076e+01/ 轮得分 403.13\n",
      "损失函数： 0.0437065\n",
      "时间步 6568000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.220680e+01/ 轮得分 403.13\n",
      "损失函数： 0.0212866\n",
      "时间步 6569000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.260268e+01/ 轮得分 403.13\n",
      "损失函数： 0.050227\n",
      "时间步 6570000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.468836e+01/ 轮得分 403.13\n",
      "损失函数： 0.0128044\n",
      "时间步 6571000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190886e+01/ 轮得分 403.13\n",
      "损失函数： 0.0606045\n",
      "时间步 6572000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314103e+01/ 轮得分 403.89\n",
      "损失函数： 0.0204085\n",
      "时间步 6573000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.440877e+01/ 轮得分 403.89\n",
      "损失函数： 0.0496631\n",
      "时间步 6574000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.237124e+01/ 轮得分 403.89\n",
      "损失函数： 0.0712155\n",
      "时间步 6575000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262842e+01/ 轮得分 403.89\n",
      "损失函数： 0.0376916\n",
      "时间步 6576000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356145e+01/ 轮得分 403.89\n",
      "损失函数： 0.015226\n",
      "时间步 6577000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.218412e+01/ 轮得分 403.89\n",
      "损失函数： 0.0131281\n",
      "时间步 6578000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362358e+01/ 轮得分 403.89\n",
      "损失函数： 0.0340697\n",
      "时间步 6579000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.317655e+01/ 轮得分 404.36\n",
      "损失函数： 0.0136608\n",
      "时间步 6580000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321797e+01/ 轮得分 404.13\n",
      "损失函数： 0.0131713\n",
      "时间步 6581000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.325868e+01/ 轮得分 403.94\n",
      "损失函数： 0.0377668\n",
      "时间步 6582000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.200892e+01/ 轮得分 403.94\n",
      "损失函数： 0.114727\n",
      "时间步 6583000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.135404e+01/ 轮得分 403.94\n",
      "损失函数： 0.0263819\n",
      "时间步 6584000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260215e+01/ 轮得分 404.32\n",
      "损失函数： 0.0197978\n",
      "时间步 6585000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277282e+01/ 轮得分 404.32\n",
      "损失函数： 0.0362043\n",
      "时间步 6586000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.405742e+01/ 轮得分 404.32\n",
      "损失函数： 0.0400188\n",
      "时间步 6587000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.169372e+01/ 轮得分 404.32\n",
      "损失函数： 0.0482594\n",
      "时间步 6588000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.392463e+01/ 轮得分 404.35\n",
      "损失函数： 0.0102239\n",
      "时间步 6589000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196397e+01/ 轮得分 404.35\n",
      "损失函数： 0.0386322\n",
      "时间步 6590000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189436e+01/ 轮得分 404.35\n",
      "损失函数： 0.0411967\n",
      "时间步 6591000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332989e+01/ 轮得分 404.56\n",
      "损失函数： 0.0518228\n",
      "时间步 6592000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.495314e+01/ 轮得分 403.77\n",
      "损失函数： 0.0127276\n",
      "时间步 6593000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.327742e+01/ 轮得分 403.77\n",
      "损失函数： 0.0246778\n",
      "时间步 6594000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.675435e+01/ 轮得分 403.77\n",
      "损失函数： 0.0260194\n",
      "时间步 6595000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.398742e+01/ 轮得分 403.54\n",
      "损失函数： 0.0701182\n",
      "时间步 6596000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295848e+01/ 轮得分 403.54\n",
      "损失函数： 0.233327\n",
      "时间步 6597000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.237667e+01/ 轮得分 403.54\n",
      "损失函数： 0.0244753\n",
      "时间步 6598000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331648e+01/ 轮得分 403.54\n",
      "损失函数： 0.0240394\n",
      "时间步 6599000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301041e+01/ 轮得分 403.54\n",
      "损失函数： 0.090604\n",
      "时间步 6600000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.330597e+01/ 轮得分 403.54\n",
      "损失函数： 0.0761893\n",
      "时间步 6601000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318693e+01/ 轮得分 403.54\n",
      "损失函数： 0.0367046\n",
      "时间步 6602000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.435005e+01/ 轮得分 403.54\n",
      "损失函数： 0.0449649\n",
      "时间步 6603000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.151175e+01/ 轮得分 404.21\n",
      "损失函数： 0.0319709\n",
      "时间步 6604000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.473265e+01/ 轮得分 404.21\n",
      "损失函数： 0.0318356\n",
      "时间步 6605000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.403447e+01/ 轮得分 404.21\n",
      "损失函数： 0.0289387\n",
      "时间步 6606000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278689e+01/ 轮得分 404.21\n",
      "损失函数： 0.0245505\n",
      "时间步 6607000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.345716e+01/ 轮得分 404.21\n",
      "损失函数： 0.0499745\n",
      "时间步 6608000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.129757e+01/ 轮得分 404.77\n",
      "损失函数： 0.0248352\n",
      "时间步 6609000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322868e+01/ 轮得分 404.77\n",
      "损失函数： 0.0401407\n",
      "时间步 6610000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334550e+01/ 轮得分 404.62\n",
      "损失函数： 0.0277785\n",
      "时间步 6611000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.152423e+01/ 轮得分 404.62\n",
      "损失函数： 0.026511\n",
      "时间步 6612000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316357e+01/ 轮得分 404.62\n",
      "损失函数： 0.149458\n",
      "时间步 6613000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296384e+01/ 轮得分 404.62\n",
      "损失函数： 0.0525567\n",
      "时间步 6614000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.479568e+01/ 轮得分 404.62\n",
      "损失函数： 0.00899988\n",
      "时间步 6615000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.409717e+01/ 轮得分 404.62\n",
      "损失函数： 0.0142161\n",
      "时间步 6616000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313729e+01/ 轮得分 404.62\n",
      "损失函数： 0.0315154\n",
      "时间步 6617000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.455310e+01/ 轮得分 404.62\n",
      "损失函数： 0.0389816\n",
      "时间步 6618000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.356437e+01/ 轮得分 404.62\n",
      "损失函数： 1.46682\n",
      "时间步 6619000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411529e+01/ 轮得分 404.62\n",
      "损失函数： 0.0116546\n",
      "时间步 6620000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296016e+01/ 轮得分 404.62\n",
      "损失函数： 0.0706545\n",
      "时间步 6621000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205633e+01/ 轮得分 404.62\n",
      "损失函数： 0.0199042\n",
      "时间步 6622000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202961e+01/ 轮得分 404.62\n",
      "损失函数： 0.0247525\n",
      "时间步 6623000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.374754e+01/ 轮得分 404.62\n",
      "损失函数： 0.0153332\n",
      "时间步 6624000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197167e+01/ 轮得分 406.21\n",
      "损失函数： 0.019654\n",
      "时间步 6625000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293194e+01/ 轮得分 406.21\n",
      "损失函数： 0.0640655\n",
      "时间步 6626000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.444436e+01/ 轮得分 406.21\n",
      "损失函数： 0.0506062\n",
      "时间步 6627000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249030e+01/ 轮得分 406.21\n",
      "损失函数： 0.00832665\n",
      "时间步 6628000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159448e+01/ 轮得分 406.21\n",
      "损失函数： 0.0306598\n",
      "时间步 6629000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264217e+01/ 轮得分 406.21\n",
      "损失函数： 0.0779588\n",
      "时间步 6630000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286617e+01/ 轮得分 406.21\n",
      "损失函数： 0.0290423\n",
      "时间步 6631000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290650e+01/ 轮得分 406.21\n",
      "损失函数： 0.0112832\n",
      "时间步 6632000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.429929e+01/ 轮得分 406.89\n",
      "损失函数： 0.0310642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6633000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284092e+01/ 轮得分 406.89\n",
      "损失函数： 0.0496383\n",
      "时间步 6634000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337142e+01/ 轮得分 406.65\n",
      "损失函数： 0.021784\n",
      "时间步 6635000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329471e+01/ 轮得分 406.65\n",
      "损失函数： 0.0179243\n",
      "时间步 6636000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293626e+01/ 轮得分 406.65\n",
      "损失函数： 0.0166957\n",
      "时间步 6637000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181729e+01/ 轮得分 406.65\n",
      "损失函数： 0.032304\n",
      "时间步 6638000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342132e+01/ 轮得分 406.65\n",
      "损失函数： 0.0167286\n",
      "时间步 6639000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.288956e+01/ 轮得分 406.65\n",
      "损失函数： 0.0315465\n",
      "时间步 6640000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189505e+01/ 轮得分 406.65\n",
      "损失函数： 0.00822364\n",
      "时间步 6641000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.392864e+01/ 轮得分 406.65\n",
      "损失函数： 0.0625017\n",
      "时间步 6642000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411523e+01/ 轮得分 406.65\n",
      "损失函数： 0.023248\n",
      "时间步 6643000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.144508e+01/ 轮得分 406.65\n",
      "损失函数： 0.0168649\n",
      "时间步 6644000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.521379e+01/ 轮得分 406.65\n",
      "损失函数： 0.0175967\n",
      "时间步 6645000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.307190e+01/ 轮得分 407.63\n",
      "损失函数： 0.0201861\n",
      "时间步 6646000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.320688e+01/ 轮得分 407.63\n",
      "损失函数： 0.0774486\n",
      "时间步 6647000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.137322e+01/ 轮得分 407.60\n",
      "损失函数： 0.0386822\n",
      "时间步 6648000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216762e+01/ 轮得分 407.60\n",
      "损失函数： 0.0226282\n",
      "时间步 6649000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.055405e+01/ 轮得分 407.60\n",
      "损失函数： 0.0118626\n",
      "时间步 6650000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262515e+01/ 轮得分 407.71\n",
      "损失函数： 0.0196954\n",
      "时间步 6651000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.383813e+01/ 轮得分 407.71\n",
      "损失函数： 0.0126093\n",
      "时间步 6652000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.535128e+01/ 轮得分 407.71\n",
      "损失函数： 0.0600771\n",
      "时间步 6653000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266547e+01/ 轮得分 407.71\n",
      "损失函数： 0.0156572\n",
      "时间步 6654000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.372866e+01/ 轮得分 408.22\n",
      "损失函数： 0.0317505\n",
      "时间步 6655000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.403184e+01/ 轮得分 408.22\n",
      "损失函数： 0.0829952\n",
      "时间步 6656000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.361352e+01/ 轮得分 408.12\n",
      "损失函数： 0.0467573\n",
      "时间步 6657000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.121625e+01/ 轮得分 408.12\n",
      "损失函数： 0.0567715\n",
      "时间步 6658000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312320e+01/ 轮得分 408.12\n",
      "损失函数： 0.0131036\n",
      "时间步 6659000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305403e+01/ 轮得分 406.87\n",
      "损失函数： 0.0287049\n",
      "时间步 6660000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.217753e+01/ 轮得分 406.87\n",
      "损失函数： 0.016297\n",
      "时间步 6661000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359299e+01/ 轮得分 406.11\n",
      "损失函数： 0.00813553\n",
      "时间步 6662000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261750e+01/ 轮得分 406.11\n",
      "损失函数： 0.0155835\n",
      "时间步 6663000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343706e+01/ 轮得分 406.11\n",
      "损失函数： 0.0276498\n",
      "时间步 6664000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210126e+01/ 轮得分 405.13\n",
      "损失函数： 0.00735619\n",
      "时间步 6665000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331003e+01/ 轮得分 405.13\n",
      "损失函数： 0.0189218\n",
      "时间步 6666000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251900e+01/ 轮得分 404.75\n",
      "损失函数： 0.0185333\n",
      "时间步 6667000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.129551e+01/ 轮得分 404.65\n",
      "损失函数： 0.0831251\n",
      "时间步 6668000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.396009e+01/ 轮得分 404.60\n",
      "损失函数： 0.0211334\n",
      "时间步 6669000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221170e+01/ 轮得分 404.60\n",
      "损失函数： 0.0393876\n",
      "时间步 6670000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330904e+01/ 轮得分 404.60\n",
      "损失函数： 0.0230166\n",
      "时间步 6671000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318124e+01/ 轮得分 404.60\n",
      "损失函数： 0.0222763\n",
      "时间步 6672000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249657e+01/ 轮得分 404.60\n",
      "损失函数： 0.0167642\n",
      "时间步 6673000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.145836e+01/ 轮得分 404.60\n",
      "损失函数： 0.00663189\n",
      "时间步 6674000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.195921e+01/ 轮得分 404.60\n",
      "损失函数： 0.0314583\n",
      "时间步 6675000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.451506e+01/ 轮得分 404.60\n",
      "损失函数： 0.029528\n",
      "时间步 6676000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276930e+01/ 轮得分 404.60\n",
      "损失函数： 0.0295242\n",
      "时间步 6677000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.259975e+01/ 轮得分 405.67\n",
      "损失函数： 0.0266616\n",
      "时间步 6678000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.209255e+01/ 轮得分 405.54\n",
      "损失函数： 0.0097643\n",
      "时间步 6679000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230283e+01/ 轮得分 405.54\n",
      "损失函数： 0.0627541\n",
      "时间步 6680000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274943e+01/ 轮得分 405.54\n",
      "损失函数： 0.0789656\n",
      "时间步 6681000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332904e+01/ 轮得分 405.54\n",
      "损失函数： 0.0109302\n",
      "时间步 6682000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.218837e+01/ 轮得分 405.54\n",
      "损失函数： 0.0187607\n",
      "时间步 6683000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.379117e+01/ 轮得分 405.99\n",
      "损失函数： 0.0334237\n",
      "时间步 6684000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.303071e+01/ 轮得分 405.99\n",
      "损失函数： 0.0115521\n",
      "时间步 6685000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391848e+01/ 轮得分 406.10\n",
      "损失函数： 0.0682905\n",
      "时间步 6686000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305104e+01/ 轮得分 406.10\n",
      "损失函数： 0.0346366\n",
      "时间步 6687000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.344380e+01/ 轮得分 406.10\n",
      "损失函数： 0.0224421\n",
      "时间步 6688000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407973e+01/ 轮得分 406.10\n",
      "损失函数： 0.0206663\n",
      "时间步 6689000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.313977e+01/ 轮得分 406.45\n",
      "损失函数： 0.0148988\n",
      "时间步 6690000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.435380e+01/ 轮得分 406.35\n",
      "损失函数： 0.0546299\n",
      "时间步 6691000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355478e+01/ 轮得分 406.46\n",
      "损失函数： 0.056265\n",
      "时间步 6692000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212326e+01/ 轮得分 406.14\n",
      "损失函数： 0.0259958\n",
      "时间步 6693000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335781e+01/ 轮得分 406.14\n",
      "损失函数： 0.0310834\n",
      "时间步 6694000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244873e+01/ 轮得分 406.14\n",
      "损失函数： 0.0876643\n",
      "时间步 6695000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198428e+01/ 轮得分 406.14\n",
      "损失函数： 0.0486106\n",
      "时间步 6696000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314721e+01/ 轮得分 406.14\n",
      "损失函数： 0.0235246\n",
      "时间步 6697000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.417437e+01/ 轮得分 406.14\n",
      "损失函数： 0.0282699\n",
      "时间步 6698000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285138e+01/ 轮得分 406.72\n",
      "损失函数： 0.039932\n",
      "时间步 6699000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389314e+01/ 轮得分 406.72\n",
      "损失函数： 0.0314032\n",
      "时间步 6700000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284454e+01/ 轮得分 406.92\n",
      "损失函数： 0.0305367\n",
      "时间步 6701000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.078974e+01/ 轮得分 406.76\n",
      "损失函数： 0.0229789\n",
      "时间步 6702000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258642e+01/ 轮得分 406.76\n",
      "损失函数： 0.0383499\n",
      "时间步 6703000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.520485e+01/ 轮得分 406.73\n",
      "损失函数： 0.124189\n",
      "时间步 6704000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159040e+01/ 轮得分 406.69\n",
      "损失函数： 0.0264778\n",
      "时间步 6705000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411005e+01/ 轮得分 406.56\n",
      "损失函数： 0.0192236\n",
      "时间步 6706000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212843e+01/ 轮得分 405.73\n",
      "损失函数： 0.0250613\n",
      "时间步 6707000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384573e+01/ 轮得分 405.73\n",
      "损失函数： 0.0857289\n",
      "时间步 6708000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227464e+01/ 轮得分 405.73\n",
      "损失函数： 0.036487\n",
      "时间步 6709000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207843e+01/ 轮得分 405.35\n",
      "损失函数： 0.0425862\n",
      "时间步 6710000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266361e+01/ 轮得分 404.84\n",
      "损失函数： 0.0656593\n",
      "时间步 6711000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226706e+01/ 轮得分 404.84\n",
      "损失函数： 0.0169647\n",
      "时间步 6712000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192525e+01/ 轮得分 404.84\n",
      "损失函数： 0.0115818\n",
      "时间步 6713000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268567e+01/ 轮得分 404.28\n",
      "损失函数： 0.0206991\n",
      "时间步 6714000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.525102e+01/ 轮得分 404.28\n",
      "损失函数： 0.0630742\n",
      "时间步 6715000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352306e+01/ 轮得分 404.28\n",
      "损失函数： 0.0180183\n",
      "时间步 6716000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365222e+01/ 轮得分 404.53\n",
      "损失函数： 0.0371072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6717000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289811e+01/ 轮得分 404.53\n",
      "损失函数： 0.040559\n",
      "时间步 6718000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.661088e+01/ 轮得分 404.53\n",
      "损失函数： 0.0555541\n",
      "时间步 6719000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377203e+01/ 轮得分 404.53\n",
      "损失函数： 0.0758298\n",
      "时间步 6720000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.549715e+01/ 轮得分 404.53\n",
      "损失函数： 0.0560985\n",
      "时间步 6721000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276865e+01/ 轮得分 404.53\n",
      "损失函数： 0.119482\n",
      "时间步 6722000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375635e+01/ 轮得分 404.53\n",
      "损失函数： 0.0458428\n",
      "时间步 6723000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367549e+01/ 轮得分 404.53\n",
      "损失函数： 0.0833804\n",
      "时间步 6724000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.455527e+01/ 轮得分 404.53\n",
      "损失函数： 0.0571893\n",
      "时间步 6725000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262179e+01/ 轮得分 404.53\n",
      "损失函数： 0.0391976\n",
      "时间步 6726000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.381811e+01/ 轮得分 405.67\n",
      "损失函数： 0.0261438\n",
      "时间步 6727000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279989e+01/ 轮得分 405.67\n",
      "损失函数： 0.00990676\n",
      "时间步 6728000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317568e+01/ 轮得分 405.67\n",
      "损失函数： 0.0686724\n",
      "时间步 6729000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.385329e+01/ 轮得分 405.67\n",
      "损失函数： 0.0264045\n",
      "时间步 6730000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357808e+01/ 轮得分 405.67\n",
      "损失函数： 0.0317864\n",
      "时间步 6731000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272991e+01/ 轮得分 405.84\n",
      "损失函数： 0.0209185\n",
      "时间步 6732000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335923e+01/ 轮得分 405.84\n",
      "损失函数： 0.0171318\n",
      "时间步 6733000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.523199e+01/ 轮得分 405.84\n",
      "损失函数： 0.0482861\n",
      "时间步 6734000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281397e+01/ 轮得分 405.84\n",
      "损失函数： 0.0531529\n",
      "时间步 6735000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.283314e+01/ 轮得分 405.84\n",
      "损失函数： 0.0289901\n",
      "时间步 6736000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.340655e+01/ 轮得分 405.84\n",
      "损失函数： 0.0186935\n",
      "时间步 6737000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338176e+01/ 轮得分 406.22\n",
      "损失函数： 0.0607865\n",
      "时间步 6738000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.421094e+01/ 轮得分 406.22\n",
      "损失函数： 0.0332317\n",
      "时间步 6739000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.436478e+01/ 轮得分 406.22\n",
      "损失函数： 0.0182057\n",
      "时间步 6740000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.569733e+01/ 轮得分 406.22\n",
      "损失函数： 0.0386732\n",
      "时间步 6741000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.291954e+01/ 轮得分 406.22\n",
      "损失函数： 0.0389045\n",
      "时间步 6742000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265114e+01/ 轮得分 406.22\n",
      "损失函数： 0.0140553\n",
      "时间步 6743000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343545e+01/ 轮得分 406.86\n",
      "损失函数： 0.0486755\n",
      "时间步 6744000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161715e+01/ 轮得分 406.86\n",
      "损失函数： 0.0749386\n",
      "时间步 6745000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.166834e+01/ 轮得分 406.03\n",
      "损失函数： 1.01072\n",
      "时间步 6746000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.232304e+01/ 轮得分 406.03\n",
      "损失函数： 0.0198626\n",
      "时间步 6747000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.539038e+00/ 轮得分 406.03\n",
      "损失函数： 0.0145049\n",
      "时间步 6748000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.358514e+01/ 轮得分 406.03\n",
      "损失函数： 0.0229755\n",
      "时间步 6749000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344308e+01/ 轮得分 406.03\n",
      "损失函数： 0.0255458\n",
      "时间步 6750000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283923e+01/ 轮得分 406.03\n",
      "损失函数： 0.0118229\n",
      "时间步 6751000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.429665e+01/ 轮得分 406.03\n",
      "损失函数： 0.0452658\n",
      "时间步 6752000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.398178e+01/ 轮得分 406.03\n",
      "损失函数： 0.185153\n",
      "时间步 6753000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.513233e+01/ 轮得分 406.03\n",
      "损失函数： 0.058871\n",
      "时间步 6754000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352641e+01/ 轮得分 406.32\n",
      "损失函数： 0.0328621\n",
      "时间步 6755000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269041e+01/ 轮得分 406.32\n",
      "损失函数： 0.0257159\n",
      "时间步 6756000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.471680e+01/ 轮得分 406.32\n",
      "损失函数： 0.0215104\n",
      "时间步 6757000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227348e+01/ 轮得分 406.32\n",
      "损失函数： 0.0405458\n",
      "时间步 6758000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289810e+01/ 轮得分 406.32\n",
      "损失函数： 0.0182951\n",
      "时间步 6759000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.224905e+01/ 轮得分 406.81\n",
      "损失函数： 0.0172786\n",
      "时间步 6760000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340877e+01/ 轮得分 406.80\n",
      "损失函数： 0.0316433\n",
      "时间步 6761000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309116e+01/ 轮得分 406.80\n",
      "损失函数： 0.0337096\n",
      "时间步 6762000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 -1/ Q_MAX 3.642803e-01/ 轮得分 406.92\n",
      "损失函数： 0.0200144\n",
      "时间步 6763000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284321e+01/ 轮得分 406.92\n",
      "损失函数： 0.0883329\n",
      "时间步 6764000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362943e+01/ 轮得分 406.92\n",
      "损失函数： 0.0098954\n",
      "时间步 6765000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.370910e+01/ 轮得分 406.92\n",
      "损失函数： 0.0197649\n",
      "时间步 6766000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.358028e+01/ 轮得分 406.92\n",
      "损失函数： 0.0332445\n",
      "时间步 6767000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.361710e+01/ 轮得分 406.92\n",
      "损失函数： 0.0749805\n",
      "时间步 6768000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.459749e+01/ 轮得分 406.92\n",
      "损失函数： 0.0283583\n",
      "时间步 6769000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254782e+01/ 轮得分 406.92\n",
      "损失函数： 0.0162013\n",
      "时间步 6770000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198318e+01/ 轮得分 407.81\n",
      "损失函数： 0.0246326\n",
      "时间步 6771000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226766e+01/ 轮得分 407.81\n",
      "损失函数： 0.0185314\n",
      "时间步 6772000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354072e+01/ 轮得分 407.81\n",
      "损失函数： 0.035263\n",
      "时间步 6773000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277176e+01/ 轮得分 407.74\n",
      "损失函数： 0.0275429\n",
      "时间步 6774000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347767e+01/ 轮得分 407.46\n",
      "损失函数： 0.0175446\n",
      "时间步 6775000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378084e+01/ 轮得分 407.46\n",
      "损失函数： 0.018524\n",
      "时间步 6776000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.239042e+01/ 轮得分 407.41\n",
      "损失函数： 0.0162886\n",
      "时间步 6777000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293316e+01/ 轮得分 407.41\n",
      "损失函数： 0.042569\n",
      "时间步 6778000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223756e+01/ 轮得分 407.23\n",
      "损失函数： 0.028492\n",
      "时间步 6779000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.200603e+01/ 轮得分 407.23\n",
      "损失函数： 0.0866328\n",
      "时间步 6780000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.270768e+01/ 轮得分 407.23\n",
      "损失函数： 0.0503236\n",
      "时间步 6781000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360579e+01/ 轮得分 407.23\n",
      "损失函数： 0.0441341\n",
      "时间步 6782000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307588e+01/ 轮得分 407.23\n",
      "损失函数： 0.0425567\n",
      "时间步 6783000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264247e+01/ 轮得分 407.63\n",
      "损失函数： 0.059477\n",
      "时间步 6784000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383146e+01/ 轮得分 407.63\n",
      "损失函数： 0.0431187\n",
      "时间步 6785000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.629237e+01/ 轮得分 407.63\n",
      "损失函数： 0.0484675\n",
      "时间步 6786000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162292e+01/ 轮得分 407.63\n",
      "损失函数： 0.0161859\n",
      "时间步 6787000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260165e+01/ 轮得分 407.63\n",
      "损失函数： 0.0347549\n",
      "时间步 6788000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280395e+01/ 轮得分 407.63\n",
      "损失函数： 0.0300712\n",
      "时间步 6789000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.346671e+01/ 轮得分 407.93\n",
      "损失函数： 0.024989\n",
      "时间步 6790000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.401173e+01/ 轮得分 407.93\n",
      "损失函数： 0.0469913\n",
      "时间步 6791000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385559e+01/ 轮得分 407.93\n",
      "损失函数： 0.0908597\n",
      "时间步 6792000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364566e+01/ 轮得分 407.93\n",
      "损失函数： 0.0293392\n",
      "时间步 6793000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.533157e+01/ 轮得分 407.93\n",
      "损失函数： 0.0491242\n",
      "时间步 6794000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235355e+01/ 轮得分 407.93\n",
      "损失函数： 0.0492907\n",
      "时间步 6795000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383773e+01/ 轮得分 408.20\n",
      "损失函数： 0.0353896\n",
      "时间步 6796000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.302239e+01/ 轮得分 408.20\n",
      "损失函数： 0.016406\n",
      "时间步 6797000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347790e+01/ 轮得分 408.20\n",
      "损失函数： 0.0204635\n",
      "时间步 6798000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.320725e+01/ 轮得分 408.20\n",
      "损失函数： 0.0166807\n",
      "时间步 6799000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190659e+01/ 轮得分 408.20\n",
      "损失函数： 0.0141033\n",
      "时间步 6800000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.486522e+01/ 轮得分 408.20\n",
      "损失函数： 0.021449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6801000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.243415e+01/ 轮得分 408.11\n",
      "损失函数： 0.0301128\n",
      "时间步 6802000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385991e+01/ 轮得分 408.11\n",
      "损失函数： 0.018498\n",
      "时间步 6803000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.466791e+01/ 轮得分 408.11\n",
      "损失函数： 0.0337331\n",
      "时间步 6804000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.752574e+00/ 轮得分 408.11\n",
      "损失函数： 0.0175967\n",
      "时间步 6805000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354766e+01/ 轮得分 408.11\n",
      "损失函数： 0.0190539\n",
      "时间步 6806000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.153823e+01/ 轮得分 408.11\n",
      "损失函数： 0.0416859\n",
      "时间步 6807000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289750e+01/ 轮得分 408.11\n",
      "损失函数： 0.020343\n",
      "时间步 6808000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.622146e+01/ 轮得分 408.11\n",
      "损失函数： 0.0596254\n",
      "时间步 6809000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191205e+01/ 轮得分 408.11\n",
      "损失函数： 0.0203701\n",
      "时间步 6810000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309129e+01/ 轮得分 408.11\n",
      "损失函数： 0.0503485\n",
      "时间步 6811000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.551178e+01/ 轮得分 409.29\n",
      "损失函数： 0.0199949\n",
      "时间步 6812000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332665e+01/ 轮得分 409.29\n",
      "损失函数： 0.0218288\n",
      "时间步 6813000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281054e+01/ 轮得分 409.29\n",
      "损失函数： 0.0213401\n",
      "时间步 6814000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343664e+01/ 轮得分 409.29\n",
      "损失函数： 0.0174452\n",
      "时间步 6815000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249760e+01/ 轮得分 409.78\n",
      "损失函数： 0.0638998\n",
      "时间步 6816000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207445e+01/ 轮得分 409.78\n",
      "损失函数： 0.035954\n",
      "时间步 6817000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216194e+01/ 轮得分 409.78\n",
      "损失函数： 0.0403386\n",
      "时间步 6818000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246657e+01/ 轮得分 409.78\n",
      "损失函数： 0.0274637\n",
      "时间步 6819000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287440e+01/ 轮得分 409.78\n",
      "损失函数： 0.0532871\n",
      "时间步 6820000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359181e+01/ 轮得分 409.78\n",
      "损失函数： 0.0226263\n",
      "时间步 6821000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255344e+01/ 轮得分 409.78\n",
      "损失函数： 0.00644272\n",
      "时间步 6822000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.371017e+01/ 轮得分 409.78\n",
      "损失函数： 0.0272001\n",
      "时间步 6823000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177771e+01/ 轮得分 410.76\n",
      "损失函数： 0.0279389\n",
      "时间步 6824000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281873e+01/ 轮得分 410.76\n",
      "损失函数： 0.0252674\n",
      "时间步 6825000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181868e+01/ 轮得分 410.76\n",
      "损失函数： 0.0435444\n",
      "时间步 6826000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280935e+01/ 轮得分 410.76\n",
      "损失函数： 0.00990297\n",
      "时间步 6827000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.115000e+01/ 轮得分 410.76\n",
      "损失函数： 0.0526833\n",
      "时间步 6828000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351392e+01/ 轮得分 410.76\n",
      "损失函数： 0.0187568\n",
      "时间步 6829000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159043e+01/ 轮得分 410.76\n",
      "损失函数： 0.0268007\n",
      "时间步 6830000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352177e+01/ 轮得分 410.76\n",
      "损失函数： 0.0971539\n",
      "时间步 6831000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.127466e+01/ 轮得分 410.76\n",
      "损失函数： 0.0439959\n",
      "时间步 6832000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310295e+01/ 轮得分 410.76\n",
      "损失函数： 0.0448856\n",
      "时间步 6833000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.132855e+01/ 轮得分 411.98\n",
      "损失函数： 0.0183164\n",
      "时间步 6834000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356721e+01/ 轮得分 411.98\n",
      "损失函数： 0.0125447\n",
      "时间步 6835000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322420e+01/ 轮得分 411.98\n",
      "损失函数： 0.01043\n",
      "时间步 6836000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264935e+01/ 轮得分 411.98\n",
      "损失函数： 0.853415\n",
      "时间步 6837000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191906e+01/ 轮得分 411.98\n",
      "损失函数： 0.0286271\n",
      "时间步 6838000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266016e+01/ 轮得分 411.98\n",
      "损失函数： 0.0257208\n",
      "时间步 6839000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412975e+01/ 轮得分 411.98\n",
      "损失函数： 0.0288943\n",
      "时间步 6840000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335727e+01/ 轮得分 411.98\n",
      "损失函数： 0.0267871\n",
      "时间步 6841000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.199515e+01/ 轮得分 411.98\n",
      "损失函数： 0.0264561\n",
      "时间步 6842000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356676e+01/ 轮得分 411.98\n",
      "损失函数： 0.0298335\n",
      "时间步 6843000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117009e+01/ 轮得分 412.70\n",
      "损失函数： 0.0112925\n",
      "时间步 6844000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246333e+01/ 轮得分 412.70\n",
      "损失函数： 0.0250905\n",
      "时间步 6845000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.164092e+01/ 轮得分 412.70\n",
      "损失函数： 0.0298177\n",
      "时间步 6846000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213831e+01/ 轮得分 412.70\n",
      "损失函数： 0.0105598\n",
      "时间步 6847000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.195303e+01/ 轮得分 412.70\n",
      "损失函数： 0.0287255\n",
      "时间步 6848000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.279664e+01/ 轮得分 412.70\n",
      "损失函数： 0.019105\n",
      "时间步 6849000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.465490e+01/ 轮得分 412.70\n",
      "损失函数： 0.0093327\n",
      "时间步 6850000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.150496e+01/ 轮得分 412.70\n",
      "损失函数： 0.01233\n",
      "时间步 6851000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333542e+01/ 轮得分 412.70\n",
      "损失函数： 0.0148142\n",
      "时间步 6852000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.114938e+01/ 轮得分 412.70\n",
      "损失函数： 0.0312875\n",
      "时间步 6853000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.153046e+01/ 轮得分 412.70\n",
      "损失函数： 0.0271778\n",
      "时间步 6854000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.122300e+01/ 轮得分 413.14\n",
      "损失函数： 0.0216183\n",
      "时间步 6855000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255870e+01/ 轮得分 412.62\n",
      "损失函数： 0.0299156\n",
      "时间步 6856000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343414e+01/ 轮得分 412.72\n",
      "损失函数： 0.0279868\n",
      "时间步 6857000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220072e+01/ 轮得分 412.72\n",
      "损失函数： 0.0171573\n",
      "时间步 6858000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185628e+01/ 轮得分 412.72\n",
      "损失函数： 0.0136361\n",
      "时间步 6859000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.140372e+01/ 轮得分 412.98\n",
      "损失函数： 0.0389779\n",
      "时间步 6860000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.183490e+01/ 轮得分 412.98\n",
      "损失函数： 0.0251308\n",
      "时间步 6861000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.314841e+01/ 轮得分 412.98\n",
      "损失函数： 0.0306677\n",
      "时间步 6862000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.350797e+01/ 轮得分 412.98\n",
      "损失函数： 0.0169604\n",
      "时间步 6863000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.405725e+01/ 轮得分 412.98\n",
      "损失函数： 0.0287142\n",
      "时间步 6864000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.109529e+01/ 轮得分 412.98\n",
      "损失函数： 0.0539295\n",
      "时间步 6865000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388448e+01/ 轮得分 412.98\n",
      "损失函数： 0.0566898\n",
      "时间步 6866000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186067e+01/ 轮得分 412.98\n",
      "损失函数： 0.0129317\n",
      "时间步 6867000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344520e+01/ 轮得分 412.98\n",
      "损失函数： 0.0327005\n",
      "时间步 6868000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.115197e+01/ 轮得分 412.98\n",
      "损失函数： 0.0174621\n",
      "时间步 6869000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.506788e+01/ 轮得分 412.98\n",
      "损失函数： 0.0195284\n",
      "时间步 6870000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.457483e+01/ 轮得分 412.98\n",
      "损失函数： 0.0208769\n",
      "时间步 6871000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294571e+01/ 轮得分 412.98\n",
      "损失函数： 0.0320821\n",
      "时间步 6872000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346852e+01/ 轮得分 412.98\n",
      "损失函数： 0.013023\n",
      "时间步 6873000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.525345e+01/ 轮得分 412.98\n",
      "损失函数： 0.0133012\n",
      "时间步 6874000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.194057e+01/ 轮得分 414.32\n",
      "损失函数： 0.0167044\n",
      "时间步 6875000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210693e+01/ 轮得分 414.32\n",
      "损失函数： 0.0147884\n",
      "时间步 6876000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360780e+01/ 轮得分 414.32\n",
      "损失函数： 0.021857\n",
      "时间步 6877000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256237e+01/ 轮得分 414.38\n",
      "损失函数： 0.0231547\n",
      "时间步 6878000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159579e+01/ 轮得分 414.38\n",
      "损失函数： 0.0203864\n",
      "时间步 6879000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236695e+01/ 轮得分 414.38\n",
      "损失函数： 0.0109143\n",
      "时间步 6880000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251680e+01/ 轮得分 414.38\n",
      "损失函数： 0.029989\n",
      "时间步 6881000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.206191e+01/ 轮得分 414.33\n",
      "损失函数： 0.0190457\n",
      "时间步 6882000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.156734e+01/ 轮得分 413.49\n",
      "损失函数： 0.020908\n",
      "时间步 6883000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203027e+01/ 轮得分 413.49\n",
      "损失函数： 0.0728056\n",
      "时间步 6884000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.148623e+01/ 轮得分 413.45\n",
      "损失函数： 0.0150628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6885000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254982e+01/ 轮得分 412.93\n",
      "损失函数： 0.0157992\n",
      "时间步 6886000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360081e+01/ 轮得分 412.93\n",
      "损失函数： 0.0449202\n",
      "时间步 6887000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285329e+01/ 轮得分 412.93\n",
      "损失函数： 0.00800544\n",
      "时间步 6888000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.377424e+01/ 轮得分 412.93\n",
      "损失函数： 0.0324668\n",
      "时间步 6889000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204040e+01/ 轮得分 412.93\n",
      "损失函数： 0.0129206\n",
      "时间步 6890000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299205e+01/ 轮得分 412.93\n",
      "损失函数： 0.0195288\n",
      "时间步 6891000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223845e+01/ 轮得分 412.93\n",
      "损失函数： 0.0205013\n",
      "时间步 6892000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244254e+01/ 轮得分 412.93\n",
      "损失函数： 0.0418479\n",
      "时间步 6893000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294806e+01/ 轮得分 412.09\n",
      "损失函数： 0.0107642\n",
      "时间步 6894000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329422e+01/ 轮得分 412.09\n",
      "损失函数： 0.0635123\n",
      "时间步 6895000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283012e+01/ 轮得分 412.09\n",
      "损失函数： 0.0830966\n",
      "时间步 6896000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.410394e+01/ 轮得分 412.09\n",
      "损失函数： 0.0374433\n",
      "时间步 6897000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196842e+01/ 轮得分 412.09\n",
      "损失函数： 0.0300765\n",
      "时间步 6898000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447566e+01/ 轮得分 412.09\n",
      "损失函数： 0.00819703\n",
      "时间步 6899000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260444e+01/ 轮得分 412.09\n",
      "损失函数： 0.0544499\n",
      "时间步 6900000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.589393e+01/ 轮得分 412.09\n",
      "损失函数： 0.080884\n",
      "时间步 6901000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.256342e+01/ 轮得分 412.09\n",
      "损失函数： 0.0478622\n",
      "时间步 6902000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387021e+01/ 轮得分 412.09\n",
      "损失函数： 0.0378481\n",
      "时间步 6903000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415241e+01/ 轮得分 412.09\n",
      "损失函数： 0.0294992\n",
      "时间步 6904000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.496349e+01/ 轮得分 413.03\n",
      "损失函数： 0.035718\n",
      "时间步 6905000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.503984e+01/ 轮得分 413.03\n",
      "损失函数： 0.0449079\n",
      "时间步 6906000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.346346e+01/ 轮得分 413.03\n",
      "损失函数： 0.03121\n",
      "时间步 6907000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.415334e+01/ 轮得分 413.03\n",
      "损失函数： 0.0255418\n",
      "时间步 6908000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.087499e+01/ 轮得分 413.03\n",
      "损失函数： 0.0457929\n",
      "时间步 6909000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.252006e+01/ 轮得分 413.38\n",
      "损失函数： 0.0376475\n",
      "时间步 6910000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279643e+01/ 轮得分 413.38\n",
      "损失函数： 0.0106941\n",
      "时间步 6911000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260739e+01/ 轮得分 413.38\n",
      "损失函数： 0.0274615\n",
      "时间步 6912000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312743e+01/ 轮得分 413.30\n",
      "损失函数： 0.0490321\n",
      "时间步 6913000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235993e+01/ 轮得分 413.30\n",
      "损失函数： 0.0133449\n",
      "时间步 6914000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337666e+01/ 轮得分 413.40\n",
      "损失函数： 0.0261419\n",
      "时间步 6915000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.105910e+01/ 轮得分 412.97\n",
      "损失函数： 0.00779082\n",
      "时间步 6916000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213125e+01/ 轮得分 412.97\n",
      "损失函数： 0.0362706\n",
      "时间步 6917000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.259628e+01/ 轮得分 412.97\n",
      "损失函数： 0.0380996\n",
      "时间步 6918000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.214480e+01/ 轮得分 412.79\n",
      "损失函数： 0.0135053\n",
      "时间步 6919000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314307e+01/ 轮得分 412.79\n",
      "损失函数： 0.0809326\n",
      "时间步 6920000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245416e+01/ 轮得分 412.79\n",
      "损失函数： 0.0229907\n",
      "时间步 6921000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223611e+01/ 轮得分 412.79\n",
      "损失函数： 0.0246201\n",
      "时间步 6922000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256079e+01/ 轮得分 412.79\n",
      "损失函数： 0.0522463\n",
      "时间步 6923000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.371869e+01/ 轮得分 412.79\n",
      "损失函数： 0.0391528\n",
      "时间步 6924000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364167e+01/ 轮得分 412.79\n",
      "损失函数： 0.00626134\n",
      "时间步 6925000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361928e+01/ 轮得分 413.29\n",
      "损失函数： 0.0157154\n",
      "时间步 6926000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183628e+01/ 轮得分 413.29\n",
      "损失函数： 0.0266972\n",
      "时间步 6927000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216294e+01/ 轮得分 412.03\n",
      "损失函数： 0.0144038\n",
      "时间步 6928000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.280845e+01/ 轮得分 411.54\n",
      "损失函数： 0.0144927\n",
      "时间步 6929000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303873e+01/ 轮得分 411.54\n",
      "损失函数： 0.00750171\n",
      "时间步 6930000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268886e+01/ 轮得分 411.54\n",
      "损失函数： 0.0145492\n",
      "时间步 6931000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236101e+01/ 轮得分 411.54\n",
      "损失函数： 0.026536\n",
      "时间步 6932000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.317562e+01/ 轮得分 411.54\n",
      "损失函数： 0.116621\n",
      "时间步 6933000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263835e+01/ 轮得分 411.54\n",
      "损失函数： 0.0301849\n",
      "时间步 6934000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254140e+01/ 轮得分 411.54\n",
      "损失函数： 0.0162967\n",
      "时间步 6935000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423493e+01/ 轮得分 411.54\n",
      "损失函数： 0.00657265\n",
      "时间步 6936000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327203e+01/ 轮得分 411.54\n",
      "损失函数： 0.0216073\n",
      "时间步 6937000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298821e+01/ 轮得分 411.54\n",
      "损失函数： 0.0180736\n",
      "时间步 6938000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.478238e+01/ 轮得分 411.54\n",
      "损失函数： 0.103648\n",
      "时间步 6939000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.433527e+01/ 轮得分 412.63\n",
      "损失函数： 0.0247049\n",
      "时间步 6940000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248511e+01/ 轮得分 412.63\n",
      "损失函数： 0.0350911\n",
      "时间步 6941000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287152e+01/ 轮得分 412.63\n",
      "损失函数： 0.020336\n",
      "时间步 6942000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.157460e+01/ 轮得分 412.63\n",
      "损失函数： 0.0217338\n",
      "时间步 6943000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.295252e+01/ 轮得分 412.63\n",
      "损失函数： 0.0121643\n",
      "时间步 6944000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271020e+01/ 轮得分 412.86\n",
      "损失函数： 0.0226451\n",
      "时间步 6945000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.167861e+01/ 轮得分 412.95\n",
      "损失函数： 0.0212364\n",
      "时间步 6946000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415715e+01/ 轮得分 412.45\n",
      "损失函数： 0.0121519\n",
      "时间步 6947000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.464935e+01/ 轮得分 412.22\n",
      "损失函数： 0.0232167\n",
      "时间步 6948000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258237e+01/ 轮得分 412.22\n",
      "损失函数： 0.0571814\n",
      "时间步 6949000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396481e+01/ 轮得分 412.22\n",
      "损失函数： 0.0671053\n",
      "时间步 6950000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181489e+01/ 轮得分 412.47\n",
      "损失函数： 0.0162387\n",
      "时间步 6951000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.473188e+01/ 轮得分 411.81\n",
      "损失函数： 0.0296071\n",
      "时间步 6952000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.418439e+01/ 轮得分 411.81\n",
      "损失函数： 0.0301295\n",
      "时间步 6953000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207633e+01/ 轮得分 411.81\n",
      "损失函数： 0.00928071\n",
      "时间步 6954000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.397978e+01/ 轮得分 411.81\n",
      "损失函数： 0.0147824\n",
      "时间步 6955000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180017e+01/ 轮得分 411.81\n",
      "损失函数： 0.0616704\n",
      "时间步 6956000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362493e+01/ 轮得分 411.81\n",
      "损失函数： 0.150983\n",
      "时间步 6957000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.174226e+01/ 轮得分 412.22\n",
      "损失函数： 0.0309303\n",
      "时间步 6958000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302064e+01/ 轮得分 412.22\n",
      "损失函数： 0.015723\n",
      "时间步 6959000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.379726e+01/ 轮得分 412.22\n",
      "损失函数： 0.0163338\n",
      "时间步 6960000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256495e+01/ 轮得分 412.41\n",
      "损失函数： 0.0219343\n",
      "时间步 6961000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194481e+01/ 轮得分 412.41\n",
      "损失函数： 0.0108337\n",
      "时间步 6962000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 2.440602e+00/ 轮得分 412.41\n",
      "损失函数： 0.0703509\n",
      "时间步 6963000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.419279e+01/ 轮得分 411.75\n",
      "损失函数： 0.118572\n",
      "时间步 6964000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117202e+01/ 轮得分 411.75\n",
      "损失函数： 0.0184026\n",
      "时间步 6965000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312295e+01/ 轮得分 411.75\n",
      "损失函数： 0.0145032\n",
      "时间步 6966000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339416e+01/ 轮得分 412.13\n",
      "损失函数： 0.0397196\n",
      "时间步 6967000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.357600e+01/ 轮得分 412.14\n",
      "损失函数： 0.0217458\n",
      "时间步 6968000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.280676e+01/ 轮得分 412.14\n",
      "损失函数： 0.037026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 6969000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223405e+01/ 轮得分 412.14\n",
      "损失函数： 0.0662477\n",
      "时间步 6970000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.488803e+01/ 轮得分 412.14\n",
      "损失函数： 0.0171665\n",
      "时间步 6971000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.265806e+01/ 轮得分 412.14\n",
      "损失函数： 0.48898\n",
      "时间步 6972000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.209408e+01/ 轮得分 412.14\n",
      "损失函数： 0.0450854\n",
      "时间步 6973000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324918e+01/ 轮得分 412.14\n",
      "损失函数： 0.0346925\n",
      "时间步 6974000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.410219e+01/ 轮得分 412.14\n",
      "损失函数： 0.0206242\n",
      "时间步 6975000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.121277e+01/ 轮得分 412.44\n",
      "损失函数： 0.0350004\n",
      "时间步 6976000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.359130e+01/ 轮得分 412.31\n",
      "损失函数： 0.0447629\n",
      "时间步 6977000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.511253e+01/ 轮得分 412.25\n",
      "损失函数： 0.0329749\n",
      "时间步 6978000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201950e+01/ 轮得分 412.25\n",
      "损失函数： 0.0304199\n",
      "时间步 6979000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328533e+01/ 轮得分 412.25\n",
      "损失函数： 0.0100515\n",
      "时间步 6980000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301966e+01/ 轮得分 412.25\n",
      "损失函数： 0.0610377\n",
      "时间步 6981000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215088e+01/ 轮得分 412.25\n",
      "损失函数： 0.0327773\n",
      "时间步 6982000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 6.013473e+00/ 轮得分 412.25\n",
      "损失函数： 0.0160789\n",
      "时间步 6983000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362742e+01/ 轮得分 412.91\n",
      "损失函数： 0.0263092\n",
      "时间步 6984000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.358035e+01/ 轮得分 412.91\n",
      "损失函数： 0.0762624\n",
      "时间步 6985000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.410089e+01/ 轮得分 412.91\n",
      "损失函数： 0.046661\n",
      "时间步 6986000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292788e+01/ 轮得分 412.91\n",
      "损失函数： 0.0349934\n",
      "时间步 6987000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279451e+01/ 轮得分 412.91\n",
      "损失函数： 0.0212564\n",
      "时间步 6988000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257586e+01/ 轮得分 412.91\n",
      "损失函数： 0.03669\n",
      "时间步 6989000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302253e+01/ 轮得分 412.91\n",
      "损失函数： 0.0202055\n",
      "时间步 6990000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307297e+01/ 轮得分 412.91\n",
      "损失函数： 0.079365\n",
      "时间步 6991000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.294167e+01/ 轮得分 412.91\n",
      "损失函数： 0.0350087\n",
      "时间步 6992000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.207036e+01/ 轮得分 412.91\n",
      "损失函数： 0.0175691\n",
      "时间步 6993000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 9.235791e+00/ 轮得分 412.91\n",
      "损失函数： 0.153175\n",
      "时间步 6994000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220866e+01/ 轮得分 414.06\n",
      "损失函数： 0.0170591\n",
      "时间步 6995000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275080e+01/ 轮得分 413.65\n",
      "损失函数： 0.0234492\n",
      "时间步 6996000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.548965e+01/ 轮得分 413.65\n",
      "损失函数： 0.0270053\n",
      "时间步 6997000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.213929e+01/ 轮得分 413.65\n",
      "损失函数： 0.00567188\n",
      "时间步 6998000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.353855e+01/ 轮得分 413.65\n",
      "损失函数： 0.0142051\n",
      "时间步 6999000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.140431e+01/ 轮得分 414.02\n",
      "损失函数： 0.0259737\n",
      "时间步 7000000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.512113e+01/ 轮得分 414.02\n",
      "损失函数： 0.0216899\n",
      "时间步 7001000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161730e+01/ 轮得分 414.02\n",
      "损失函数： 0.0191813\n",
      "时间步 7002000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.331369e+01/ 轮得分 414.02\n",
      "损失函数： 0.0592167\n",
      "时间步 7003000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183848e+01/ 轮得分 414.02\n",
      "损失函数： 0.0168167\n",
      "时间步 7004000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250726e+01/ 轮得分 413.52\n",
      "损失函数： 0.0166769\n",
      "时间步 7005000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319387e+01/ 轮得分 413.52\n",
      "损失函数： 0.0339932\n",
      "时间步 7006000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.506246e+01/ 轮得分 413.52\n",
      "损失函数： 0.00912942\n",
      "时间步 7007000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216900e+01/ 轮得分 413.68\n",
      "损失函数： 0.0126357\n",
      "时间步 7008000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356956e+01/ 轮得分 413.68\n",
      "损失函数： 0.0112498\n",
      "时间步 7009000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.485469e+01/ 轮得分 413.68\n",
      "损失函数： 0.00849681\n",
      "时间步 7010000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297065e+01/ 轮得分 413.68\n",
      "损失函数： 0.0329037\n",
      "时间步 7011000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.312918e+01/ 轮得分 413.68\n",
      "损失函数： 0.0140202\n",
      "时间步 7012000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.166972e+01/ 轮得分 413.68\n",
      "损失函数： 0.0151092\n",
      "时间步 7013000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317091e+01/ 轮得分 413.68\n",
      "损失函数： 0.0214585\n",
      "时间步 7014000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347643e+01/ 轮得分 413.68\n",
      "损失函数： 0.0322239\n",
      "时间步 7015000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229749e+01/ 轮得分 413.68\n",
      "损失函数： 0.0141916\n",
      "时间步 7016000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387499e+01/ 轮得分 413.68\n",
      "损失函数： 0.0327923\n",
      "时间步 7017000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259998e+01/ 轮得分 413.68\n",
      "损失函数： 0.0104959\n",
      "时间步 7018000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231709e+01/ 轮得分 413.68\n",
      "损失函数： 0.00891415\n",
      "时间步 7019000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341413e+01/ 轮得分 415.03\n",
      "损失函数： 0.0436758\n",
      "时间步 7020000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279334e+01/ 轮得分 415.03\n",
      "损失函数： 0.0504573\n",
      "时间步 7021000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322660e+01/ 轮得分 415.03\n",
      "损失函数： 0.0625051\n",
      "时间步 7022000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.209284e+01/ 轮得分 415.03\n",
      "损失函数： 0.033515\n",
      "时间步 7023000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201784e+01/ 轮得分 415.03\n",
      "损失函数： 0.0221784\n",
      "时间步 7024000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229646e+01/ 轮得分 415.03\n",
      "损失函数： 0.0511653\n",
      "时间步 7025000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210735e+01/ 轮得分 415.34\n",
      "损失函数： 0.016607\n",
      "时间步 7026000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248810e+01/ 轮得分 415.34\n",
      "损失函数： 0.0433919\n",
      "时间步 7027000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.253508e+01/ 轮得分 415.34\n",
      "损失函数： 0.0592377\n",
      "时间步 7028000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277156e+01/ 轮得分 415.46\n",
      "损失函数： 0.0525094\n",
      "时间步 7029000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235384e+01/ 轮得分 415.46\n",
      "损失函数： 0.0223342\n",
      "时间步 7030000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.124452e+01/ 轮得分 415.46\n",
      "损失函数： 0.0357498\n",
      "时间步 7031000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.121015e+01/ 轮得分 415.80\n",
      "损失函数： 0.0318387\n",
      "时间步 7032000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.151396e+01/ 轮得分 415.80\n",
      "损失函数： 0.0342686\n",
      "时间步 7033000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.123097e+01/ 轮得分 415.80\n",
      "损失函数： 0.0199403\n",
      "时间步 7034000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.121751e+01/ 轮得分 415.85\n",
      "损失函数： 0.0297258\n",
      "时间步 7035000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309381e+01/ 轮得分 415.85\n",
      "损失函数： 0.0125301\n",
      "时间步 7036000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.072220e+01/ 轮得分 415.85\n",
      "损失函数： 0.0292374\n",
      "时间步 7037000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285079e+01/ 轮得分 415.85\n",
      "损失函数： 0.0115045\n",
      "时间步 7038000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257525e+01/ 轮得分 415.85\n",
      "损失函数： 0.00984584\n",
      "时间步 7039000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373425e+01/ 轮得分 415.85\n",
      "损失函数： 0.0332844\n",
      "时间步 7040000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278718e+01/ 轮得分 416.23\n",
      "损失函数： 0.0298826\n",
      "时间步 7041000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281538e+01/ 轮得分 415.53\n",
      "损失函数： 0.0260567\n",
      "时间步 7042000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254444e+01/ 轮得分 415.53\n",
      "损失函数： 0.114515\n",
      "时间步 7043000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 9.030440e+00/ 轮得分 415.53\n",
      "损失函数： 0.0397513\n",
      "时间步 7044000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294954e+01/ 轮得分 414.75\n",
      "损失函数： 0.0202717\n",
      "时间步 7045000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245687e+01/ 轮得分 414.75\n",
      "损失函数： 0.0422293\n",
      "时间步 7046000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.426761e+01/ 轮得分 414.75\n",
      "损失函数： 0.0195926\n",
      "时间步 7047000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287175e+01/ 轮得分 414.75\n",
      "损失函数： 0.02893\n",
      "时间步 7048000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.353109e+01/ 轮得分 414.75\n",
      "损失函数： 0.042245\n",
      "时间步 7049000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366347e+01/ 轮得分 414.75\n",
      "损失函数： 0.037821\n",
      "时间步 7050000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236314e+01/ 轮得分 414.75\n",
      "损失函数： 0.0510829\n",
      "时间步 7051000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227079e+01/ 轮得分 415.28\n",
      "损失函数： 0.0483668\n",
      "时间步 7052000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.410503e+01/ 轮得分 415.28\n",
      "损失函数： 0.0173646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7053000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418412e+01/ 轮得分 415.28\n",
      "损失函数： 0.013679\n",
      "时间步 7054000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340929e+01/ 轮得分 415.28\n",
      "损失函数： 0.0519686\n",
      "时间步 7055000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.411077e+01/ 轮得分 415.28\n",
      "损失函数： 0.0600503\n",
      "时间步 7056000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.472304e+01/ 轮得分 415.79\n",
      "损失函数： 0.0214211\n",
      "时间步 7057000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.154132e+01/ 轮得分 415.79\n",
      "损失函数： 0.034348\n",
      "时间步 7058000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377732e+01/ 轮得分 415.79\n",
      "损失函数： 0.0220106\n",
      "时间步 7059000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388669e+01/ 轮得分 415.79\n",
      "损失函数： 0.029248\n",
      "时间步 7060000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362012e+01/ 轮得分 416.21\n",
      "损失函数： 0.022073\n",
      "时间步 7061000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273216e+01/ 轮得分 416.21\n",
      "损失函数： 0.0347369\n",
      "时间步 7062000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242427e+01/ 轮得分 416.44\n",
      "损失函数： 0.00925095\n",
      "时间步 7063000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345815e+01/ 轮得分 416.44\n",
      "损失函数： 0.0510209\n",
      "时间步 7064000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331041e+01/ 轮得分 416.44\n",
      "损失函数： 0.0400636\n",
      "时间步 7065000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.489438e+01/ 轮得分 416.44\n",
      "损失函数： 0.0167894\n",
      "时间步 7066000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230701e+01/ 轮得分 416.44\n",
      "损失函数： 0.0148329\n",
      "时间步 7067000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165611e+01/ 轮得分 416.73\n",
      "损失函数： 0.0271113\n",
      "时间步 7068000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235822e+01/ 轮得分 416.73\n",
      "损失函数： 0.0307466\n",
      "时间步 7069000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237745e+01/ 轮得分 416.73\n",
      "损失函数： 0.0180454\n",
      "时间步 7070000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303817e+01/ 轮得分 416.73\n",
      "损失函数： 0.00968933\n",
      "时间步 7071000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.404615e+01/ 轮得分 416.73\n",
      "损失函数： 0.0272469\n",
      "时间步 7072000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342223e+01/ 轮得分 416.73\n",
      "损失函数： 0.0299535\n",
      "时间步 7073000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326036e+01/ 轮得分 417.01\n",
      "损失函数： 0.0218118\n",
      "时间步 7074000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203469e+01/ 轮得分 416.84\n",
      "损失函数： 0.0225617\n",
      "时间步 7075000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271746e+01/ 轮得分 416.84\n",
      "损失函数： 0.042661\n",
      "时间步 7076000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.247437e+01/ 轮得分 416.84\n",
      "损失函数： 0.0184347\n",
      "时间步 7077000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.173254e+01/ 轮得分 417.17\n",
      "损失函数： 0.0765295\n",
      "时间步 7078000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319314e+01/ 轮得分 417.17\n",
      "损失函数： 0.052412\n",
      "时间步 7079000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250948e+01/ 轮得分 417.17\n",
      "损失函数： 0.0209359\n",
      "时间步 7080000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.420619e+01/ 轮得分 417.17\n",
      "损失函数： 0.0116246\n",
      "时间步 7081000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238170e+01/ 轮得分 417.27\n",
      "损失函数： 0.0366574\n",
      "时间步 7082000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376680e+01/ 轮得分 417.33\n",
      "损失函数： 0.0397979\n",
      "时间步 7083000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.157320e+01/ 轮得分 417.33\n",
      "损失函数： 0.0135245\n",
      "时间步 7084000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288540e+01/ 轮得分 417.33\n",
      "损失函数： 0.00963951\n",
      "时间步 7085000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319755e+01/ 轮得分 417.33\n",
      "损失函数： 0.0411532\n",
      "时间步 7086000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188738e+01/ 轮得分 417.33\n",
      "损失函数： 0.014777\n",
      "时间步 7087000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201631e+01/ 轮得分 417.33\n",
      "损失函数： 0.0252917\n",
      "时间步 7088000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383075e+01/ 轮得分 417.33\n",
      "损失函数： 0.054463\n",
      "时间步 7089000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259215e+01/ 轮得分 417.33\n",
      "损失函数： 0.0209024\n",
      "时间步 7090000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.197561e+01/ 轮得分 417.33\n",
      "损失函数： 0.0787409\n",
      "时间步 7091000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270115e+01/ 轮得分 418.46\n",
      "损失函数： 0.0121953\n",
      "时间步 7092000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.200702e+01/ 轮得分 418.46\n",
      "损失函数： 0.00996461\n",
      "时间步 7093000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184331e+01/ 轮得分 418.46\n",
      "损失函数： 0.0175424\n",
      "时间步 7094000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.215685e+01/ 轮得分 418.46\n",
      "损失函数： 0.0291462\n",
      "时间步 7095000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252588e+01/ 轮得分 418.46\n",
      "损失函数： 0.0196878\n",
      "时间步 7096000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.467883e+01/ 轮得分 418.46\n",
      "损失函数： 0.0314647\n",
      "时间步 7097000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.093904e+01/ 轮得分 418.96\n",
      "损失函数： 0.0465559\n",
      "时间步 7098000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.137800e+01/ 轮得分 418.96\n",
      "损失函数： 0.0196866\n",
      "时间步 7099000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282890e+01/ 轮得分 418.96\n",
      "损失函数： 0.0184182\n",
      "时间步 7100000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204926e+01/ 轮得分 418.96\n",
      "损失函数： 0.0130829\n",
      "时间步 7101000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212080e+01/ 轮得分 418.96\n",
      "损失函数： 0.0116496\n",
      "时间步 7102000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.103368e+01/ 轮得分 418.95\n",
      "损失函数： 0.0212367\n",
      "时间步 7103000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.297249e+01/ 轮得分 418.95\n",
      "损失函数： 0.016443\n",
      "时间步 7104000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.416829e+01/ 轮得分 418.95\n",
      "损失函数： 0.0111499\n",
      "时间步 7105000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212882e+01/ 轮得分 418.95\n",
      "损失函数： 0.0244312\n",
      "时间步 7106000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263744e+01/ 轮得分 418.95\n",
      "损失函数： 0.0271054\n",
      "时间步 7107000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351227e+01/ 轮得分 418.95\n",
      "损失函数： 0.0366928\n",
      "时间步 7108000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339967e+01/ 轮得分 418.95\n",
      "损失函数： 0.0247209\n",
      "时间步 7109000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.404789e+01/ 轮得分 419.68\n",
      "损失函数： 0.0417035\n",
      "时间步 7110000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201222e+01/ 轮得分 419.68\n",
      "损失函数： 0.0146335\n",
      "时间步 7111000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183756e+01/ 轮得分 419.50\n",
      "损失函数： 0.0184934\n",
      "时间步 7112000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269374e+01/ 轮得分 419.50\n",
      "损失函数： 0.0202382\n",
      "时间步 7113000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312328e+01/ 轮得分 419.50\n",
      "损失函数： 0.0448683\n",
      "时间步 7114000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.200521e+01/ 轮得分 419.50\n",
      "损失函数： 0.0129139\n",
      "时间步 7115000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.433598e+01/ 轮得分 419.50\n",
      "损失函数： 0.0125885\n",
      "时间步 7116000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.282221e+01/ 轮得分 419.82\n",
      "损失函数： 0.0166507\n",
      "时间步 7117000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.428062e+01/ 轮得分 419.82\n",
      "损失函数： 0.00916906\n",
      "时间步 7118000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299840e+01/ 轮得分 419.82\n",
      "损失函数： 0.010152\n",
      "时间步 7119000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.195337e+01/ 轮得分 419.96\n",
      "损失函数： 0.0757019\n",
      "时间步 7120000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.433862e+01/ 轮得分 420.00\n",
      "损失函数： 0.0451259\n",
      "时间步 7121000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.469318e+01/ 轮得分 420.00\n",
      "损失函数： 0.0442819\n",
      "时间步 7122000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189837e+01/ 轮得分 420.03\n",
      "损失函数： 0.0270424\n",
      "时间步 7123000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.445825e+01/ 轮得分 420.03\n",
      "损失函数： 0.0285653\n",
      "时间步 7124000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234698e+01/ 轮得分 420.03\n",
      "损失函数： 0.0296286\n",
      "时间步 7125000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.179463e+01/ 轮得分 420.03\n",
      "损失函数： 0.049474\n",
      "时间步 7126000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.326485e+01/ 轮得分 420.03\n",
      "损失函数： 0.0117227\n",
      "时间步 7127000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.071039e+01/ 轮得分 420.03\n",
      "损失函数： 0.117337\n",
      "时间步 7128000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.392274e+01/ 轮得分 420.03\n",
      "损失函数： 0.00632306\n",
      "时间步 7129000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212331e+01/ 轮得分 420.03\n",
      "损失函数： 0.0307526\n",
      "时间步 7130000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305158e+01/ 轮得分 420.03\n",
      "损失函数： 0.0340976\n",
      "时间步 7131000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261521e+01/ 轮得分 420.03\n",
      "损失函数： 0.0387298\n",
      "时间步 7132000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333289e+01/ 轮得分 420.35\n",
      "损失函数： 0.0236145\n",
      "时间步 7133000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269757e+01/ 轮得分 420.35\n",
      "损失函数： 0.070677\n",
      "时间步 7134000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.442743e+01/ 轮得分 420.35\n",
      "损失函数： 0.0241872\n",
      "时间步 7135000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339692e+01/ 轮得分 420.35\n",
      "损失函数： 0.0217298\n",
      "时间步 7136000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.462952e+01/ 轮得分 420.35\n",
      "损失函数： 0.0217949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7137000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291355e+01/ 轮得分 420.35\n",
      "损失函数： 0.0339578\n",
      "时间步 7138000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337002e+01/ 轮得分 420.35\n",
      "损失函数： 0.128706\n",
      "时间步 7139000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301630e+01/ 轮得分 420.35\n",
      "损失函数： 0.0194599\n",
      "时间步 7140000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.440995e+01/ 轮得分 420.35\n",
      "损失函数： 0.0719025\n",
      "时间步 7141000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362837e+01/ 轮得分 420.35\n",
      "损失函数： 0.0265732\n",
      "时间步 7142000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.455078e+01/ 轮得分 420.35\n",
      "损失函数： 0.0301454\n",
      "时间步 7143000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.503274e+01/ 轮得分 421.41\n",
      "损失函数： 0.0816597\n",
      "时间步 7144000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.577011e+01/ 轮得分 421.41\n",
      "损失函数： 0.0272605\n",
      "时间步 7145000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.155818e+01/ 轮得分 421.43\n",
      "损失函数： 0.0387877\n",
      "时间步 7146000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.275667e+01/ 轮得分 421.43\n",
      "损失函数： 0.0304069\n",
      "时间步 7147000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227757e+01/ 轮得分 420.84\n",
      "损失函数： 0.0459681\n",
      "时间步 7148000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367334e+01/ 轮得分 420.84\n",
      "损失函数： 0.0202295\n",
      "时间步 7149000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322515e+01/ 轮得分 420.84\n",
      "损失函数： 0.0494361\n",
      "时间步 7150000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342052e+01/ 轮得分 420.84\n",
      "损失函数： 0.0257081\n",
      "时间步 7151000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359129e+01/ 轮得分 420.84\n",
      "损失函数： 0.0954903\n",
      "时间步 7152000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277485e+01/ 轮得分 420.84\n",
      "损失函数： 0.0221362\n",
      "时间步 7153000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223969e+01/ 轮得分 420.84\n",
      "损失函数： 0.0103412\n",
      "时间步 7154000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.477144e+01/ 轮得分 420.84\n",
      "损失函数： 0.032353\n",
      "时间步 7155000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238217e+01/ 轮得分 421.30\n",
      "损失函数： 0.0160993\n",
      "时间步 7156000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338712e+01/ 轮得分 421.30\n",
      "损失函数： 0.0299851\n",
      "时间步 7157000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.097817e+01/ 轮得分 421.30\n",
      "损失函数： 0.00468629\n",
      "时间步 7158000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.402256e+01/ 轮得分 421.30\n",
      "损失函数： 0.0211813\n",
      "时间步 7159000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270659e+01/ 轮得分 421.54\n",
      "损失函数： 0.0537935\n",
      "时间步 7160000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162853e+01/ 轮得分 421.54\n",
      "损失函数： 0.0193945\n",
      "时间步 7161000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.226449e+01/ 轮得分 421.20\n",
      "损失函数： 0.0245832\n",
      "时间步 7162000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257984e+01/ 轮得分 421.20\n",
      "损失函数： 0.0163487\n",
      "时间步 7163000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357283e+01/ 轮得分 421.20\n",
      "损失函数： 0.0297697\n",
      "时间步 7164000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387059e+01/ 轮得分 421.20\n",
      "损失函数： 0.0368802\n",
      "时间步 7165000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.132511e+01/ 轮得分 421.57\n",
      "损失函数： 0.0178862\n",
      "时间步 7166000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363167e+01/ 轮得分 421.57\n",
      "损失函数： 0.0235206\n",
      "时间步 7167000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.501006e+01/ 轮得分 421.57\n",
      "损失函数： 0.0140978\n",
      "时间步 7168000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.380946e+01/ 轮得分 421.85\n",
      "损失函数： 0.0373683\n",
      "时间步 7169000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.551923e+01/ 轮得分 421.85\n",
      "损失函数： 0.020754\n",
      "时间步 7170000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365030e+01/ 轮得分 421.85\n",
      "损失函数： 0.0337735\n",
      "时间步 7171000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.118565e+01/ 轮得分 422.12\n",
      "损失函数： 0.0275844\n",
      "时间步 7172000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183712e+01/ 轮得分 422.12\n",
      "损失函数： 0.39903\n",
      "时间步 7173000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.236648e+01/ 轮得分 422.12\n",
      "损失函数： 0.0196207\n",
      "时间步 7174000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.092096e+01/ 轮得分 422.12\n",
      "损失函数： 0.0194968\n",
      "时间步 7175000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.200175e+01/ 轮得分 422.15\n",
      "损失函数： 0.0267024\n",
      "时间步 7176000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.262591e+01/ 轮得分 422.15\n",
      "损失函数： 0.0151359\n",
      "时间步 7177000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298462e+01/ 轮得分 422.15\n",
      "损失函数： 0.01049\n",
      "时间步 7178000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.609986e+01/ 轮得分 422.15\n",
      "损失函数： 0.0254936\n",
      "时间步 7179000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.110805e+01/ 轮得分 422.15\n",
      "损失函数： 0.122513\n",
      "时间步 7180000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.176993e+01/ 轮得分 422.46\n",
      "损失函数： 0.0390658\n",
      "时间步 7181000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312198e+01/ 轮得分 422.08\n",
      "损失函数： 0.0177251\n",
      "时间步 7182000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322216e+01/ 轮得分 422.08\n",
      "损失函数： 0.0517538\n",
      "时间步 7183000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293445e+01/ 轮得分 422.08\n",
      "损失函数： 0.0360114\n",
      "时间步 7184000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356136e+01/ 轮得分 422.36\n",
      "损失函数： 0.0976444\n",
      "时间步 7185000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.110981e+01/ 轮得分 422.36\n",
      "损失函数： 0.0113365\n",
      "时间步 7186000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.439521e+01/ 轮得分 422.36\n",
      "损失函数： 0.0276948\n",
      "时间步 7187000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311126e+01/ 轮得分 422.36\n",
      "损失函数： 0.0356144\n",
      "时间步 7188000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.416522e+01/ 轮得分 422.36\n",
      "损失函数： 0.0147543\n",
      "时间步 7189000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351403e+01/ 轮得分 422.36\n",
      "损失函数： 0.0378418\n",
      "时间步 7190000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226553e+01/ 轮得分 422.36\n",
      "损失函数： 0.0311055\n",
      "时间步 7191000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302598e+01/ 轮得分 422.36\n",
      "损失函数： 0.0149553\n",
      "时间步 7192000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328448e+01/ 轮得分 422.36\n",
      "损失函数： 0.0269069\n",
      "时间步 7193000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318737e+01/ 轮得分 423.44\n",
      "损失函数： 0.0244582\n",
      "时间步 7194000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204688e+01/ 轮得分 423.44\n",
      "损失函数： 0.0255419\n",
      "时间步 7195000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198507e+01/ 轮得分 423.30\n",
      "损失函数： 0.0730385\n",
      "时间步 7196000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332656e+01/ 轮得分 423.30\n",
      "损失函数： 0.0184512\n",
      "时间步 7197000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280418e+01/ 轮得分 423.30\n",
      "损失函数： 0.0176153\n",
      "时间步 7198000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181005e+01/ 轮得分 423.30\n",
      "损失函数： 0.0276087\n",
      "时间步 7199000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.429718e+01/ 轮得分 423.30\n",
      "损失函数： 0.0238891\n",
      "时间步 7200000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340242e+01/ 轮得分 423.30\n",
      "损失函数： 0.036759\n",
      "时间步 7201000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.188894e+01/ 轮得分 423.48\n",
      "损失函数： 0.017519\n",
      "时间步 7202000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.247096e+01/ 轮得分 423.48\n",
      "损失函数： 0.0368886\n",
      "时间步 7203000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304910e+01/ 轮得分 422.96\n",
      "损失函数： 0.0679301\n",
      "时间步 7204000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.466370e+01/ 轮得分 422.96\n",
      "损失函数： 0.0195539\n",
      "时间步 7205000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.328278e+01/ 轮得分 422.96\n",
      "损失函数： 0.00984532\n",
      "时间步 7206000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.352284e+01/ 轮得分 422.96\n",
      "损失函数： 0.0435371\n",
      "时间步 7207000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.389004e+01/ 轮得分 423.40\n",
      "损失函数： 0.0347735\n",
      "时间步 7208000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216581e+01/ 轮得分 423.40\n",
      "损失函数： 0.035408\n",
      "时间步 7209000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378395e+01/ 轮得分 422.88\n",
      "损失函数： 0.0388458\n",
      "时间步 7210000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.358355e+01/ 轮得分 422.88\n",
      "损失函数： 0.0481645\n",
      "时间步 7211000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192575e+01/ 轮得分 422.85\n",
      "损失函数： 0.0831491\n",
      "时间步 7212000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.449342e+01/ 轮得分 422.85\n",
      "损失函数： 0.144508\n",
      "时间步 7213000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.470551e+01/ 轮得分 422.85\n",
      "损失函数： 0.0493543\n",
      "时间步 7214000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345490e+01/ 轮得分 422.85\n",
      "损失函数： 0.0372658\n",
      "时间步 7215000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.592494e+01/ 轮得分 422.85\n",
      "损失函数： 0.014367\n",
      "时间步 7216000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377664e+01/ 轮得分 422.85\n",
      "损失函数： 0.0423129\n",
      "时间步 7217000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.222311e+01/ 轮得分 423.39\n",
      "损失函数： 0.0290817\n",
      "时间步 7218000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308816e+01/ 轮得分 423.39\n",
      "损失函数： 0.022331\n",
      "时间步 7219000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.123499e+01/ 轮得分 423.28\n",
      "损失函数： 0.0711411\n",
      "时间步 7220000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.422021e+01/ 轮得分 423.28\n",
      "损失函数： 0.0326478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7221000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.179984e+01/ 轮得分 423.28\n",
      "损失函数： 0.117268\n",
      "时间步 7222000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280997e+01/ 轮得分 423.28\n",
      "损失函数： 0.0296868\n",
      "时间步 7223000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.486504e+01/ 轮得分 423.28\n",
      "损失函数： 0.0515786\n",
      "时间步 7224000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.347631e+01/ 轮得分 423.28\n",
      "损失函数： 0.0241753\n",
      "时间步 7225000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.507778e+01/ 轮得分 423.28\n",
      "损失函数： 0.0246985\n",
      "时间步 7226000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.240167e+01/ 轮得分 423.28\n",
      "损失函数： 0.0246845\n",
      "时间步 7227000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236205e+01/ 轮得分 423.86\n",
      "损失函数： 0.0236099\n",
      "时间步 7228000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.374030e+01/ 轮得分 423.54\n",
      "损失函数： 0.0411122\n",
      "时间步 7229000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.181029e+01/ 轮得分 423.54\n",
      "损失函数： 0.0202183\n",
      "时间步 7230000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378452e+01/ 轮得分 423.66\n",
      "损失函数： 0.0180663\n",
      "时间步 7231000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375472e+01/ 轮得分 423.66\n",
      "损失函数： 0.0277241\n",
      "时间步 7232000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375083e+01/ 轮得分 423.66\n",
      "损失函数： 0.0220783\n",
      "时间步 7233000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412068e+01/ 轮得分 423.66\n",
      "损失函数： 0.0974587\n",
      "时间步 7234000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363648e+01/ 轮得分 423.66\n",
      "损失函数： 0.0188662\n",
      "时间步 7235000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337454e+01/ 轮得分 423.66\n",
      "损失函数： 0.0201488\n",
      "时间步 7236000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.403018e+01/ 轮得分 423.66\n",
      "损失函数： 0.0402084\n",
      "时间步 7237000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.264307e+01/ 轮得分 423.66\n",
      "损失函数： 0.0925381\n",
      "时间步 7238000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.311538e+01/ 轮得分 423.66\n",
      "损失函数： 0.0172784\n",
      "时间步 7239000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340268e+01/ 轮得分 423.66\n",
      "损失函数： 0.0428925\n",
      "时间步 7240000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376912e+01/ 轮得分 424.78\n",
      "损失函数： 0.0547582\n",
      "时间步 7241000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376120e+01/ 轮得分 424.78\n",
      "损失函数： 0.027794\n",
      "时间步 7242000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414363e+01/ 轮得分 424.78\n",
      "损失函数： 0.021315\n",
      "时间步 7243000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343101e+01/ 轮得分 424.78\n",
      "损失函数： 0.0573631\n",
      "时间步 7244000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355080e+01/ 轮得分 424.78\n",
      "损失函数： 0.0458121\n",
      "时间步 7245000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335320e+01/ 轮得分 424.78\n",
      "损失函数： 0.0217006\n",
      "时间步 7246000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201397e+01/ 轮得分 424.78\n",
      "损失函数： 0.0403071\n",
      "时间步 7247000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.497142e+01/ 轮得分 424.78\n",
      "损失函数： 0.0266282\n",
      "时间步 7248000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.372954e+01/ 轮得分 424.78\n",
      "损失函数： 0.0327724\n",
      "时间步 7249000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.514545e+01/ 轮得分 425.57\n",
      "损失函数： 0.0170514\n",
      "时间步 7250000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287369e+01/ 轮得分 425.57\n",
      "损失函数： 0.024903\n",
      "时间步 7251000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.435227e+01/ 轮得分 425.57\n",
      "损失函数： 0.0144854\n",
      "时间步 7252000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.229142e+01/ 轮得分 425.57\n",
      "损失函数： 0.0283399\n",
      "时间步 7253000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274527e+01/ 轮得分 426.03\n",
      "损失函数： 0.0358687\n",
      "时间步 7254000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343005e+01/ 轮得分 426.03\n",
      "损失函数： 0.0281562\n",
      "时间步 7255000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261204e+01/ 轮得分 426.03\n",
      "损失函数： 0.0448315\n",
      "时间步 7256000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.435439e+01/ 轮得分 426.03\n",
      "损失函数： 0.0482179\n",
      "时间步 7257000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.390382e+01/ 轮得分 426.03\n",
      "损失函数： 0.0606053\n",
      "时间步 7258000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.218899e+01/ 轮得分 426.03\n",
      "损失函数： 0.0281793\n",
      "时间步 7259000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.658939e+01/ 轮得分 426.03\n",
      "损失函数： 0.0247719\n",
      "时间步 7260000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.287008e+01/ 轮得分 426.03\n",
      "损失函数： 0.0284983\n",
      "时间步 7261000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347624e+01/ 轮得分 426.03\n",
      "损失函数： 0.0635828\n",
      "时间步 7262000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.472206e+01/ 轮得分 426.98\n",
      "损失函数： 0.0409202\n",
      "时间步 7263000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219754e+01/ 轮得分 426.98\n",
      "损失函数： 0.00979955\n",
      "时间步 7264000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.274968e+01/ 轮得分 426.98\n",
      "损失函数： 0.0499032\n",
      "时间步 7265000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.408321e+01/ 轮得分 426.98\n",
      "损失函数： 0.0125253\n",
      "时间步 7266000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257048e+01/ 轮得分 426.98\n",
      "损失函数： 0.0303531\n",
      "时间步 7267000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295269e+01/ 轮得分 427.48\n",
      "损失函数： 0.0154848\n",
      "时间步 7268000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.351776e+01/ 轮得分 427.48\n",
      "损失函数： 0.0202671\n",
      "时间步 7269000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.330513e+01/ 轮得分 427.48\n",
      "损失函数： 0.0468885\n",
      "时间步 7270000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347221e+01/ 轮得分 427.48\n",
      "损失函数： 0.0387845\n",
      "时间步 7271000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.354769e+01/ 轮得分 427.48\n",
      "损失函数： 0.0226831\n",
      "时间步 7272000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277236e+01/ 轮得分 427.48\n",
      "损失函数： 0.032764\n",
      "时间步 7273000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347688e+01/ 轮得分 427.48\n",
      "损失函数： 0.00966999\n",
      "时间步 7274000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265925e+01/ 轮得分 427.48\n",
      "损失函数： 0.0310216\n",
      "时间步 7275000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.124417e+01/ 轮得分 427.48\n",
      "损失函数： 0.0379592\n",
      "时间步 7276000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248462e+01/ 轮得分 427.48\n",
      "损失函数： 0.0293788\n",
      "时间步 7277000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274782e+01/ 轮得分 427.61\n",
      "损失函数： 0.00833422\n",
      "时间步 7278000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340989e+01/ 轮得分 427.61\n",
      "损失函数： 0.017511\n",
      "时间步 7279000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.087515e+01/ 轮得分 427.85\n",
      "损失函数： 0.0171393\n",
      "时间步 7280000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.156609e+01/ 轮得分 427.85\n",
      "损失函数： 0.0220551\n",
      "时间步 7281000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286222e+01/ 轮得分 427.67\n",
      "损失函数： 0.00981111\n",
      "时间步 7282000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161135e+01/ 轮得分 427.67\n",
      "损失函数： 0.0145905\n",
      "时间步 7283000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230640e+01/ 轮得分 427.67\n",
      "损失函数： 0.0313001\n",
      "时间步 7284000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.089045e+01/ 轮得分 427.67\n",
      "损失函数： 0.0171761\n",
      "时间步 7285000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.494442e+01/ 轮得分 427.67\n",
      "损失函数： 0.142223\n",
      "时间步 7286000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.097982e+01/ 轮得分 428.16\n",
      "损失函数： 0.040194\n",
      "时间步 7287000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.114086e+01/ 轮得分 428.16\n",
      "损失函数： 0.0870153\n",
      "时间步 7288000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.451855e+01/ 轮得分 428.16\n",
      "损失函数： 0.00963313\n",
      "时间步 7289000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229978e+01/ 轮得分 428.16\n",
      "损失函数： 0.0431682\n",
      "时间步 7290000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.172258e+01/ 轮得分 428.16\n",
      "损失函数： 0.00826723\n",
      "时间步 7291000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277057e+01/ 轮得分 428.16\n",
      "损失函数： 0.0363336\n",
      "时间步 7292000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197115e+01/ 轮得分 428.16\n",
      "损失函数： 0.0314212\n",
      "时间步 7293000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.369270e+01/ 轮得分 428.74\n",
      "损失函数： 0.0407085\n",
      "时间步 7294000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.122750e+01/ 轮得分 428.74\n",
      "损失函数： 0.0171748\n",
      "时间步 7295000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365165e+01/ 轮得分 428.74\n",
      "损失函数： 0.0327934\n",
      "时间步 7296000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.202748e+01/ 轮得分 428.74\n",
      "损失函数： 0.0238561\n",
      "时间步 7297000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341489e+01/ 轮得分 428.74\n",
      "损失函数： 0.100126\n",
      "时间步 7298000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250333e+01/ 轮得分 428.74\n",
      "损失函数： 0.0690101\n",
      "时间步 7299000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.374209e+01/ 轮得分 429.29\n",
      "损失函数： 0.0789475\n",
      "时间步 7300000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447595e+01/ 轮得分 429.29\n",
      "损失函数： 0.0503777\n",
      "时间步 7301000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.408627e+01/ 轮得分 429.29\n",
      "损失函数： 0.0290298\n",
      "时间步 7302000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367668e+01/ 轮得分 429.29\n",
      "损失函数： 0.019246\n",
      "时间步 7303000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448624e+01/ 轮得分 429.29\n",
      "损失函数： 0.0113176\n",
      "时间步 7304000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216913e+01/ 轮得分 429.29\n",
      "损失函数： 0.0284133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7305000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298822e+01/ 轮得分 429.29\n",
      "损失函数： 0.010464\n",
      "时间步 7306000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.101033e+01/ 轮得分 429.29\n",
      "损失函数： 0.0100791\n",
      "时间步 7307000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279659e+01/ 轮得分 429.29\n",
      "损失函数： 0.0280747\n",
      "时间步 7308000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387017e+01/ 轮得分 429.29\n",
      "损失函数： 0.0134661\n",
      "时间步 7309000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.218297e+01/ 轮得分 429.29\n",
      "损失函数： 0.034018\n",
      "时间步 7310000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317243e+01/ 轮得分 430.17\n",
      "损失函数： 0.0265105\n",
      "时间步 7311000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385624e+01/ 轮得分 430.17\n",
      "损失函数： 0.0458051\n",
      "时间步 7312000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447091e+01/ 轮得分 430.29\n",
      "损失函数： 0.0222536\n",
      "时间步 7313000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396156e+01/ 轮得分 430.29\n",
      "损失函数： 0.0105567\n",
      "时间步 7314000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306412e+01/ 轮得分 430.29\n",
      "损失函数： 0.0136452\n",
      "时间步 7315000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393912e+01/ 轮得分 430.29\n",
      "损失函数： 0.0280772\n",
      "时间步 7316000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198539e+01/ 轮得分 430.76\n",
      "损失函数： 0.0387701\n",
      "时间步 7317000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.124267e+01/ 轮得分 430.76\n",
      "损失函数： 0.0369475\n",
      "时间步 7318000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.208015e+01/ 轮得分 430.62\n",
      "损失函数： 0.0295186\n",
      "时间步 7319000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272843e+01/ 轮得分 430.49\n",
      "损失函数： 0.0295903\n",
      "时间步 7320000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.417771e+01/ 轮得分 430.49\n",
      "损失函数： 0.0331537\n",
      "时间步 7321000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.410101e+01/ 轮得分 430.49\n",
      "损失函数： 0.0457469\n",
      "时间步 7322000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.289461e+01/ 轮得分 430.49\n",
      "损失函数： 0.0446738\n",
      "时间步 7323000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378547e+01/ 轮得分 430.49\n",
      "损失函数： 0.0438112\n",
      "时间步 7324000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343921e+01/ 轮得分 430.49\n",
      "损失函数： 0.0264821\n",
      "时间步 7325000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.275778e+01/ 轮得分 430.93\n",
      "损失函数： 0.0374294\n",
      "时间步 7326000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.400355e+01/ 轮得分 430.93\n",
      "损失函数： 0.139066\n",
      "时间步 7327000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.053494e+01/ 轮得分 430.93\n",
      "损失函数： 0.021453\n",
      "时间步 7328000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.186414e+01/ 轮得分 430.81\n",
      "损失函数： 0.0915459\n",
      "时间步 7329000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.400979e+01/ 轮得分 430.81\n",
      "损失函数： 0.0159183\n",
      "时间步 7330000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.507810e+01/ 轮得分 430.81\n",
      "损失函数： 0.0243746\n",
      "时间步 7331000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185239e+01/ 轮得分 430.81\n",
      "损失函数： 0.0181826\n",
      "时间步 7332000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.203726e+01/ 轮得分 430.81\n",
      "损失函数： 0.0439342\n",
      "时间步 7333000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.118577e+01/ 轮得分 430.87\n",
      "损失函数： 0.0339621\n",
      "时间步 7334000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231164e+01/ 轮得分 430.87\n",
      "损失函数： 0.00929508\n",
      "时间步 7335000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219561e+01/ 轮得分 430.87\n",
      "损失函数： 0.0243325\n",
      "时间步 7336000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332487e+01/ 轮得分 430.87\n",
      "损失函数： 0.0161694\n",
      "时间步 7337000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183201e+01/ 轮得分 431.03\n",
      "损失函数： 0.0264276\n",
      "时间步 7338000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262694e+01/ 轮得分 430.73\n",
      "损失函数： 0.00890915\n",
      "时间步 7339000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.520624e+01/ 轮得分 430.73\n",
      "损失函数： 0.0415548\n",
      "时间步 7340000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215170e+01/ 轮得分 430.73\n",
      "损失函数： 0.0581236\n",
      "时间步 7341000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196781e+01/ 轮得分 430.73\n",
      "损失函数： 0.0215854\n",
      "时间步 7342000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343590e+01/ 轮得分 430.73\n",
      "损失函数： 0.0103016\n",
      "时间步 7343000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302602e+01/ 轮得分 430.73\n",
      "损失函数： 0.0413024\n",
      "时间步 7344000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.047644e+01/ 轮得分 430.27\n",
      "损失函数： 0.0388225\n",
      "时间步 7345000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318643e+01/ 轮得分 430.27\n",
      "损失函数： 0.0291892\n",
      "时间步 7346000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.175243e+01/ 轮得分 430.17\n",
      "损失函数： 0.0266993\n",
      "时间步 7347000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260267e+01/ 轮得分 430.17\n",
      "损失函数： 0.0571428\n",
      "时间步 7348000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.135623e+01/ 轮得分 430.17\n",
      "损失函数： 0.0415821\n",
      "时间步 7349000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248720e+01/ 轮得分 430.17\n",
      "损失函数： 0.0179982\n",
      "时间步 7350000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.448903e+01/ 轮得分 430.17\n",
      "损失函数： 0.0259199\n",
      "时间步 7351000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248313e+01/ 轮得分 430.60\n",
      "损失函数： 0.00746259\n",
      "时间步 7352000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271669e+01/ 轮得分 430.60\n",
      "损失函数： 0.0224631\n",
      "时间步 7353000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269862e+01/ 轮得分 430.66\n",
      "损失函数： 0.0164154\n",
      "时间步 7354000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.155264e+01/ 轮得分 430.66\n",
      "损失函数： 0.0719518\n",
      "时间步 7355000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.436745e+01/ 轮得分 430.66\n",
      "损失函数： 0.0294863\n",
      "时间步 7356000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216798e+01/ 轮得分 430.94\n",
      "损失函数： 0.0593869\n",
      "时间步 7357000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222635e+01/ 轮得分 429.50\n",
      "损失函数： 0.00764778\n",
      "时间步 7358000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278470e+01/ 轮得分 429.50\n",
      "损失函数： 0.010323\n",
      "时间步 7359000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418956e+01/ 轮得分 429.50\n",
      "损失函数： 0.0689422\n",
      "时间步 7360000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230025e+01/ 轮得分 429.50\n",
      "损失函数： 0.0118774\n",
      "时间步 7361000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.178956e+01/ 轮得分 429.50\n",
      "损失函数： 0.0331833\n",
      "时间步 7362000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284693e+01/ 轮得分 429.50\n",
      "损失函数： 0.0184299\n",
      "时间步 7363000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265950e+01/ 轮得分 429.50\n",
      "损失函数： 0.0354975\n",
      "时间步 7364000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216275e+01/ 轮得分 429.50\n",
      "损失函数： 0.0154927\n",
      "时间步 7365000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.360308e+01/ 轮得分 429.50\n",
      "损失函数： 0.0175874\n",
      "时间步 7366000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205497e+01/ 轮得分 429.07\n",
      "损失函数： 0.0405082\n",
      "时间步 7367000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263100e+01/ 轮得分 429.07\n",
      "损失函数： 0.0135818\n",
      "时间步 7368000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293040e+01/ 轮得分 429.07\n",
      "损失函数： 0.013686\n",
      "时间步 7369000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.126082e+01/ 轮得分 429.07\n",
      "损失函数： 0.0192619\n",
      "时间步 7370000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272465e+01/ 轮得分 429.07\n",
      "损失函数： 0.0383179\n",
      "时间步 7371000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.309712e+01/ 轮得分 429.07\n",
      "损失函数： 0.00826348\n",
      "时间步 7372000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354521e+01/ 轮得分 429.07\n",
      "损失函数： 0.0260068\n",
      "时间步 7373000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273161e+01/ 轮得分 429.07\n",
      "损失函数： 0.0153364\n",
      "时间步 7374000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.473723e+01/ 轮得分 429.07\n",
      "损失函数： 0.0472587\n",
      "时间步 7375000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310632e+01/ 轮得分 429.07\n",
      "损失函数： 0.0161061\n",
      "时间步 7376000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272977e+01/ 轮得分 429.07\n",
      "损失函数： 0.0964402\n",
      "时间步 7377000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226596e+01/ 轮得分 429.07\n",
      "损失函数： 0.0347552\n",
      "时间步 7378000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285685e+01/ 轮得分 429.07\n",
      "损失函数： 0.0118724\n",
      "时间步 7379000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.141267e+01/ 轮得分 430.53\n",
      "损失函数： 0.0212309\n",
      "时间步 7380000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219500e+01/ 轮得分 430.01\n",
      "损失函数： 0.0771864\n",
      "时间步 7381000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267817e+01/ 轮得分 430.01\n",
      "损失函数： 0.0123591\n",
      "时间步 7382000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407184e+01/ 轮得分 430.01\n",
      "损失函数： 0.0273574\n",
      "时间步 7383000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262075e+01/ 轮得分 430.01\n",
      "损失函数： 0.00608656\n",
      "时间步 7384000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354881e+01/ 轮得分 430.01\n",
      "损失函数： 0.0458574\n",
      "时间步 7385000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.125788e+01/ 轮得分 430.01\n",
      "损失函数： 0.0263063\n",
      "时间步 7386000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.120034e+01/ 轮得分 430.79\n",
      "损失函数： 0.0517188\n",
      "时间步 7387000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326333e+01/ 轮得分 430.79\n",
      "损失函数： 0.0191826\n",
      "时间步 7388000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.182222e+01/ 轮得分 431.03\n",
      "损失函数： 0.033703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7389000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242177e+01/ 轮得分 431.03\n",
      "损失函数： 0.043768\n",
      "时间步 7390000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329621e+01/ 轮得分 431.03\n",
      "损失函数： 0.0333035\n",
      "时间步 7391000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.433764e+01/ 轮得分 431.03\n",
      "损失函数： 0.011602\n",
      "时间步 7392000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311883e+01/ 轮得分 431.03\n",
      "损失函数： 0.0180075\n",
      "时间步 7393000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 7.414763e+00/ 轮得分 431.30\n",
      "损失函数： 0.0190813\n",
      "时间步 7394000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303226e+01/ 轮得分 431.27\n",
      "损失函数： 0.209325\n",
      "时间步 7395000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294379e+01/ 轮得分 431.27\n",
      "损失函数： 0.0132241\n",
      "时间步 7396000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415150e+01/ 轮得分 431.27\n",
      "损失函数： 0.0250523\n",
      "时间步 7397000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340400e+01/ 轮得分 431.27\n",
      "损失函数： 0.0492312\n",
      "时间步 7398000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332902e+01/ 轮得分 430.77\n",
      "损失函数： 0.0992073\n",
      "时间步 7399000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296241e+01/ 轮得分 430.77\n",
      "损失函数： 0.202829\n",
      "时间步 7400000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356809e+01/ 轮得分 430.77\n",
      "损失函数： 0.0709089\n",
      "时间步 7401000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.408417e+01/ 轮得分 430.77\n",
      "损失函数： 0.0117602\n",
      "时间步 7402000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.431145e+01/ 轮得分 430.77\n",
      "损失函数： 0.0200267\n",
      "时间步 7403000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.039194e+01/ 轮得分 430.77\n",
      "损失函数： 0.0118414\n",
      "时间步 7404000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270955e+01/ 轮得分 431.27\n",
      "损失函数： 0.014082\n",
      "时间步 7405000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.314629e+01/ 轮得分 431.27\n",
      "损失函数： 0.0300921\n",
      "时间步 7406000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236250e+01/ 轮得分 431.27\n",
      "损失函数： 0.0215689\n",
      "时间步 7407000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.178421e+01/ 轮得分 431.44\n",
      "损失函数： 0.0391091\n",
      "时间步 7408000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.566660e+01/ 轮得分 431.44\n",
      "损失函数： 0.0183636\n",
      "时间步 7409000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.345236e+01/ 轮得分 431.44\n",
      "损失函数： 0.0570792\n",
      "时间步 7410000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337152e+01/ 轮得分 431.44\n",
      "损失函数： 0.0400223\n",
      "时间步 7411000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306448e+01/ 轮得分 431.44\n",
      "损失函数： 0.0252697\n",
      "时间步 7412000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.377374e+01/ 轮得分 431.44\n",
      "损失函数： 0.118283\n",
      "时间步 7413000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.220150e+01/ 轮得分 431.44\n",
      "损失函数： 0.0505244\n",
      "时间步 7414000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.104542e+01/ 轮得分 431.44\n",
      "损失函数： 0.0204716\n",
      "时间步 7415000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206705e+01/ 轮得分 431.44\n",
      "损失函数： 0.0309684\n",
      "时间步 7416000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306211e+01/ 轮得分 431.44\n",
      "损失函数： 0.0287976\n",
      "时间步 7417000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385080e+01/ 轮得分 431.44\n",
      "损失函数： 0.0170702\n",
      "时间步 7418000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259219e+01/ 轮得分 432.26\n",
      "损失函数： 0.0685149\n",
      "时间步 7419000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181450e+01/ 轮得分 432.26\n",
      "损失函数： 0.018727\n",
      "时间步 7420000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321074e+01/ 轮得分 432.26\n",
      "损失函数： 0.0185596\n",
      "时间步 7421000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269382e+01/ 轮得分 432.26\n",
      "损失函数： 0.0251581\n",
      "时间步 7422000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190750e+01/ 轮得分 432.26\n",
      "损失函数： 0.0252644\n",
      "时间步 7423000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260512e+01/ 轮得分 432.26\n",
      "损失函数： 0.0450035\n",
      "时间步 7424000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.480963e+01/ 轮得分 432.26\n",
      "损失函数： 0.00999033\n",
      "时间步 7425000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384001e+01/ 轮得分 432.26\n",
      "损失函数： 0.0144901\n",
      "时间步 7426000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219393e+01/ 轮得分 432.26\n",
      "损失函数： 0.0236382\n",
      "时间步 7427000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159053e+01/ 轮得分 432.26\n",
      "损失函数： 0.0108676\n",
      "时间步 7428000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363518e+01/ 轮得分 432.26\n",
      "损失函数： 0.0093357\n",
      "时间步 7429000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.543884e+01/ 轮得分 433.21\n",
      "损失函数： 0.0347043\n",
      "时间步 7430000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387582e+01/ 轮得分 433.21\n",
      "损失函数： 0.0548081\n",
      "时间步 7431000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220893e+01/ 轮得分 433.01\n",
      "损失函数： 0.0113589\n",
      "时间步 7432000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.144426e+01/ 轮得分 433.01\n",
      "损失函数： 0.0393047\n",
      "时间步 7433000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394768e+01/ 轮得分 433.01\n",
      "损失函数： 0.0159989\n",
      "时间步 7434000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245285e+01/ 轮得分 433.01\n",
      "损失函数： 0.0151928\n",
      "时间步 7435000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.435588e+01/ 轮得分 433.01\n",
      "损失函数： 0.0353478\n",
      "时间步 7436000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.202095e+01/ 轮得分 433.01\n",
      "损失函数： 0.0202466\n",
      "时间步 7437000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319438e+01/ 轮得分 433.01\n",
      "损失函数： 0.0282303\n",
      "时间步 7438000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.145274e+01/ 轮得分 433.01\n",
      "损失函数： 0.0375306\n",
      "时间步 7439000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204728e+01/ 轮得分 433.74\n",
      "损失函数： 0.0170645\n",
      "时间步 7440000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242444e+01/ 轮得分 433.74\n",
      "损失函数： 0.0276691\n",
      "时间步 7441000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275254e+01/ 轮得分 433.74\n",
      "损失函数： 0.0258372\n",
      "时间步 7442000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411939e+01/ 轮得分 433.74\n",
      "损失函数： 0.00731319\n",
      "时间步 7443000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231188e+01/ 轮得分 433.74\n",
      "损失函数： 0.0960155\n",
      "时间步 7444000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327767e+01/ 轮得分 434.06\n",
      "损失函数： 0.046583\n",
      "时间步 7445000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229708e+01/ 轮得分 434.06\n",
      "损失函数： 0.00859577\n",
      "时间步 7446000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.063487e+01/ 轮得分 434.06\n",
      "损失函数： 0.0293858\n",
      "时间步 7447000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266205e+01/ 轮得分 434.30\n",
      "损失函数： 0.0521308\n",
      "时间步 7448000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265526e+01/ 轮得分 434.30\n",
      "损失函数： 0.0536112\n",
      "时间步 7449000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224632e+01/ 轮得分 434.30\n",
      "损失函数： 0.0107169\n",
      "时间步 7450000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249471e+01/ 轮得分 434.30\n",
      "损失函数： 0.0300273\n",
      "时间步 7451000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.384610e+01/ 轮得分 434.30\n",
      "损失函数： 0.0349042\n",
      "时间步 7452000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254061e+01/ 轮得分 434.30\n",
      "损失函数： 0.0208315\n",
      "时间步 7453000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289100e+01/ 轮得分 434.30\n",
      "损失函数： 0.0211394\n",
      "时间步 7454000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335993e+01/ 轮得分 434.30\n",
      "损失函数： 0.00894651\n",
      "时间步 7455000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196513e+01/ 轮得分 434.30\n",
      "损失函数： 0.0296632\n",
      "时间步 7456000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.030954e+01/ 轮得分 434.91\n",
      "损失函数： 0.00938993\n",
      "时间步 7457000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198200e+01/ 轮得分 434.59\n",
      "损失函数： 0.0224904\n",
      "时间步 7458000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332610e+01/ 轮得分 434.59\n",
      "损失函数： 0.0146613\n",
      "时间步 7459000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259954e+01/ 轮得分 434.59\n",
      "损失函数： 0.0128982\n",
      "时间步 7460000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295613e+01/ 轮得分 434.59\n",
      "损失函数： 0.020909\n",
      "时间步 7461000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242246e+01/ 轮得分 434.59\n",
      "损失函数： 0.0297216\n",
      "时间步 7462000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.267329e+01/ 轮得分 434.59\n",
      "损失函数： 0.00812537\n",
      "时间步 7463000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.168110e+01/ 轮得分 434.59\n",
      "损失函数： 0.0328507\n",
      "时间步 7464000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254828e+01/ 轮得分 435.08\n",
      "损失函数： 0.022651\n",
      "时间步 7465000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.231148e+01/ 轮得分 435.08\n",
      "损失函数： 0.045766\n",
      "时间步 7466000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.329423e+01/ 轮得分 435.08\n",
      "损失函数： 0.0185587\n",
      "时间步 7467000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258076e+01/ 轮得分 435.08\n",
      "损失函数： 0.0110439\n",
      "时间步 7468000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.179128e+01/ 轮得分 435.08\n",
      "损失函数： 0.0322312\n",
      "时间步 7469000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239824e+01/ 轮得分 435.08\n",
      "损失函数： 0.012949\n",
      "时间步 7470000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.417339e+01/ 轮得分 435.08\n",
      "损失函数： 0.0291374\n",
      "时间步 7471000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277881e+01/ 轮得分 435.08\n",
      "损失函数： 0.028033\n",
      "时间步 7472000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394510e+01/ 轮得分 435.08\n",
      "损失函数： 0.00976881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7473000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301021e+01/ 轮得分 435.08\n",
      "损失函数： 0.0144519\n",
      "时间步 7474000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.093280e+01/ 轮得分 435.08\n",
      "损失函数： 0.0250553\n",
      "时间步 7475000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.447153e+01/ 轮得分 435.68\n",
      "损失函数： 0.0389653\n",
      "时间步 7476000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.553409e+01/ 轮得分 435.68\n",
      "损失函数： 0.0308431\n",
      "时间步 7477000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249322e+01/ 轮得分 435.68\n",
      "损失函数： 0.0217311\n",
      "时间步 7478000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.555144e+01/ 轮得分 435.68\n",
      "损失函数： 0.0335932\n",
      "时间步 7479000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278994e+01/ 轮得分 435.68\n",
      "损失函数： 0.0453611\n",
      "时间步 7480000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.247487e+01/ 轮得分 435.68\n",
      "损失函数： 0.0176203\n",
      "时间步 7481000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.315244e+01/ 轮得分 436.35\n",
      "损失函数： 0.0391028\n",
      "时间步 7482000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.050410e+01/ 轮得分 436.27\n",
      "损失函数： 0.0301078\n",
      "时间步 7483000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.556736e+01/ 轮得分 436.08\n",
      "损失函数： 0.00877213\n",
      "时间步 7484000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.353391e+01/ 轮得分 436.08\n",
      "损失函数： 0.0655332\n",
      "时间步 7485000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279281e+01/ 轮得分 436.08\n",
      "损失函数： 0.0389685\n",
      "时间步 7486000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.145880e+01/ 轮得分 436.08\n",
      "损失函数： 0.018439\n",
      "时间步 7487000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117272e+01/ 轮得分 436.08\n",
      "损失函数： 0.0261922\n",
      "时间步 7488000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.273308e+01/ 轮得分 436.08\n",
      "损失函数： 0.00715842\n",
      "时间步 7489000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.265458e+01/ 轮得分 436.66\n",
      "损失函数： 0.0211642\n",
      "时间步 7490000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366242e+01/ 轮得分 436.65\n",
      "损失函数： 0.0240321\n",
      "时间步 7491000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223166e+01/ 轮得分 436.65\n",
      "损失函数： 0.0246804\n",
      "时间步 7492000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304094e+01/ 轮得分 436.65\n",
      "损失函数： 0.0175225\n",
      "时间步 7493000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335056e+01/ 轮得分 436.65\n",
      "损失函数： 0.0127215\n",
      "时间步 7494000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.115133e+01/ 轮得分 436.65\n",
      "损失函数： 0.0420105\n",
      "时间步 7495000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300203e+01/ 轮得分 437.12\n",
      "损失函数： 0.0353521\n",
      "时间步 7496000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314037e+01/ 轮得分 437.12\n",
      "损失函数： 0.0243874\n",
      "时间步 7497000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177730e+01/ 轮得分 437.12\n",
      "损失函数： 0.0223708\n",
      "时间步 7498000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.407634e+01/ 轮得分 437.12\n",
      "损失函数： 0.0205711\n",
      "时间步 7499000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.425847e+01/ 轮得分 437.12\n",
      "损失函数： 0.0209342\n",
      "时间步 7500000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.295087e+01/ 轮得分 437.12\n",
      "损失函数： 0.0384248\n",
      "时间步 7501000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241860e+01/ 轮得分 437.12\n",
      "损失函数： 0.0339168\n",
      "时间步 7502000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.152827e+01/ 轮得分 437.12\n",
      "损失函数： 0.0173479\n",
      "时间步 7503000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.218852e+01/ 轮得分 437.85\n",
      "损失函数： 0.0424361\n",
      "时间步 7504000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313473e+01/ 轮得分 437.85\n",
      "损失函数： 0.130414\n",
      "时间步 7505000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.214396e+01/ 轮得分 438.01\n",
      "损失函数： 0.0261583\n",
      "时间步 7506000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.277081e+01/ 轮得分 437.81\n",
      "损失函数： 0.0388546\n",
      "时间步 7507000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 8.406464e+00/ 轮得分 437.81\n",
      "损失函数： 0.0176542\n",
      "时间步 7508000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.370715e+01/ 轮得分 437.87\n",
      "损失函数： 0.0323348\n",
      "时间步 7509000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.328339e+01/ 轮得分 437.21\n",
      "损失函数： 0.01029\n",
      "时间步 7510000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363955e+01/ 轮得分 437.16\n",
      "损失函数： 0.014283\n",
      "时间步 7511000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159728e+01/ 轮得分 437.16\n",
      "损失函数： 0.0133684\n",
      "时间步 7512000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258896e+01/ 轮得分 437.16\n",
      "损失函数： 0.0278436\n",
      "时间步 7513000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276359e+01/ 轮得分 437.16\n",
      "损失函数： 0.0272821\n",
      "时间步 7514000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.417684e+01/ 轮得分 437.56\n",
      "损失函数： 0.0270055\n",
      "时间步 7515000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.405186e+01/ 轮得分 437.56\n",
      "损失函数： 0.11012\n",
      "时间步 7516000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389748e+01/ 轮得分 437.56\n",
      "损失函数： 0.0784588\n",
      "时间步 7517000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.152065e+01/ 轮得分 437.97\n",
      "损失函数： 0.0713332\n",
      "时间步 7518000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.481189e+01/ 轮得分 437.97\n",
      "损失函数： 0.0150489\n",
      "时间步 7519000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229956e+01/ 轮得分 437.97\n",
      "损失函数： 0.0284357\n",
      "时间步 7520000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390604e+01/ 轮得分 437.97\n",
      "损失函数： 0.0184697\n",
      "时间步 7521000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.332264e+01/ 轮得分 437.97\n",
      "损失函数： 0.0419489\n",
      "时间步 7522000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325559e+01/ 轮得分 437.97\n",
      "损失函数： 0.0198366\n",
      "时间步 7523000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.303278e+01/ 轮得分 437.97\n",
      "损失函数： 0.0264085\n",
      "时间步 7524000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.198181e+01/ 轮得分 437.97\n",
      "损失函数： 0.0205729\n",
      "时间步 7525000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 7.073417e+00/ 轮得分 437.97\n",
      "损失函数： 0.0119759\n",
      "时间步 7526000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260075e+01/ 轮得分 438.63\n",
      "损失函数： 0.0236469\n",
      "时间步 7527000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310393e+01/ 轮得分 437.52\n",
      "损失函数： 0.0135252\n",
      "时间步 7528000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258926e+01/ 轮得分 437.52\n",
      "损失函数： 0.153994\n",
      "时间步 7529000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246187e+01/ 轮得分 437.52\n",
      "损失函数： 0.0264692\n",
      "时间步 7530000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245389e+01/ 轮得分 437.70\n",
      "损失函数： 0.0527568\n",
      "时间步 7531000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.412909e+01/ 轮得分 437.68\n",
      "损失函数： 0.0324645\n",
      "时间步 7532000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.334723e+01/ 轮得分 437.68\n",
      "损失函数： 0.0244762\n",
      "时间步 7533000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290996e+01/ 轮得分 437.68\n",
      "损失函数： 0.0273585\n",
      "时间步 7534000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391714e+01/ 轮得分 438.05\n",
      "损失函数： 0.0850524\n",
      "时间步 7535000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283818e+01/ 轮得分 438.05\n",
      "损失函数： 0.0363377\n",
      "时间步 7536000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269535e+01/ 轮得分 437.80\n",
      "损失函数： 0.0168271\n",
      "时间步 7537000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299765e+01/ 轮得分 437.80\n",
      "损失函数： 0.0359255\n",
      "时间步 7538000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.253385e+01/ 轮得分 437.80\n",
      "损失函数： 0.02194\n",
      "时间步 7539000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.481146e+01/ 轮得分 437.80\n",
      "损失函数： 0.00627268\n",
      "时间步 7540000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362170e+01/ 轮得分 438.15\n",
      "损失函数： 0.0781605\n",
      "时间步 7541000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279646e+01/ 轮得分 438.15\n",
      "损失函数： 0.0247585\n",
      "时间步 7542000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331925e+01/ 轮得分 438.27\n",
      "损失函数： 0.00461865\n",
      "时间步 7543000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346585e+01/ 轮得分 438.27\n",
      "损失函数： 0.0227476\n",
      "时间步 7544000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.236250e+01/ 轮得分 438.25\n",
      "损失函数： 0.038148\n",
      "时间步 7545000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.165976e+01/ 轮得分 438.25\n",
      "损失函数： 0.0426745\n",
      "时间步 7546000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293085e+01/ 轮得分 438.25\n",
      "损失函数： 0.0467483\n",
      "时间步 7547000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357084e+01/ 轮得分 438.25\n",
      "损失函数： 0.0334517\n",
      "时间步 7548000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268025e+01/ 轮得分 438.25\n",
      "损失函数： 0.0406507\n",
      "时间步 7549000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360305e+01/ 轮得分 438.34\n",
      "损失函数： 0.0492325\n",
      "时间步 7550000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400493e+01/ 轮得分 438.34\n",
      "损失函数： 0.0335007\n",
      "时间步 7551000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324461e+01/ 轮得分 438.34\n",
      "损失函数： 0.0584624\n",
      "时间步 7552000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.400074e+01/ 轮得分 438.34\n",
      "损失函数： 0.0437929\n",
      "时间步 7553000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273348e+01/ 轮得分 438.81\n",
      "损失函数： 0.0280745\n",
      "时间步 7554000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344502e+01/ 轮得分 438.81\n",
      "损失函数： 0.0345537\n",
      "时间步 7555000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306789e+01/ 轮得分 438.81\n",
      "损失函数： 0.0372444\n",
      "时间步 7556000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364727e+01/ 轮得分 438.81\n",
      "损失函数： 0.0266747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7557000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258465e+01/ 轮得分 438.81\n",
      "损失函数： 0.0457017\n",
      "时间步 7558000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281530e+01/ 轮得分 438.81\n",
      "损失函数： 0.0165413\n",
      "时间步 7559000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.410906e+01/ 轮得分 438.81\n",
      "损失函数： 0.0135033\n",
      "时间步 7560000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327162e+01/ 轮得分 438.81\n",
      "损失函数： 0.0192562\n",
      "时间步 7561000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226724e+01/ 轮得分 438.81\n",
      "损失函数： 0.0523341\n",
      "时间步 7562000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.243193e+01/ 轮得分 439.78\n",
      "损失函数： 0.0193294\n",
      "时间步 7563000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315448e+01/ 轮得分 439.78\n",
      "损失函数： 0.0430081\n",
      "时间步 7564000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307575e+01/ 轮得分 439.78\n",
      "损失函数： 0.0229506\n",
      "时间步 7565000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389093e+01/ 轮得分 439.78\n",
      "损失函数： 0.0124087\n",
      "时间步 7566000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.210844e+01/ 轮得分 439.78\n",
      "损失函数： 0.0237542\n",
      "时间步 7567000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.200167e+01/ 轮得分 439.78\n",
      "损失函数： 0.00780896\n",
      "时间步 7568000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263075e+01/ 轮得分 439.78\n",
      "损失函数： 0.011054\n",
      "时间步 7569000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355953e+01/ 轮得分 439.78\n",
      "损失函数： 0.034888\n",
      "时间步 7570000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318742e+01/ 轮得分 439.78\n",
      "损失函数： 0.0280503\n",
      "时间步 7571000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.384924e+01/ 轮得分 440.65\n",
      "损失函数： 0.0321915\n",
      "时间步 7572000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194486e+01/ 轮得分 440.65\n",
      "损失函数： 0.0140065\n",
      "时间步 7573000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.434596e+01/ 轮得分 440.65\n",
      "损失函数： 0.0456749\n",
      "时间步 7574000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383136e+01/ 轮得分 440.65\n",
      "损失函数： 0.0494208\n",
      "时间步 7575000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343061e+01/ 轮得分 440.65\n",
      "损失函数： 0.0170237\n",
      "时间步 7576000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323099e+01/ 轮得分 440.65\n",
      "损失函数： 0.0127184\n",
      "时间步 7577000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308401e+01/ 轮得分 440.65\n",
      "损失函数： 0.0175627\n",
      "时间步 7578000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324881e+01/ 轮得分 440.65\n",
      "损失函数： 0.0256288\n",
      "时间步 7579000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.268345e+01/ 轮得分 440.65\n",
      "损失函数： 0.0211594\n",
      "时间步 7580000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219148e+01/ 轮得分 440.65\n",
      "损失函数： 0.0100429\n",
      "时间步 7581000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.508862e+01/ 轮得分 440.65\n",
      "损失函数： 0.039324\n",
      "时间步 7582000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323188e+01/ 轮得分 440.65\n",
      "损失函数： 0.0163135\n",
      "时间步 7583000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.438042e+01/ 轮得分 440.65\n",
      "损失函数： 0.0120925\n",
      "时间步 7584000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159941e+01/ 轮得分 440.65\n",
      "损失函数： 0.0389322\n",
      "时间步 7585000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.474365e+01/ 轮得分 440.65\n",
      "损失函数： 0.00885958\n",
      "时间步 7586000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.146416e+01/ 轮得分 442.23\n",
      "损失函数： 0.0491345\n",
      "时间步 7587000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.288240e+01/ 轮得分 442.23\n",
      "损失函数： 0.0306005\n",
      "时间步 7588000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.572728e+01/ 轮得分 442.23\n",
      "损失函数： 0.0266143\n",
      "时间步 7589000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.230591e+01/ 轮得分 441.17\n",
      "损失函数： 0.0289453\n",
      "时间步 7590000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.131658e+00/ 轮得分 441.17\n",
      "损失函数： 0.0202174\n",
      "时间步 7591000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286290e+01/ 轮得分 441.17\n",
      "损失函数： 0.0188166\n",
      "时间步 7592000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.384133e+01/ 轮得分 441.17\n",
      "损失函数： 0.0409475\n",
      "时间步 7593000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328818e+01/ 轮得分 441.17\n",
      "损失函数： 0.081886\n",
      "时间步 7594000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.446047e+01/ 轮得分 441.17\n",
      "损失函数： 0.00902013\n",
      "时间步 7595000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.132175e+01/ 轮得分 441.17\n",
      "损失函数： 0.0402024\n",
      "时间步 7596000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.312538e+01/ 轮得分 441.17\n",
      "损失函数： 0.0183402\n",
      "时间步 7597000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266195e+01/ 轮得分 441.17\n",
      "损失函数： 0.0162638\n",
      "时间步 7598000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.392763e+01/ 轮得分 441.85\n",
      "损失函数： 0.0132347\n",
      "时间步 7599000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.413987e+01/ 轮得分 441.85\n",
      "损失函数： 0.0418142\n",
      "时间步 7600000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.166330e+01/ 轮得分 441.85\n",
      "损失函数： 0.0254323\n",
      "时间步 7601000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323462e+01/ 轮得分 441.85\n",
      "损失函数： 0.0264823\n",
      "时间步 7602000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.418661e+01/ 轮得分 441.85\n",
      "损失函数： 0.0214517\n",
      "时间步 7603000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.406515e+01/ 轮得分 441.85\n",
      "损失函数： 0.0148569\n",
      "时间步 7604000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.227105e+01/ 轮得分 442.33\n",
      "损失函数： 0.0203238\n",
      "时间步 7605000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340234e+01/ 轮得分 442.33\n",
      "损失函数： 0.0140925\n",
      "时间步 7606000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.244314e+01/ 轮得分 442.33\n",
      "损失函数： 0.0128086\n",
      "时间步 7607000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.318769e+01/ 轮得分 442.33\n",
      "损失函数： 0.00873264\n",
      "时间步 7608000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.365601e+01/ 轮得分 442.33\n",
      "损失函数： 0.0257124\n",
      "时间步 7609000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246701e+01/ 轮得分 442.33\n",
      "损失函数： 0.0152504\n",
      "时间步 7610000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271402e+01/ 轮得分 442.33\n",
      "损失函数： 0.00809989\n",
      "时间步 7611000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.207065e+01/ 轮得分 442.33\n",
      "损失函数： 0.0155639\n",
      "时间步 7612000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.193251e+01/ 轮得分 442.33\n",
      "损失函数： 0.0228053\n",
      "时间步 7613000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.148310e+01/ 轮得分 442.33\n",
      "损失函数： 0.0321067\n",
      "时间步 7614000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318610e+01/ 轮得分 442.33\n",
      "损失函数： 0.0253601\n",
      "时间步 7615000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330073e+01/ 轮得分 443.64\n",
      "损失函数： 0.0244315\n",
      "时间步 7616000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240391e+01/ 轮得分 443.64\n",
      "损失函数： 0.0348441\n",
      "时间步 7617000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259334e+01/ 轮得分 443.64\n",
      "损失函数： 0.0274061\n",
      "时间步 7618000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.413240e+01/ 轮得分 443.64\n",
      "损失函数： 0.0541215\n",
      "时间步 7619000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254647e+01/ 轮得分 443.70\n",
      "损失函数： 0.0104114\n",
      "时间步 7620000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303898e+01/ 轮得分 443.65\n",
      "损失函数： 0.0215527\n",
      "时间步 7621000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162596e+01/ 轮得分 443.65\n",
      "损失函数： 0.00999968\n",
      "时间步 7622000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216527e+01/ 轮得分 443.65\n",
      "损失函数： 0.038524\n",
      "时间步 7623000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448651e+01/ 轮得分 443.12\n",
      "损失函数： 0.0337461\n",
      "时间步 7624000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.405375e+01/ 轮得分 443.12\n",
      "损失函数： 0.0774316\n",
      "时间步 7625000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290318e+01/ 轮得分 443.12\n",
      "损失函数： 0.0202007\n",
      "时间步 7626000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.178667e+01/ 轮得分 442.25\n",
      "损失函数： 0.0110249\n",
      "时间步 7627000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187499e+01/ 轮得分 442.25\n",
      "损失函数： 0.222354\n",
      "时间步 7628000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.154129e+01/ 轮得分 442.25\n",
      "损失函数： 0.0536943\n",
      "时间步 7629000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.300825e+01/ 轮得分 442.25\n",
      "损失函数： 0.0189385\n",
      "时间步 7630000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.158064e+01/ 轮得分 442.25\n",
      "损失函数： 0.0227469\n",
      "时间步 7631000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300807e+01/ 轮得分 442.25\n",
      "损失函数： 0.048129\n",
      "时间步 7632000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237515e+01/ 轮得分 442.25\n",
      "损失函数： 0.0412209\n",
      "时间步 7633000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.237646e+01/ 轮得分 442.25\n",
      "损失函数： 0.00865551\n",
      "时间步 7634000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.467901e+01/ 轮得分 442.25\n",
      "损失函数： 0.01739\n",
      "时间步 7635000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161474e+01/ 轮得分 442.25\n",
      "损失函数： 0.00980749\n",
      "时间步 7636000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287515e+01/ 轮得分 442.25\n",
      "损失函数： 0.0177941\n",
      "时间步 7637000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241065e+01/ 轮得分 442.25\n",
      "损失函数： 0.0307227\n",
      "时间步 7638000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275538e+01/ 轮得分 442.25\n",
      "损失函数： 0.0339358\n",
      "时间步 7639000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.202046e+01/ 轮得分 442.25\n",
      "损失函数： 0.0134825\n",
      "时间步 7640000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344408e+01/ 轮得分 442.25\n",
      "损失函数： 0.00751045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7641000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275310e+01/ 轮得分 442.25\n",
      "损失函数： 0.0867406\n",
      "时间步 7642000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.359000e+01/ 轮得分 442.25\n",
      "损失函数： 0.0283617\n",
      "时间步 7643000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282825e+01/ 轮得分 443.57\n",
      "损失函数： 0.011436\n",
      "时间步 7644000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377293e+01/ 轮得分 443.57\n",
      "损失函数： 0.0193825\n",
      "时间步 7645000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242879e+01/ 轮得分 443.57\n",
      "损失函数： 0.0285763\n",
      "时间步 7646000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.201912e+01/ 轮得分 443.57\n",
      "损失函数： 0.0180583\n",
      "时间步 7647000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.471161e+01/ 轮得分 443.59\n",
      "损失函数： 0.0346986\n",
      "时间步 7648000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228881e+01/ 轮得分 443.59\n",
      "损失函数： 0.0695665\n",
      "时间步 7649000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.154996e+01/ 轮得分 443.59\n",
      "损失函数： 0.0512984\n",
      "时间步 7650000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.185182e+01/ 轮得分 443.59\n",
      "损失函数： 0.0258999\n",
      "时间步 7651000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.435863e+01/ 轮得分 443.49\n",
      "损失函数： 0.0326839\n",
      "时间步 7652000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.253884e+01/ 轮得分 443.49\n",
      "损失函数： 0.0636793\n",
      "时间步 7653000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184826e+01/ 轮得分 443.49\n",
      "损失函数： 0.0205531\n",
      "时间步 7654000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309030e+01/ 轮得分 443.66\n",
      "损失函数： 0.00849108\n",
      "时间步 7655000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327317e+01/ 轮得分 443.66\n",
      "损失函数： 0.0468529\n",
      "时间步 7656000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.286193e+01/ 轮得分 443.66\n",
      "损失函数： 0.0164935\n",
      "时间步 7657000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305838e+01/ 轮得分 443.66\n",
      "损失函数： 0.103493\n",
      "时间步 7658000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194058e+01/ 轮得分 443.66\n",
      "损失函数： 0.0308347\n",
      "时间步 7659000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299663e+01/ 轮得分 443.66\n",
      "损失函数： 0.022017\n",
      "时间步 7660000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303300e+01/ 轮得分 443.66\n",
      "损失函数： 0.0227293\n",
      "时间步 7661000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295138e+01/ 轮得分 443.66\n",
      "损失函数： 0.0112492\n",
      "时间步 7662000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347587e+01/ 轮得分 443.66\n",
      "损失函数： 0.0114442\n",
      "时间步 7663000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281979e+01/ 轮得分 443.66\n",
      "损失函数： 0.0142231\n",
      "时间步 7664000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244673e+01/ 轮得分 443.66\n",
      "损失函数： 0.0499113\n",
      "时间步 7665000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.215863e+01/ 轮得分 443.66\n",
      "损失函数： 0.0184452\n",
      "时间步 7666000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278981e+01/ 轮得分 443.66\n",
      "损失函数： 0.0313749\n",
      "时间步 7667000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.436410e+01/ 轮得分 443.66\n",
      "损失函数： 0.01282\n",
      "时间步 7668000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.338230e+01/ 轮得分 443.66\n",
      "损失函数： 0.00996091\n",
      "时间步 7669000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306822e+01/ 轮得分 443.66\n",
      "损失函数： 0.0462429\n",
      "时间步 7670000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191928e+01/ 轮得分 443.66\n",
      "损失函数： 0.0138424\n",
      "时间步 7671000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.247113e+01/ 轮得分 443.66\n",
      "损失函数： 0.0187792\n",
      "时间步 7672000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347441e+01/ 轮得分 443.66\n",
      "损失函数： 0.0480946\n",
      "时间步 7673000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.160940e+01/ 轮得分 445.16\n",
      "损失函数： 0.0191593\n",
      "时间步 7674000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.461654e+01/ 轮得分 445.16\n",
      "损失函数： 0.0350987\n",
      "时间步 7675000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228037e+01/ 轮得分 445.16\n",
      "损失函数： 0.0209768\n",
      "时间步 7676000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.490341e+01/ 轮得分 445.16\n",
      "损失函数： 0.0250868\n",
      "时间步 7677000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224770e+01/ 轮得分 445.16\n",
      "损失函数： 0.0244909\n",
      "时间步 7678000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196378e+01/ 轮得分 445.16\n",
      "损失函数： 0.0173267\n",
      "时间步 7679000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.223318e+01/ 轮得分 445.16\n",
      "损失函数： 0.0319069\n",
      "时间步 7680000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265515e+01/ 轮得分 445.90\n",
      "损失函数： 0.030048\n",
      "时间步 7681000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.427101e+01/ 轮得分 445.90\n",
      "损失函数： 0.0120346\n",
      "时间步 7682000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263885e+01/ 轮得分 445.90\n",
      "损失函数： 0.0249569\n",
      "时间步 7683000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.199971e+01/ 轮得分 445.90\n",
      "损失函数： 0.0205068\n",
      "时间步 7684000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196853e+01/ 轮得分 445.90\n",
      "损失函数： 0.0176864\n",
      "时间步 7685000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221959e+01/ 轮得分 445.90\n",
      "损失函数： 0.025613\n",
      "时间步 7686000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.336865e+01/ 轮得分 445.90\n",
      "损失函数： 0.0190177\n",
      "时间步 7687000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.361642e+01/ 轮得分 446.40\n",
      "损失函数： 0.0271008\n",
      "时间步 7688000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.211259e+01/ 轮得分 446.40\n",
      "损失函数： 0.0497933\n",
      "时间步 7689000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.289250e+01/ 轮得分 446.12\n",
      "损失函数： 0.0150781\n",
      "时间步 7690000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234176e+01/ 轮得分 446.12\n",
      "损失函数： 0.0556528\n",
      "时间步 7691000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291951e+01/ 轮得分 446.12\n",
      "损失函数： 0.0216357\n",
      "时间步 7692000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186915e+01/ 轮得分 446.12\n",
      "损失函数： 0.0405878\n",
      "时间步 7693000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325184e+01/ 轮得分 446.07\n",
      "损失函数： 0.0136867\n",
      "时间步 7694000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284654e+01/ 轮得分 446.07\n",
      "损失函数： 0.0192544\n",
      "时间步 7695000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.359188e+01/ 轮得分 446.07\n",
      "损失函数： 0.0124624\n",
      "时间步 7696000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415161e+01/ 轮得分 446.07\n",
      "损失函数： 0.0500524\n",
      "时间步 7697000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.620096e+01/ 轮得分 446.48\n",
      "损失函数： 0.0310484\n",
      "时间步 7698000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.106732e+01/ 轮得分 446.56\n",
      "损失函数： 0.0163613\n",
      "时间步 7699000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310137e+01/ 轮得分 445.42\n",
      "损失函数： 0.0266064\n",
      "时间步 7700000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.354578e+01/ 轮得分 445.42\n",
      "损失函数： 0.0107363\n",
      "时间步 7701000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233449e+01/ 轮得分 445.42\n",
      "损失函数： 0.0186319\n",
      "时间步 7702000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325280e+01/ 轮得分 445.12\n",
      "损失函数： 0.0364012\n",
      "时间步 7703000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.168892e+01/ 轮得分 445.12\n",
      "损失函数： 0.0175343\n",
      "时间步 7704000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324521e+01/ 轮得分 445.12\n",
      "损失函数： 0.0260398\n",
      "时间步 7705000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.193274e+01/ 轮得分 445.12\n",
      "损失函数： 0.0286828\n",
      "时间步 7706000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.141647e+01/ 轮得分 445.63\n",
      "损失函数： 0.0144274\n",
      "时间步 7707000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.256814e+01/ 轮得分 445.63\n",
      "损失函数： 0.0506918\n",
      "时间步 7708000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.452225e+01/ 轮得分 445.63\n",
      "损失函数： 0.0390725\n",
      "时间步 7709000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.379827e+01/ 轮得分 445.74\n",
      "损失函数： 0.014703\n",
      "时间步 7710000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337401e+01/ 轮得分 445.74\n",
      "损失函数： 0.0170564\n",
      "时间步 7711000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366121e+01/ 轮得分 445.74\n",
      "损失函数： 0.0142597\n",
      "时间步 7712000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222394e+01/ 轮得分 445.74\n",
      "损失函数： 0.0102454\n",
      "时间步 7713000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339388e+01/ 轮得分 446.09\n",
      "损失函数： 0.0233421\n",
      "时间步 7714000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.137503e+01/ 轮得分 445.73\n",
      "损失函数： 0.464076\n",
      "时间步 7715000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.269273e+01/ 轮得分 445.73\n",
      "损失函数： 0.0140687\n",
      "时间步 7716000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.528537e+01/ 轮得分 445.73\n",
      "损失函数： 0.0245812\n",
      "时间步 7717000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.121325e+01/ 轮得分 445.73\n",
      "损失函数： 0.0347071\n",
      "时间步 7718000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387885e+01/ 轮得分 445.25\n",
      "损失函数： 0.0390876\n",
      "时间步 7719000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.272176e+01/ 轮得分 445.25\n",
      "损失函数： 0.0193335\n",
      "时间步 7720000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372992e+01/ 轮得分 445.25\n",
      "损失函数： 0.0302957\n",
      "时间步 7721000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.077359e+01/ 轮得分 445.25\n",
      "损失函数： 0.0393129\n",
      "时间步 7722000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.397105e+01/ 轮得分 445.25\n",
      "损失函数： 0.0637117\n",
      "时间步 7723000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364000e+01/ 轮得分 445.51\n",
      "损失函数： 0.0715832\n",
      "时间步 7724000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322764e+01/ 轮得分 445.51\n",
      "损失函数： 0.0200208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7725000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283705e+01/ 轮得分 445.35\n",
      "损失函数： 0.0351916\n",
      "时间步 7726000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198152e+01/ 轮得分 445.35\n",
      "损失函数： 0.0448063\n",
      "时间步 7727000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.164777e+01/ 轮得分 445.19\n",
      "损失函数： 0.018958\n",
      "时间步 7728000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.400749e+01/ 轮得分 445.19\n",
      "损失函数： 0.0464141\n",
      "时间步 7729000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.105662e+01/ 轮得分 445.22\n",
      "损失函数： 0.0215237\n",
      "时间步 7730000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.145688e+01/ 轮得分 445.22\n",
      "损失函数： 0.0342804\n",
      "时间步 7731000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.381465e+01/ 轮得分 445.22\n",
      "损失函数： 0.00748715\n",
      "时间步 7732000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240027e+01/ 轮得分 445.48\n",
      "损失函数： 0.0087482\n",
      "时间步 7733000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.247983e+01/ 轮得分 445.48\n",
      "损失函数： 0.0261892\n",
      "时间步 7734000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432398e+01/ 轮得分 445.48\n",
      "损失函数： 0.0509177\n",
      "时间步 7735000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345912e+01/ 轮得分 445.48\n",
      "损失函数： 0.0140911\n",
      "时间步 7736000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241156e+01/ 轮得分 445.85\n",
      "损失函数： 0.0207572\n",
      "时间步 7737000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.128220e+01/ 轮得分 445.85\n",
      "损失函数： 0.0318558\n",
      "时间步 7738000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.398973e+01/ 轮得分 445.85\n",
      "损失函数： 0.0660485\n",
      "时间步 7739000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.374021e+01/ 轮得分 445.85\n",
      "损失函数： 0.0218165\n",
      "时间步 7740000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.426256e+01/ 轮得分 445.85\n",
      "损失函数： 0.0371839\n",
      "时间步 7741000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196907e+01/ 轮得分 445.85\n",
      "损失函数： 0.017779\n",
      "时间步 7742000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285233e+01/ 轮得分 445.85\n",
      "损失函数： 0.0546178\n",
      "时间步 7743000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.317030e+01/ 轮得分 445.85\n",
      "损失函数： 0.0174218\n",
      "时间步 7744000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.299958e+01/ 轮得分 445.85\n",
      "损失函数： 0.0243587\n",
      "时间步 7745000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341968e+01/ 轮得分 445.85\n",
      "损失函数： 0.0437137\n",
      "时间步 7746000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.489803e+01/ 轮得分 445.85\n",
      "损失函数： 0.0526705\n",
      "时间步 7747000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193100e+01/ 轮得分 446.54\n",
      "损失函数： 0.0671144\n",
      "时间步 7748000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.488054e+01/ 轮得分 446.54\n",
      "损失函数： 0.0256269\n",
      "时间步 7749000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.365026e+01/ 轮得分 446.70\n",
      "损失函数： 0.0197714\n",
      "时间步 7750000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.432913e+01/ 轮得分 446.70\n",
      "损失函数： 0.0433416\n",
      "时间步 7751000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.136150e+01/ 轮得分 446.70\n",
      "损失函数： 0.0203669\n",
      "时间步 7752000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.359632e+01/ 轮得分 446.70\n",
      "损失函数： 0.021425\n",
      "时间步 7753000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.253142e+01/ 轮得分 446.66\n",
      "损失函数： 0.0199977\n",
      "时间步 7754000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347477e+01/ 轮得分 446.66\n",
      "损失函数： 0.0150056\n",
      "时间步 7755000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271164e+01/ 轮得分 446.79\n",
      "损失函数： 0.0303152\n",
      "时间步 7756000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.510929e+01/ 轮得分 446.42\n",
      "损失函数： 0.0550596\n",
      "时间步 7757000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316541e+01/ 轮得分 446.42\n",
      "损失函数： 0.047772\n",
      "时间步 7758000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365119e+01/ 轮得分 446.42\n",
      "损失函数： 0.0327863\n",
      "时间步 7759000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.169630e+01/ 轮得分 446.73\n",
      "损失函数： 0.0503788\n",
      "时间步 7760000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254693e+01/ 轮得分 446.73\n",
      "损失函数： 0.0370453\n",
      "时间步 7761000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.364043e+01/ 轮得分 446.73\n",
      "损失函数： 0.0322563\n",
      "时间步 7762000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.546627e+01/ 轮得分 446.73\n",
      "损失函数： 0.0342468\n",
      "时间步 7763000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.124373e+01/ 轮得分 446.73\n",
      "损失函数： 0.0612907\n",
      "时间步 7764000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.134183e+01/ 轮得分 446.73\n",
      "损失函数： 0.0514871\n",
      "时间步 7765000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387916e+01/ 轮得分 446.73\n",
      "损失函数： 0.0318287\n",
      "时间步 7766000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207588e+01/ 轮得分 446.73\n",
      "损失函数： 0.04547\n",
      "时间步 7767000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.505726e+01/ 轮得分 446.73\n",
      "损失函数： 0.0242303\n",
      "时间步 7768000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.081357e+01/ 轮得分 447.34\n",
      "损失函数： 0.018625\n",
      "时间步 7769000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.448769e+01/ 轮得分 447.11\n",
      "损失函数： 0.00655481\n",
      "时间步 7770000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388330e+01/ 轮得分 447.11\n",
      "损失函数： 0.0487153\n",
      "时间步 7771000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240213e+01/ 轮得分 447.11\n",
      "损失函数： 0.0168879\n",
      "时间步 7772000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161728e+01/ 轮得分 447.11\n",
      "损失函数： 0.362292\n",
      "时间步 7773000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.332027e+01/ 轮得分 447.57\n",
      "损失函数： 0.0272269\n",
      "时间步 7774000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.483570e+01/ 轮得分 447.25\n",
      "损失函数： 0.0257824\n",
      "时间步 7775000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.422851e+01/ 轮得分 447.25\n",
      "损失函数： 0.0376375\n",
      "时间步 7776000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.425833e+01/ 轮得分 447.25\n",
      "损失函数： 0.013566\n",
      "时间步 7777000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.140591e+01/ 轮得分 447.25\n",
      "损失函数： 0.0242672\n",
      "时间步 7778000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180848e+01/ 轮得分 447.25\n",
      "损失函数： 0.0205453\n",
      "时间步 7779000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204977e+01/ 轮得分 447.25\n",
      "损失函数： 0.0696445\n",
      "时间步 7780000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.388178e+01/ 轮得分 447.25\n",
      "损失函数： 0.0319845\n",
      "时间步 7781000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.380552e+01/ 轮得分 447.25\n",
      "损失函数： 0.0224637\n",
      "时间步 7782000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201756e+01/ 轮得分 447.25\n",
      "损失函数： 0.0382615\n",
      "时间步 7783000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288962e+01/ 轮得分 447.25\n",
      "损失函数： 0.0312798\n",
      "时间步 7784000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.213796e+01/ 轮得分 447.25\n",
      "损失函数： 0.0160163\n",
      "时间步 7785000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290098e+01/ 轮得分 448.42\n",
      "损失函数： 0.0440981\n",
      "时间步 7786000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388973e+01/ 轮得分 448.42\n",
      "损失函数： 0.0305771\n",
      "时间步 7787000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203222e+01/ 轮得分 448.42\n",
      "损失函数： 0.042902\n",
      "时间步 7788000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.258872e+01/ 轮得分 448.42\n",
      "损失函数： 0.0138126\n",
      "时间步 7789000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.380316e+01/ 轮得分 448.61\n",
      "损失函数： 0.053585\n",
      "时间步 7790000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.356695e+01/ 轮得分 448.61\n",
      "损失函数： 0.0620063\n",
      "时间步 7791000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.198187e+01/ 轮得分 448.61\n",
      "损失函数： 0.0275436\n",
      "时间步 7792000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.501884e+01/ 轮得分 448.61\n",
      "损失函数： 0.0257684\n",
      "时间步 7793000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.454822e+01/ 轮得分 448.61\n",
      "损失函数： 0.0537987\n",
      "时间步 7794000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.403125e+01/ 轮得分 448.97\n",
      "损失函数： 0.0776215\n",
      "时间步 7795000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184067e+01/ 轮得分 448.35\n",
      "损失函数： 0.013735\n",
      "时间步 7796000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.133160e+01/ 轮得分 448.39\n",
      "损失函数： 0.0113306\n",
      "时间步 7797000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.370413e+01/ 轮得分 448.39\n",
      "损失函数： 0.00612029\n",
      "时间步 7798000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414425e+01/ 轮得分 448.39\n",
      "损失函数： 0.0523358\n",
      "时间步 7799000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.373513e+01/ 轮得分 448.39\n",
      "损失函数： 0.0364103\n",
      "时间步 7800000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203197e+01/ 轮得分 448.39\n",
      "损失函数： 0.0177686\n",
      "时间步 7801000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251635e+01/ 轮得分 448.39\n",
      "损失函数： 0.0665825\n",
      "时间步 7802000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.371878e+01/ 轮得分 449.00\n",
      "损失函数： 0.0186602\n",
      "时间步 7803000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.329174e+01/ 轮得分 449.00\n",
      "损失函数： 0.0451122\n",
      "时间步 7804000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.142407e+01/ 轮得分 449.00\n",
      "损失函数： 0.0200676\n",
      "时间步 7805000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.043296e+01/ 轮得分 449.00\n",
      "损失函数： 0.0390823\n",
      "时间步 7806000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.527474e+01/ 轮得分 449.35\n",
      "损失函数： 0.0280415\n",
      "时间步 7807000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330619e+01/ 轮得分 449.35\n",
      "损失函数： 0.0240895\n",
      "时间步 7808000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.149298e+01/ 轮得分 449.35\n",
      "损失函数： 0.0318134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7809000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.426126e+01/ 轮得分 449.42\n",
      "损失函数： 0.0484333\n",
      "时间步 7810000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.340265e+01/ 轮得分 449.42\n",
      "损失函数： 0.0440142\n",
      "时间步 7811000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.435911e+01/ 轮得分 449.42\n",
      "损失函数： 0.0265332\n",
      "时间步 7812000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.475288e+01/ 轮得分 449.42\n",
      "损失函数： 0.0102948\n",
      "时间步 7813000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.334789e+01/ 轮得分 448.55\n",
      "损失函数： 0.0115931\n",
      "时间步 7814000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233334e+01/ 轮得分 448.55\n",
      "损失函数： 0.0366373\n",
      "时间步 7815000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.344963e+01/ 轮得分 448.55\n",
      "损失函数： 0.0280051\n",
      "时间步 7816000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331658e+01/ 轮得分 448.55\n",
      "损失函数： 0.0186982\n",
      "时间步 7817000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192450e+01/ 轮得分 448.55\n",
      "损失函数： 0.00514655\n",
      "时间步 7818000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187356e+01/ 轮得分 448.55\n",
      "损失函数： 0.030971\n",
      "时间步 7819000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.339219e+01/ 轮得分 448.55\n",
      "损失函数： 0.0147789\n",
      "时间步 7820000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255411e+01/ 轮得分 448.55\n",
      "损失函数： 0.0176966\n",
      "时间步 7821000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189340e+01/ 轮得分 448.55\n",
      "损失函数： 0.022872\n",
      "时间步 7822000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.146411e+01/ 轮得分 448.55\n",
      "损失函数： 0.0219757\n",
      "时间步 7823000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.398760e+01/ 轮得分 448.55\n",
      "损失函数： 0.0263711\n",
      "时间步 7824000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378758e+01/ 轮得分 448.55\n",
      "损失函数： 0.0364064\n",
      "时间步 7825000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319361e+01/ 轮得分 449.68\n",
      "损失函数： 0.0345437\n",
      "时间步 7826000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248107e+01/ 轮得分 449.68\n",
      "损失函数： 0.0169815\n",
      "时间步 7827000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343997e+01/ 轮得分 449.68\n",
      "损失函数： 0.0132427\n",
      "时间步 7828000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271703e+01/ 轮得分 449.68\n",
      "损失函数： 0.0236557\n",
      "时间步 7829000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.199392e+01/ 轮得分 449.68\n",
      "损失函数： 0.0312773\n",
      "时间步 7830000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.095043e+01/ 轮得分 450.37\n",
      "损失函数： 0.0384845\n",
      "时间步 7831000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352416e+01/ 轮得分 450.37\n",
      "损失函数： 0.0100167\n",
      "时间步 7832000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.412375e+01/ 轮得分 450.37\n",
      "损失函数： 0.0102476\n",
      "时间步 7833000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.287434e+01/ 轮得分 450.37\n",
      "损失函数： 0.0279212\n",
      "时间步 7834000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244321e+01/ 轮得分 450.37\n",
      "损失函数： 0.0259631\n",
      "时间步 7835000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254589e+01/ 轮得分 450.37\n",
      "损失函数： 0.0392393\n",
      "时间步 7836000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.217662e+01/ 轮得分 450.37\n",
      "损失函数： 0.0133258\n",
      "时间步 7837000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.214588e+01/ 轮得分 450.37\n",
      "损失函数： 0.0175856\n",
      "时间步 7838000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.125467e+01/ 轮得分 450.37\n",
      "损失函数： 0.0210884\n",
      "时间步 7839000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327758e+01/ 轮得分 450.37\n",
      "损失函数： 0.0372002\n",
      "时间步 7840000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260311e+01/ 轮得分 450.37\n",
      "损失函数： 0.0163352\n",
      "时间步 7841000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375246e+01/ 轮得分 451.45\n",
      "损失函数： 0.054268\n",
      "时间步 7842000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.187420e+01/ 轮得分 450.78\n",
      "损失函数： 0.0108515\n",
      "时间步 7843000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254922e+01/ 轮得分 450.78\n",
      "损失函数： 0.031146\n",
      "时间步 7844000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.427284e+01/ 轮得分 450.78\n",
      "损失函数： 0.151216\n",
      "时间步 7845000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.419054e+01/ 轮得分 450.78\n",
      "损失函数： 0.0236427\n",
      "时间步 7846000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.141798e+01/ 轮得分 450.41\n",
      "损失函数： 0.0281013\n",
      "时间步 7847000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.141193e+01/ 轮得分 450.09\n",
      "损失函数： 0.037857\n",
      "时间步 7848000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202120e+01/ 轮得分 450.09\n",
      "损失函数： 0.0322157\n",
      "时间步 7849000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.143350e+01/ 轮得分 450.11\n",
      "损失函数： 0.0277607\n",
      "时间步 7850000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.408347e+01/ 轮得分 450.11\n",
      "损失函数： 0.0593993\n",
      "时间步 7851000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355042e+01/ 轮得分 450.11\n",
      "损失函数： 0.0143735\n",
      "时间步 7852000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.302208e+01/ 轮得分 450.11\n",
      "损失函数： 0.0641986\n",
      "时间步 7853000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.642066e+00/ 轮得分 450.11\n",
      "损失函数： 0.0256839\n",
      "时间步 7854000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221510e+01/ 轮得分 449.40\n",
      "损失函数： 0.0365247\n",
      "时间步 7855000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278566e+01/ 轮得分 449.40\n",
      "损失函数： 0.0349764\n",
      "时间步 7856000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.421949e+01/ 轮得分 449.40\n",
      "损失函数： 0.0348892\n",
      "时间步 7857000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301207e+01/ 轮得分 449.40\n",
      "损失函数： 0.0229398\n",
      "时间步 7858000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229664e+01/ 轮得分 449.40\n",
      "损失函数： 0.0490315\n",
      "时间步 7859000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.283937e+01/ 轮得分 449.40\n",
      "损失函数： 0.011191\n",
      "时间步 7860000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.387572e+01/ 轮得分 449.40\n",
      "损失函数： 0.0437356\n",
      "时间步 7861000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270418e+01/ 轮得分 449.40\n",
      "损失函数： 0.054758\n",
      "时间步 7862000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229627e+01/ 轮得分 449.40\n",
      "损失函数： 0.0309191\n",
      "时间步 7863000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.143194e+01/ 轮得分 449.40\n",
      "损失函数： 0.0376884\n",
      "时间步 7864000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.450970e+01/ 轮得分 449.40\n",
      "损失函数： 0.0229658\n",
      "时间步 7865000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.284903e+01/ 轮得分 450.55\n",
      "损失函数： 0.0104801\n",
      "时间步 7866000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228523e+01/ 轮得分 450.55\n",
      "损失函数： 0.0202371\n",
      "时间步 7867000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.133512e+01/ 轮得分 450.55\n",
      "损失函数： 0.0366904\n",
      "时间步 7868000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162757e+01/ 轮得分 450.55\n",
      "损失函数： 0.0356774\n",
      "时间步 7869000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276272e+01/ 轮得分 450.55\n",
      "损失函数： 0.0186714\n",
      "时间步 7870000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249074e+01/ 轮得分 450.55\n",
      "损失函数： 0.0136023\n",
      "时间步 7871000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.409671e+01/ 轮得分 451.13\n",
      "损失函数： 0.0301876\n",
      "时间步 7872000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343429e+01/ 轮得分 451.13\n",
      "损失函数： 0.432254\n",
      "时间步 7873000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.485292e+01/ 轮得分 451.13\n",
      "损失函数： 0.0323462\n",
      "时间步 7874000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279255e+01/ 轮得分 451.21\n",
      "损失函数： 0.0293475\n",
      "时间步 7875000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233059e+01/ 轮得分 451.21\n",
      "损失函数： 0.0263096\n",
      "时间步 7876000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.223802e+01/ 轮得分 451.38\n",
      "损失函数： 0.0293156\n",
      "时间步 7877000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255138e+01/ 轮得分 451.38\n",
      "损失函数： 0.0316823\n",
      "时间步 7878000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189198e+01/ 轮得分 451.40\n",
      "损失函数： 0.0288076\n",
      "时间步 7879000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.290166e+01/ 轮得分 451.40\n",
      "损失函数： 0.0625871\n",
      "时间步 7880000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.401198e+01/ 轮得分 451.40\n",
      "损失函数： 0.0757195\n",
      "时间步 7881000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271260e+01/ 轮得分 451.40\n",
      "损失函数： 0.0551215\n",
      "时间步 7882000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366049e+01/ 轮得分 451.40\n",
      "损失函数： 0.0437118\n",
      "时间步 7883000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.325080e+01/ 轮得分 451.40\n",
      "损失函数： 0.00649397\n",
      "时间步 7884000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237743e+01/ 轮得分 451.40\n",
      "损失函数： 0.0372754\n",
      "时间步 7885000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367448e+01/ 轮得分 451.40\n",
      "损失函数： 0.0304104\n",
      "时间步 7886000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221732e+01/ 轮得分 451.40\n",
      "损失函数： 0.0639068\n",
      "时间步 7887000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362580e+01/ 轮得分 451.40\n",
      "损失函数： 0.0200073\n",
      "时间步 7888000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219581e+01/ 轮得分 451.40\n",
      "损失函数： 0.0208333\n",
      "时间步 7889000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.318283e+01/ 轮得分 452.71\n",
      "损失函数： 0.0144111\n",
      "时间步 7890000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316788e+01/ 轮得分 452.71\n",
      "损失函数： 0.0375581\n",
      "时间步 7891000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298219e+01/ 轮得分 452.71\n",
      "损失函数： 0.0229841\n",
      "时间步 7892000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.219372e+01/ 轮得分 452.71\n",
      "损失函数： 0.0962017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7893000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.132219e+01/ 轮得分 452.71\n",
      "损失函数： 0.0146854\n",
      "时间步 7894000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290170e+01/ 轮得分 452.71\n",
      "损失函数： 0.0168784\n",
      "时间步 7895000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327923e+01/ 轮得分 452.71\n",
      "损失函数： 0.0472674\n",
      "时间步 7896000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415712e+01/ 轮得分 452.71\n",
      "损失函数： 0.0367535\n",
      "时间步 7897000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321276e+01/ 轮得分 453.63\n",
      "损失函数： 0.0129472\n",
      "时间步 7898000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315751e+01/ 轮得分 453.63\n",
      "损失函数： 0.0142566\n",
      "时间步 7899000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.380847e+01/ 轮得分 453.63\n",
      "损失函数： 0.0191767\n",
      "时间步 7900000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225582e+01/ 轮得分 453.63\n",
      "损失函数： 0.072152\n",
      "时间步 7901000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.280250e+01/ 轮得分 453.98\n",
      "损失函数： 0.020012\n",
      "时间步 7902000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360845e+01/ 轮得分 453.98\n",
      "损失函数： 0.0256061\n",
      "时间步 7903000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266876e+01/ 轮得分 453.78\n",
      "损失函数： 0.0581565\n",
      "时间步 7904000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207705e+01/ 轮得分 453.78\n",
      "损失函数： 0.0201963\n",
      "时间步 7905000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.196113e+01/ 轮得分 453.78\n",
      "损失函数： 0.0380149\n",
      "时间步 7906000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.519848e+01/ 轮得分 453.78\n",
      "损失函数： 0.0203221\n",
      "时间步 7907000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255225e+01/ 轮得分 454.24\n",
      "损失函数： 0.0151404\n",
      "时间步 7908000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220866e+01/ 轮得分 454.24\n",
      "损失函数： 0.0273119\n",
      "时间步 7909000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262092e+01/ 轮得分 454.24\n",
      "损失函数： 0.0333287\n",
      "时间步 7910000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.215191e+01/ 轮得分 454.24\n",
      "损失函数： 0.0190664\n",
      "时间步 7911000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352168e+01/ 轮得分 454.24\n",
      "损失函数： 0.0277624\n",
      "时间步 7912000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365178e+01/ 轮得分 454.24\n",
      "损失函数： 0.0179449\n",
      "时间步 7913000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366716e+01/ 轮得分 454.24\n",
      "损失函数： 0.0258475\n",
      "时间步 7914000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.398771e+01/ 轮得分 454.24\n",
      "损失函数： 0.0331625\n",
      "时间步 7915000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.128541e+01/ 轮得分 454.24\n",
      "损失函数： 0.0251547\n",
      "时间步 7916000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.349016e+01/ 轮得分 454.24\n",
      "损失函数： 0.0491137\n",
      "时间步 7917000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.214057e+01/ 轮得分 454.24\n",
      "损失函数： 0.0503958\n",
      "时间步 7918000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296227e+01/ 轮得分 454.24\n",
      "损失函数： 0.0149046\n",
      "时间步 7919000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.231446e+01/ 轮得分 455.33\n",
      "损失函数： 0.019488\n",
      "时间步 7920000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313311e+01/ 轮得分 455.33\n",
      "损失函数： 0.0139987\n",
      "时间步 7921000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.072019e+01/ 轮得分 455.33\n",
      "损失函数： 0.0317433\n",
      "时间步 7922000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309391e+01/ 轮得分 455.33\n",
      "损失函数： 0.0143557\n",
      "时间步 7923000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.324258e+01/ 轮得分 455.33\n",
      "损失函数： 0.0257824\n",
      "时间步 7924000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318128e+01/ 轮得分 455.33\n",
      "损失函数： 0.0223667\n",
      "时间步 7925000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.155733e+01/ 轮得分 456.02\n",
      "损失函数： 0.0144056\n",
      "时间步 7926000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.538742e+01/ 轮得分 456.02\n",
      "损失函数： 0.0297662\n",
      "时间步 7927000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346292e+01/ 轮得分 456.02\n",
      "损失函数： 0.0188031\n",
      "时间步 7928000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.379607e+01/ 轮得分 455.53\n",
      "损失函数： 0.0765194\n",
      "时间步 7929000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.369365e+01/ 轮得分 455.53\n",
      "损失函数： 0.0155583\n",
      "时间步 7930000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165981e+01/ 轮得分 455.53\n",
      "损失函数： 0.270904\n",
      "时间步 7931000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.249690e+01/ 轮得分 455.53\n",
      "损失函数： 0.0296248\n",
      "时间步 7932000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.524897e+01/ 轮得分 455.53\n",
      "损失函数： 0.0192021\n",
      "时间步 7933000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.163657e+01/ 轮得分 455.64\n",
      "损失函数： 0.0182279\n",
      "时间步 7934000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.410192e+01/ 轮得分 455.10\n",
      "损失函数： 0.119603\n",
      "时间步 7935000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.419461e+01/ 轮得分 455.10\n",
      "损失函数： 0.0409819\n",
      "时间步 7936000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205712e+01/ 轮得分 455.10\n",
      "损失函数： 0.0224916\n",
      "时间步 7937000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.152790e+01/ 轮得分 455.25\n",
      "损失函数： 0.0163098\n",
      "时间步 7938000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266371e+01/ 轮得分 455.25\n",
      "损失函数： 0.016597\n",
      "时间步 7939000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.306121e+01/ 轮得分 455.25\n",
      "损失函数： 0.0377039\n",
      "时间步 7940000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306937e+01/ 轮得分 455.25\n",
      "损失函数： 0.0147263\n",
      "时间步 7941000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.263795e+01/ 轮得分 455.60\n",
      "损失函数： 0.0262619\n",
      "时间步 7942000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.127566e+01/ 轮得分 455.26\n",
      "损失函数： 0.0221973\n",
      "时间步 7943000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.171226e+01/ 轮得分 455.26\n",
      "损失函数： 0.0108588\n",
      "时间步 7944000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292023e+01/ 轮得分 455.26\n",
      "损失函数： 0.0211746\n",
      "时间步 7945000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346277e+01/ 轮得分 455.26\n",
      "损失函数： 0.0313181\n",
      "时间步 7946000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.265423e+01/ 轮得分 454.93\n",
      "损失函数： 0.0784006\n",
      "时间步 7947000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275223e+01/ 轮得分 455.04\n",
      "损失函数： 0.0304197\n",
      "时间步 7948000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344579e+01/ 轮得分 455.04\n",
      "损失函数： 0.0385328\n",
      "时间步 7949000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238835e+01/ 轮得分 455.22\n",
      "损失函数： 0.0236004\n",
      "时间步 7950000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310105e+01/ 轮得分 455.22\n",
      "损失函数： 0.200658\n",
      "时间步 7951000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.247309e+01/ 轮得分 455.22\n",
      "损失函数： 0.0215941\n",
      "时间步 7952000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196001e+01/ 轮得分 455.25\n",
      "损失函数： 0.0204478\n",
      "时间步 7953000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.164444e+01/ 轮得分 453.43\n",
      "损失函数： 0.0339427\n",
      "时间步 7954000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.294998e+01/ 轮得分 453.43\n",
      "损失函数： 0.047896\n",
      "时间步 7955000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208692e+01/ 轮得分 453.43\n",
      "损失函数： 0.0431299\n",
      "时间步 7956000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.296671e+01/ 轮得分 453.43\n",
      "损失函数： 0.025269\n",
      "时间步 7957000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.315094e+01/ 轮得分 453.43\n",
      "损失函数： 0.0419319\n",
      "时间步 7958000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.358326e+01/ 轮得分 453.82\n",
      "损失函数： 0.030974\n",
      "时间步 7959000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378725e+01/ 轮得分 453.82\n",
      "损失函数： 0.0292786\n",
      "时间步 7960000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.425982e+01/ 轮得分 453.97\n",
      "损失函数： 0.108886\n",
      "时间步 7961000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355243e+01/ 轮得分 453.45\n",
      "损失函数： 0.0425022\n",
      "时间步 7962000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.281539e+01/ 轮得分 453.45\n",
      "损失函数： 0.015834\n",
      "时间步 7963000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337741e+01/ 轮得分 453.45\n",
      "损失函数： 0.0174699\n",
      "时间步 7964000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.348531e+01/ 轮得分 453.45\n",
      "损失函数： 0.0229263\n",
      "时间步 7965000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196049e+01/ 轮得分 453.45\n",
      "损失函数： 0.0255219\n",
      "时间步 7966000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 6.746437e+00/ 轮得分 453.60\n",
      "损失函数： 0.0498997\n",
      "时间步 7967000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365785e+01/ 轮得分 453.60\n",
      "损失函数： 0.0218584\n",
      "时间步 7968000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.378715e+01/ 轮得分 453.60\n",
      "损失函数： 0.0689546\n",
      "时间步 7969000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302772e+01/ 轮得分 453.55\n",
      "损失函数： 0.0174726\n",
      "时间步 7970000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.485405e+01/ 轮得分 453.58\n",
      "损失函数： 0.06766\n",
      "时间步 7971000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.221313e+01/ 轮得分 452.57\n",
      "损失函数： 0.0789946\n",
      "时间步 7972000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.241147e+01/ 轮得分 452.57\n",
      "损失函数： 0.0347169\n",
      "时间步 7973000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331750e+01/ 轮得分 452.57\n",
      "损失函数： 0.0357103\n",
      "时间步 7974000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291645e+01/ 轮得分 452.66\n",
      "损失函数： 0.0291504\n",
      "时间步 7975000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.225110e+01/ 轮得分 452.66\n",
      "损失函数： 0.0139249\n",
      "时间步 7976000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.313982e+01/ 轮得分 452.66\n",
      "损失函数： 0.0798686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 7977000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.199852e+01/ 轮得分 452.66\n",
      "损失函数： 0.0714895\n",
      "时间步 7978000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.513978e+01/ 轮得分 452.66\n",
      "损失函数： 0.0223801\n",
      "时间步 7979000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.128089e+01/ 轮得分 452.66\n",
      "损失函数： 0.0220967\n",
      "时间步 7980000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337213e+01/ 轮得分 452.66\n",
      "损失函数： 0.0336311\n",
      "时间步 7981000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299159e+01/ 轮得分 452.66\n",
      "损失函数： 0.00846806\n",
      "时间步 7982000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.288760e+01/ 轮得分 452.66\n",
      "损失函数： 0.0124739\n",
      "时间步 7983000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270576e+01/ 轮得分 452.66\n",
      "损失函数： 0.0311708\n",
      "时间步 7984000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396230e+01/ 轮得分 452.66\n",
      "损失函数： 0.0288518\n",
      "时间步 7985000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.311171e+01/ 轮得分 452.66\n",
      "损失函数： 1.71674\n",
      "时间步 7986000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.086578e+01/ 轮得分 453.43\n",
      "损失函数： 0.00595536\n",
      "时间步 7987000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206208e+01/ 轮得分 453.43\n",
      "损失函数： 0.0195472\n",
      "时间步 7988000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.159060e+01/ 轮得分 453.43\n",
      "损失函数： 0.0216997\n",
      "时间步 7989000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.390731e+01/ 轮得分 452.57\n",
      "损失函数： 0.0230733\n",
      "时间步 7990000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.071584e+01/ 轮得分 452.63\n",
      "损失函数： 0.0295357\n",
      "时间步 7991000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255364e+01/ 轮得分 452.72\n",
      "损失函数： 0.0161029\n",
      "时间步 7992000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.200957e+01/ 轮得分 452.72\n",
      "损失函数： 0.017944\n",
      "时间步 7993000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 7.637206e+00/ 轮得分 452.72\n",
      "损失函数： 0.0893487\n",
      "时间步 7994000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293542e+01/ 轮得分 452.41\n",
      "损失函数： 0.0149062\n",
      "时间步 7995000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.094595e+01/ 轮得分 452.41\n",
      "损失函数： 0.0197202\n",
      "时间步 7996000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393524e+01/ 轮得分 452.41\n",
      "损失函数： 0.0153605\n",
      "时间步 7997000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.155296e+01/ 轮得分 452.41\n",
      "损失函数： 0.0181678\n",
      "时间步 7998000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220900e+01/ 轮得分 452.41\n",
      "损失函数： 0.0384606\n",
      "时间步 7999000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.399901e+01/ 轮得分 452.41\n",
      "损失函数： 0.0217126\n",
      "时间步 8000000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203495e+01/ 轮得分 452.41\n",
      "损失函数： 0.0390194\n",
      "时间步 8001000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300585e+01/ 轮得分 452.41\n",
      "损失函数： 0.029491\n",
      "时间步 8002000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276664e+01/ 轮得分 452.97\n",
      "损失函数： 0.0122261\n",
      "时间步 8003000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212445e+01/ 轮得分 452.97\n",
      "损失函数： 0.0439058\n",
      "时间步 8004000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.056628e+01/ 轮得分 452.97\n",
      "损失函数： 0.0436532\n",
      "时间步 8005000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289345e+01/ 轮得分 453.23\n",
      "损失函数： 0.032849\n",
      "时间步 8006000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196528e+01/ 轮得分 453.23\n",
      "损失函数： 0.0138959\n",
      "时间步 8007000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.429786e+01/ 轮得分 453.23\n",
      "损失函数： 0.0347577\n",
      "时间步 8008000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.503783e+01/ 轮得分 453.23\n",
      "损失函数： 0.042641\n",
      "时间步 8009000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302581e+01/ 轮得分 453.23\n",
      "损失函数： 0.0375478\n",
      "时间步 8010000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.451925e+01/ 轮得分 453.61\n",
      "损失函数： 0.0157935\n",
      "时间步 8011000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.343733e+01/ 轮得分 453.61\n",
      "损失函数： 0.0493521\n",
      "时间步 8012000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.368105e+01/ 轮得分 453.63\n",
      "损失函数： 0.0713605\n",
      "时间步 8013000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235437e+01/ 轮得分 453.63\n",
      "损失函数： 0.0537653\n",
      "时间步 8014000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 7.387931e+00/ 轮得分 453.63\n",
      "损失函数： 0.0297244\n",
      "时间步 8015000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.535417e+01/ 轮得分 453.63\n",
      "损失函数： 0.0577639\n",
      "时间步 8016000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278791e+01/ 轮得分 453.63\n",
      "损失函数： 0.0376359\n",
      "时间步 8017000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302096e+01/ 轮得分 453.63\n",
      "损失函数： 0.0841693\n",
      "时间步 8018000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.332172e+01/ 轮得分 453.63\n",
      "损失函数： 0.20843\n",
      "时间步 8019000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.249132e+01/ 轮得分 453.63\n",
      "损失函数： 0.0543011\n",
      "时间步 8020000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.537511e+01/ 轮得分 453.63\n",
      "损失函数： 0.0261279\n",
      "时间步 8021000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240635e+01/ 轮得分 453.63\n",
      "损失函数： 0.0245396\n",
      "时间步 8022000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279477e+01/ 轮得分 453.63\n",
      "损失函数： 0.0350159\n",
      "时间步 8023000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342889e+01/ 轮得分 454.10\n",
      "损失函数： 0.020208\n",
      "时间步 8024000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.460642e+01/ 轮得分 454.10\n",
      "损失函数： 0.0264747\n",
      "时间步 8025000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.151225e+01/ 轮得分 454.08\n",
      "损失函数： 0.0151241\n",
      "时间步 8026000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221208e+01/ 轮得分 453.90\n",
      "损失函数： 0.0139938\n",
      "时间步 8027000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.308921e+01/ 轮得分 453.90\n",
      "损失函数： 0.0156947\n",
      "时间步 8028000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389542e+01/ 轮得分 453.90\n",
      "损失函数： 0.0593564\n",
      "时间步 8029000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.458974e+01/ 轮得分 453.90\n",
      "损失函数： 0.0118806\n",
      "时间步 8030000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.404416e+01/ 轮得分 453.90\n",
      "损失函数： 0.0307492\n",
      "时间步 8031000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342430e+01/ 轮得分 453.90\n",
      "损失函数： 0.0199501\n",
      "时间步 8032000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229601e+01/ 轮得分 453.05\n",
      "损失函数： 0.0128228\n",
      "时间步 8033000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.348890e+01/ 轮得分 453.05\n",
      "损失函数： 0.0387985\n",
      "时间步 8034000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.611211e+01/ 轮得分 453.05\n",
      "损失函数： 0.0362155\n",
      "时间步 8035000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.192275e+01/ 轮得分 453.32\n",
      "损失函数： 0.0287326\n",
      "时间步 8036000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.270133e+01/ 轮得分 453.32\n",
      "损失函数： 0.0300916\n",
      "时间步 8037000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323214e+01/ 轮得分 453.32\n",
      "损失函数： 0.0433104\n",
      "时间步 8038000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394727e+01/ 轮得分 452.46\n",
      "损失函数： 0.0288156\n",
      "时间步 8039000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.172543e+01/ 轮得分 452.38\n",
      "损失函数： 0.0453119\n",
      "时间步 8040000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.635896e+01/ 轮得分 452.38\n",
      "损失函数： 0.0410309\n",
      "时间步 8041000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.257550e+01/ 轮得分 452.38\n",
      "损失函数： 0.0252267\n",
      "时间步 8042000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362047e+01/ 轮得分 449.42\n",
      "损失函数： 0.0137412\n",
      "时间步 8043000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300539e+01/ 轮得分 449.42\n",
      "损失函数： 0.035714\n",
      "时间步 8044000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260044e+01/ 轮得分 449.42\n",
      "损失函数： 0.0517566\n",
      "时间步 8045000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263275e+01/ 轮得分 449.42\n",
      "损失函数： 0.0257063\n",
      "时间步 8046000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.033265e+01/ 轮得分 449.42\n",
      "损失函数： 0.036593\n",
      "时间步 8047000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.234166e+01/ 轮得分 449.86\n",
      "损失函数： 0.0259019\n",
      "时间步 8048000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.178782e+01/ 轮得分 449.18\n",
      "损失函数： 0.0478389\n",
      "时间步 8049000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.261891e+01/ 轮得分 449.18\n",
      "损失函数： 0.0238947\n",
      "时间步 8050000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.182967e+01/ 轮得分 449.18\n",
      "损失函数： 0.0296779\n",
      "时间步 8051000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.380705e+01/ 轮得分 449.18\n",
      "损失函数： 0.0169468\n",
      "时间步 8052000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331769e+01/ 轮得分 449.18\n",
      "损失函数： 0.0245686\n",
      "时间步 8053000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352379e+01/ 轮得分 448.54\n",
      "损失函数： 0.0291583\n",
      "时间步 8054000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.293178e+01/ 轮得分 448.54\n",
      "损失函数： 0.022913\n",
      "时间步 8055000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.143745e+01/ 轮得分 448.54\n",
      "损失函数： 0.05251\n",
      "时间步 8056000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.140044e+01/ 轮得分 448.75\n",
      "损失函数： 0.0329111\n",
      "时间步 8057000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267980e+01/ 轮得分 448.75\n",
      "损失函数： 0.0784673\n",
      "时间步 8058000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.376372e+01/ 轮得分 448.65\n",
      "损失函数： 0.034428\n",
      "时间步 8059000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259457e+01/ 轮得分 448.65\n",
      "损失函数： 0.0147733\n",
      "时间步 8060000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177768e+01/ 轮得分 448.83\n",
      "损失函数： 0.0215476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 8061000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.441839e+01/ 轮得分 448.83\n",
      "损失函数： 0.0318726\n",
      "时间步 8062000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.294140e+01/ 轮得分 448.83\n",
      "损失函数： 0.0169519\n",
      "时间步 8063000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302291e+01/ 轮得分 448.83\n",
      "损失函数： 0.0152071\n",
      "时间步 8064000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.203962e+01/ 轮得分 448.83\n",
      "损失函数： 0.0190404\n",
      "时间步 8065000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.440968e+01/ 轮得分 448.83\n",
      "损失函数： 0.0315943\n",
      "时间步 8066000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396613e+01/ 轮得分 448.85\n",
      "损失函数： 0.0301328\n",
      "时间步 8067000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298885e+01/ 轮得分 448.74\n",
      "损失函数： 0.0336961\n",
      "时间步 8068000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383919e+01/ 轮得分 448.74\n",
      "损失函数： 0.03727\n",
      "时间步 8069000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.348746e+01/ 轮得分 448.24\n",
      "损失函数： 0.0170902\n",
      "时间步 8070000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259200e+01/ 轮得分 448.24\n",
      "损失函数： 0.0232358\n",
      "时间步 8071000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.262609e+01/ 轮得分 448.24\n",
      "损失函数： 0.0255707\n",
      "时间步 8072000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194874e+01/ 轮得分 448.24\n",
      "损失函数： 0.0275363\n",
      "时间步 8073000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.291632e+01/ 轮得分 448.24\n",
      "损失函数： 0.0281635\n",
      "时间步 8074000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275396e+01/ 轮得分 447.96\n",
      "损失函数： 0.0309375\n",
      "时间步 8075000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.274933e+01/ 轮得分 447.96\n",
      "损失函数： 0.0198924\n",
      "时间步 8076000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342322e+01/ 轮得分 447.96\n",
      "损失函数： 0.00820959\n",
      "时间步 8077000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.166494e+01/ 轮得分 447.96\n",
      "损失函数： 0.043674\n",
      "时间步 8078000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.397911e+01/ 轮得分 447.96\n",
      "损失函数： 0.0228568\n",
      "时间步 8079000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.442001e+01/ 轮得分 447.96\n",
      "损失函数： 0.0408201\n",
      "时间步 8080000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.215342e+01/ 轮得分 447.38\n",
      "损失函数： 0.0251695\n",
      "时间步 8081000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.306546e+01/ 轮得分 447.38\n",
      "损失函数： 0.0173502\n",
      "时间步 8082000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257785e+01/ 轮得分 447.38\n",
      "损失函数： 0.015933\n",
      "时间步 8083000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.276925e+01/ 轮得分 446.10\n",
      "损失函数： 0.0136894\n",
      "时间步 8084000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315964e+01/ 轮得分 446.10\n",
      "损失函数： 0.018897\n",
      "时间步 8085000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331335e+01/ 轮得分 446.10\n",
      "损失函数： 0.0306981\n",
      "时间步 8086000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269158e+01/ 轮得分 446.10\n",
      "损失函数： 0.0182704\n",
      "时间步 8087000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.133744e+01/ 轮得分 445.05\n",
      "损失函数： 0.0187782\n",
      "时间步 8088000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363184e+01/ 轮得分 445.05\n",
      "损失函数： 0.0480266\n",
      "时间步 8089000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.357777e+01/ 轮得分 445.05\n",
      "损失函数： 0.0323776\n",
      "时间步 8090000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268527e+01/ 轮得分 445.05\n",
      "损失函数： 0.0313878\n",
      "时间步 8091000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.313624e+01/ 轮得分 445.28\n",
      "损失函数： 0.0269512\n",
      "时间步 8092000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.167794e+01/ 轮得分 444.68\n",
      "损失函数： 0.031195\n",
      "时间步 8093000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181898e+01/ 轮得分 444.68\n",
      "损失函数： 0.012828\n",
      "时间步 8094000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.131249e+01/ 轮得分 444.68\n",
      "损失函数： 0.0356289\n",
      "时间步 8095000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377830e+01/ 轮得分 444.68\n",
      "损失函数： 0.0301229\n",
      "时间步 8096000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.216262e+01/ 轮得分 444.68\n",
      "损失函数： 0.0242859\n",
      "时间步 8097000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.309548e+01/ 轮得分 444.55\n",
      "损失函数： 0.0599825\n",
      "时间步 8098000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.308999e+01/ 轮得分 444.55\n",
      "损失函数： 0.0774713\n",
      "时间步 8099000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329583e+01/ 轮得分 444.55\n",
      "损失函数： 0.0207011\n",
      "时间步 8100000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314827e+01/ 轮得分 444.55\n",
      "损失函数： 0.0420926\n",
      "时间步 8101000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255674e+01/ 轮得分 444.55\n",
      "损失函数： 0.0341944\n",
      "时间步 8102000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393269e+01/ 轮得分 444.55\n",
      "损失函数： 0.0244742\n",
      "时间步 8103000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.217332e+01/ 轮得分 444.71\n",
      "损失函数： 0.0164484\n",
      "时间步 8104000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.433970e+01/ 轮得分 444.71\n",
      "损失函数： 0.0232557\n",
      "时间步 8105000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.263808e+01/ 轮得分 444.82\n",
      "损失函数： 0.00838671\n",
      "时间步 8106000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.428681e+01/ 轮得分 444.82\n",
      "损失函数： 0.0423554\n",
      "时间步 8107000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.254590e+01/ 轮得分 444.82\n",
      "损失函数： 0.0184572\n",
      "时间步 8108000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.167417e+01/ 轮得分 444.06\n",
      "损失函数： 0.0174913\n",
      "时间步 8109000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117739e+01/ 轮得分 444.06\n",
      "损失函数： 0.00720786\n",
      "时间步 8110000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226472e+01/ 轮得分 444.06\n",
      "损失函数： 0.0281716\n",
      "时间步 8111000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.220548e+01/ 轮得分 443.90\n",
      "损失函数： 0.118744\n",
      "时间步 8112000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239034e+01/ 轮得分 443.90\n",
      "损失函数： 0.0234459\n",
      "时间步 8113000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268614e+01/ 轮得分 443.60\n",
      "损失函数： 0.0264395\n",
      "时间步 8114000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.140844e+01/ 轮得分 442.57\n",
      "损失函数： 0.0567919\n",
      "时间步 8115000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285769e+01/ 轮得分 442.55\n",
      "损失函数： 0.0244893\n",
      "时间步 8116000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.090393e+01/ 轮得分 442.61\n",
      "损失函数： 0.0181184\n",
      "时间步 8117000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.497438e+01/ 轮得分 442.61\n",
      "损失函数： 0.0347388\n",
      "时间步 8118000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.358181e+01/ 轮得分 442.61\n",
      "损失函数： 0.014932\n",
      "时间步 8119000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.202068e+01/ 轮得分 442.61\n",
      "损失函数： 0.0531439\n",
      "时间步 8120000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.063297e+01/ 轮得分 442.61\n",
      "损失函数： 0.0442452\n",
      "时间步 8121000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.196005e+01/ 轮得分 442.61\n",
      "损失函数： 0.0462053\n",
      "时间步 8122000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357717e+01/ 轮得分 442.61\n",
      "损失函数： 0.0295373\n",
      "时间步 8123000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.290044e+01/ 轮得分 442.61\n",
      "损失函数： 0.0159281\n",
      "时间步 8124000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.092734e+01/ 轮得分 442.61\n",
      "损失函数： 0.0255957\n",
      "时间步 8125000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244777e+01/ 轮得分 442.61\n",
      "损失函数： 0.0161247\n",
      "时间步 8126000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.328113e+01/ 轮得分 442.61\n",
      "损失函数： 0.0694444\n",
      "时间步 8127000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.085153e+01/ 轮得分 442.96\n",
      "损失函数： 0.0212415\n",
      "时间步 8128000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.164505e+01/ 轮得分 442.96\n",
      "损失函数： 0.0324167\n",
      "时间步 8129000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.105527e+01/ 轮得分 442.96\n",
      "损失函数： 0.0243252\n",
      "时间步 8130000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 5.679866e+00/ 轮得分 442.96\n",
      "损失函数： 0.0366178\n",
      "时间步 8131000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.444186e+01/ 轮得分 442.97\n",
      "损失函数： 0.0280052\n",
      "时间步 8132000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295155e+01/ 轮得分 442.97\n",
      "损失函数： 0.0494625\n",
      "时间步 8133000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.204049e+01/ 轮得分 442.97\n",
      "损失函数： 0.0515076\n",
      "时间步 8134000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252802e+01/ 轮得分 442.97\n",
      "损失函数： 0.0811998\n",
      "时间步 8135000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317222e+01/ 轮得分 442.97\n",
      "损失函数： 0.0180663\n",
      "时间步 8136000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.425415e+01/ 轮得分 442.97\n",
      "损失函数： 0.0167332\n",
      "时间步 8137000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301084e+01/ 轮得分 442.97\n",
      "损失函数： 0.022543\n",
      "时间步 8138000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345122e+01/ 轮得分 442.97\n",
      "损失函数： 0.0243227\n",
      "时间步 8139000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277829e+01/ 轮得分 442.97\n",
      "损失函数： 0.0120167\n",
      "时间步 8140000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.496673e+01/ 轮得分 442.97\n",
      "损失函数： 0.0179076\n",
      "时间步 8141000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.247960e+01/ 轮得分 444.11\n",
      "损失函数： 0.0631056\n",
      "时间步 8142000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.469168e+01/ 轮得分 444.11\n",
      "损失函数： 0.0504344\n",
      "时间步 8143000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.246744e+01/ 轮得分 444.28\n",
      "损失函数： 0.0614159\n",
      "时间步 8144000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278736e+01/ 轮得分 444.28\n",
      "损失函数： 0.036858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 8145000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221073e+01/ 轮得分 444.28\n",
      "损失函数： 0.0490206\n",
      "时间步 8146000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.239692e+01/ 轮得分 444.28\n",
      "损失函数： 0.0493139\n",
      "时间步 8147000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.599106e+01/ 轮得分 443.26\n",
      "损失函数： 0.0223172\n",
      "时间步 8148000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180171e+01/ 轮得分 443.26\n",
      "损失函数： 0.0367385\n",
      "时间步 8149000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165480e+01/ 轮得分 443.26\n",
      "损失函数： 0.0452127\n",
      "时间步 8150000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.264192e+01/ 轮得分 443.26\n",
      "损失函数： 0.0126727\n",
      "时间步 8151000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224970e+01/ 轮得分 443.11\n",
      "损失函数： 0.110968\n",
      "时间步 8152000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.458752e+01/ 轮得分 443.11\n",
      "损失函数： 0.0351377\n",
      "时间步 8153000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.415519e+01/ 轮得分 443.11\n",
      "损失函数： 0.0119218\n",
      "时间步 8154000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.464993e+01/ 轮得分 443.11\n",
      "损失函数： 0.0143979\n",
      "时间步 8155000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.238224e+01/ 轮得分 443.11\n",
      "损失函数： 0.0480999\n",
      "时间步 8156000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.247642e+01/ 轮得分 443.11\n",
      "损失函数： 0.0298183\n",
      "时间步 8157000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355654e+01/ 轮得分 443.11\n",
      "损失函数： 0.0297658\n",
      "时间步 8158000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.319423e+01/ 轮得分 443.36\n",
      "损失函数： 0.0124174\n",
      "时间步 8159000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.174721e+01/ 轮得分 443.43\n",
      "损失函数： 0.0472044\n",
      "时间步 8160000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288757e+01/ 轮得分 443.43\n",
      "损失函数： 0.0272315\n",
      "时间步 8161000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.267407e+01/ 轮得分 443.43\n",
      "损失函数： 0.027856\n",
      "时间步 8162000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.314018e+01/ 轮得分 443.43\n",
      "损失函数： 0.0146777\n",
      "时间步 8163000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.421665e+01/ 轮得分 443.43\n",
      "损失函数： 0.0665696\n",
      "时间步 8164000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.320713e+01/ 轮得分 443.43\n",
      "损失函数： 0.0628995\n",
      "时间步 8165000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162260e+01/ 轮得分 443.99\n",
      "损失函数： 1.01408\n",
      "时间步 8166000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385283e+01/ 轮得分 443.99\n",
      "损失函数： 0.0693725\n",
      "时间步 8167000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384921e+01/ 轮得分 443.99\n",
      "损失函数： 0.0387889\n",
      "时间步 8168000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.191260e+01/ 轮得分 443.99\n",
      "损失函数： 0.0173474\n",
      "时间步 8169000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.406374e+01/ 轮得分 443.99\n",
      "损失函数： 0.0295341\n",
      "时间步 8170000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.419283e+01/ 轮得分 443.99\n",
      "损失函数： 0.0157891\n",
      "时间步 8171000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.146328e+01/ 轮得分 443.99\n",
      "损失函数： 0.0456331\n",
      "时间步 8172000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.371377e+01/ 轮得分 443.99\n",
      "损失函数： 0.0125324\n",
      "时间步 8173000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302936e+01/ 轮得分 444.68\n",
      "损失函数： 0.00934465\n",
      "时间步 8174000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.259860e+01/ 轮得分 444.68\n",
      "损失函数： 0.0240718\n",
      "时间步 8175000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.263225e+01/ 轮得分 443.73\n",
      "损失函数： 0.0263319\n",
      "时间步 8176000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.451269e+01/ 轮得分 443.73\n",
      "损失函数： 0.0288355\n",
      "时间步 8177000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.460571e+01/ 轮得分 443.73\n",
      "损失函数： 0.0152786\n",
      "时间步 8178000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.120078e+01/ 轮得分 443.73\n",
      "损失函数： 0.013409\n",
      "时间步 8179000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.132720e+01/ 轮得分 443.73\n",
      "损失函数： 0.00863981\n",
      "时间步 8180000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.299800e+01/ 轮得分 443.73\n",
      "损失函数： 0.0339514\n",
      "时间步 8181000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.373632e+01/ 轮得分 443.73\n",
      "损失函数： 0.0292455\n",
      "时间步 8182000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.178330e+01/ 轮得分 443.73\n",
      "损失函数： 0.0502858\n",
      "时间步 8183000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296287e+01/ 轮得分 443.73\n",
      "损失函数： 0.0220506\n",
      "时间步 8184000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.336772e+01/ 轮得分 443.73\n",
      "损失函数： 0.0272847\n",
      "时间步 8185000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.372541e+01/ 轮得分 444.75\n",
      "损失函数： 0.00943029\n",
      "时间步 8186000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268071e+01/ 轮得分 444.75\n",
      "损失函数： 0.0113717\n",
      "时间步 8187000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363874e+01/ 轮得分 444.75\n",
      "损失函数： 0.0856641\n",
      "时间步 8188000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251076e+01/ 轮得分 444.98\n",
      "损失函数： 0.00846002\n",
      "时间步 8189000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252957e+01/ 轮得分 444.56\n",
      "损失函数： 0.0471205\n",
      "时间步 8190000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.120893e+01/ 轮得分 444.23\n",
      "损失函数： 0.0132806\n",
      "时间步 8191000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.302499e+01/ 轮得分 444.23\n",
      "损失函数： 0.0383007\n",
      "时间步 8192000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.284332e+01/ 轮得分 444.23\n",
      "损失函数： 0.0481633\n",
      "时间步 8193000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.452160e+01/ 轮得分 444.29\n",
      "损失函数： 0.0208772\n",
      "时间步 8194000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.292192e+01/ 轮得分 444.29\n",
      "损失函数： 0.0188454\n",
      "时间步 8195000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.277882e+01/ 轮得分 444.29\n",
      "损失函数： 0.0257531\n",
      "时间步 8196000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212218e+01/ 轮得分 444.29\n",
      "损失函数： 0.0298671\n",
      "时间步 8197000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.209810e+01/ 轮得分 444.29\n",
      "损失函数： 0.0155785\n",
      "时间步 8198000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.398094e+01/ 轮得分 444.29\n",
      "损失函数： 0.0341063\n",
      "时间步 8199000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181541e+01/ 轮得分 444.97\n",
      "损失函数： 0.0521401\n",
      "时间步 8200000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207314e+01/ 轮得分 444.74\n",
      "损失函数： 0.0404458\n",
      "时间步 8201000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342330e+01/ 轮得分 444.60\n",
      "损失函数： 0.0494408\n",
      "时间步 8202000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.160007e+01/ 轮得分 444.60\n",
      "损失函数： 0.0545506\n",
      "时间步 8203000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273601e+01/ 轮得分 444.73\n",
      "损失函数： 0.0549162\n",
      "时间步 8204000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228363e+01/ 轮得分 444.73\n",
      "损失函数： 0.0201873\n",
      "时间步 8205000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.241473e+01/ 轮得分 444.88\n",
      "损失函数： 0.0688948\n",
      "时间步 8206000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.305940e+01/ 轮得分 444.88\n",
      "损失函数： 0.0396879\n",
      "时间步 8207000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.445756e+01/ 轮得分 445.08\n",
      "损失函数： 0.0272685\n",
      "时间步 8208000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.184583e+01/ 轮得分 445.08\n",
      "损失函数： 0.0166847\n",
      "时间步 8209000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.177004e+01/ 轮得分 445.08\n",
      "损失函数： 0.0209227\n",
      "时间步 8210000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.178713e+01/ 轮得分 445.08\n",
      "损失函数： 0.0255772\n",
      "时间步 8211000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.455531e+01/ 轮得分 445.08\n",
      "损失函数： 0.0728376\n",
      "时间步 8212000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.341143e+01/ 轮得分 445.08\n",
      "损失函数： 0.0309899\n",
      "时间步 8213000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.189068e+01/ 轮得分 445.08\n",
      "损失函数： 0.0389035\n",
      "时间步 8214000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.173293e+01/ 轮得分 445.08\n",
      "损失函数： 0.0131979\n",
      "时间步 8215000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321728e+01/ 轮得分 445.08\n",
      "损失函数： 0.0129114\n",
      "时间步 8216000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224519e+01/ 轮得分 445.08\n",
      "损失函数： 0.0699862\n",
      "时间步 8217000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271734e+01/ 轮得分 445.08\n",
      "损失函数： 0.0776574\n",
      "时间步 8218000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326971e+01/ 轮得分 445.08\n",
      "损失函数： 0.0350974\n",
      "时间步 8219000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384346e+01/ 轮得分 446.34\n",
      "损失函数： 0.0155508\n",
      "时间步 8220000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.271318e+01/ 轮得分 446.34\n",
      "损失函数： 0.0234599\n",
      "时间步 8221000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.277162e+01/ 轮得分 446.34\n",
      "损失函数： 0.030446\n",
      "时间步 8222000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.460433e+01/ 轮得分 446.34\n",
      "损失函数： 0.0256705\n",
      "时间步 8223000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.661366e+01/ 轮得分 446.34\n",
      "损失函数： 0.0210611\n",
      "时间步 8224000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.379619e+01/ 轮得分 446.61\n",
      "损失函数： 0.04665\n",
      "时间步 8225000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.158001e+01/ 轮得分 446.61\n",
      "损失函数： 0.0217778\n",
      "时间步 8226000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.554127e+01/ 轮得分 446.11\n",
      "损失函数： 0.128619\n",
      "时间步 8227000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.150518e+01/ 轮得分 446.06\n",
      "损失函数： 0.0627792\n",
      "时间步 8228000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.446004e+01/ 轮得分 446.06\n",
      "损失函数： 0.0816026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 8229000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.439928e+01/ 轮得分 446.06\n",
      "损失函数： 0.0375536\n",
      "时间步 8230000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321744e+01/ 轮得分 445.35\n",
      "损失函数： 0.0656617\n",
      "时间步 8231000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.226215e+01/ 轮得分 445.35\n",
      "损失函数： 0.0056465\n",
      "时间步 8232000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.262035e+01/ 轮得分 445.35\n",
      "损失函数： 0.0374684\n",
      "时间步 8233000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335661e+01/ 轮得分 445.35\n",
      "损失函数： 0.0243875\n",
      "时间步 8234000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.206079e+01/ 轮得分 445.12\n",
      "损失函数： 0.0265527\n",
      "时间步 8235000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.223653e+01/ 轮得分 445.12\n",
      "损失函数： 0.0268422\n",
      "时间步 8236000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284743e+01/ 轮得分 445.12\n",
      "损失函数： 0.0207967\n",
      "时间步 8237000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.114252e+01/ 轮得分 445.12\n",
      "损失函数： 0.0325642\n",
      "时间步 8238000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.213628e+01/ 轮得分 445.46\n",
      "损失函数： 0.0343947\n",
      "时间步 8239000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.255333e+01/ 轮得分 445.46\n",
      "损失函数： 0.0179967\n",
      "时间步 8240000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.239504e+01/ 轮得分 445.46\n",
      "损失函数： 0.0322268\n",
      "时间步 8241000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.484508e+01/ 轮得分 445.46\n",
      "损失函数： 0.0322521\n",
      "时间步 8242000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233077e+01/ 轮得分 445.46\n",
      "损失函数： 0.0295379\n",
      "时间步 8243000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.170089e+01/ 轮得分 445.46\n",
      "损失函数： 0.0282626\n",
      "时间步 8244000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228941e+01/ 轮得分 445.33\n",
      "损失函数： 0.0257842\n",
      "时间步 8245000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342538e+01/ 轮得分 445.33\n",
      "损失函数： 0.0202344\n",
      "时间步 8246000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.121576e+01/ 轮得分 445.37\n",
      "损失函数： 0.0367133\n",
      "时间步 8247000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.186843e+01/ 轮得分 445.33\n",
      "损失函数： 0.0388388\n",
      "时间步 8248000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.441733e+01/ 轮得分 445.33\n",
      "损失函数： 0.0420071\n",
      "时间步 8249000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.342087e+01/ 轮得分 445.33\n",
      "损失函数： 0.0148495\n",
      "时间步 8250000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.421144e+01/ 轮得分 445.31\n",
      "损失函数： 0.0211168\n",
      "时间步 8251000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.175628e+01/ 轮得分 445.31\n",
      "损失函数： 0.0318948\n",
      "时间步 8252000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.245677e+01/ 轮得分 445.30\n",
      "损失函数： 0.0253356\n",
      "时间步 8253000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.200250e+01/ 轮得分 445.04\n",
      "损失函数： 0.0634796\n",
      "时间步 8254000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.192677e+01/ 轮得分 444.96\n",
      "损失函数： 0.0141951\n",
      "时间步 8255000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 1.1/ Q_MAX 1.269941e+01/ 轮得分 444.96\n",
      "损失函数： 0.0315753\n",
      "时间步 8256000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.159522e+01/ 轮得分 444.96\n",
      "损失函数： 0.0584718\n",
      "时间步 8257000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257618e+01/ 轮得分 444.96\n",
      "损失函数： 0.0499766\n",
      "时间步 8258000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229881e+01/ 轮得分 444.96\n",
      "损失函数： 0.0195592\n",
      "时间步 8259000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.209880e+01/ 轮得分 444.18\n",
      "损失函数： 0.0167613\n",
      "时间步 8260000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.201194e+01/ 轮得分 444.18\n",
      "损失函数： 0.0674074\n",
      "时间步 8261000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.355124e+01/ 轮得分 444.18\n",
      "损失函数： 0.0213355\n",
      "时间步 8262000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351712e+01/ 轮得分 444.18\n",
      "损失函数： 0.0185369\n",
      "时间步 8263000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.139976e+01/ 轮得分 444.18\n",
      "损失函数： 0.0218295\n",
      "时间步 8264000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.114054e+01/ 轮得分 444.18\n",
      "损失函数： 0.060384\n",
      "时间步 8265000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.161825e+01/ 轮得分 444.18\n",
      "损失函数： 0.0576597\n",
      "时间步 8266000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.441269e+01/ 轮得分 444.18\n",
      "损失函数： 0.00735053\n",
      "时间步 8267000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205257e+01/ 轮得分 444.18\n",
      "损失函数： 0.0709738\n",
      "时间步 8268000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188976e+01/ 轮得分 444.18\n",
      "损失函数： 0.0205473\n",
      "时间步 8269000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.207581e+01/ 轮得分 444.18\n",
      "损失函数： 0.0199726\n",
      "时间步 8270000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.497061e+01/ 轮得分 444.18\n",
      "损失函数： 0.0187659\n",
      "时间步 8271000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388640e+01/ 轮得分 444.18\n",
      "损失函数： 0.0117192\n",
      "时间步 8272000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.381497e+01/ 轮得分 444.18\n",
      "损失函数： 0.0195944\n",
      "时间步 8273000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.386255e+01/ 轮得分 444.18\n",
      "损失函数： 0.0371695\n",
      "时间步 8274000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.407248e+01/ 轮得分 444.18\n",
      "损失函数： 0.015244\n",
      "时间步 8275000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.310241e+01/ 轮得分 444.18\n",
      "损失函数： 0.0367256\n",
      "时间步 8276000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.435373e+01/ 轮得分 444.18\n",
      "损失函数： 0.0183255\n",
      "时间步 8277000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.424599e+01/ 轮得分 444.18\n",
      "损失函数： 0.0385126\n",
      "时间步 8278000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303185e+01/ 轮得分 444.18\n",
      "损失函数： 0.013033\n",
      "时间步 8279000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.434361e+01/ 轮得分 445.14\n",
      "损失函数： 0.0234979\n",
      "时间步 8280000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.384630e+01/ 轮得分 445.14\n",
      "损失函数： 0.0457082\n",
      "时间步 8281000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.195544e+01/ 轮得分 445.23\n",
      "损失函数： 0.0218071\n",
      "时间步 8282000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301985e+01/ 轮得分 445.11\n",
      "损失函数： 0.0335623\n",
      "时间步 8283000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.244881e+01/ 轮得分 445.11\n",
      "损失函数： 0.0432249\n",
      "时间步 8284000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251420e+01/ 轮得分 445.11\n",
      "损失函数： 0.0231895\n",
      "时间步 8285000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.099713e+01/ 轮得分 445.11\n",
      "损失函数： 0.0223775\n",
      "时间步 8286000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.250708e+01/ 轮得分 445.11\n",
      "损失函数： 0.00741778\n",
      "时间步 8287000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 1.1/ Q_MAX 1.251085e+01/ 轮得分 445.11\n",
      "损失函数： 0.0139403\n",
      "时间步 8288000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.133277e+01/ 轮得分 445.57\n",
      "损失函数： 0.0112006\n",
      "时间步 8289000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248267e+01/ 轮得分 445.57\n",
      "损失函数： 0.0777788\n",
      "时间步 8290000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.128452e+01/ 轮得分 445.50\n",
      "损失函数： 0.0125293\n",
      "时间步 8291000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.389146e+01/ 轮得分 445.50\n",
      "损失函数： 0.020328\n",
      "时间步 8292000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.357066e+01/ 轮得分 445.50\n",
      "损失函数： 0.0177714\n",
      "时间步 8293000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.427666e+01/ 轮得分 445.50\n",
      "损失函数： 0.0320992\n",
      "时间步 8294000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.131531e+01/ 轮得分 445.50\n",
      "损失函数： 0.0093501\n",
      "时间步 8295000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.258578e+01/ 轮得分 445.50\n",
      "损失函数： 0.0275535\n",
      "时间步 8296000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272196e+01/ 轮得分 445.50\n",
      "损失函数： 0.0197389\n",
      "时间步 8297000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.275420e+01/ 轮得分 445.50\n",
      "损失函数： 0.0157896\n",
      "时间步 8298000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194825e+01/ 轮得分 445.50\n",
      "损失函数： 0.0236171\n",
      "时间步 8299000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225356e+01/ 轮得分 445.50\n",
      "损失函数： 0.0115986\n",
      "时间步 8300000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307879e+01/ 轮得分 445.50\n",
      "损失函数： 0.0208934\n",
      "时间步 8301000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.385223e+01/ 轮得分 445.50\n",
      "损失函数： 0.0169781\n",
      "时间步 8302000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.452870e+01/ 轮得分 445.50\n",
      "损失函数： 0.022245\n",
      "时间步 8303000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.390346e+01/ 轮得分 446.52\n",
      "损失函数： 0.0138658\n",
      "时间步 8304000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362062e+01/ 轮得分 445.81\n",
      "损失函数： 0.0465365\n",
      "时间步 8305000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.481858e+01/ 轮得分 445.82\n",
      "损失函数： 0.0137117\n",
      "时间步 8306000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.260103e+01/ 轮得分 445.82\n",
      "损失函数： 0.0190132\n",
      "时间步 8307000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.188405e+01/ 轮得分 445.82\n",
      "损失函数： 0.014473\n",
      "时间步 8308000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423403e+01/ 轮得分 445.43\n",
      "损失函数： 0.0244373\n",
      "时间步 8309000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352960e+01/ 轮得分 445.38\n",
      "损失函数： 0.0204382\n",
      "时间步 8310000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.168730e+01/ 轮得分 445.31\n",
      "损失函数： 0.0717818\n",
      "时间步 8311000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.273186e+01/ 轮得分 445.31\n",
      "损失函数： 0.0252206\n",
      "时间步 8312000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.383759e+01/ 轮得分 445.31\n",
      "损失函数： 0.0208541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 8313000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294928e+01/ 轮得分 445.31\n",
      "损失函数： 0.0756732\n",
      "时间步 8314000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272546e+01/ 轮得分 445.68\n",
      "损失函数： 0.013709\n",
      "时间步 8315000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272030e+01/ 轮得分 445.68\n",
      "损失函数： 0.0388904\n",
      "时间步 8316000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.037844e+01/ 轮得分 445.68\n",
      "损失函数： 0.0507094\n",
      "时间步 8317000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.331272e+01/ 轮得分 445.68\n",
      "损失函数： 0.0187611\n",
      "时间步 8318000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229025e+01/ 轮得分 445.68\n",
      "损失函数： 0.0380019\n",
      "时间步 8319000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.132611e+01/ 轮得分 446.05\n",
      "损失函数： 0.0626436\n",
      "时间步 8320000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266914e+01/ 轮得分 446.05\n",
      "损失函数： 0.0608519\n",
      "时间步 8321000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.347990e+01/ 轮得分 446.05\n",
      "损失函数： 0.0562615\n",
      "时间步 8322000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.268257e+01/ 轮得分 446.05\n",
      "损失函数： 0.0268996\n",
      "时间步 8323000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.225105e+01/ 轮得分 446.05\n",
      "损失函数： 0.0438783\n",
      "时间步 8324000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.404349e+01/ 轮得分 446.05\n",
      "损失函数： 0.0128334\n",
      "时间步 8325000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.362421e+01/ 轮得分 446.34\n",
      "损失函数： 0.0582903\n",
      "时间步 8326000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.445846e+01/ 轮得分 446.34\n",
      "损失函数： 0.0297903\n",
      "时间步 8327000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252763e+01/ 轮得分 446.34\n",
      "损失函数： 0.0477425\n",
      "时间步 8328000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.266784e+01/ 轮得分 446.07\n",
      "损失函数： 0.0578514\n",
      "时间步 8329000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.326941e+01/ 轮得分 446.07\n",
      "损失函数： 0.0915054\n",
      "时间步 8330000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.517866e+01/ 轮得分 446.07\n",
      "损失函数： 0.0552822\n",
      "时间步 8331000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396405e+01/ 轮得分 446.07\n",
      "损失函数： 0.0162127\n",
      "时间步 8332000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 1.1/ Q_MAX 1.325996e+01/ 轮得分 445.76\n",
      "损失函数： 0.048705\n",
      "时间步 8333000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327858e+01/ 轮得分 445.53\n",
      "损失函数： 0.0313785\n",
      "时间步 8334000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329589e+01/ 轮得分 445.53\n",
      "损失函数： 0.0183559\n",
      "时间步 8335000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.350339e+01/ 轮得分 445.53\n",
      "损失函数： 0.0489902\n",
      "时间步 8336000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.381564e+01/ 轮得分 445.80\n",
      "损失函数： 0.0170879\n",
      "时间步 8337000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.356086e+01/ 轮得分 445.80\n",
      "损失函数： 0.0852761\n",
      "时间步 8338000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.345005e+01/ 轮得分 445.80\n",
      "损失函数： 0.0276311\n",
      "时间步 8339000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181971e+01/ 轮得分 445.80\n",
      "损失函数： 0.0354776\n",
      "时间步 8340000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296578e+01/ 轮得分 445.80\n",
      "损失函数： 0.141143\n",
      "时间步 8341000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.194458e+01/ 轮得分 445.80\n",
      "损失函数： 0.0176325\n",
      "时间步 8342000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337325e+01/ 轮得分 445.80\n",
      "损失函数： 0.0239689\n",
      "时间步 8343000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.152432e+01/ 轮得分 446.37\n",
      "损失函数： 0.017959\n",
      "时间步 8344000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344423e+01/ 轮得分 446.37\n",
      "损失函数： 0.00830347\n",
      "时间步 8345000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.205315e+01/ 轮得分 446.37\n",
      "损失函数： 0.0179007\n",
      "时间步 8346000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.315453e+01/ 轮得分 446.37\n",
      "损失函数： 0.0251333\n",
      "时间步 8347000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.391522e+01/ 轮得分 446.39\n",
      "损失函数： 0.0181578\n",
      "时间步 8348000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.257235e+01/ 轮得分 446.39\n",
      "损失函数： 0.0458641\n",
      "时间步 8349000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.208820e+01/ 轮得分 445.92\n",
      "损失函数： 0.0327064\n",
      "时间步 8350000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.447758e+01/ 轮得分 445.92\n",
      "损失函数： 0.0154339\n",
      "时间步 8351000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.075148e+01/ 轮得分 445.92\n",
      "损失函数： 0.016526\n",
      "时间步 8352000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.379932e+01/ 轮得分 445.92\n",
      "损失函数： 0.0142346\n",
      "时间步 8353000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190975e+01/ 轮得分 445.92\n",
      "损失函数： 0.025688\n",
      "时间步 8354000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351925e+01/ 轮得分 445.92\n",
      "损失函数： 0.0189526\n",
      "时间步 8355000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.248759e+01/ 轮得分 446.18\n",
      "损失函数： 0.0518003\n",
      "时间步 8356000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.165943e+01/ 轮得分 446.19\n",
      "损失函数： 0.00963319\n",
      "时间步 8357000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.344052e+01/ 轮得分 446.19\n",
      "损失函数： 0.00973118\n",
      "时间步 8358000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.104007e+01/ 轮得分 445.80\n",
      "损失函数： 0.0153523\n",
      "时间步 8359000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.150653e+01/ 轮得分 445.40\n",
      "损失函数： 0.0741106\n",
      "时间步 8360000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.375488e+01/ 轮得分 445.40\n",
      "损失函数： 0.0298476\n",
      "时间步 8361000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.229161e+01/ 轮得分 445.40\n",
      "损失函数： 0.158121\n",
      "时间步 8362000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.323371e+01/ 轮得分 445.40\n",
      "损失函数： 0.0302038\n",
      "时间步 8363000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.321711e+01/ 轮得分 445.40\n",
      "损失函数： 0.0194901\n",
      "时间步 8364000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294210e+01/ 轮得分 445.78\n",
      "损失函数： 0.0182646\n",
      "时间步 8365000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.139063e+01/ 轮得分 445.78\n",
      "损失函数： 0.0237098\n",
      "时间步 8366000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.337360e+01/ 轮得分 445.78\n",
      "损失函数： 0.0459581\n",
      "时间步 8367000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.204186e+01/ 轮得分 445.78\n",
      "损失函数： 0.0558042\n",
      "时间步 8368000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.124936e+01/ 轮得分 445.78\n",
      "损失函数： 0.0143906\n",
      "时间步 8369000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117536e+01/ 轮得分 445.65\n",
      "损失函数： 0.00655748\n",
      "时间步 8370000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.330702e+01/ 轮得分 445.65\n",
      "损失函数： 0.0379406\n",
      "时间步 8371000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.351923e+01/ 轮得分 445.65\n",
      "损失函数： 0.042202\n",
      "时间步 8372000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.288557e+01/ 轮得分 445.63\n",
      "损失函数： 0.020865\n",
      "时间步 8373000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.437438e+01/ 轮得分 445.63\n",
      "损失函数： 0.0105576\n",
      "时间步 8374000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.237011e+01/ 轮得分 445.93\n",
      "损失函数： 0.0489196\n",
      "时间步 8375000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307259e+01/ 轮得分 445.93\n",
      "损失函数： 0.0190278\n",
      "时间步 8376000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296864e+01/ 轮得分 445.93\n",
      "损失函数： 0.0386165\n",
      "时间步 8377000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.419381e+01/ 轮得分 445.52\n",
      "损失函数： 0.0399428\n",
      "时间步 8378000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.408183e+01/ 轮得分 445.25\n",
      "损失函数： 0.0431994\n",
      "时间步 8379000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.363081e+01/ 轮得分 445.25\n",
      "损失函数： 0.0646924\n",
      "时间步 8380000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.224325e+01/ 轮得分 445.25\n",
      "损失函数： 0.00582537\n",
      "时间步 8381000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.411590e+01/ 轮得分 445.25\n",
      "损失函数： 0.0334838\n",
      "时间步 8382000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.318180e+01/ 轮得分 445.73\n",
      "损失函数： 0.0179862\n",
      "时间步 8383000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.285120e+01/ 轮得分 445.73\n",
      "损失函数： 0.0204794\n",
      "时间步 8384000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.109758e+01/ 轮得分 445.73\n",
      "损失函数： 0.095462\n",
      "时间步 8385000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.233614e+01/ 轮得分 445.92\n",
      "损失函数： 0.0538449\n",
      "时间步 8386000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.145315e+01/ 轮得分 445.92\n",
      "损失函数： 0.0142202\n",
      "时间步 8387000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.117307e+01/ 轮得分 445.92\n",
      "损失函数： 0.0253445\n",
      "时间步 8388000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.253195e+01/ 轮得分 445.92\n",
      "损失函数： 0.0264544\n",
      "时间步 8389000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.461869e+01/ 轮得分 446.40\n",
      "损失函数： 0.0142894\n",
      "时间步 8390000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.179101e+01/ 轮得分 446.40\n",
      "损失函数： 0.019469\n",
      "时间步 8391000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.421385e+01/ 轮得分 446.40\n",
      "损失函数： 0.0234232\n",
      "时间步 8392000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303170e+01/ 轮得分 446.40\n",
      "损失函数： 0.0575635\n",
      "时间步 8393000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.082442e+01/ 轮得分 446.40\n",
      "损失函数： 0.0281657\n",
      "时间步 8394000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190168e+01/ 轮得分 446.32\n",
      "损失函数： 0.02336\n",
      "时间步 8395000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.335428e+01/ 轮得分 446.32\n",
      "损失函数： 0.0548722\n",
      "时间步 8396000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.304371e+01/ 轮得分 446.32\n",
      "损失函数： 0.0382591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 8397000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.396830e+01/ 轮得分 446.32\n",
      "损失函数： 0.0186819\n",
      "时间步 8398000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.307060e+01/ 轮得分 446.32\n",
      "损失函数： 0.0342656\n",
      "时间步 8399000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.423028e+01/ 轮得分 446.32\n",
      "损失函数： 0.0457408\n",
      "时间步 8400000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235588e+01/ 轮得分 446.32\n",
      "损失函数： 0.0222342\n",
      "时间步 8401000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.271147e+01/ 轮得分 446.32\n",
      "损失函数： 0.0334115\n",
      "时间步 8402000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.228147e+01/ 轮得分 446.32\n",
      "损失函数： 0.0397942\n",
      "时间步 8403000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.282128e+01/ 轮得分 446.32\n",
      "损失函数： 0.0469836\n",
      "时间步 8404000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329106e+01/ 轮得分 446.32\n",
      "损失函数： 0.0532065\n",
      "时间步 8405000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.329662e+01/ 轮得分 446.32\n",
      "损失函数： 0.011729\n",
      "时间步 8406000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.295697e+01/ 轮得分 447.06\n",
      "损失函数： 0.013919\n",
      "时间步 8407000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.379900e+01/ 轮得分 447.06\n",
      "损失函数： 0.0290138\n",
      "时间步 8408000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242534e+01/ 轮得分 447.06\n",
      "损失函数： 0.0202158\n",
      "时间步 8409000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.430811e+01/ 轮得分 447.06\n",
      "损失函数： 0.0153229\n",
      "时间步 8410000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.471591e+01/ 轮得分 447.06\n",
      "损失函数： 0.0254602\n",
      "时间步 8411000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221950e+01/ 轮得分 447.06\n",
      "损失函数： 0.0206085\n",
      "时间步 8412000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.388644e+01/ 轮得分 446.14\n",
      "损失函数： 0.0471704\n",
      "时间步 8413000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.193176e+01/ 轮得分 446.14\n",
      "损失函数： 0.01641\n",
      "时间步 8414000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.079319e+01/ 轮得分 446.36\n",
      "损失函数： 0.0397599\n",
      "时间步 8415000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352838e+01/ 轮得分 446.36\n",
      "损失函数： 0.0416038\n",
      "时间步 8416000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.539905e+01/ 轮得分 446.24\n",
      "损失函数： 0.0153446\n",
      "时间步 8417000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.284984e+01/ 轮得分 446.24\n",
      "损失函数： 0.0304832\n",
      "时间步 8418000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.209843e+01/ 轮得分 446.24\n",
      "损失函数： 0.0132974\n",
      "时间步 8419000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.367778e+01/ 轮得分 446.24\n",
      "损失函数： 0.0287696\n",
      "时间步 8420000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.544515e+01/ 轮得分 445.16\n",
      "损失函数： 0.0217738\n",
      "时间步 8421000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.346151e+01/ 轮得分 445.16\n",
      "损失函数： 0.0102887\n",
      "时间步 8422000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.327601e+01/ 轮得分 445.16\n",
      "损失函数： 0.0197278\n",
      "时间步 8423000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.301457e+01/ 轮得分 445.29\n",
      "损失函数： 0.0342048\n",
      "时间步 8424000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.301849e+01/ 轮得分 445.26\n",
      "损失函数： 0.00978395\n",
      "时间步 8425000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.115156e+01/ 轮得分 445.20\n",
      "损失函数： 0.0250446\n",
      "时间步 8426000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.341147e+01/ 轮得分 445.20\n",
      "损失函数： 0.0245381\n",
      "时间步 8427000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.477882e+01/ 轮得分 445.20\n",
      "损失函数： 0.0358017\n",
      "时间步 8428000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.146083e+01/ 轮得分 445.20\n",
      "损失函数： 0.0231938\n",
      "时间步 8429000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.284999e+01/ 轮得分 445.20\n",
      "损失函数： 0.108353\n",
      "时间步 8430000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.374922e+01/ 轮得分 445.20\n",
      "损失函数： 0.0199697\n",
      "时间步 8431000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.360861e+01/ 轮得分 445.10\n",
      "损失函数： 0.0594635\n",
      "时间步 8432000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.303701e+01/ 轮得分 444.82\n",
      "损失函数： 0.0235699\n",
      "时间步 8433000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.294424e+01/ 轮得分 444.82\n",
      "损失函数： 0.0540526\n",
      "时间步 8434000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212091e+01/ 轮得分 444.82\n",
      "损失函数： 0.00841995\n",
      "时间步 8435000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.162699e+01/ 轮得分 444.82\n",
      "损失函数： 0.0780853\n",
      "时间步 8436000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.368132e+01/ 轮得分 444.82\n",
      "损失函数： 0.0251115\n",
      "时间步 8437000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.115282e+01/ 轮得分 444.82\n",
      "损失函数： 0.0184428\n",
      "时间步 8438000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.211327e+01/ 轮得分 445.04\n",
      "损失函数： 0.0180437\n",
      "时间步 8439000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.242321e+01/ 轮得分 445.04\n",
      "损失函数： 0.043057\n",
      "时间步 8440000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.438155e+01/ 轮得分 445.19\n",
      "损失函数： 0.071639\n",
      "时间步 8441000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.222726e+01/ 轮得分 445.27\n",
      "损失函数： 0.0484902\n",
      "时间步 8442000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.169217e+01/ 轮得分 445.30\n",
      "损失函数： 0.0458163\n",
      "时间步 8443000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.197793e+01/ 轮得分 445.30\n",
      "损失函数： 0.0339394\n",
      "时间步 8444000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 9.983875e+00/ 轮得分 445.30\n",
      "损失函数： 0.0373196\n",
      "时间步 8445000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.278792e+01/ 轮得分 445.30\n",
      "损失函数： 0.106936\n",
      "时间步 8446000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.244568e+01/ 轮得分 445.61\n",
      "损失函数： 0.0893305\n",
      "时间步 8447000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.435579e+01/ 轮得分 445.61\n",
      "损失函数： 0.0609879\n",
      "时间步 8448000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.207348e+01/ 轮得分 445.61\n",
      "损失函数： 0.0183606\n",
      "时间步 8449000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293288e+01/ 轮得分 445.61\n",
      "损失函数： 0.0390883\n",
      "时间步 8450000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.317066e+01/ 轮得分 445.92\n",
      "损失函数： 0.0585631\n",
      "时间步 8451000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.279768e+01/ 轮得分 445.92\n",
      "损失函数： 0.00729555\n",
      "时间步 8452000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.313363e+01/ 轮得分 446.01\n",
      "损失函数： 0.0488372\n",
      "时间步 8453000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.521708e+01/ 轮得分 446.01\n",
      "损失函数： 0.0367152\n",
      "时间步 8454000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.469679e+01/ 轮得分 446.01\n",
      "损失函数： 0.0316355\n",
      "时间步 8455000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.413757e+01/ 轮得分 446.24\n",
      "损失函数： 0.0129655\n",
      "时间步 8456000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.269779e+01/ 轮得分 446.24\n",
      "损失函数： 0.0188302\n",
      "时间步 8457000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.352193e+01/ 轮得分 446.22\n",
      "损失函数： 0.0547437\n",
      "时间步 8458000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.219979e+01/ 轮得分 446.22\n",
      "损失函数： 0.0206311\n",
      "时间步 8459000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.197880e+01/ 轮得分 446.22\n",
      "损失函数： 0.057793\n",
      "时间步 8460000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393731e+01/ 轮得分 446.22\n",
      "损失函数： 0.0189498\n",
      "时间步 8461000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.190036e+01/ 轮得分 446.22\n",
      "损失函数： 0.0244566\n",
      "时间步 8462000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.460345e+01/ 轮得分 446.22\n",
      "损失函数： 0.0422244\n",
      "时间步 8463000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.468724e+01/ 轮得分 446.22\n",
      "损失函数： 0.035553\n",
      "时间步 8464000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.298061e+01/ 轮得分 446.22\n",
      "损失函数： 0.0100208\n",
      "时间步 8465000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.296684e+01/ 轮得分 446.22\n",
      "损失函数： 0.103943\n",
      "时间步 8466000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377739e+01/ 轮得分 446.83\n",
      "损失函数： 0.078676\n",
      "时间步 8467000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.252578e+01/ 轮得分 446.83\n",
      "损失函数： 0.0197564\n",
      "时间步 8468000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.235644e+01/ 轮得分 446.83\n",
      "损失函数： 0.0275154\n",
      "时间步 8469000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.394631e+01/ 轮得分 446.82\n",
      "损失函数： 0.0236345\n",
      "时间步 8470000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.167825e+01/ 轮得分 446.82\n",
      "损失函数： 0.0856581\n",
      "时间步 8471000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.333205e+01/ 轮得分 446.82\n",
      "损失函数： 0.0503916\n",
      "时间步 8472000/ 状态 train/ Epsilon 0.00/ 行动 2/ 奖励 0.1/ Q_MAX 1.261692e+01/ 轮得分 447.09\n",
      "损失函数： 0.0293773\n",
      "时间步 8473000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.221585e+01/ 轮得分 447.09\n",
      "损失函数： 0.146545\n",
      "时间步 8474000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.251540e+01/ 轮得分 447.09\n",
      "损失函数： 0.0224536\n",
      "时间步 8475000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.414285e+01/ 轮得分 447.09\n",
      "损失函数： 0.0154706\n",
      "时间步 8476000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.322469e+01/ 轮得分 447.09\n",
      "损失函数： 0.0129983\n",
      "时间步 8477000/ 状态 train/ Epsilon 0.00/ 行动 1/ 奖励 0.1/ Q_MAX 1.244364e+01/ 轮得分 447.32\n",
      "损失函数： 0.0115017\n",
      "时间步 8478000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.180927e+01/ 轮得分 447.17\n",
      "损失函数： 0.0121675\n",
      "时间步 8479000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.300147e+01/ 轮得分 447.26\n",
      "损失函数： 0.0110282\n",
      "时间步 8480000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.181561e+01/ 轮得分 447.26\n",
      "损失函数： 0.091273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 8481000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.408702e+01/ 轮得分 447.26\n",
      "损失函数： 0.0561699\n",
      "时间步 8482000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.014893e+01/ 轮得分 447.26\n",
      "损失函数： 0.0148712\n",
      "时间步 8483000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.293924e+01/ 轮得分 447.45\n",
      "损失函数： 0.0235055\n",
      "时间步 8484000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.167108e+01/ 轮得分 447.21\n",
      "损失函数： 0.022948\n",
      "时间步 8485000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.316842e+01/ 轮得分 447.21\n",
      "损失函数： 0.0358363\n",
      "时间步 8486000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.286606e+01/ 轮得分 447.21\n",
      "损失函数： 0.0268682\n",
      "时间步 8487000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.463191e+01/ 轮得分 447.21\n",
      "损失函数： 0.015153\n",
      "时间步 8488000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.272605e+01/ 轮得分 447.21\n",
      "损失函数： 0.0386806\n",
      "时间步 8489000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.297719e+01/ 轮得分 447.17\n",
      "损失函数： 0.0498415\n",
      "时间步 8490000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.557994e+01/ 轮得分 447.17\n",
      "损失函数： 0.0180429\n",
      "时间步 8491000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.456245e+01/ 轮得分 447.17\n",
      "损失函数： 0.0739674\n",
      "时间步 8492000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.279671e+01/ 轮得分 447.17\n",
      "损失函数： 0.0546758\n",
      "时间步 8493000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.377842e+01/ 轮得分 447.17\n",
      "损失函数： 0.0199554\n",
      "时间步 8494000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.366251e+01/ 轮得分 447.17\n",
      "损失函数： 0.0382874\n",
      "时间步 8495000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.443300e+01/ 轮得分 447.26\n",
      "损失函数： 0.0282493\n",
      "时间步 8496000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.289102e+01/ 轮得分 447.26\n",
      "损失函数： 0.0161213\n",
      "时间步 8497000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.454518e+01/ 轮得分 447.26\n",
      "损失函数： 0.0519417\n",
      "时间步 8498000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.365994e+01/ 轮得分 447.26\n",
      "损失函数： 0.0651163\n",
      "时间步 8499000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.183984e+01/ 轮得分 447.76\n",
      "损失函数： 0.0384072\n",
      "时间步 8500000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 5.642570e+00/ 轮得分 445.94\n",
      "损失函数： 0.0609833\n",
      "时间步 8501000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.212711e+01/ 轮得分 445.56\n",
      "损失函数： 0.0494998\n",
      "时间步 8502000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.471507e+01/ 轮得分 445.56\n",
      "损失函数： 0.0178268\n",
      "时间步 8503000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.393179e+01/ 轮得分 445.56\n",
      "损失函数： 0.0230526\n",
      "时间步 8504000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.240397e+01/ 轮得分 445.56\n",
      "损失函数： 0.0356343\n",
      "时间步 8505000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.140701e+01/ 轮得分 445.56\n",
      "损失函数： 0.016645\n",
      "时间步 8506000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.234935e+01/ 轮得分 445.56\n",
      "损失函数： 0.0316043\n",
      "时间步 8507000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.423994e+01/ 轮得分 445.56\n",
      "损失函数： 0.0181476\n",
      "时间步 8508000/ 状态 train/ Epsilon 0.00/ 行动 0/ 奖励 0.1/ Q_MAX 1.134195e+01/ 轮得分 445.56\n",
      "损失函数： 0.0227462\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1bd9afaf3dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_j_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 设置初始的epsilon（采取随机行动的概率），并准备训练\n",
    "epsilon = INITIAL_EPSILON\n",
    "t = 0\n",
    "\n",
    "# 记录每轮平均得分的容器\n",
    "scores = []\n",
    "all_turn_scores = []\n",
    "while \"plane survival\" != \"angry bird\":\n",
    "    # 开始游戏循环\n",
    "    ######################################################\n",
    "    ##########首先，按照贪婪策略选择一个行动 ##################\n",
    "    s = Variable(torch.from_numpy(s_t).type(torch.FloatTensor))\n",
    "    s = s.cuda() if use_cuda else s\n",
    "    s = s.view(-1, s.size()[0], s.size()[1], s.size()[2])\n",
    "    # 获取当前时刻的游戏画面，输入到神经网络中\n",
    "    readout, h_fc1 = net(s)\n",
    "    # 神经网络产生的输出为readout：选择每一个行动的预期Q值\n",
    "    readout = readout.cpu() if use_cuda else readout\n",
    "    # readout为一个二维向量，分别对应每一个动作的预期Q值\n",
    "    readout_t = readout.data.numpy()[0]\n",
    "\n",
    "    # 按照epsilon贪婪策略产生小鸟的行动，即以epsilon的概率随机输出行动或者以\n",
    "    # 1-epsilon的概率按照预期输出最大的Q值给出行动\n",
    "    a_t = np.zeros([ACTIONS])\n",
    "    action_index = 0\n",
    "    action_index_old = action_index\n",
    "    if t % FRAME_PER_ACTION == 0:\n",
    "        # 如果当前帧可以行动，则\n",
    "        if random.random() <= epsilon:\n",
    "            # 产生随机行动\n",
    "            #print(\"----------Random Action----------\")\n",
    "            if random.random() < 0.6:\n",
    "                action_index = action_index_old\n",
    "            else:\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                action_index_old = action_index\n",
    "        else:\n",
    "            # 选择神经网络判断的预期Q最大的行动\n",
    "            action_index = np.argmax(readout_t)\n",
    "            action_index_old = action_index\n",
    "            \n",
    "        a_t[action_index] = 1\n",
    "    else:\n",
    "        a_t[0] = 1 # do nothing\n",
    "\n",
    "    # 模拟退火：让epsilon开始降低\n",
    "    if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "    ######################################################################### \n",
    "    ##########其次，将选择好的行动输入给游戏引擎，并得到下一帧的状态 ################### \n",
    "    x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "    # 返回的x_t1_colored为游戏画面，r_t为本轮的得分，terminal为游戏在本轮是否已经结束\n",
    "    \n",
    "    # 记录一下每一步的成绩\n",
    "    scores.append(r_t)\n",
    "    if terminal:\n",
    "        # 当游戏结束的时候，计算一下本轮的总成绩，并将总成绩存储到all_turn_scores中\n",
    "        all_turn_scores.append(sum(scores))\n",
    "        scores = []\n",
    "    \n",
    "    # 对游戏的原始画面做相应的处理，从而变成一张80*80的，朴素的（无背景画面）的图\n",
    "    x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY)\n",
    "    x_t1 = np.reshape(x_t1, (1, 80, 80))\n",
    "    # 将当前帧的画面和前三帧的画面合并起来作为Agent获得的环境反馈结果\n",
    "    s_t1 = np.append(x_t1, s_t[:3, :, :], axis=0)\n",
    "    # 生成一个训练数据，分别将本帧的输入画面s_t,本帧的行动a_t，得到的环境回报r_t以及环境被转换的新状态s_t1存到D中\n",
    "    D.append((s_t, a_t, r_t, s_t1, terminal))\n",
    "    if len(D) > REPLAY_MEMORY:\n",
    "        # 如果D中的元素已满，则扔掉最老的一条训练数据\n",
    "        D.popleft()\n",
    "\n",
    "    ######################################################################### \n",
    "    ##########最后，当运行周期超过一定次数后开始训练神经网络 ################### \n",
    "    if t > OBSERVE:\n",
    "        # 从D中随机采样出一个batch的训练数据\n",
    "        minibatch = random.sample(D, BATCH)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 将这个batch中的s变量都分别存放到列表中\n",
    "        s_j_batch = [d[0] for d in minibatch]\n",
    "        a_batch = [d[1] for d in minibatch]\n",
    "        r_batch = [d[2] for d in minibatch]\n",
    "        s_j1_batch = [d[3] for d in minibatch]\n",
    "\n",
    "        # 接下来，要根据s_j1_batch，神经网络给出预估的未来Q值\n",
    "        \n",
    "        s = Variable(torch.FloatTensor(np.array(s_j1_batch, dtype=float)))\n",
    "        s = s.cuda() if use_cuda else s\n",
    "        readout, h_fc1 = net(s)\n",
    "        readout = readout.cpu() if use_cuda else readout\n",
    "        readout_j1_batch = readout.data.numpy()\n",
    "        # readout_j1_batch存储了一个minibatch中的所有未来一步的Q预估值\n",
    "        # 根据Q的预估值，当前的反馈r，以及游戏是否结束，更新待训练的目标函数值\n",
    "        y_batch = []\n",
    "        for i in range(0, len(minibatch)):\n",
    "            terminal = minibatch[i][4]\n",
    "            # 当游戏结束的时候，则用环境的反馈作为目标，否则用下一状态的Q值＋本期的环境反馈\n",
    "            if terminal:\n",
    "                y_batch.append(r_batch[i])\n",
    "            else:\n",
    "                y_batch.append(r_batch[i] + GAMMA * np.max(readout_j1_batch[i]))\n",
    "\n",
    "        # 开始梯度更新\n",
    "        y = Variable(torch.FloatTensor(y_batch))\n",
    "        a = Variable(torch.FloatTensor(a_batch))\n",
    "        s = Variable(torch.FloatTensor(np.array(s_j_batch, dtype=float)))\n",
    "        if use_cuda:\n",
    "            y = y.cuda()\n",
    "            a = a.cuda()\n",
    "            s = s.cuda()\n",
    "        # 计算s_j_batch的Q值\n",
    "        readout, h_fc1 = net(s)\n",
    "        readout_action = readout.mul(a).sum(1)\n",
    "        # 根据s_j_batch下所选择的预估Q和目标y的Q值的差来作为损失函数训练网络\n",
    "        loss = criterion(readout_action, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if t % 1000 == 0:\n",
    "            print('损失函数：', loss.cpu().data.numpy()[0])\n",
    "       \n",
    "\n",
    "    # 将状态更新一次，时间步＋1\n",
    "    s_t = s_t1\n",
    "    t += 1\n",
    "\n",
    "    # 每隔 10000 次循环，存储一下网络\n",
    "    if t % 10000 == 0:\n",
    "        torch.save(net, 'saving_nets/' + GAME + '-dqn' + str(t) + '.txt')\n",
    "    \n",
    "    # 状态信息的转化，基本分为Observe，explore和train三个阶段\n",
    "    # Observe没有训练，explore开始训练，并且开始模拟退火，train模拟退火结束\n",
    "    state = \"\"\n",
    "    if t <= OBSERVE:\n",
    "        state = \"observe\"\n",
    "    elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "        state = \"explore\"\n",
    "    else:\n",
    "        state = \"train\"\n",
    "        \n",
    "    # 打印当前运行的一些基本数据，分别输出到屏幕以及log文件中\n",
    "    if t % 1000 == 0:\n",
    "        sss = \"时间步 {}/ 状态 {}/ Epsilon {:.2f}/ 行动 {}/ 奖励 {}/ Q_MAX {:e}/ 轮得分 {:.2f}\".format(\n",
    "            t, state, epsilon, action_index, r_t, np.max(readout_t), np.mean(all_turn_scores[-1000:]))\n",
    "        print(sss)\n",
    "        f = open('log_file.txt', 'a')\n",
    "        f.write(sss + '\\n')\n",
    "        f.close()\n",
    "    # write info to files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f970edddc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open('log_file.txt', 'r')\n",
    "line = f.read().strip().split('\\n')\n",
    "values = []\n",
    "for ln in line:\n",
    "    segs = ln.split('/')\n",
    "    values.append(float(segs[-1].split(' ')[-1]))\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(values))*1000, values)\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Average Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net = torch.load('saving_nets/' + GAME + '-dqn' + str(2876000) + '.txt')\n",
    "net = torch.load('bird-dqn8500000-Copy1.txt')\n",
    "FINAL_EPSILON = 0.0000 # epsilon的最终值\n",
    "BATCH = 32 # 每一个批次的数据记录条数\n",
    "FRAME_PER_ACTION = 1 # 每间隔多少时间完成一次有效动作的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f970ed766a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 开始在内存／GPU上定义一个网络\n",
    "use_cuda = torch.cuda.is_available() #检测本台机器中是否有GPU\n",
    "\n",
    "# 如果有GPU，就把神经网络全部搬到GPU内存中做运算\n",
    "net = net.cuda() if use_cuda else net\n",
    "\n",
    "# 开启一个游戏进程，开始与游戏引擎通话\n",
    "game_state = GameState()\n",
    "\n",
    "# 状态打印log记录位置\n",
    "#a_file = open(\"logs_\" + GAME + \"/readout.txt\", 'w')\n",
    "#h_file = open(\"logs_\" + GAME + \"/hidden.txt\", 'w')\n",
    "\n",
    "# 将游戏设置为初始状态，并获得一个80*80的游戏湖面\n",
    "do_nothing = np.zeros(ACTIONS)\n",
    "do_nothing[0] = 1\n",
    "x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "x_t = cv2.cvtColor(cv2.resize(x_t, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# 将初始的游戏画面叠加成4张作为神经网络的初始输入状态s_t\n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=0)\n",
    "\n",
    "# 设置初始的epsilon（采取随机行动的概率），并准备训练\n",
    "epsilon = FINAL_EPSILON\n",
    "t = 0# 记录每轮平均得分的容器\n",
    "scores = []\n",
    "all_turn_scores = []\n",
    "\n",
    "fig = plt.figure()\n",
    "axe = fig.add_subplot(111)\n",
    "dat = np.zeros((10, 10))\n",
    "img = axe.imshow(dat)\n",
    "\n",
    "i = 0\n",
    "while \"flappy bird\" != \"angry bird\":\n",
    "    i += 1\n",
    "    # 开始游戏循环\n",
    "    ######################################################\n",
    "    ##########首先，按照贪婪策略选择一个行动 ##################\n",
    "    s = Variable(torch.from_numpy(s_t).type(torch.FloatTensor))\n",
    "    s = s.cuda() if use_cuda else s\n",
    "    s = s.view(-1, s.size()[0], s.size()[1], s.size()[2])\n",
    "    # 获取当前时刻的游戏画面，输入到神经网络中\n",
    "    readout, h_fc1 = net(s)\n",
    "    # 神经网络产生的输出为readout：选择每一个行动的预期Q值\n",
    "    readout = readout.cpu() if use_cuda else readout\n",
    "    # readout为一个二维向量，分别对应每一个动作的预期Q值\n",
    "    readout_t = readout.data.numpy()[0]\n",
    "\n",
    "    # 按照epsilon贪婪策略产生小鸟的行动，即以epsilon的概率随机输出行动或者以\n",
    "    # 1-epsilon的概率按照预期输出最大的Q值给出行动\n",
    "    a_t = np.zeros([ACTIONS])\n",
    "    action_index = 0\n",
    "    if t % FRAME_PER_ACTION == 0:\n",
    "        # 如果当前帧可以行动，则\n",
    "        if random.random() <= epsilon:\n",
    "            # 产生随机行动\n",
    "            #print(\"----------Random Action----------\")\n",
    "            action_index = random.randrange(ACTIONS)\n",
    "        else:\n",
    "            # 选择神经网络判断的预期Q最大的行动\n",
    "            action_index = np.argmax(readout_t)\n",
    "        a_t[action_index] = 1\n",
    "    else:\n",
    "        a_t[0] = 1 # do nothing\n",
    "    ######################################################################### \n",
    "    ##########其次，将选择好的行动输入给游戏引擎，并得到下一帧的状态 ################### \n",
    "    x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "    # 返回的x_t1_colored为游戏画面，r_t为本轮的得分，terminal为游戏在本轮是否已经结束\n",
    "    \n",
    "    # 记录一下每一步的成绩\n",
    "    scores.append(r_t)\n",
    "    if terminal:\n",
    "        # 当游戏结束的时候，计算一下本轮的总成绩，并将总成绩存储到all_turn_scores中\n",
    "        all_turn_scores.append(sum(scores))\n",
    "        scores = []\n",
    "    \n",
    "    # 对游戏的原始画面做相应的处理，从而变成一张80*80的，朴素的（无背景画面）的图\n",
    "    x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY)\n",
    "    x_t1 = np.reshape(x_t1, (1, 80, 80))\n",
    "    # 将当前帧的画面和前三帧的画面合并起来作为Agent获得的环境反馈结果\n",
    "    s_t1 = np.append(x_t1, s_t[:3, :, :], axis=0)\n",
    "    s_t = s_t1\n",
    "    t += 1\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    image = np.transpose(x_t1_colored, (1, 0, 2))\n",
    "    img.set_data(image)\n",
    "    img.autoscale()\n",
    "    display(fig)\n",
    "    \n",
    "    if i > 500:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
