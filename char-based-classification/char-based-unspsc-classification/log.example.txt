Using TensorFlow backend.
Loading data...
Creating vocab...
Chars vocab: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '!', '"', '#', '$', '%', '&', "'", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\', ']', '^', '_', '`', '{', '|', '}', '~', '\n', ' ']
Chars vocab size: 70
X_train.shape: (64757, 200)
Build model...
Fit model...
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 200)               0
_________________________________________________________________
lambda_1 (Lambda)            (None, 200, 70)           0
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 200, 128)          89728
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 100, 128)          0
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 100, 256)          229632
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 50, 256)           0
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 50, 512)           393728
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 50, 512)           786944
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 25, 512)           0
_________________________________________________________________
flatten_1 (Flatten)          (None, 12800)             0
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              13108224
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024)              0
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              1049600
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0
_________________________________________________________________
output (Dense)               (None, 1007)              1032175
=================================================================
Total params: 16,690,031
Trainable params: 16,690,031
Non-trainable params: 0
_________________________________________________________________
Train on 64757 samples, validate on 27754 samples
Epoch 1/10
2018-01-21 20:17:37.208036: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-21 20:17:37.208054: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-21 20:17:37.208059: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-21 20:17:37.208062: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-21 20:17:37.208065: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-01-21 20:17:37.301244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-01-21 20:17:37.301536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:01:00.0
Total memory: 10.91GiB
Free memory: 9.77GiB
2018-01-21 20:17:37.301548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
2018-01-21 20:17:37.301551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
2018-01-21 20:17:37.301557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)
64757/64757 [==============================] - 27s - loss: 14.4680 - acc: 0.1011 - val_loss: 14.4868 - val_acc: 0.1012
Epoch 2/10
64757/64757 [==============================] - 25s - loss: 14.4868 - acc: 0.1012 - val_loss: 14.4868 - val_acc: 0.1012
Epoch 3/10
64757/64757 [==============================] - 25s - loss: 14.4868 - acc: 0.1012 - val_loss: 14.4868 - val_acc: 0.1012
Epoch 4/10
64757/64757 [==============================] - 24s - loss: 14.4868 - acc: 0.1012 - val_loss: 14.4868 - val_acc: 0.1012
Epoch 5/10
64757/64757 [==============================] - 25s - loss: 14.4868 - acc: 0.1012 - val_loss: 14.4868 - val_acc: 0.1012
Epoch 6/10
64757/64757 [==============================] - 26s - loss: 14.4868 - acc: 0.1012 - val_loss: 14.4868 - val_acc: 0.1012
Epoch 7/10
64757/64757 [==============================] - 25s - loss: 14.4868 - acc: 0.1012 - val_loss: 14.4868 - val_acc: 0.1012
Epoch 8/10
64757/64757 [==============================] - 25s - loss: 14.4868 - acc: 0.1012 - val_loss: 14.4868 - val_acc: 0.1012
Epoch 9/10
64757/64757 [==============================] - 25s - loss: 14.4868 - acc: 0.1012 - val_loss: 14.4868 - val_acc: 0.1012
Epoch 10/10
64757/64757 [==============================] - 25s - loss: 14.4868 - acc: 0.1012 - val_loss: 14.4868 - val_acc: 0.1012
